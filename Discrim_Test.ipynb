{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Discrim_Test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5v3qXT5f2eTS"},"source":["import tensorflow as tf\r\n","import keras\r\n","import math\r\n","import numpy as np\r\n","from tensorflow.keras import layers\r\n","from keras.models import Sequential\r\n","from keras.layers import Conv1D, LeakyReLU, Dense\r\n","import numpy as np\r\n","import time\r\n","import argparse\r\n","!pip install livelossplot --quiet\r\n","%matplotlib inline\r\n","\r\n","from time import sleep\r\n","import numpy as np\r\n","\r\n","from livelossplot import PlotLosses\r\n","from google.colab import drive\r\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dkCPuKbK-Sqw"},"source":["import numpy as np\n","from numpy.linalg import norm\n","import matplotlib.pylab  as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","def rand_rotation_matrix(deflection=1.0, seed=None):\n","    '''Creates a random rotation matrix.\n","    deflection: the magnitude of the rotation. For 0, no rotation; for 1, completely random\n","    rotation. Small deflection => small perturbation.\n","    DOI: http://www.realtimerendering.com/resources/GraphicsGems/gemsiii/rand_rotation.c\n","         http://blog.lostinmyterminal.com/python/2015/05/12/random-rotation-matrix.html\n","    '''\n","    if seed is not None:\n","        np.random.seed(seed)\n","\n","    randnums = np.random.uniform(size=(3,))\n","\n","    theta, phi, z = randnums\n","\n","    theta = theta * 2.0 * deflection * np.pi    # Rotation about the pole (Z).\n","    phi = phi * 2.0 * np.pi     # For direction of pole deflection.\n","    z = z * 2.0 * deflection    # For magnitude of pole deflection.\n","\n","    # Compute a vector V used for distributing points over the sphere\n","    # via the reflection I - V Transpose(V).  This formulation of V\n","    # will guarantee that if x[1] and x[2] are uniformly distributed,\n","    # the reflected points will be uniform on the sphere.  Note that V\n","    # has length sqrt(2) to eliminate the 2 in the Householder matrix.\n","\n","    r = np.sqrt(z)\n","    V = (\n","        np.sin(phi) * r,\n","        np.cos(phi) * r,\n","        np.sqrt(2.0 - z))\n","\n","    st = np.sin(theta)\n","    ct = np.cos(theta)\n","\n","    R = np.array(((ct, st, 0), (-st, ct, 0), (0, 0, 1)))\n","\n","    # Construct the rotation matrix  ( V Transpose(V) - I ) R.\n","    M = (np.outer(V, V) - np.eye(3)).dot(R)\n","    return M\n","\n","\n","def iterate_in_chunks(l, n):\n","    '''Yield successive 'n'-sized chunks from iterable 'l'.\n","    Note: last chunk will be smaller than l if n doesn't divide l perfectly.\n","    '''\n","    for i in range(0, len(l), n):\n","        yield l[i:i + n]\n","\n","        \n","def add_gaussian_noise_to_pcloud(pcloud, mu=0, sigma=1):\n","    gnoise = np.random.normal(mu, sigma, pcloud.shape[0])\n","    gnoise = np.tile(gnoise, (3, 1)).T\n","    pcloud += gnoise\n","    return pcloud\n","\n","\n","def apply_augmentations(batch, conf):\n","    if conf.gauss_augment is not None or conf.z_rotate:\n","        batch = batch.copy()\n","\n","    if conf.gauss_augment is not None:\n","        mu = conf.gauss_augment['mu']\n","        sigma = conf.gauss_augment['sigma']\n","        batch += np.random.normal(mu, sigma, batch.shape)\n","\n","    if conf.z_rotate:\n","        r_rotation = rand_rotation_matrix()\n","        r_rotation[0, 2] = 0\n","        r_rotation[2, 0] = 0\n","        r_rotation[1, 2] = 0\n","        r_rotation[2, 1] = 0\n","        r_rotation[2, 2] = 1\n","        batch = batch.dot(r_rotation)\n","    return batch\n","\n","\n","def unit_cube_grid_point_cloud(resolution, clip_sphere=False):\n","    '''Returns the center coordinates of each cell of a 3D grid with resolution^3 cells,\n","    that is placed in the unit-cube.\n","    If clip_sphere it True it drops the \"corner\" cells that lie outside the unit-sphere.\n","    '''\n","    grid = np.ndarray((resolution, resolution, resolution, 3), np.float32)\n","    spacing = 1.0 / float(resolution - 1)\n","    for i in range(resolution):\n","        for j in range(resolution):\n","            for k in range(resolution):\n","                grid[i, j, k, 0] = i * spacing - 0.5\n","                grid[i, j, k, 1] = j * spacing - 0.5\n","                grid[i, j, k, 2] = k * spacing - 0.5\n","\n","    if clip_sphere:\n","        grid = grid.reshape(-1, 3)\n","        grid = grid[norm(grid, axis=1) <= 0.5]\n","\n","    return grid, spacing\n","\n","def plot_3d_point_cloud(x, y, z, show=True, show_axis=True, in_u_sphere=False, marker='.', s=8, alpha=.8, figsize=(5, 5), elev=10, azim=240, axis=None, title=None, *args, **kwargs):\n","\n","    if axis is None:\n","        fig = plt.figure(figsize=figsize)\n","        ax = fig.add_subplot(111, projection='3d')        \n","    else:\n","        ax = axis\n","        fig = axis\n","\n","    if title is not None:\n","        plt.title(title)\n","\n","    sc = ax.scatter(x, y, z, marker=marker, s=s, alpha=alpha, *args, **kwargs)\n","    ax.view_init(elev=elev, azim=azim)\n","\n","    if in_u_sphere:\n","        ax.set_xlim3d(-0.5, 0.5)\n","        ax.set_ylim3d(-0.5, 0.5)\n","        ax.set_zlim3d(-0.5, 0.5)\n","    else:\n","        miv = 0.7 * np.min([np.min(x), np.min(y), np.min(z)])  # Multiply with 0.7 to squeeze free-space.\n","        mav = 0.7 * np.max([np.max(x), np.max(y), np.max(z)])\n","        ax.set_xlim(miv, mav)\n","        ax.set_ylim(miv, mav)\n","        ax.set_zlim(miv, mav)\n","        plt.tight_layout()\n","\n","    if not show_axis:\n","        plt.axis('off')\n","\n","    if 'c' in kwargs:\n","        plt.colorbar(sc)\n","\n","    if show:\n","        plt.show()\n","\n","    return fig\n","\n","import tensorflow as tf\n","import numpy as np\n","import warnings\n","\n","from scipy.stats import entropy\n","\n","try:\n","    from sklearn.neighbors import NearestNeighbors\n","except:\n","    print ('Sklearn module not installed (JSD metric will not work).')\n","\n","try:    \n","    from .. external.structural_losses.tf_nndistance import nn_distance\n","    from .. external.structural_losses.tf_approxmatch import approx_match, match_cost\n","except:\n","    print('External Losses (Chamfer-EMD) cannot be loaded. Please install them first.')\n","\n","def jsd_between_point_cloud_sets(sample_pcs, ref_pcs, resolution=28):\n","    '''Computes the JSD between two sets of point-clouds, as introduced in the paper ```Learning Representations And Generative Models For 3D Point Clouds```.    \n","    Args:\n","        sample_pcs: (np.ndarray S1xR2x3) S1 point-clouds, each of R1 points.\n","        ref_pcs: (np.ndarray S2xR2x3) S2 point-clouds, each of R2 points.\n","        resolution: (int) grid-resolution. Affects granularity of measurements.\n","    '''   \n","    in_unit_sphere = True\n","    sample_grid_var = entropy_of_occupancy_grid(sample_pcs, resolution, in_unit_sphere)[1]\n","    ref_grid_var = entropy_of_occupancy_grid(ref_pcs, resolution, in_unit_sphere)[1]\n","    return jensen_shannon_divergence(sample_grid_var, ref_grid_var)\n","    \n","def entropy_of_occupancy_grid(pclouds, grid_resolution, in_sphere=False):\n","    '''Given a collection of point-clouds, estimate the entropy of the random variables\n","    corresponding to occupancy-grid activation patterns.\n","    Inputs:\n","        pclouds: (numpy array) #point-clouds x points per point-cloud x 3\n","        grid_resolution (int) size of occupancy grid that will be used.\n","    '''\n","    epsilon = 10e-4\n","    bound = 0.5 + epsilon\n","    if abs(np.max(pclouds)) > bound or abs(np.min(pclouds)) > bound:\n","        warnings.warn('Point-clouds are not in unit cube.')\n","\n","    if in_sphere and np.max(np.sqrt(np.sum(pclouds ** 2, axis=2))) > bound:\n","        warnings.warn('Point-clouds are not in unit sphere.')\n","\n","    grid_coordinates, _ = unit_cube_grid_point_cloud(grid_resolution, in_sphere)\n","    grid_coordinates = grid_coordinates.reshape(-1, 3)\n","    grid_counters = np.zeros(len(grid_coordinates))\n","    grid_bernoulli_rvars = np.zeros(len(grid_coordinates))\n","    nn = NearestNeighbors(n_neighbors=1).fit(grid_coordinates)\n","\n","    for pc in pclouds:\n","        _, indices = nn.kneighbors(pc)\n","        indices = np.squeeze(indices)\n","        for i in indices:\n","            grid_counters[i] += 1\n","        indices = np.unique(indices)\n","        for i in indices:\n","            grid_bernoulli_rvars[i] += 1\n","\n","    acc_entropy = 0.0\n","    n = float(len(pclouds))\n","    for g in grid_bernoulli_rvars:\n","        p = 0.0\n","        if g > 0:\n","            p = float(g) / n\n","            acc_entropy += entropy([p, 1.0 - p])\n","\n","    return acc_entropy / len(grid_counters), grid_counters\n","\n","\n","def jensen_shannon_divergence(P, Q):\n","    if np.any(P < 0) or np.any(Q < 0):\n","        raise ValueError('Negative values.')\n","    if len(P) != len(Q):\n","        raise ValueError('Non equal size.')\n","\n","    P_ = P / np.sum(P)      # Ensure probabilities.\n","    Q_ = Q / np.sum(Q)\n","\n","    e1 = entropy(P_, base=2)\n","    e2 = entropy(Q_, base=2)\n","    e_sum = entropy((P_ + Q_) / 2.0, base=2)\n","    res = e_sum - ((e1 + e2) / 2.0)\n","\n","    res2 = _jsdiv(P_, Q_)\n","\n","    if not np.allclose(res, res2, atol=10e-5, rtol=0):\n","        warnings.warn('Numerical values of two JSD methods don\\'t agree.')\n","\n","    return res\n","    \n","def _jsdiv(P, Q):\n","    '''another way of computing JSD'''\n","    def _kldiv(A, B):\n","        a = A.copy()\n","        b = B.copy()\n","        idx = np.logical_and(a > 0, b > 0)\n","        a = a[idx]\n","        b = b[idx]\n","        return np.sum([v for v in a * np.log2(a / b)])\n","\n","    P_ = P / np.sum(P)\n","    Q_ = Q / np.sum(Q)\n","\n","    M = 0.5 * (P_ + Q_)\n","\n","    return 0.5 * (_kldiv(P_, M) + _kldiv(Q_, M))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvAaTEVbhHzF"},"source":["class Arguments:\n","  def __init__(self):\n","    self._parser = argparse.ArgumentParser(description='Arguments for TreeGAN.')\n","\n","    # Datatset arguements\n","    self._parser.add_argument('--batch_size', type=int, default=1, help='Integer value for batch size.')\n","    self._parser.add_argument('--point_num', type=int, default=3072, help='Integer value for number of points.')\n","    self._parser.add_argument('--latent_dim', type=int, default=96, help='Integer value for latent vector dimension')\n","    # Training arguments\n","    self._parser.add_argument('--epochs', type=int, default=5, help='Integer value for epochs')\n","    self._parser.add_argument('--lr', type=float, default=1e-4, help='Float value for learning rate')\n","    # Add checkpoint saving arguments\n","    self._parser.add_argument('--save_rate', type=int, default=10, help='Model is saved every epoch multiple of this value')\n","    self._parser.add_argument('--save_d_ckpt', type=str, default='save_checkpoint_path', help='Save location for checkpoints') # Discriminator save checkpoint path\n","    self._parser.add_argument('--load_d_ckpt', type=str, default='load_checkpoint_path', help='Load location for checkpoints') # Discriminator load checkpoint path\n","    self._parser.add_argument('--save_g_ckpt', type=str, default='save_checkpoint_path', help='Save location for checkpoints') # Generator save checkpoint path\n","    self._parser.add_argument('--load_g_ckpt', type=str, default='load_checkpoint_path', help='Load location for checkpoints') # Generator load checkpoint path\n","\n","    #visualization args\n","    self._parser.add_argument('--visdom_port', type=int, default=8097, help='Visdom port number. (default:8097)')\n","    self._parser.add_argument('--visdom_color', type=int, default=4, help='Number of colors for visdom pointcloud visualization. (default:4)')  \n","    \n","    #Network arguments\n","    self._parser.add_argument('--lamdaGP', type=int, default=10, help='Lambda for GP term')\n","    self._parser.add_argument('--D_iter', type=int, default=5, help='Number of training iterations for discriminator')\n","    self._parser.add_argument('--support', type=int, default=10, help='Support term value for TreeGCN loop term')\n","    self._parser.add_argument('--DEGREE', type=int, default=[1, 2, 2, 3, 2, 2, 64], nargs='+', help='Upsample degrees for generator')\n","    self._parser.add_argument('--G_FEAT', type=int, default=[96, 256, 256, 256, 128, 128, 128, 3], nargs='+', help='Features for generator')\n","    self._parser.add_argument('--D_FEAT', type=int, default=[3, 64, 128, 256, 512, 1024], nargs='+', help='Features for discriminator')\n","\n","  def parser(self):\n","    return self._parser"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDW5kXv5tcN0"},"source":["class real_args:\r\n","  def __init__(self):\r\n","    self.batch_size=1\r\n","    self.point_num=3072\r\n","    self.latent_dim=96\r\n","    # Training arguments\r\n","    self.epochs=5\r\n","    self.lr=1e-4\r\n","    # Add checkpoint saving arguments\r\n","    self.save_rate=2\r\n","    self.save_d_ckpt = '/content/drive/MyDrive/Qmind Object Completion Team/TreeGAN/Discriminator_Ckpt/'\r\n","    self.load_d_ckpt='/content/drive/MyDrive/Qmind Object Completion Team/TreeGAN/Discriminator_Ckpt/disc4.h5'\r\n","    self.save_g_ckpt='/content/drive/MyDrive/Qmind Object Completion Team/TreeGAN/Generator_Ckpt/'\r\n","    self.load_g_ckpt='/content/drive/MyDrive/Qmind Object Completion Team/TreeGAN/Generator_Ckpt/gen4.h5'\r\n","\r\n","    #visualization args\r\n","    self.visdom_port=8097\r\n","    self.visdom_color=4 \r\n","    \r\n","    #Network arguments\r\n","    self.lambdaGP=10\r\n","    self.D_iter=5\r\n","    self.support=10\r\n","    self.DEGREES=[1, 2, 2, 3, 2, 2, 64]\r\n","    self.G_FEAT=[96, 256, 256, 256, 128, 128, 128, 3]\r\n","    self.D_FEAT=[3, 64, 128, 256, 512, 1024]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oq1LsZVR13kG"},"source":["class TreeGCN(keras.layers.Layer):\r\n","  def __init__(self, batch, depth, features, degrees, support=10, node=1, upsample=False, activation=True, kernel_initializer='glorot_uniform', debug_print=True):\r\n","    self.print = debug_print\r\n","    self.batch = batch\r\n","    self.depth = depth\r\n","    self.features = features\r\n","    self.in_feature = features[depth]\r\n","    self.out_feature = features[depth+1]\r\n","    self.node = node\r\n","    self.degree = degrees[depth]\r\n","    self.upsample = upsample\r\n","    self.activation = activation \r\n","    super(TreeGCN, self).__init__()\r\n","\r\n","    #Need to create a list of submodules similar to nn.ModuleList\r\n","    #This is certainly creating an accessible array of layers, not sure if it has the same dependencies\r\n","    # self.W_root = Sequential()\r\n","    self.W_root = [Sequential(layers=Dense(self.out_feature, input_dim=features[index], use_bias=False)) for index in range(self.depth + 1)]\r\n","    # for index in range(self.depth + 1):\r\n","    # self.W_root.add(Dense(self.out_feature, input_dim=features[index], use_bias=False))\r\n","    # self.W_root.add(Dense(self.features[index + 1], input_dim=features[index], use_bias=False))\r\n","    \r\n","    # if self.print: print(\"printing root network\")\r\n","    # for layer in self.W_root:\r\n","    #   print(\"W ROOT AT DEPTH \",self.depth, layer.summary())\r\n","    \r\n","    #Declare the loop, which has two linear layers (Dense in keras) with no bias and this input shape\r\n","    self.W_loop = Sequential()\r\n","    self.W_loop.add(Dense(self.in_feature*support, input_dim=self.in_feature, use_bias=False))\r\n","    self.W_loop.add(Dense(self.out_feature , use_bias=False)) \r\n","    \r\n","    # if self.print: print(\"printing loop network\")\r\n","    print(\"W LOOP AT DEPTH \",self.depth, self.W_loop.summary())\r\n","\r\n","    # def build_branch(self):\r\n","    def build_branch():\r\n","      if self.upsample:\r\n","        kernel_initializer = tf.keras.initializers.glorot_uniform()\r\n","        self.branch_input_shape = (self.node, self.in_feature, self.in_feature * self.degree,)\r\n","        self.W_branch = self.add_weight(name = 'branch' + str(depth),\r\n","                    shape=self.branch_input_shape,\r\n","                    initializer= kernel_initializer,\r\n","                    trainable= True)\r\n","        # if self.print: print(\"printing w_branch --- \" * 3)\r\n","        # if self.print: print(self.W_branch)\r\n","\r\n","      stdv =  1. / math.sqrt(self.out_feature)\r\n","      bias_initializer = tf.keras.initializers.RandomUniform(minval=-stdv, maxval=stdv)\r\n","      self.bias = self.add_weight(name= 'bias' + str(depth),\r\n","                    shape= (1, self.degree, self.out_feature),\r\n","                    initializer= bias_initializer,\r\n","                    trainable=True) \r\n","      # gain -> relu used here in original code\r\n","      # print(\"W_BRANCH AT DEPTH \", self.depth, self.W_branch)\r\n","      # print(\"bias \", self.bias)\r\n","\r\n","\r\n","    self.leaky_relu = LeakyReLU(alpha=0.2)\r\n","    build_branch()\r\n","\r\n","  def build(self,inputShape):\r\n","        super(TreeGCN,self).build(inputShape)\r\n","\r\n","  def call(self, tree):\r\n","    root = 0\r\n","    # if self.print: print(\"CALLING \" * 4)\r\n","    for inx in range(self.depth+1):\r\n","      if self.print: print(inx)\r\n","      if self.print: print(\"Tree INDEX: \", inx, self.depth)\r\n","      if self.print: print(tree[inx])\r\n","      root_num = tree[inx].shape[1] # obtains number of roots in layer\r\n","      repeat_num = int(self.node / root_num) # all nodes / nodes in curr tree\r\n","      if self.print: print(\"PRINTING ROOT_NUM, REPEAT_NUM\")\r\n","      if self.print: print(root_num, repeat_num)\r\n","      # if self.print: print(\"W_root Summary:\", self.W_root[inx].summary())\r\n","      root_node = self.W_root[inx](tree[inx]) # applies tree at inx into layer inx and returns matrix of size: out_features * (depth + 1)\r\n","      if self.print: print(\"Root Node\")\r\n","      if self.print: print(root_node)\r\n","      if self.print: print(tf.shape(root_node))\r\n","      # taking the output from W_root network\r\n","      # temp = tf.tile(root_node,tf.constant([1, 1, repeat_num], tf.int32)) # having problems with this****************\r\n","      temp = tf.tile(root_node, (1,1, repeat_num,)) # having problems with this****************\r\n","      # if self.print: print(\"Here\")\r\n","      if self.print: print(\"TEMP AFTER TILE\")\r\n","      if self.print: print(temp)\r\n","      # if self.print: print(f\"Shaping temp from {temp.shape} to {str((self.batch, -1, self.out_feature,))}\")\r\n","      temp = tf.reshape(temp, (self.batch, -1, self.out_feature,))\r\n","      root = root + temp\r\n","      if self.print: print(\"ROOT\")\r\n","      if self.print: print(root)\r\n","    # if self.print: print(\"LOOP FINISHED\")\r\n","    branch = 0\r\n","    if self.upsample:\r\n","      # if self.print: print(\" before_\" * 4)\r\n","      # if self.print: print(self.W_branch)\r\n","      # if self.print: print(\"EXPAND DIMS\")\r\n","      # if self.print: print(tree[-1])\r\n","      # if self.print: print(\"Tree shape before expand dims\", tree)\r\n","      if self.print: print(\"W_BRANCH\")\r\n","      if self.print: print(self.W_branch)\r\n","      branch = tf.expand_dims(tree[-1], axis=2) @ self.W_branch # This is matrix multiplication between the first and second one\r\n","      if self.print: print(\"branch shape after EXPAND DIMS\", branch)\r\n","      # if self.print: print(\"-\" * 50)\r\n","      # if self.print: print(self.W_branch)\r\n","      branch = self.leaky_relu(branch)\r\n","      # branch = branch.reshape(self.batch, self.node*self.degree, self.in_feature)\r\n","      branch = tf.reshape(branch, (self.batch, self.node*self.degree, self.in_feature,))\r\n","      if self.print: print(\"BRANCH AFTER RESHAPE\")\r\n","      if self.print: print(branch)\r\n","      branch = self.W_loop(branch)\r\n","      if self.print: print(\"Branch W_loop call\")\r\n","      if self.print: print(branch)\r\n","      temp = tf.tile(root,(1,1, self.degree,))\r\n","      branch = tf.reshape(temp, (self.batch, -1, self.out_feature,)) + branch\r\n","      if self.print: print(\"BRANCH AFTER RE TILE\")\r\n","      if self.print: print(branch)\r\n","    else:\r\n","      if self.print: print(\"no upsample\")\r\n","      branch = self.W_loop(tree[-1])\r\n","      branch = root + branch\r\n","\r\n","    if self.activation:\r\n","      branch = self.leaky_relu(branch + tf.tile(self.bias, (1, self.node, 1,)))\r\n","    # if self.print: print(\"BRANCH\" * 4)\r\n","    # if self.print: print(branch)\r\n","    # if self.print: print(\"printing tree type\")\r\n","    # if self.print: print(type(tree))\r\n","    # tree.append(branch)\r\n","    # return tf.experimental.numpy.append(tree, branch)\r\n","    # temp = tf.ragged.stack([tree, tf.reshape(branch, (1, -1, -1, -1))], axis=0) #This solves the issue but idk if stack does what we want it to\r\n","    # temp = tf.concat([tree, tf.reshape(branch, (1, -1, -1, -1))], axis=0)\r\n","    # temp =  tf.concat([tf.RaggedTensor.from_tensor(tree), tf.reshape(branch, (1, -1,-1,-1 ))], axis=0)\r\n","    # temp1 = tf.RaggedTensor.from_tensor(tree)\r\n","    # temp2 = tf.reshape(branch, (1, -1, -1, -1))\r\n","    # temp2 = tf.RaggedTensor.from_tensor(temp2)\r\n","    # temp = tf.concat([[temp1], [temp2]], axis=0)\r\n","    # temp = [np.append([tree], [branch])]\r\n","    # temp = tf.stack(tree, branch)\r\n","    # temp = [tree, branch]\r\n","    # if self.print: print(\"\\nTREE TREE TREE\")\r\n","    # if self.print: print(temp)\r\n","  \r\n","    # if self.print: print(np.shape(temp)) # What they are doing is creating a list of tensors in the original thing, we need to try and replicate that (just a common numpy array of type tensor)\r\n","    # if self.print: print(\"DONE\" * 4)\r\n","\r\n","\r\n","\r\n","    # testing new method\r\n","    ret = []\r\n","    for layer in tree:\r\n","      ret.append(layer)\r\n","    ret.append(branch)\r\n","    # if self.print: print(\"PRINTING OUTPUT\")\r\n","    # if self.print: print(\"PRINTING TREE\", ret)\r\n","    return ret\r\n","\r\n","  ''' THIS IS NOT TESTED AN MAY NOT BE CORRECT'''\r\n","  def compute_output_shape(self,inputShape):\r\n","    out_shape = []\r\n","    for i in range(self.depth + 1):\r\n","      out_shape.append((self.degrees[i], features[i])) # double check this\r\n","    return out_shape\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U75NJSD32HQb"},"source":["class Generator(keras.models.Model):\r\n","    def __init__(self, batch_size, features, degrees, support, debug_print=False):\r\n","        self.print = debug_print\r\n","        self.batch_size = batch_size\r\n","        self.layer_num = len(features)-1\r\n","        self.degrees = degrees\r\n","        self.features = features\r\n","        self.support = support\r\n","        assert self.layer_num == len(degrees), \"Number of features should be one more than number of degrees.\"\r\n","        self.pointcloud = None\r\n","        super(Generator, self).__init__()\r\n","                \r\n","        vertex_num = 1\r\n","        # self.gcn = Sequential()\r\n","        # self.gcn = keras.Model()\r\n","        self.input_layer = keras.Input(shape=(1,1,96,))\r\n","        layer = self.input_layer\r\n","        for inx in range(self.layer_num):\r\n","          print(f\"layer num : {str(inx)}\")\r\n","          if inx == self.layer_num-1:\r\n","            layer = TreeGCN(self.batch_size, inx, self.features, self.degrees, support=self.support, node=vertex_num, upsample=True, activation=False, debug_print=self.print)(layer)\r\n","          else:\r\n","            layer = TreeGCN(self.batch_size, inx, self.features, self.degrees, support=self.support, node=vertex_num, upsample=True, activation=True, debug_print=self.print)(layer)\r\n","          print(\"LAYER \", inx, layer)\r\n","          vertex_num = int(vertex_num * degrees[inx])\r\n","\r\n","        self.gcn = keras.Model(self.input_layer, layer, name='TreeGCN')\r\n","        # self.out = self.call([self.input_layer])\r\n","\r\n","    def call(self, tree):\r\n","        # print(self.gcn.summary())\r\n","        feat = self.gcn(tree)\r\n","        # print(feat)\r\n","        \r\n","        self.pointcloud = feat[-1]\r\n","\r\n","        return self.pointcloud\r\n","\r\n","    def model(self):\r\n","      x = Input(shape=(1,1,96))\r\n","      return Model(inputs=[x], outputs=self.call(x))\r\n","\r\n","    def getPointcloud(self):\r\n","        return self.pointcloud[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yc-4gMx62HTc"},"source":["# TODO(Noah): Can play around with the discriminator architecture\r\n","class Discriminator(tf.keras.Model):\r\n","  # MAYBE INHERIT LAYER\r\n","    \r\n","    def __init__(self, batch_size, features):\r\n","        \r\n","        self.batch_size = batch_size\r\n","        self.layer_num = len(features)-1\r\n","        # super(KerasDiscriminator, self).__init__()\r\n","        super(Discriminator, self).__init__()\r\n","        \r\n","        self.fc_layers = []\r\n","        for inx in range(self.layer_num):\r\n","            # self.fc_layers.append(tf.keras.layers.Conv1D( filters=features[inx+1], kernel_size=1, stride=1 ))\r\n","            self.fc_layers.append(tf.keras.layers.Conv1D( filters=features[inx+1], kernel_size=1, strides=1 ))\r\n","\r\n","            \r\n","        self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\r\n","    \r\n","        self.final_layer = keras.Sequential()\r\n","        self.final_layer.add(tf.keras.layers.Dense(features[-1]))\r\n","        self.final_layer.add(tf.keras.layers.Dense(features[-2]))\r\n","        self.final_layer.add(tf.keras.layers.Dense(features[-2]))\r\n","        self.final_layer.add(tf.keras.layers.Dense(1))\r\n","        \r\n","    def call(self, inputs, training=False):\r\n","        # inputs is a batch of tensors \r\n","        \r\n","        feat = tf.transpose(inputs, perm=[0, 2, 1])\r\n","        #feat = inputs.transpose(1,2) # NOT SURE IF THIS WORKS\r\n","        \r\n","        vertex_num = feat.shape[2]\r\n","        #vertex_num = feat.size(2) # NOT SURE IF THIS WORKS\r\n","\r\n","        for inx in range(self.layer_num):\r\n","            feat = self.fc_layers[inx](feat)\r\n","            feat = self.leaky_relu(feat)\r\n","        \r\n","        maxpool = tf.keras.layers.GlobalMaxPool1D()\r\n","        out = maxpool(feat)\r\n","        out = self.final_layer(out)\r\n","\r\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMgx-CJB2gVG"},"source":["class GradientPenalty:\r\n","  \"\"\"Computes the gradient penalty as deefined in \"Improved Training of Wassertein GANS\"\r\n","    (https://arxiv.org/abs/1704.00028)\r\n","  \"\"\"\r\n","  #Initialize class attributes\r\n","  def __init__(self, lambdaGP, gamma=1):\r\n","    self.lambdaGP = lambdaGP\r\n","    self.gamma = gamma\r\n","\r\n","  #Call class using parameters discriminator model, the real data, and fake data\r\n","  def __call__(self, disc_model, real_data, fake_data):\r\n","    batch_size = real_data.shape[0]\r\n","    fake_data = fake_data[:batch_size]\r\n","    print(\"Fake Data\", fake_data)\r\n","    print(\"Real Data\", real_data)\r\n","\r\n","    # alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\r\n","    alpha = tf.random.uniform([batch_size,  1, 1], 0.0, 1.0)\r\n","    print(\"Alpha\", alpha)\r\n","\r\n","    inters = real_data + alpha * (fake_data - real_data)\r\n","\r\n","    with tf.GradientTape() as t:\r\n","      t.watch(inters)\r\n","      # print(inter)\r\n","      # print(inter.shape)\r\n","      pred = [disc_model(inter) for inter in inters]\r\n","      print(pred)\r\n","    \r\n","    grad1 = t.gradient(pred, [inters])\r\n","    # print(grad1)\r\n","    grad = grad1[0]\r\n","    # print(grad)\r\n","    # grad = t.gradient(pred, [inter])[0]\r\n","\r\n","    # slopes = tf.sqrt(tf.reduce_sum(tf.square(grad), axis=[1, 2, 3]))\r\n","\r\n","    slopes = tf.sqrt(tf.reduce_sum(tf.square(grad), axis=[0, 1, 2]))\r\n","    gp = tf.reduce_mean(((slopes - self.gamma)/self.gamma)**2)*self.lambdaGP\r\n","    return gp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlmY6liF2tQ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614826272870,"user_tz":300,"elapsed":474,"user":{"displayName":"Spencer Hill","photoUrl":"","userId":"06492296408916193265"}},"outputId":"c4838bb4-180f-4afb-d6c7-384d4cae8ee5"},"source":["male_30 = np.load('/content/drive/MyDrive/Qmind Object Completion Team/TreeGAN/male_meshes.npy')\r\n","female_30 = np.load('/content/drive/MyDrive/Qmind Object Completion Team/TreeGAN/female_meshes.npy')\r\n","print(female_30.shape, male_30.shape)\r\n","male_30_train = np.reshape(male_30, (1531, 1, 3072, 3))\r\n","female_30_train = np.reshape(female_30, (1517, 1, 3072, 3))\r\n","male_30_train = tf.cast(male_30_train, dtype=tf.float32)\r\n","female_30_train = tf.cast(female_30_train, dtype=tf.float32)\r\n","print(male_30_train.shape, female_30_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1517, 3072, 3) (1531, 3072, 3)\n","(1531, 1, 3072, 3) (1517, 1, 3072, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lpq4QuiThPfs"},"source":["# Declare model architecture - Generator (TreeGCN), Discriminator, GradientPenalty\n","class TreeGAN():\n","  def __init__(self, args, data):\n","    self.args = args\n","    self.G = Generator(batch_size=args.batch_size, features=args.G_FEAT, degrees=args.DEGREES, support=args.support)\n","    self.D = Discriminator(batch_size=args.batch_size, features=args.D_FEAT)\n","\n","    self.GP = GradientPenalty(args.lambdaGP, gamma=1)\n","    self.data = data\n","    self.num_samples = self.data.shape[0]\n","\n","    self.D_optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n","    self.G_optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n","    print(\"Network Prepared\") \n","\n","    # self.visualize = visdom.Visdom(port=args.visdom_port)\n","    # assert self.visualize.check_connection()\n","    # print(\"Visdom Connected\")\n","\n","  def run(self, save_d_ckpt=None, save_g_ckpt=None, load_g_ckpt=None, load_d_ckpt=None): # Add arguments for whether to save/load data\n","    # #visdom visualizations\n","    # color_num = self.args.visdom_color\n","    # chunk_size = int(self.args.point_num / color_num)\n","    # #color list\n","    # colors = np.array([(227,0,27),(231,64,28),(237,120,15),(246,176,44),\n","    #                        (252,234,0),(224,221,128),(142,188,40),(18,126,68),\n","    #                        (63,174,0),(113,169,156),(164,194,184),(51,186,216),\n","    #                        (0,152,206),(16,68,151),(57,64,139),(96,72,132),\n","    #                        (172,113,161),(202,174,199),(145,35,132),(201,47,133),\n","    #                        (229,0,123),(225,106,112),(163,38,42),(128,128,128)])\n","    # #randomly choose color from list\n","    # colors = colors[np.random.choice(len(colors), color_num, replace=False)]\n","    # label = tf.stack([tf.ones(chunk_size) * inx for inx in range(1,int(color_num)+1)], axis=0).view(-1)\n","\n","    # Add option to load trained model parameters\n","    if not load_g_ckpt == None:\n","      latent = [tf.random.uniform((1, 1, 1, 96))]\n","      points = self.G(latent)\n","      self.D(points)\n","      self.G.load_weights(load_g_ckpt)\n","      print(\"Generator Checkpoint Loaded\")\n","      self.D.load_weights(load_d_ckpt)\n","      print(\"Discriminator Checkpoint Loaded\")\n","    #training loop (for one epoch)\n","    plotlosses = PlotLosses()\n","    for epoch in range(self.args.epochs):\n","      g_loss_epoch = 0\n","      d_loss_epoch = 0\n","      self.data = tf.random.shuffle(\n","      self.data, seed=None, name=None\n","      )\n","      for batch in range(self.num_samples // self.args.batch_size):\n","        start_time = time.time()\n","        half_batch = int (self.args.batch_size / 2)\n","\n","        d_loss_iter = 0\n","        for iter in range(self.args.D_iter):\n","          # -------Discriminator------- #\n","          d_loss_sum = 0\n","          self.D.trainable = True\n","          # for i in range(self.num_samples):\n","          # Generate latent vectors\n","          # latent = np.random.randn(self.args.latent_dim * self.args.batch_size)\n","          # latent = latent.reshape(self.args.batch_size, self.args.latent_dim)\n","          # BATCH_SIZE = 1 come back and fix\n","          latent = [[tf.random.uniform((1,1,  1, 96))] for i in range(self.args.batch_size)]\n","          # Generate fake points using Generator network\n","          # if batch == 1:\n","          #   print(\"GENERATED IMAGE \", fake_point.shape )\n","          # Need to get real points\n","          with tf.GradientTape() as tape:\n","            fake_points = [self.G(latent_example) for latent_example in latent]\n","\n","            real_points = self.data[batch * self.args.batch_size : (batch + 1) * self.args.batch_size]\n","\n","            # Calculate loss on fake points (mean over a batch)\n","            # loss_f = =np.array([self.D(fake_point) for fake_point in fake_points])\n","            # loss_f_mean = np.mean(loss_f)\n","            loss_f = tf.convert_to_tensor([self.D(fake_point) for fake_point in fake_points], dtype=tf.float32)\n","            loss_f_mean = tf.reduce_mean(loss_f)\n","            \n","            # Calculate loss on real points (mean over a batch)\n","            # loss_r = np.array([self.D(real_point) for real_point in real_points])\n","            # loss_r_mean = np.mean(loss_r)\n","            loss_r = tf.convert_to_tensor([self.D(real_point) for real_point in real_points], dtype=tf.float32)\n","            loss_r_mean = tf.reduce_mean(loss_r)\n","\n","            # Get total loss and apply gradient penalty to it\n","\n","            d_loss = -loss_r_mean + loss_f_mean\n","            \n","            d_loss = d_loss + self.GP(self.D, real_points, fake_points)\n","\n","            \n","\n","            # Calculate gradients and backpropogate through discriminator network\n","            # print(\"Disc Loss\")\n","            # print(d_loss)\n","            # print(np.array(self.D.trainable_weights).shape)\n","          d_loss_iter += d_loss\n","          # FIX THIS ALSO G WEIGHTS\n","\n","            # d_gradients = tf.GradientTape.gradient(d_loss, self.D.trainable_weights)\n","          d_gradients = tape.gradient(d_loss, self.D.trainable_weights)\n","          # d_gradients = tf.GradientTape.gradient(self.D.trainable_weights)\n","\n","          self.D_optimizer.apply_gradients(zip(d_gradients, self.D.trainable_weights))\n","          \n","          # -------Generator-------- #\n","          # Create latent vector\n","          # latent = np.random.randn(self.args.latent_dim * self.args.batch_size)\n","          # latent = latent.reshape(self.args.batch_size, self.args.latent_dim)\n","          # BATCH_SIZE = 1 come back and fix\n","          # latent2 = [tf.random.uniform((1,1,  1, 96))]\n","\n","          # Use latent vector to generate examples\n","          \n","          # self.D.trainable = False\n","          # Calculate mean loss using discriminator\n","        d_loss_epoch += d_loss_iter / self.args.D_iter\n","        latent_gen = [[tf.random.uniform((1,1,  1, 96))] for i in range(self.args.batch_size)]\n","\n","        with tf.GradientTape() as tape2:\n","          # Watching the input vector because it isn't a tf.Variable\n","          tape2.watch(latent_gen)\n","          fake_points_gen = [self.G(latent) for latent in latent_gen]\n","          self.D.trainable = False\n","          # G_fake = np.array([self.D(fake_point) for fake_point in fake_point_gen])\n","          G_fake = tf.convert_to_tensor([self.D(fake_point) for fake_point in fake_points_gen], dtype=tf.float32)\n","          G_fake_mean = tf.math.reduce_mean(G_fake)\n","          g_loss = -G_fake_mean\n","          # print(\"Watched: \", tape2.watched_variables())\n","          # print(\"Trainable: \", self.D.trainable_weights)\n","\n","\n","        # Apply gradients and backpropograte to train\n","\n","          #   HERE\n","          # print(\"G LOSS\")\n","          # g_loss = tf.Variable(g_loss, dtype=tf.float32)\n","          # print(\"Disc watched variables: \", self.watched_variables)\n","          # print(\"Gen Watched Variables: \", tape2.watched_variables)\n","        \n","        g_gradients = tape2.gradient(g_loss, self.G.trainable_weights)\n","        \n","\n","        # print(g_gradients)\n","        self.G_optimizer.apply_gradients(zip(g_gradients, self.G.trainable_weights))\n","        \n","        g_loss_epoch += g_loss\n","        \n","        end_time = time.time()\n","\n","        # ----- Visualization ------- #\n","\n","      print(\"[Epoch/Iter] \", \"{:3} / {:3}\".format(epoch, iter),\n","            \"[ D_Loss ] \", \"{: 7.6f}\".format(d_loss), \n","            \"[ G_Loss ] \", \"{: 7.6f}\".format(g_loss), \n","            \"[ Time ] \", \"{:4.2f}s\".format(time.time()-start_time))\n","\n","      if iter % 10 == 0:\n","          generated_point = self.G.getPointcloud()\n","          print(generated_point)\n","          # plot_X = np.stack([np.arange(len(loss_log[legend])) for legend in loss_legend], 1)\n","          # plot_Y = np.stack([np.array(loss_log[legend]) for legend in loss_legend], 1)\n","\n","          # self.visualize.line(X=plot_X, Y=plot_Y, win=1,\n","          #               opts={'title': 'TreeGAN Loss', 'legend': loss_legend, 'xlabel': 'Iteration', 'ylabel': 'Loss'})\n","\n","          self.visualize.scatter(X=generated_point[:,tf.convert_to_tensor([2,0,1], np.float32)], Y=label, win=2,\n","                            opts={'title': \"Generated Pointcloud\", 'markersize': 2, 'markercolor': colors, 'webgl': True})\n","\n","          # print('Figures are saved.')\n","      mean_g_loss_epoch = g_loss_epoch / (self.num_samples // self.args.batch_size)\n","      mean_d_loss_epoch = d_loss_epoch / (self.num_samples // self.args.batch_size)\n","      plotlosses.update({\n","          'gen_loss': mean_g_loss_epoch,\n","          'disc_loss': mean_d_loss_epoch,\n","          'gen - disc loss' : mean_g_loss_epoch - mean_d_loss_epoch\n","          # 'loss': 1. / (i + 2.),\n","          # 'val_loss': 1. / (i + 0.5)\n","      })\n","      plotlosses.send()\n","\n","    if epoch % self.args.save_rate == 0: #acutal number can be changed (maybe through arguments file??)\n","      #visualize\n","\n","      # save model\n","      if not save_g_ckpt == None:\n","        self.G.save_weights(save_g_ckpt + 'gen_' + str(epoch) + '.h5')\n","        # Maybe save visualizations somehow?\n","        \n","        latent = [[tf.random.uniform((1,1,  1, 96))] for i in range(10)]\n","        pc = [self.G(noise) for noise in latent]\n","        os.mkdir(\"vis\")\n","        for i in range(pc):\n","          cloud = pc[i]\n","          fig = plt.figure(figsize=(10, 10))\n","          ax = fig.add_subplot(111, projection=\"3d\")\n","          ax.scatter(cloud[:, 0], cloud[:, 1], cloud[:, 2])\n","          # ax.set_axis_off()\n","          ax.view_init(30,245)\n","          os.mkdir(\"/Visualizations/\" + str(epoch))\n","          plt.savefig(\"/Visualizations/\" + str(epoch) + \"_\" + str(i) + \".png\")\n","      if not save_d_ckpt == None:\n","        self.D.save_weights(save_d_ckpt + 'disc_' + str(epoch) + '.h5')\n","        print(\"\\n----------Model Saved-----------\\n\")\n","        \n","        \n","      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWQ0egO39VZt"},"source":["! mkdir Visualizations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RothamWbh6pc","executionInfo":{"status":"error","timestamp":1614826287093,"user_tz":300,"elapsed":8995,"user":{"displayName":"Spencer Hill","photoUrl":"","userId":"06492296408916193265"}},"outputId":"d76d984a-17b0-482c-fab8-e0ba93daf350"},"source":["args = real_args()\r\n","model = TreeGAN(args, male_30_train)\r\n","model.run(save_d_ckpt=args.save_d_ckpt, save_g_ckpt=args.save_g_ckpt)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["layer num : 0\n","Model: \"sequential_37\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_47 (Dense)             (None, 960)               92160     \n","_________________________________________________________________\n","dense_48 (Dense)             (None, 256)               245760    \n","=================================================================\n","Total params: 337,920\n","Trainable params: 337,920\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  0 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_46_input'), name='dense_46_input', description=\"created by layer 'dense_46_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_47_input'), name='dense_47_input', description=\"created by layer 'dense_47_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","LAYER  0 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_7')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_7')>]\n","layer num : 1\n","Model: \"sequential_40\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_51 (Dense)             (None, 2560)              655360    \n","_________________________________________________________________\n","dense_52 (Dense)             (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  1 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_49_input'), name='dense_49_input', description=\"created by layer 'dense_49_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_50_input'), name='dense_50_input', description=\"created by layer 'dense_50_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_51_input'), name='dense_51_input', description=\"created by layer 'dense_51_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","LAYER  1 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_8')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_8')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_8')>]\n","layer num : 2\n","Model: \"sequential_44\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_56 (Dense)             (None, 2560)              655360    \n","_________________________________________________________________\n","dense_57 (Dense)             (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  2 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_53_input'), name='dense_53_input', description=\"created by layer 'dense_53_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_55_input'), name='dense_55_input', description=\"created by layer 'dense_55_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","LAYER  2 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_9')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_9')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_9')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_9')>]\n","layer num : 3\n","Model: \"sequential_49\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_62 (Dense)             (None, 2560)              655360    \n","_________________________________________________________________\n","dense_63 (Dense)             (None, 128)               327680    \n","=================================================================\n","Total params: 983,040\n","Trainable params: 983,040\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  3 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_58_input'), name='dense_58_input', description=\"created by layer 'dense_58_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_59_input'), name='dense_59_input', description=\"created by layer 'dense_59_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_61_input'), name='dense_61_input', description=\"created by layer 'dense_61_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_62_input'), name='dense_62_input', description=\"created by layer 'dense_62_input'\"), but it was called on an input with incompatible shape (1, 12, 256).\n","LAYER  3 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_10')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_10')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_10')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_10')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_10')>]\n","layer num : 4\n","Model: \"sequential_55\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_69 (Dense)             (None, 1280)              163840    \n","_________________________________________________________________\n","dense_70 (Dense)             (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  4 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_64_input'), name='dense_64_input', description=\"created by layer 'dense_64_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_65_input'), name='dense_65_input', description=\"created by layer 'dense_65_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_66_input'), name='dense_66_input', description=\"created by layer 'dense_66_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_67_input'), name='dense_67_input', description=\"created by layer 'dense_67_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_68_input'), name='dense_68_input', description=\"created by layer 'dense_68_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_69_input'), name='dense_69_input', description=\"created by layer 'dense_69_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","LAYER  4 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_11')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_11')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_11')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_11')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_11')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_11')>]\n","layer num : 5\n","Model: \"sequential_62\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_77 (Dense)             (None, 1280)              163840    \n","_________________________________________________________________\n","dense_78 (Dense)             (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  5 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_71_input'), name='dense_71_input', description=\"created by layer 'dense_71_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_72_input'), name='dense_72_input', description=\"created by layer 'dense_72_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_73_input'), name='dense_73_input', description=\"created by layer 'dense_73_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_74_input'), name='dense_74_input', description=\"created by layer 'dense_74_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_75_input'), name='dense_75_input', description=\"created by layer 'dense_75_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_76_input'), name='dense_76_input', description=\"created by layer 'dense_76_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_77_input'), name='dense_77_input', description=\"created by layer 'dense_77_input'\"), but it was called on an input with incompatible shape (1, 48, 128).\n","LAYER  5 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_12')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_12')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_12')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_12')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_12')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_12')>, <KerasTensor: shape=(1, 48, 128) dtype=float32 (created by layer 'tree_gcn_12')>]\n","layer num : 6\n","Model: \"sequential_70\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_86 (Dense)             (None, 1280)              163840    \n","_________________________________________________________________\n","dense_87 (Dense)             (None, 3)                 3840      \n","=================================================================\n","Total params: 167,680\n","Trainable params: 167,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  6 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_79_input'), name='dense_79_input', description=\"created by layer 'dense_79_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_80_input'), name='dense_80_input', description=\"created by layer 'dense_80_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_81_input'), name='dense_81_input', description=\"created by layer 'dense_81_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_82_input'), name='dense_82_input', description=\"created by layer 'dense_82_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_83_input'), name='dense_83_input', description=\"created by layer 'dense_83_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_84_input'), name='dense_84_input', description=\"created by layer 'dense_84_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_85_input'), name='dense_85_input', description=\"created by layer 'dense_85_input'\"), but it was called on an input with incompatible shape (1, 48, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_86_input'), name='dense_86_input', description=\"created by layer 'dense_86_input'\"), but it was called on an input with incompatible shape (1, 3072, 128).\n","LAYER  6 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_13')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_13')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_13')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_13')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_13')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_13')>, <KerasTensor: shape=(1, 48, 128) dtype=float32 (created by layer 'tree_gcn_13')>, <KerasTensor: shape=(1, 3072, 3) dtype=float32 (created by layer 'tree_gcn_13')>]\n","Network Prepared\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.21288167,  1.3197068 ,  2.075687  ],\n","        [-0.23954049,  1.3346872 ,  2.0662732 ],\n","        [-0.23017928,  1.3548349 ,  2.0889149 ],\n","        ...,\n","        [ 0.29741952,  0.8365276 ,  2.073691  ],\n","        [ 0.2825628 ,  0.8313841 ,  2.0770314 ],\n","        [ 0.32543376,  0.81462944,  2.0524259 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24087647  0.11817322 -0.13514963]\n","   [ 0.20452361  0.00774421 -0.52982646]\n","   [ 0.2249845  -0.00915485 -0.36160356]\n","   ...\n","   [ 0.08655477  0.00208981 -0.39382243]\n","   [ 0.2035765   0.1773779  -0.17294502]\n","   [ 0.11980268 -0.05485963  0.07425503]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.79246306]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.39961573]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.9063112 , -0.06534193, -0.31669512],\n","        [-1.9408293 , -0.06260683, -0.32069403],\n","        [-1.9294782 , -0.04306523, -0.30457196],\n","        ...,\n","        [-1.470787  , -0.43498662,  0.4886959 ],\n","        [-1.4857336 , -0.44343555,  0.48778355],\n","        [-1.4452934 , -0.46127012,  0.4794163 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24087647  0.11817322 -0.13514963]\n","   [ 0.20452361  0.00774421 -0.52982646]\n","   [ 0.2249845  -0.00915485 -0.36160356]\n","   ...\n","   [ 0.08655477  0.00208981 -0.39382243]\n","   [ 0.2035765   0.1773779  -0.17294502]\n","   [ 0.11980268 -0.05485963  0.07425503]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.08714509]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.16121756]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-3.215354 ,  2.253031 ,  2.0687928],\n","        [-3.236477 ,  2.2590826,  2.069405 ],\n","        [-3.2387228,  2.2745876,  2.082624 ],\n","        ...,\n","        [-1.911002 ,  1.9618593,  2.5894313],\n","        [-1.9218829,  1.959751 ,  2.5828896],\n","        [-1.8814459,  1.9403471,  2.5688722]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24087647  0.11817322 -0.13514963]\n","   [ 0.20452361  0.00774421 -0.52982646]\n","   [ 0.2249845  -0.00915485 -0.36160356]\n","   ...\n","   [ 0.08655477  0.00208981 -0.39382243]\n","   [ 0.2035765   0.1773779  -0.17294502]\n","   [ 0.11980268 -0.05485963  0.07425503]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.17187154]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-1.1538141]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.8983091 , -0.53331006,  1.3212768 ],\n","        [-1.9485054 , -0.5130074 ,  1.3179821 ],\n","        [-1.9181165 , -0.49608418,  1.3198189 ],\n","        ...,\n","        [-1.6814402 , -1.1973199 ,  1.3710696 ],\n","        [-1.708579  , -1.201033  ,  1.3616143 ],\n","        [-1.6600614 , -1.208147  ,  1.3461677 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24087647  0.11817322 -0.13514963]\n","   [ 0.20452361  0.00774421 -0.52982646]\n","   [ 0.2249845  -0.00915485 -0.36160356]\n","   ...\n","   [ 0.08655477  0.00208981 -0.39382243]\n","   [ 0.2035765   0.1773779  -0.17294502]\n","   [ 0.11980268 -0.05485963  0.07425503]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.8257835]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-5.5602236]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-3.4555538 ,  0.74274623,  2.716567  ],\n","        [-3.5076556 ,  0.7658226 ,  2.7141845 ],\n","        [-3.4727335 ,  0.79105395,  2.7118666 ],\n","        ...,\n","        [-2.5184193 ,  0.40923342,  3.1043434 ],\n","        [-2.5310261 ,  0.3982807 ,  3.1011598 ],\n","        [-2.4946353 ,  0.39957634,  3.0974019 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24087647  0.11817322 -0.13514963]\n","   [ 0.20452361  0.00774421 -0.52982646]\n","   [ 0.2249845  -0.00915485 -0.36160356]\n","   ...\n","   [ 0.08655477  0.00208981 -0.39382243]\n","   [ 0.2035765   0.1773779  -0.17294502]\n","   [ 0.11980268 -0.05485963  0.07425503]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.10123527]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-1.3260944]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[ 1.4505956 ,  4.0373497 , -0.7962339 ],\n","        [ 1.4511433 ,  4.065197  , -0.7899696 ],\n","        [ 1.4824673 ,  4.066654  , -0.777235  ],\n","        ...,\n","        [ 1.8242742 ,  3.2360535 , -0.05470345],\n","        [ 1.8098315 ,  3.2242312 , -0.03884892],\n","        [ 1.8856922 ,  3.2179177 , -0.07999467]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.12031282  0.15178972  0.4767773 ]\n","   [ 0.2451713   0.02141604 -0.651398  ]\n","   [-0.00439172  0.11667994 -0.9808386 ]\n","   ...\n","   [ 0.05739999  0.00235224  0.5470336 ]\n","   [-0.05475423  0.29410407  0.12128416]\n","   [-0.09138167  0.05987156  0.11449379]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.73891973]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-22.458344]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[ 0.4228024 , -0.32287765,  1.6960208 ],\n","        [ 0.41550717, -0.2805336 ,  1.6984031 ],\n","        [ 0.4623372 , -0.28892615,  1.7208484 ],\n","        ...,\n","        [ 0.9985592 , -1.0908062 ,  1.6947316 ],\n","        [ 0.98042774, -1.0977315 ,  1.7243606 ],\n","        [ 1.0706526 , -1.1058501 ,  1.6749309 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.12031282  0.15178972  0.4767773 ]\n","   [ 0.2451713   0.02141604 -0.651398  ]\n","   [-0.00439172  0.11667994 -0.9808386 ]\n","   ...\n","   [ 0.05739999  0.00235224  0.5470336 ]\n","   [-0.05475423  0.29410407  0.12128416]\n","   [-0.09138167  0.05987156  0.11449379]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.21881735]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-2.8246999]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[0.8902769 , 1.6492484 , 1.5933756 ],\n","        [0.8844896 , 1.696549  , 1.5886797 ],\n","        [0.92308116, 1.680817  , 1.6117958 ],\n","        ...,\n","        [1.7925466 , 1.0382211 , 1.2634434 ],\n","        [1.7730387 , 1.0371811 , 1.2914014 ],\n","        [1.8542165 , 1.023781  , 1.2434146 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.12031282  0.15178972  0.4767773 ]\n","   [ 0.2451713   0.02141604 -0.651398  ]\n","   [-0.00439172  0.11667994 -0.9808386 ]\n","   ...\n","   [ 0.05739999  0.00235224  0.5470336 ]\n","   [-0.05475423  0.29410407  0.12128416]\n","   [-0.09138167  0.05987156  0.11449379]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.22589815]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-6.130747]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[ 1.0779142 , -2.5498724 ,  0.5722886 ],\n","        [ 1.0671524 , -2.515959  ,  0.57605284],\n","        [ 1.107048  , -2.5219631 ,  0.5968008 ],\n","        ...,\n","        [ 1.3261476 , -3.1542165 ,  1.1701405 ],\n","        [ 1.3191726 , -3.1564255 ,  1.1956921 ],\n","        [ 1.3994914 , -3.1743767 ,  1.1550208 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.12031282  0.15178972  0.4767773 ]\n","   [ 0.2451713   0.02141604 -0.651398  ]\n","   [-0.00439172  0.11667994 -0.9808386 ]\n","   ...\n","   [ 0.05739999  0.00235224  0.5470336 ]\n","   [-0.05475423  0.29410407  0.12128416]\n","   [-0.09138167  0.05987156  0.11449379]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.16951]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-8.224098]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[2.5456336 , 1.2898371 , 0.32260782],\n","        [2.5516498 , 1.3296841 , 0.3322297 ],\n","        [2.5747857 , 1.3094978 , 0.34942898],\n","        ...,\n","        [3.2127287 , 0.76520604, 0.79613894],\n","        [3.1984231 , 0.7601362 , 0.8168575 ],\n","        [3.2808044 , 0.74256593, 0.7706606 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.12031282  0.15178972  0.4767773 ]\n","   [ 0.2451713   0.02141604 -0.651398  ]\n","   [-0.00439172  0.11667994 -0.9808386 ]\n","   ...\n","   [ 0.05739999  0.00235224  0.5470336 ]\n","   [-0.05475423  0.29410407  0.12128416]\n","   [-0.09138167  0.05987156  0.11449379]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.48926175]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-36.195183]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.9183573 , -0.7439918 , -1.2663357 ],\n","        [-0.8820249 , -0.7050764 , -1.252074  ],\n","        [-0.8337406 , -0.7030512 , -1.2300137 ],\n","        ...,\n","        [-0.10596001, -1.808615  , -1.0302252 ],\n","        [-0.07641193, -1.8184644 , -1.0026333 ],\n","        [-0.02743464, -1.8281517 , -1.0609701 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24383429 -0.3534773  -0.1733486 ]\n","   [ 0.2527897  -0.13106303  0.21973234]\n","   [ 0.0864055   0.08926845 -0.48365507]\n","   ...\n","   [ 0.09043055  0.1731431  -0.50699556]\n","   [-0.06974696  0.17845881 -0.20255622]\n","   [ 0.10921703  0.13718158 -0.39473987]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.39776635]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-10.955135]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.9039073 ,  2.0626664 , -0.43560967],\n","        [-2.87098   ,  2.1263633 , -0.41605324],\n","        [-2.816253  ,  2.1198773 , -0.3957449 ],\n","        ...,\n","        [-2.5456388 ,  0.80866206, -0.35924777],\n","        [-2.5299416 ,  0.8060424 , -0.3239162 ],\n","        [-2.456933  ,  0.7905961 , -0.38832724]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24383429 -0.3534773  -0.1733486 ]\n","   [ 0.2527897  -0.13106303  0.21973234]\n","   [ 0.0864055   0.08926845 -0.48365507]\n","   ...\n","   [ 0.09043055  0.1731431  -0.50699556]\n","   [-0.06974696  0.17845881 -0.20255622]\n","   [ 0.10921703  0.13718158 -0.39473987]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.7222754]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-71.702805]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.1366462 ,  1.0420711 ,  0.58076364],\n","        [-1.101236  ,  1.0980226 ,  0.59701574],\n","        [-1.0466464 ,  1.0966828 ,  0.620811  ],\n","        ...,\n","        [-0.44181994,  0.26471615, -0.0375272 ],\n","        [-0.41975898,  0.2677424 ,  0.00516634],\n","        [-0.3664827 ,  0.24777304, -0.05056995]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24383429 -0.3534773  -0.1733486 ]\n","   [ 0.2527897  -0.13106303  0.21973234]\n","   [ 0.0864055   0.08926845 -0.48365507]\n","   ...\n","   [ 0.09043055  0.1731431  -0.50699556]\n","   [-0.06974696  0.17845881 -0.20255622]\n","   [ 0.10921703  0.13718158 -0.39473987]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.21457756]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-13.1280575]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.75416565, -0.09316263,  1.5813407 ],\n","        [-0.7197854 , -0.04082332,  1.5939918 ],\n","        [-0.67775357, -0.03945665,  1.601628  ],\n","        ...,\n","        [ 0.15100051, -0.72199786,  1.8757565 ],\n","        [ 0.1795253 , -0.73378074,  1.9048096 ],\n","        [ 0.23029497, -0.7485688 ,  1.8464233 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24383429 -0.3534773  -0.1733486 ]\n","   [ 0.2527897  -0.13106303  0.21973234]\n","   [ 0.0864055   0.08926845 -0.48365507]\n","   ...\n","   [ 0.09043055  0.1731431  -0.50699556]\n","   [-0.06974696  0.17845881 -0.20255622]\n","   [ 0.10921703  0.13718158 -0.39473987]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.7361276]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-67.52556]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[ 0.6443345 ,  1.3581711 , -1.0307914 ],\n","        [ 0.68081236,  1.4243984 , -1.0145606 ],\n","        [ 0.7397049 ,  1.4017552 , -0.9863483 ],\n","        ...,\n","        [ 0.878189  ,  0.88281137, -1.2523557 ],\n","        [ 0.90401   ,  0.88436145, -1.2077943 ],\n","        [ 0.9516882 ,  0.8722509 , -1.2737323 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.24383429 -0.3534773  -0.1733486 ]\n","   [ 0.2527897  -0.13106303  0.21973234]\n","   [ 0.0864055   0.08926845 -0.48365507]\n","   ...\n","   [ 0.09043055  0.1731431  -0.50699556]\n","   [-0.06974696  0.17845881 -0.20255622]\n","   [ 0.10921703  0.13718158 -0.39473987]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.66141236]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-72.870056]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.276912  , -1.3732625 ,  0.25296858],\n","        [-2.2155173 , -1.2779108 ,  0.26964247],\n","        [-2.141572  , -1.3113925 ,  0.30907202],\n","        ...,\n","        [-1.2924888 , -2.1853034 ,  0.2259967 ],\n","        [-1.2473686 , -2.1573634 ,  0.26451623],\n","        [-1.2112832 , -2.191316  ,  0.21329108]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.01237402  0.15611646  0.46133193]\n","   [-0.14598502  0.33424908 -0.03729378]\n","   [ 0.05791174  0.23473847  0.41717976]\n","   ...\n","   [-0.06073029  0.1199905  -0.07102943]\n","   [ 0.13851222  0.16312478 -0.5342294 ]\n","   [-0.09190297  0.26004326  0.23701805]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.67054784]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-54.81221]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-3.3734722 , -0.8875688 ,  0.23391917],\n","        [-3.3053954 , -0.7977389 ,  0.26858962],\n","        [-3.259039  , -0.8205106 ,  0.29102883],\n","        ...,\n","        [-2.4153752 , -1.1953763 , -0.07390039],\n","        [-2.3780518 , -1.1681973 , -0.03139603],\n","        [-2.3311265 , -1.2088296 , -0.06204878]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.01237402  0.15611646  0.46133193]\n","   [-0.14598502  0.33424908 -0.03729378]\n","   [ 0.05791174  0.23473847  0.41717976]\n","   ...\n","   [-0.06073029  0.1199905  -0.07102943]\n","   [ 0.13851222  0.16312478 -0.5342294 ]\n","   [-0.09190297  0.26004326  0.23701805]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.5380403]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-88.61]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.8666918 , -0.17659295, -0.40319467],\n","        [-2.806511  , -0.09800814, -0.37315166],\n","        [-2.756032  , -0.12722345, -0.34548163],\n","        ...,\n","        [-2.5450013 , -1.060928  , -0.5575851 ],\n","        [-2.4990916 , -1.0260837 , -0.5270841 ],\n","        [-2.461558  , -1.065967  , -0.55770576]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.01237402  0.15611646  0.46133193]\n","   [-0.14598502  0.33424908 -0.03729378]\n","   [ 0.05791174  0.23473847  0.41717976]\n","   ...\n","   [-0.06073029  0.1199905  -0.07102943]\n","   [ 0.13851222  0.16312478 -0.5342294 ]\n","   [-0.09190297  0.26004326  0.23701805]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.7103838]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-135.82428]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.8847196, -1.984645 ,  3.6015866],\n","        [-2.8464825, -1.8920544,  3.6311338],\n","        [-2.7918086, -1.9111319,  3.6443875],\n","        ...,\n","        [-2.8113549, -2.8141706,  3.727549 ],\n","        [-2.7659638, -2.7859979,  3.7608929],\n","        [-2.7123349, -2.832543 ,  3.7280133]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.01237402  0.15611646  0.46133193]\n","   [-0.14598502  0.33424908 -0.03729378]\n","   [ 0.05791174  0.23473847  0.41717976]\n","   ...\n","   [-0.06073029  0.1199905  -0.07102943]\n","   [ 0.13851222  0.16312478 -0.5342294 ]\n","   [-0.09190297  0.26004326  0.23701805]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.72237694]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-313.3451]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.975824  , -1.5439651 , -0.12219115],\n","        [-2.9114418 , -1.4589698 , -0.10763343],\n","        [-2.865021  , -1.4948963 , -0.07801774],\n","        ...,\n","        [-2.3101735 , -2.7470853 , -0.10665943],\n","        [-2.265545  , -2.7154818 , -0.08319363],\n","        [-2.2383647 , -2.7600913 , -0.12021171]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.01237402  0.15611646  0.46133193]\n","   [-0.14598502  0.33424908 -0.03729378]\n","   [ 0.05791174  0.23473847  0.41717976]\n","   ...\n","   [-0.06073029  0.1199905  -0.07102943]\n","   [ 0.13851222  0.16312478 -0.5342294 ]\n","   [-0.09190297  0.26004326  0.23701805]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.81428075]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-201.57347]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.2433169 , -0.84277487, -0.1741862 ],\n","        [-1.1631035 , -0.7384738 , -0.11774139],\n","        [-1.1114206 , -0.7585608 , -0.10484606],\n","        ...,\n","        [-0.40268716, -1.5909547 , -0.08626067],\n","        [-0.33660513, -1.5383674 , -0.0206717 ],\n","        [-0.30710933, -1.5578858 , -0.05930944]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.04361098 -0.08022338 -0.184389  ]\n","   [ 0.08040427 -0.05719299  0.52244115]\n","   [ 0.1933978  -0.08488399 -0.35864496]\n","   ...\n","   [ 0.11103451  0.21635047 -0.10174527]\n","   [ 0.03670978  0.01887075 -0.16557637]\n","   [ 0.03703855  0.18648647 -0.83710027]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.04250312]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-9.775769]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.1928259 , -0.5416096 ,  0.6255995 ],\n","        [-1.1042277 , -0.44997853,  0.684879  ],\n","        [-1.066436  , -0.45783886,  0.691782  ],\n","        ...,\n","        [ 0.19248551, -1.3370075 ,  0.29629445],\n","        [ 0.25323054, -1.2912215 ,  0.36382964],\n","        [ 0.27714345, -1.3215853 ,  0.31422737]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.04361098 -0.08022338 -0.184389  ]\n","   [ 0.08040427 -0.05719299  0.52244115]\n","   [ 0.1933978  -0.08488399 -0.35864496]\n","   ...\n","   [ 0.11103451  0.21635047 -0.10174527]\n","   [ 0.03670978  0.01887075 -0.16557637]\n","   [ 0.03703855  0.18648647 -0.83710027]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.42674232]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-40.08867]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-4.546419  , -2.3938694 , -0.602909  ],\n","        [-4.4721613 , -2.277211  , -0.55044776],\n","        [-4.4233155 , -2.2946317 , -0.5382456 ],\n","        ...,\n","        [-3.8154685 , -2.9027333 , -0.8624182 ],\n","        [-3.7530503 , -2.8619382 , -0.8001159 ],\n","        [-3.7165813 , -2.8743467 , -0.83443266]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.04361098 -0.08022338 -0.184389  ]\n","   [ 0.08040427 -0.05719299  0.52244115]\n","   [ 0.1933978  -0.08488399 -0.35864496]\n","   ...\n","   [ 0.11103451  0.21635047 -0.10174527]\n","   [ 0.03670978  0.01887075 -0.16557637]\n","   [ 0.03703855  0.18648647 -0.83710027]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.88961756]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-543.5869]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.7112639 , -1.1790253 ,  0.41872257],\n","        [-1.6336865 , -1.081348  ,  0.4769958 ],\n","        [-1.6043495 , -1.0995387 ,  0.4896662 ],\n","        ...,\n","        [-0.979604  , -1.2996444 ,  0.5301224 ],\n","        [-0.93047875, -1.2626102 ,  0.58462805],\n","        [-0.9075267 , -1.2807885 ,  0.54965216]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.04361098 -0.08022338 -0.184389  ]\n","   [ 0.08040427 -0.05719299  0.52244115]\n","   [ 0.1933978  -0.08488399 -0.35864496]\n","   ...\n","   [ 0.11103451  0.21635047 -0.10174527]\n","   [ 0.03670978  0.01887075 -0.16557637]\n","   [ 0.03703855  0.18648647 -0.83710027]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.4686842]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-116.18364]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.75745255,  0.16926101,  2.6135843 ],\n","        [-0.6793432 ,  0.27294064,  2.6609108 ],\n","        [-0.6311551 ,  0.2619071 ,  2.675291  ],\n","        ...,\n","        [-0.00549685, -0.6706088 ,  2.2257862 ],\n","        [ 0.05542583, -0.6313535 ,  2.2705927 ],\n","        [ 0.07681969, -0.65080893,  2.2326982 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.04361098 -0.08022338 -0.184389  ]\n","   [ 0.08040427 -0.05719299  0.52244115]\n","   [ 0.1933978  -0.08488399 -0.35864496]\n","   ...\n","   [ 0.11103451  0.21635047 -0.10174527]\n","   [ 0.03670978  0.01887075 -0.16557637]\n","   [ 0.03703855  0.18648647 -0.83710027]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.36052966]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-108.41168]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.2069728 ,  1.0866628 , -0.28328848],\n","        [-2.064539  ,  1.2418758 , -0.18374112],\n","        [-2.039403  ,  1.2289953 , -0.18699913],\n","        ...,\n","        [-1.8195077 ,  0.6324293 , -1.3588428 ],\n","        [-1.7204233 ,  0.7002624 , -1.2682364 ],\n","        [-1.7048283 ,  0.7085957 , -1.3179564 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[-0.16937922  0.34966365 -0.25887498]\n","   [-0.04397081  0.22479343  0.01247927]\n","   [ 0.04551483  0.14844914 -0.74965364]\n","   ...\n","   [ 0.0788562  -0.08536159 -0.30202824]\n","   [ 0.06825142 -0.07230105  0.02317087]\n","   [ 0.10989682 -0.10044838  0.15258348]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.5550014]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-228.12387]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.6435571e+00, -1.3390240e-01, -2.6136630e+00],\n","        [-2.5365565e+00,  1.4806606e-02, -2.5296099e+00],\n","        [-2.4869497e+00,  2.3590848e-03, -2.5338240e+00],\n","        ...,\n","        [-2.4844728e+00, -5.9521788e-01, -2.8929045e+00],\n","        [-2.4099791e+00, -5.4521132e-01, -2.8060446e+00],\n","        [-2.3743315e+00, -5.3229368e-01, -2.8434379e+00]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[-0.16937922  0.34966365 -0.25887498]\n","   [-0.04397081  0.22479343  0.01247927]\n","   [ 0.04551483  0.14844914 -0.74965364]\n","   ...\n","   [ 0.0788562  -0.08536159 -0.30202824]\n","   [ 0.06825142 -0.07230105  0.02317087]\n","   [ 0.10989682 -0.10044838  0.15258348]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.5459224]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-301.1765]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.4070382 ,  1.8754512 ,  0.50650287],\n","        [-1.2839559 ,  2.0148766 ,  0.6019373 ],\n","        [-1.2566345 ,  2.0019302 ,  0.60285354],\n","        ...,\n","        [-0.847147  ,  0.6413161 ,  0.49111038],\n","        [-0.759674  ,  0.703637  ,  0.5674593 ],\n","        [-0.7333435 ,  0.6893007 ,  0.5207196 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[-0.16937922  0.34966365 -0.25887498]\n","   [-0.04397081  0.22479343  0.01247927]\n","   [ 0.04551483  0.14844914 -0.74965364]\n","   ...\n","   [ 0.0788562  -0.08536159 -0.30202824]\n","   [ 0.06825142 -0.07230105  0.02317087]\n","   [ 0.10989682 -0.10044838  0.15258348]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.5258186]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-185.42181]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-3.4486988 , -0.39052898, -1.5649313 ],\n","        [-3.3354514 , -0.27109057, -1.4785113 ],\n","        [-3.3078408 , -0.2785595 , -1.4818467 ],\n","        ...,\n","        [-3.0766308 , -1.0614111 , -1.3535895 ],\n","        [-2.998159  , -1.0067397 , -1.2670197 ],\n","        [-2.9756148 , -1.0056016 , -1.3211981 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[-0.16937922  0.34966365 -0.25887498]\n","   [-0.04397081  0.22479343  0.01247927]\n","   [ 0.04551483  0.14844914 -0.74965364]\n","   ...\n","   [ 0.0788562  -0.08536159 -0.30202824]\n","   [ 0.06825142 -0.07230105  0.02317087]\n","   [ 0.10989682 -0.10044838  0.15258348]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.4297396]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-294.0276]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-4.107778 ,  2.9532838, -2.6653478],\n","        [-3.993912 ,  3.0719998, -2.5785873],\n","        [-3.9733243,  3.071102 , -2.576507 ],\n","        ...,\n","        [-3.0945888,  1.941398 , -2.9471998],\n","        [-3.0231926,  1.9933512, -2.8792639],\n","        [-3.0058248,  2.0092318, -2.9111223]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[-0.16937922  0.34966365 -0.25887498]\n","   [-0.04397081  0.22479343  0.01247927]\n","   [ 0.04551483  0.14844914 -0.74965364]\n","   ...\n","   [ 0.0788562  -0.08536159 -0.30202824]\n","   [ 0.06825142 -0.07230105  0.02317087]\n","   [ 0.10989682 -0.10044838  0.15258348]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.02852869]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-64.18417]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-3.035381  ,  2.287704  , -1.0115572 ],\n","        [-2.9110756 ,  2.4405098 , -0.903397  ],\n","        [-2.8952224 ,  2.4399638 , -0.9052379 ],\n","        ...,\n","        [-2.1597416 ,  1.8657894 , -1.0262979 ],\n","        [-2.0702262 ,  1.9498158 , -0.9432637 ],\n","        [-2.059629  ,  1.9647619 , -0.95713353]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14164959  0.0366879  -0.65513206]\n","   [ 0.05618173  0.05921495 -0.2563793 ]\n","   [-0.03402415  0.25214013 -0.26643944]\n","   ...\n","   [ 0.17260805  0.10980847 -0.27665845]\n","   [ 0.11873414  0.19824822 -0.93202955]\n","   [ 0.0465838   0.24028358 -0.3994771 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.46413374]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-389.9889]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-3.5917358 ,  1.0502876 ,  0.5432889 ],\n","        [-3.4579399 ,  1.2252059 ,  0.6574217 ],\n","        [-3.42807   ,  1.2183968 ,  0.6477072 ],\n","        ...,\n","        [-2.9256558 ,  0.9782471 ,  0.6270873 ],\n","        [-2.829893  ,  1.0466549 ,  0.7078565 ],\n","        [-2.8189518 ,  1.0785238 ,  0.68674654]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14164959  0.0366879  -0.65513206]\n","   [ 0.05618173  0.05921495 -0.2563793 ]\n","   [-0.03402415  0.25214013 -0.26643944]\n","   ...\n","   [ 0.17260805  0.10980847 -0.27665845]\n","   [ 0.11873414  0.19824822 -0.93202955]\n","   [ 0.0465838   0.24028358 -0.3994771 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.3657776]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-348.5072]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-3.9153128 , -0.6464375 ,  0.34056884],\n","        [-3.7662785 , -0.47071242,  0.45814228],\n","        [-3.7468362 , -0.47083843,  0.4555546 ],\n","        ...,\n","        [-3.4043953 , -1.2867824 ,  0.77935344],\n","        [-3.2899365 , -1.2083312 ,  0.88128054],\n","        [-3.289508  , -1.1755502 ,  0.8483945 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14164959  0.0366879  -0.65513206]\n","   [ 0.05618173  0.05921495 -0.2563793 ]\n","   [-0.03402415  0.25214013 -0.26643944]\n","   ...\n","   [ 0.17260805  0.10980847 -0.27665845]\n","   [ 0.11873414  0.19824822 -0.93202955]\n","   [ 0.0465838   0.24028358 -0.3994771 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.854005]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-1034.6079]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.5059901 ,  2.6346126 , -0.6414986 ],\n","        [-0.3479212 ,  2.809241  , -0.52831453],\n","        [-0.3291354 ,  2.789455  , -0.51729226],\n","        ...,\n","        [ 0.01983707,  2.169214  , -0.7479318 ],\n","        [ 0.1401608 ,  2.2590523 , -0.6521686 ],\n","        [ 0.13739604,  2.28058   , -0.68509185]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14164959  0.0366879  -0.65513206]\n","   [ 0.05618173  0.05921495 -0.2563793 ]\n","   [-0.03402415  0.25214013 -0.26643944]\n","   ...\n","   [ 0.17260805  0.10980847 -0.27665845]\n","   [ 0.11873414  0.19824822 -0.93202955]\n","   [ 0.0465838   0.24028358 -0.3994771 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.22831202]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-219.11674]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-4.5480256 ,  1.5641664 , -0.16137259],\n","        [-4.407382  ,  1.75754   , -0.03805657],\n","        [-4.384153  ,  1.7493198 , -0.03369186],\n","        ...,\n","        [-3.409464  ,  1.0677288 , -0.33256057],\n","        [-3.2974572 ,  1.1499999 , -0.2247258 ],\n","        [-3.2863557 ,  1.179745  , -0.24869752]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14164959  0.0366879  -0.65513206]\n","   [ 0.05618173  0.05921495 -0.2563793 ]\n","   [-0.03402415  0.25214013 -0.26643944]\n","   ...\n","   [ 0.17260805  0.10980847 -0.27665845]\n","   [ 0.11873414  0.19824822 -0.93202955]\n","   [ 0.0465838   0.24028358 -0.3994771 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.860108]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-1606.7699]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.496716  ,  1.0401461 ,  0.17188978],\n","        [-2.297879  ,  1.2599639 ,  0.32305047],\n","        [-2.273574  ,  1.2456111 ,  0.33558893],\n","        ...,\n","        [-1.3398746 ,  0.8528846 ,  0.6217251 ],\n","        [-1.1942626 ,  0.9676975 ,  0.73344755],\n","        [-1.1718587 ,  1.0077493 ,  0.72379345]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14436464  0.12371741 -0.261418  ]\n","   [ 0.04233354 -0.03068457 -0.32516393]\n","   [-0.01966546  0.09395696 -0.44930646]\n","   ...\n","   [ 0.10106564 -0.04263135  0.5275554 ]\n","   [ 0.13841338  0.08235979  0.39298058]\n","   [ 0.16782773  0.05959858 -0.6631697 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.9886532]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-1024.2422]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-2.969902  ,  0.99052083,  0.88415253],\n","        [-2.8282218 ,  1.1570417 ,  1.0109226 ],\n","        [-2.806652  ,  1.1616045 ,  1.0069966 ],\n","        ...,\n","        [-2.24106   ,  0.51167774,  1.1509559 ],\n","        [-2.1430247 ,  0.5856573 ,  1.2494113 ],\n","        [-2.1216002 ,  0.62738895,  1.2429966 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14436464  0.12371741 -0.261418  ]\n","   [ 0.04233354 -0.03068457 -0.32516393]\n","   [-0.01966546  0.09395696 -0.44930646]\n","   ...\n","   [ 0.10106564 -0.04263135  0.5275554 ]\n","   [ 0.13841338  0.08235979  0.39298058]\n","   [ 0.16782773  0.05959858 -0.6631697 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.37456048]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-538.74817]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.76199543,  0.6442347 ,  2.96384   ],\n","        [-0.58674604,  0.85623336,  3.0976808 ],\n","        [-0.5706676 ,  0.83460724,  3.1104245 ],\n","        ...,\n","        [ 0.16155443,  0.45644665,  3.5281937 ],\n","        [ 0.29126292,  0.55711156,  3.627441  ],\n","        [ 0.29401565,  0.5832068 ,  3.6022437 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14436464  0.12371741 -0.261418  ]\n","   [ 0.04233354 -0.03068457 -0.32516393]\n","   [-0.01966546  0.09395696 -0.44930646]\n","   ...\n","   [ 0.10106564 -0.04263135  0.5275554 ]\n","   [ 0.13841338  0.08235979  0.39298058]\n","   [ 0.16782773  0.05959858 -0.6631697 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.65067613]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-718.14844]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-1.8679045, -1.6587828,  1.2777784],\n","        [-1.7290272, -1.4721195,  1.413291 ],\n","        [-1.6966053, -1.4852523,  1.403234 ],\n","        ...,\n","        [-1.7323682, -2.142846 ,  1.0941454],\n","        [-1.6340085, -2.0487928,  1.196758 ],\n","        [-1.5867858, -2.0136764,  1.1847656]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14436464  0.12371741 -0.261418  ]\n","   [ 0.04233354 -0.03068457 -0.32516393]\n","   [-0.01966546  0.09395696 -0.44930646]\n","   ...\n","   [ 0.10106564 -0.04263135  0.5275554 ]\n","   [ 0.13841338  0.08235979  0.39298058]\n","   [ 0.16782773  0.05959858 -0.6631697 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.32677257]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-355.38696]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.49818128,  1.4895394 ,  1.3001626 ],\n","        [-0.34822333,  1.6703367 ,  1.4204668 ],\n","        [-0.33695197,  1.6672822 ,  1.4180781 ],\n","        ...,\n","        [-0.16813317,  1.0043949 ,  1.028145  ],\n","        [-0.06554975,  1.0987048 ,  1.1206099 ],\n","        [-0.04266892,  1.1217655 ,  1.1143533 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.14436464  0.12371741 -0.261418  ]\n","   [ 0.04233354 -0.03068457 -0.32516393]\n","   [-0.01966546  0.09395696 -0.44930646]\n","   ...\n","   [ 0.10106564 -0.04263135  0.5275554 ]\n","   [ 0.13841338  0.08235979  0.39298058]\n","   [ 0.16782773  0.05959858 -0.6631697 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.95335925]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-620.34064]], dtype=float32)>]\n","WARNING:tensorflow:Gradients do not exist for variables ['bias6:0'] when minimizing the loss.\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[-0.92382836, -0.6182194 ,  2.6319675 ],\n","        [-0.79399997, -0.43263334,  2.747805  ],\n","        [-0.75666094, -0.44540262,  2.754959  ],\n","        ...,\n","        [-0.49087876, -0.9527454 ,  2.9612415 ],\n","        [-0.37898293, -0.8580242 ,  3.0474167 ],\n","        [-0.36194777, -0.8269478 ,  3.0438647 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.1011057  -0.05876088 -0.9662721 ]\n","   [ 0.15528381  0.03251173  0.5988837 ]\n","   [ 0.28975818 -0.17094652  0.13389377]\n","   ...\n","   [ 0.21870925  0.02623707 -0.92572296]\n","   [ 0.08260866  0.22834176 -0.7254324 ]\n","   [ 0.15164989  0.02220552 -0.7653203 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.15768838]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-137.25793]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[ 0.6286222 , -0.3065659 ,  0.24025741],\n","        [ 0.7878734 , -0.08620621,  0.36425114],\n","        [ 0.8294787 , -0.11054778,  0.38469446],\n","        ...,\n","        [ 1.1577585 , -0.19581096,  0.39069694],\n","        [ 1.2902288 , -0.08078432,  0.5055885 ],\n","        [ 1.3036221 , -0.04542454,  0.48465395]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.1011057  -0.05876088 -0.9662721 ]\n","   [ 0.15528381  0.03251173  0.5988837 ]\n","   [ 0.28975818 -0.17094652  0.13389377]\n","   ...\n","   [ 0.21870925  0.02623707 -0.92572296]\n","   [ 0.08260866  0.22834176 -0.7254324 ]\n","   [ 0.15164989  0.02220552 -0.7653203 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.570616]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-214.26389]], dtype=float32)>]\n","Fake Data [<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[ 1.3009647 ,  0.2796675 ,  2.007755  ],\n","        [ 1.4858723 ,  0.54764706,  2.1594436 ],\n","        [ 1.5250823 ,  0.49864805,  2.1755586 ],\n","        ...,\n","        [ 1.9138434 , -0.05664977,  2.207027  ],\n","        [ 2.057665  ,  0.09065111,  2.3337755 ],\n","        [ 2.1012552 ,  0.11814046,  2.3218043 ]]], dtype=float32)>]\n","Real Data tf.Tensor(\n","[[[[ 0.1011057  -0.05876088 -0.9662721 ]\n","   [ 0.15528381  0.03251173  0.5988837 ]\n","   [ 0.28975818 -0.17094652  0.13389377]\n","   ...\n","   [ 0.21870925  0.02623707 -0.92572296]\n","   [ 0.08260866  0.22834176 -0.7254324 ]\n","   [ 0.15164989  0.02220552 -0.7653203 ]]]], shape=(1, 1, 3072, 3), dtype=float32)\n","Alpha tf.Tensor([[[0.34857965]]], shape=(1, 1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-253.70155]], dtype=float32)>]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-f93149bf0f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmale_30_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_d_ckpt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_d_ckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_g_ckpt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_g_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-f3ffddf67475>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, save_d_ckpt, save_g_ckpt, load_g_ckpt, load_d_ckpt)\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0;31m# Need to get real points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mfake_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_example\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlatent_example\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mreal_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-f3ffddf67475>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0;31m# Need to get real points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mfake_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_example\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlatent_example\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mreal_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-d67730337afc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# print(self.gcn.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# print(feat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-7655251d51e7>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W_BRANCH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_branch\u001b[0m \u001b[0;31m# This is matrix multiplication between the first and second one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"branch shape after EXPAND DIMS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;31m# if self.print: print(\"-\" * 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   3257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3258\u001b[0m     \u001b[0;31m# TODO(apassos) remove _shape_tuple here when it is not needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3259\u001b[0;31m     \u001b[0ma_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3260\u001b[0m     \u001b[0mb_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqOWGoNTUp03","executionInfo":{"status":"ok","timestamp":1614823021890,"user_tz":300,"elapsed":2796,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"8edff58d-d8c0-4809-be02-6208558c5358"},"source":["args2 = real_args()\n","model2 = TreeGAN(args, male_30_train)\n","latent = [tf.random.uniform((1,1,  1, 96))]\n","points = model2.G(latent)\n","rslt = model2.D(points)\n","model2.G.load_weights(args2.load_g_ckpt)\n","model2.D.load_weights(args2.load_d_ckpt)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["layer num : 0\n","Model: \"sequential_109\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_139 (Dense)            (None, 960)               92160     \n","_________________________________________________________________\n","dense_140 (Dense)            (None, 256)               245760    \n","=================================================================\n","Total params: 337,920\n","Trainable params: 337,920\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  0 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_138_input'), name='dense_138_input', description=\"created by layer 'dense_138_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_139_input'), name='dense_139_input', description=\"created by layer 'dense_139_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","LAYER  0 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_21')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_21')>]\n","layer num : 1\n","Model: \"sequential_112\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_143 (Dense)            (None, 2560)              655360    \n","_________________________________________________________________\n","dense_144 (Dense)            (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  1 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_141_input'), name='dense_141_input', description=\"created by layer 'dense_141_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_142_input'), name='dense_142_input', description=\"created by layer 'dense_142_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_143_input'), name='dense_143_input', description=\"created by layer 'dense_143_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","LAYER  1 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_22')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_22')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_22')>]\n","layer num : 2\n","Model: \"sequential_116\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_148 (Dense)            (None, 2560)              655360    \n","_________________________________________________________________\n","dense_149 (Dense)            (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  2 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_145_input'), name='dense_145_input', description=\"created by layer 'dense_145_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_146_input'), name='dense_146_input', description=\"created by layer 'dense_146_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_147_input'), name='dense_147_input', description=\"created by layer 'dense_147_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_148_input'), name='dense_148_input', description=\"created by layer 'dense_148_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","LAYER  2 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_23')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_23')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_23')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_23')>]\n","layer num : 3\n","Model: \"sequential_121\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_154 (Dense)            (None, 2560)              655360    \n","_________________________________________________________________\n","dense_155 (Dense)            (None, 128)               327680    \n","=================================================================\n","Total params: 983,040\n","Trainable params: 983,040\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  3 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_150_input'), name='dense_150_input', description=\"created by layer 'dense_150_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_151_input'), name='dense_151_input', description=\"created by layer 'dense_151_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_152_input'), name='dense_152_input', description=\"created by layer 'dense_152_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_153_input'), name='dense_153_input', description=\"created by layer 'dense_153_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_154_input'), name='dense_154_input', description=\"created by layer 'dense_154_input'\"), but it was called on an input with incompatible shape (1, 12, 256).\n","LAYER  3 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_24')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_24')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_24')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_24')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_24')>]\n","layer num : 4\n","Model: \"sequential_127\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_161 (Dense)            (None, 1280)              163840    \n","_________________________________________________________________\n","dense_162 (Dense)            (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  4 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_156_input'), name='dense_156_input', description=\"created by layer 'dense_156_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_157_input'), name='dense_157_input', description=\"created by layer 'dense_157_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_158_input'), name='dense_158_input', description=\"created by layer 'dense_158_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_159_input'), name='dense_159_input', description=\"created by layer 'dense_159_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_160_input'), name='dense_160_input', description=\"created by layer 'dense_160_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_161_input'), name='dense_161_input', description=\"created by layer 'dense_161_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","LAYER  4 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_25')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_25')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_25')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_25')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_25')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_25')>]\n","layer num : 5\n","Model: \"sequential_134\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_169 (Dense)            (None, 1280)              163840    \n","_________________________________________________________________\n","dense_170 (Dense)            (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  5 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_163_input'), name='dense_163_input', description=\"created by layer 'dense_163_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_164_input'), name='dense_164_input', description=\"created by layer 'dense_164_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_165_input'), name='dense_165_input', description=\"created by layer 'dense_165_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_166_input'), name='dense_166_input', description=\"created by layer 'dense_166_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_167_input'), name='dense_167_input', description=\"created by layer 'dense_167_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_168_input'), name='dense_168_input', description=\"created by layer 'dense_168_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_169_input'), name='dense_169_input', description=\"created by layer 'dense_169_input'\"), but it was called on an input with incompatible shape (1, 48, 128).\n","LAYER  5 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_26')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_26')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_26')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_26')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_26')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_26')>, <KerasTensor: shape=(1, 48, 128) dtype=float32 (created by layer 'tree_gcn_26')>]\n","layer num : 6\n","Model: \"sequential_142\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_178 (Dense)            (None, 1280)              163840    \n","_________________________________________________________________\n","dense_179 (Dense)            (None, 3)                 3840      \n","=================================================================\n","Total params: 167,680\n","Trainable params: 167,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  6 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_171_input'), name='dense_171_input', description=\"created by layer 'dense_171_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_172_input'), name='dense_172_input', description=\"created by layer 'dense_172_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_173_input'), name='dense_173_input', description=\"created by layer 'dense_173_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_174_input'), name='dense_174_input', description=\"created by layer 'dense_174_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_175_input'), name='dense_175_input', description=\"created by layer 'dense_175_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_176_input'), name='dense_176_input', description=\"created by layer 'dense_176_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_177_input'), name='dense_177_input', description=\"created by layer 'dense_177_input'\"), but it was called on an input with incompatible shape (1, 48, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_178_input'), name='dense_178_input', description=\"created by layer 'dense_178_input'\"), but it was called on an input with incompatible shape (1, 3072, 128).\n","LAYER  6 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_27')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_27')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_27')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_27')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_27')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_27')>, <KerasTensor: shape=(1, 48, 128) dtype=float32 (created by layer 'tree_gcn_27')>, <KerasTensor: shape=(1, 3072, 3) dtype=float32 (created by layer 'tree_gcn_27')>]\n","Network Prepared\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPF2lFy6pe_l","executionInfo":{"status":"ok","timestamp":1614801369517,"user_tz":300,"elapsed":1475,"user":{"displayName":"Spencer Hill","photoUrl":"","userId":"06492296408916193265"}},"outputId":"62ccb68e-8aba-4506-8a48-f67b7ee7dbb5"},"source":["print(\"Model1\", model.G.trainable_weights)\n","print(\"Model2\", model2.G.trainable_weights)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","          0.05172013,  0.05439574, -0.04262165,  0.03123333,\n","         -0.04035519, -0.0337803 ,  0.01901002,  0.05383895,\n","          0.00401743,  0.05892237,  0.05317504, -0.05333544,\n","          0.04583832, -0.05961495,  0.03239198,  0.00641273,\n","         -0.01757636, -0.04225505,  0.0095505 , -0.04096653,\n","         -0.02104567,  0.03744185, -0.03372666, -0.01346496,\n","         -0.03107395,  0.01474391, -0.05553752,  0.04932202,\n","         -0.04188412, -0.0544083 ,  0.01077228, -0.0272481 ],\n","        [-0.01725648, -0.00563066, -0.03834386, -0.06216302,\n","         -0.03096004,  0.04422218,  0.00207201,  0.04765581,\n","          0.06065127, -0.04629595,  0.0605631 ,  0.03321254,\n","         -0.0580611 ,  0.00969821,  0.02579394, -0.03662082,\n","          0.03097125, -0.03377077, -0.04514841, -0.04274591,\n","          0.0244335 ,  0.04024693, -0.0153524 , -0.05479556,\n","         -0.06239074, -0.01629759, -0.01308654,  0.02694043,\n","          0.01374841, -0.02578443,  0.0392315 , -0.00080083,\n","          0.05309027, -0.03109206,  0.01637409,  0.00410225,\n","         -0.05167555,  0.00981575,  0.01505969,  0.04323092,\n","         -0.00647129, -0.03960614,  0.01780731, -0.02436424,\n","         -0.00862525,  0.01209195, -0.05571   ,  0.05703761,\n","         -0.02201812,  0.02966912, -0.03246683,  0.02417113,\n","          0.04419063, -0.04056788,  0.03141976,  0.00466466,\n","         -0.02898107, -0.0050794 ,  0.05872126, -0.04181157,\n","         -0.05656622, -0.01227034, -0.02818225, -0.06348162,\n","          0.04522953, -0.00302819,  0.05027967, -0.02119636,\n","          0.05319335, -0.01491634,  0.02049506,  0.0146432 ,\n","         -0.03723869,  0.03416541, -0.06404492, -0.00024009,\n","          0.05006101,  0.01066707,  0.01332225,  0.04250252,\n","         -0.03847496,  0.03464805,  0.01385943,  0.00267359,\n","         -0.06179352,  0.0211281 , -0.02208113, -0.02078665,\n","         -0.01386622,  0.03602402, -0.04880543, -0.03834594,\n","         -0.02013259, -0.01538331, -0.04220078, -0.06143294,\n","          0.02335986,  0.03193076, -0.04695211, -0.03955469,\n","          0.05070663,  0.00833515,  0.05619171, -0.03427547,\n","         -0.02156251,  0.06211275,  0.02734596,  0.02139066,\n","          0.03578303,  0.04239621, -0.05355034, -0.04428725,\n","         -0.02287129,  0.00368285,  0.03894898,  0.02582019,\n","         -0.05662815,  0.02795697, -0.04158449, -0.04429867,\n","          0.06120475,  0.05826214,  0.0011826 ,  0.04632804,\n","          0.01059381,  0.05868853, -0.02916252,  0.05679736,\n","          0.0060181 , -0.03933907, -0.05202184,  0.03766335,\n","          0.03060506, -0.05754177,  0.05106151,  0.0125281 ,\n","         -0.03471197,  0.01964708,  0.00122603, -0.02175792,\n","         -0.01123021, -0.02449585,  0.06088763,  0.05205509,\n","          0.02215676,  0.01221266,  0.00779143,  0.04655312,\n","          0.01184078, -0.0422303 ,  0.04322788, -0.01250899,\n","          0.05156768, -0.05975584,  0.06081637,  0.01249517,\n","          0.0504831 ,  0.02344519,  0.03221968,  0.00393211,\n","         -0.04207132, -0.04841089, -0.02405739, -0.01848624,\n","         -0.04330851,  0.0434767 , -0.00090254, -0.02605934,\n","          0.03979011,  0.021052  , -0.03650683, -0.00339518,\n","         -0.00407155,  0.0259764 , -0.05952606, -0.01108627,\n","          0.00747609,  0.04408707, -0.01127222,  0.00045466,\n","         -0.03686358, -0.03652939, -0.03913738, -0.00568352,\n","         -0.03593649, -0.05727329,  0.0117813 ,  0.05466966,\n","          0.0068629 ,  0.02531727, -0.00802622, -0.04416739,\n","          0.02105649, -0.00909224, -0.05634666,  0.01801453,\n","          0.00488559, -0.00934478, -0.00352976, -0.05776354,\n","         -0.05719715, -0.0356518 , -0.05236075, -0.047247  ,\n","          0.04660604, -0.03862333, -0.01073518, -0.04664015,\n","         -0.04126133, -0.05286197, -0.04059696,  0.0083252 ,\n","          0.01680423,  0.02009842, -0.00017785,  0.01781044,\n","          0.03323563, -0.02378669,  0.0330603 ,  0.03679267,\n","         -0.01293233, -0.04174531,  0.03418037, -0.00779217,\n","         -0.00777221, -0.05761841,  0.03986576,  0.0132005 ,\n","         -0.01667752, -0.04121991,  0.02782422,  0.04780002,\n","          0.01969668,  0.02266746, -0.05643562, -0.00673726,\n","         -0.06357911, -0.06133455,  0.00020296, -0.00236826,\n","         -0.01223738, -0.03918181,  0.04606792, -0.00179956,\n","         -0.05431848,  0.01494424, -0.00946932,  0.02107131,\n","          0.04174285,  0.03432243, -0.01378136,  0.01696687,\n","         -0.02373981,  0.05567751,  0.03354984,  0.00029264]]],\n","      dtype=float32)>, <tf.Variable 'dense_99/kernel:0' shape=(96, 256) dtype=float32, numpy=\n","array([[-0.09739899, -0.13025889, -0.12035018, ...,  0.01140693,\n","         0.11692663,  0.06106129],\n","       [ 0.04116393,  0.0860467 ,  0.12065399, ..., -0.05844325,\n","        -0.00180621, -0.06195508],\n","       [ 0.1104893 ,  0.04502698,  0.11505762, ...,  0.04387947,\n","        -0.07242703, -0.10434368],\n","       ...,\n","       [ 0.06440482, -0.09411471, -0.05707778, ...,  0.0490198 ,\n","        -0.09479151, -0.13075277],\n","       [ 0.12688506,  0.02353051, -0.10353474, ...,  0.03603563,\n","        -0.01809956, -0.08878884],\n","       [-0.08376311,  0.04773676,  0.03333021, ..., -0.04961055,\n","         0.13005574, -0.09731243]], dtype=float32)>, <tf.Variable 'dense_100/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[-0.10017354,  0.06170798,  0.03300967, ..., -0.0652581 ,\n","         0.02444748, -0.08531592],\n","       [ 0.03994995, -0.1023453 ,  0.04360989, ...,  0.0819817 ,\n","         0.10115474,  0.04971376],\n","       [ 0.08005267,  0.10381325, -0.00606651, ..., -0.02003239,\n","        -0.02159635, -0.10567459],\n","       ...,\n","       [-0.05033389, -0.06906796, -0.04942266, ...,  0.05176851,\n","         0.10472336,  0.03805351],\n","       [ 0.02985754, -0.08652861,  0.07706703, ..., -0.01049207,\n","         0.05218913,  0.05885396],\n","       [ 0.06581765,  0.06069366, -0.05695751, ..., -0.09238882,\n","        -0.01371567,  0.06152188]], dtype=float32)>, <tf.Variable 'dense_101/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[-0.06169   , -0.00556312, -0.02917129, ...,  0.01605481,\n","         0.03414463,  0.06672268],\n","       [-0.07668096,  0.07880238,  0.06145543, ..., -0.08839779,\n","         0.0829457 ,  0.03354944],\n","       [ 0.00649484,  0.04210104,  0.07108685, ...,  0.0085452 ,\n","         0.00630143,  0.04108372],\n","       ...,\n","       [-0.00143533, -0.01287334,  0.02982481, ..., -0.08979022,\n","         0.05548995, -0.09838253],\n","       [ 0.09979702, -0.09753756,  0.02995286, ..., -0.01984732,\n","         0.06048414,  0.00892361],\n","       [ 0.07349636, -0.1021708 , -0.0772859 , ..., -0.08715671,\n","        -0.08637319,  0.08200949]], dtype=float32)>, <tf.Variable 'dense_102/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[-0.01865826,  0.03591511, -0.00663586, ...,  0.02568613,\n","         0.0062669 , -0.03475317],\n","       [ 0.0050615 , -0.02637897,  0.03077742, ..., -0.0084155 ,\n","         0.03908883, -0.03415943],\n","       [ 0.00257031, -0.01221294, -0.01138738, ...,  0.00703126,\n","         0.00835627, -0.02295435],\n","       ...,\n","       [-0.04451935, -0.03345425, -0.04063169, ...,  0.03960349,\n","         0.02758398,  0.01987173],\n","       [-0.04483561, -0.00652729,  0.01642455, ..., -0.03406894,\n","        -0.04584883,  0.02648583],\n","       [-0.01060003,  0.02630966, -0.04399138, ..., -0.01485901,\n","        -0.03560781, -0.02267521]], dtype=float32)>, <tf.Variable 'dense_103/kernel:0' shape=(2560, 256) dtype=float32, numpy=\n","array([[-0.00514854, -0.01890207, -0.00340231, ..., -0.03817935,\n","         0.0113937 ,  0.04015946],\n","       [ 0.01891679, -0.02643198, -0.00306967, ..., -0.03373956,\n","        -0.001579  , -0.01085821],\n","       [ 0.03359025, -0.01329856,  0.0211578 , ..., -0.00391524,\n","        -0.01876942,  0.0223019 ],\n","       ...,\n","       [ 0.03369665, -0.00447073, -0.00511747, ..., -0.04070548,\n","        -0.04139595, -0.01958253],\n","       [-0.01237512,  0.02819242, -0.0020678 , ...,  0.00234072,\n","         0.03344894, -0.0060506 ],\n","       [-0.03429585, -0.03466303,  0.03272067, ...,  0.01996873,\n","         0.02948453,  0.00469905]], dtype=float32)>, <tf.Variable 'branch3:0' shape=(4, 256, 768) dtype=float32, numpy=\n","array([[[-0.0360182 ,  0.03167838,  0.02948195, ..., -0.02782009,\n","          0.0017646 , -0.00352701],\n","        [ 0.02910357, -0.0300224 ,  0.01505985, ..., -0.02375098,\n","          0.01048895,  0.02438298],\n","        [-0.02841219, -0.03677503, -0.00797758, ..., -0.01000279,\n","          0.02180456, -0.01718596],\n","        ...,\n","        [ 0.01615583, -0.01954172,  0.01344432, ..., -0.02512797,\n","          0.03972906, -0.0402951 ],\n","        [-0.0261596 , -0.02362129, -0.00718993, ..., -0.01104768,\n","         -0.01643074, -0.01199542],\n","        [-0.02526634, -0.03084963,  0.00899966, ..., -0.00120709,\n","          0.02699381, -0.00108439]],\n","\n","       [[ 0.0193261 ,  0.03893007,  0.03001237, ...,  0.00854367,\n","         -0.00949517, -0.0391679 ],\n","        [ 0.02549387, -0.02370414,  0.00250519, ..., -0.02683023,\n","          0.00211091,  0.02245214],\n","        [ 0.02360766,  0.01583728, -0.03338089, ...,  0.0302862 ,\n","         -0.00881903, -0.03490588],\n","        ...,\n","        [-0.02958889,  0.03954687,  0.00987176, ..., -0.02054532,\n","          0.01649158, -0.02701342],\n","        [-0.00780359,  0.0233427 ,  0.01430223, ..., -0.00037523,\n","          0.02888579,  0.02478104],\n","        [-0.01797616, -0.0337058 , -0.01407617, ...,  0.02537994,\n","         -0.02691267,  0.01013145]],\n","\n","       [[ 0.01110279,  0.02078325, -0.00953118, ...,  0.01613094,\n","          0.00061624, -0.01709788],\n","        [ 0.02017759,  0.03995953, -0.00167558, ...,  0.01765514,\n","         -0.02460291, -0.03048488],\n","        [-0.00782889, -0.00889615,  0.02513274, ...,  0.03332903,\n","         -0.01404201, -0.0280965 ],\n","        ...,\n","        [-0.00878078, -0.00999576, -0.02074144, ..., -0.01696743,\n","         -0.02598067, -0.03347441],\n","        [-0.01383718,  0.02638197,  0.0198249 , ...,  0.01636848,\n","         -0.0171539 ,  0.0228622 ],\n","        [-0.01081507, -0.01750443, -0.03098853, ...,  0.00921757,\n","         -0.01959517, -0.00329225]],\n","\n","       [[ 0.03198532,  0.02401438, -0.03589596, ..., -0.0316892 ,\n","          0.02669718,  0.00062877],\n","        [ 0.025903  , -0.03701739, -0.01387738, ..., -0.00236414,\n","          0.0339319 , -0.01943348],\n","        [ 0.02260599,  0.03120217,  0.0086136 , ...,  0.03364794,\n","         -0.02730314, -0.03719779],\n","        ...,\n","        [ 0.03092322,  0.01920233, -0.0020004 , ..., -0.03062234,\n","         -0.01405834,  0.00141632],\n","        [-0.0004653 , -0.0246098 ,  0.00204756, ..., -0.01349667,\n","         -0.03561966, -0.02684077],\n","        [-0.00287339,  0.00765637,  0.01138186, ...,  0.01494616,\n","         -0.03246992,  0.03993271]]], dtype=float32)>, <tf.Variable 'bias3:0' shape=(1, 3, 128) dtype=float32, numpy=\n","array([[[ 0.04634103,  0.02720437,  0.01193692,  0.05490629,\n","         -0.00950426,  0.0335086 ,  0.05847668,  0.07229882,\n","          0.04334614, -0.01194647, -0.03823023,  0.06693035,\n","          0.08136687, -0.00657124, -0.02250013,  0.0447565 ,\n","          0.03495789,  0.05493969, -0.00771009,  0.0161814 ,\n","         -0.01293831,  0.00468238, -0.02560127,  0.00834316,\n","          0.04510961,  0.01450809, -0.05424883, -0.01593298,\n","         -0.02744883, -0.00574748,  0.03731198, -0.00974939,\n","         -0.07990453,  0.04128021, -0.03395059, -0.04887639,\n","          0.0828681 ,  0.02079985, -0.01176505, -0.01294739,\n","         -0.06504694,  0.05320704, -0.02277394, -0.07281233,\n","          0.08157752,  0.03439125,  0.04127866, -0.04441702,\n","         -0.00118872,  0.00598545, -0.05326395, -0.00293707,\n","         -0.07770939, -0.03538711,  0.00820873,  0.07309026,\n","          0.02813836, -0.06562829,  0.02993288,  0.00526367,\n","         -0.02140023,  0.02978454,  0.06855702, -0.05318634,\n","          0.03941833,  0.04425956,  0.04461828,  0.08778622,\n","          0.03007651, -0.08875619,  0.02179649,  0.04207109,\n","          0.00826595, -0.08382361,  0.03683051, -0.06936184,\n","          0.0291544 , -0.07314449, -0.04462419,  0.02674854,\n","         -0.06917435,  0.06930309, -0.05467991, -0.06871071,\n","          0.01451224,  0.05889408,  0.06770641,  0.04400721,\n","          0.03033103,  0.06304793, -0.02310013,  0.03838625,\n","         -0.05357364,  0.02235715, -0.07741695, -0.04593771,\n","         -0.08353613,  0.07637538,  0.07203849, -0.00463704,\n","         -0.02744108, -0.07593668,  0.0397174 , -0.04239862,\n","          0.02022567,  0.00917404, -0.08786801,  0.00982738,\n","          0.01960512,  0.03229909, -0.07260887, -0.08492571,\n","         -0.08052768,  0.04240155, -0.03632296, -0.04839914,\n","          0.05053069,  0.04802104, -0.04333637, -0.0866385 ,\n","         -0.02904262,  0.04917845,  0.04680907, -0.05321964,\n","          0.03934541, -0.06722732, -0.05268626, -0.07617298],\n","        [-0.08957338, -0.01759384,  0.04449338,  0.00972872,\n","          0.00912703,  0.06445634,  0.08286131, -0.01384744,\n","          0.03032115, -0.07375181, -0.06075938, -0.03553306,\n","         -0.00195502, -0.07104284, -0.08759425,  0.06392097,\n","          0.05070242, -0.03780909, -0.03747442, -0.01522202,\n","          0.05087367, -0.04858892,  0.03148258,  0.01209378,\n","         -0.0637251 ,  0.06453532, -0.01365125,  0.00755405,\n","         -0.02764228, -0.07899664, -0.03168031, -0.08166769,\n","         -0.08700135, -0.08337002, -0.0696567 , -0.04174385,\n","          0.05158224, -0.0022421 ,  0.0155097 ,  0.05963966,\n","          0.05425929, -0.06886198, -0.00348797, -0.01370661,\n","         -0.04743099,  0.07430899,  0.06227495, -0.00039534,\n","         -0.03009494, -0.06192334,  0.06961071,  0.05828529,\n","          0.01247398, -0.07475799,  0.04574407,  0.06988733,\n","          0.08678797,  0.06043648,  0.00639344, -0.07784368,\n","         -0.07919414,  0.08438872,  0.01425503,  0.0418306 ,\n","          0.00974876,  0.04251967, -0.04171151, -0.02627138,\n","          0.07774816, -0.08998163,  0.00404744, -0.03735642,\n","         -0.06809098,  0.0583815 , -0.0684193 , -0.04105501,\n","          0.08136009, -0.05519766,  0.05384197, -0.08748513,\n","          0.06120737,  0.08425508, -0.07701072,  0.0193243 ,\n","         -0.04506827,  0.01413996, -0.02105198,  0.01715542,\n","          0.03169798,  0.07005164, -0.03860802,  0.00667487,\n","         -0.02244732, -0.02406092,  0.03987132, -0.0825977 ,\n","          0.07317249, -0.04847979, -0.0014075 ,  0.02734903,\n","          0.03234548,  0.00305505,  0.03536218,  0.03327337,\n","          0.07676686,  0.07041183,  0.02121424, -0.08311057,\n","          0.04115425,  0.00363699, -0.00113157, -0.07965519,\n","         -0.0825571 ,  0.04620492, -0.03804759,  0.0284082 ,\n","          0.05559434,  0.0273691 ,  0.01626934, -0.0644104 ,\n","         -0.00237276,  0.02688436,  0.05270332, -0.02574918,\n","          0.06861866,  0.03605694,  0.07237253,  0.03559139],\n","        [ 0.00077839, -0.02358013, -0.05667056,  0.05504069,\n","         -0.04064786, -0.05010494, -0.06448337, -0.00200351,\n","          0.0040057 , -0.04069502,  0.07024623, -0.04769859,\n","          0.05624159,  0.01892546, -0.04534045,  0.0032221 ,\n","         -0.01715143,  0.08065107, -0.03382434,  0.03228641,\n","         -0.0303791 , -0.03494138,  0.04603163,  0.08166162,\n","         -0.08382702, -0.08718895,  0.00660766, -0.02891628,\n","         -0.02716233,  0.0652825 ,  0.01497349,  0.04509449,\n","         -0.07281428, -0.02359448,  0.03603888, -0.05002807,\n","         -0.08870869,  0.01195987, -0.06151645, -0.07999817,\n","         -0.01489216,  0.02474531, -0.00609919, -0.07294287,\n","         -0.00535793,  0.0022754 ,  0.08449177,  0.07552891,\n","          0.0366312 ,  0.02202318,  0.00728292, -0.07307369,\n","         -0.04597808, -0.03508451,  0.01173956,  0.0557733 ,\n","         -0.0123817 , -0.0157373 ,  0.01351829,  0.00087411,\n","          0.08145143,  0.07980371, -0.0404509 ,  0.01113257,\n","         -0.04347964,  0.02800928, -0.05947873,  0.02096776,\n","          0.05444201, -0.02722191, -0.02550862, -0.07888101,\n","         -0.00413837,  0.03953076, -0.05386929,  0.00862681,\n","          0.01260093, -0.05786153,  0.06636225, -0.06394072,\n","          0.00117445, -0.0283879 ,  0.05072307, -0.06328954,\n","         -0.07107162, -0.03466193,  0.08280484, -0.01347031,\n","          0.03537709,  0.03765247,  0.08381937,  0.05702018,\n","          0.04489143, -0.05339779,  0.01388083,  0.02132739,\n","         -0.02020671,  0.05212324,  0.01949212, -0.03228089,\n","          0.04062882,  0.0265575 , -0.02844628,  0.03846696,\n","         -0.06570923, -0.05090246, -0.06931178,  0.07926259,\n","          0.00377478,  0.00010859, -0.01021696,  0.03262249,\n","          0.04303188, -0.07001013, -0.01589519,  0.08472649,\n","          0.06505841,  0.0872607 , -0.05272499, -0.07033797,\n","          0.0758028 , -0.07769713, -0.00631334,  0.0675677 ,\n","         -0.08300004,  0.00668959, -0.0529277 ,  0.01165446]]],\n","      dtype=float32)>, <tf.Variable 'dense_104/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[-0.16347922,  0.15881972,  0.14321025, ...,  0.05843497,\n","         0.01205291,  0.02381265],\n","       [ 0.09456233, -0.10315389, -0.0422026 , ..., -0.14538985,\n","         0.16179158,  0.03355367],\n","       [-0.0877778 , -0.05910852, -0.03341557, ...,  0.03685634,\n","        -0.13591133, -0.09362165],\n","       ...,\n","       [-0.07874357,  0.12425136, -0.05547371, ..., -0.10754333,\n","         0.00412877,  0.01326108],\n","       [-0.03151532,  0.04779917, -0.12773964, ...,  0.11068282,\n","        -0.0126535 ,  0.05803245],\n","       [ 0.1581596 , -0.02044338, -0.06437758, ..., -0.04121003,\n","         0.11861183,  0.08296925]], dtype=float32)>, <tf.Variable 'dense_105/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.09804297,  0.07734857,  0.07218462, ...,  0.08147936,\n","        -0.04991472,  0.05239867],\n","       [ 0.07232708, -0.09070755,  0.03022682, ...,  0.1183114 ,\n","         0.08786003, -0.02719322],\n","       [-0.05403371,  0.10961819, -0.10301477, ...,  0.0888712 ,\n","         0.11113347, -0.04304576],\n","       ...,\n","       [-0.03021172, -0.03499157, -0.07959042, ..., -0.10731421,\n","        -0.09665866, -0.09004173],\n","       [-0.05037158,  0.06071015, -0.10893636, ...,  0.06505703,\n","         0.04775197, -0.01936116],\n","       [-0.01742276,  0.0898591 , -0.04717904, ..., -0.00794149,\n","         0.10113354,  0.01831636]], dtype=float32)>, <tf.Variable 'dense_106/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.06555793,  0.05088718,  0.02909757, ..., -0.07611503,\n","        -0.02340306, -0.10544302],\n","       [ 0.06433959,  0.02902587, -0.05736057, ...,  0.07196891,\n","        -0.10544583,  0.0580183 ],\n","       [-0.06177134,  0.00279943, -0.12050352, ...,  0.04546612,\n","        -0.07727043,  0.02968721],\n","       ...,\n","       [-0.10456152, -0.01041036, -0.00116802, ...,  0.11377615,\n","         0.01712133, -0.09812535],\n","       [ 0.05147739,  0.12057787,  0.09183155, ...,  0.08015604,\n","        -0.10236701,  0.08648501],\n","       [-0.11719682, -0.07241688, -0.09776108, ..., -0.0514675 ,\n","         0.0332412 , -0.10067768]], dtype=float32)>, <tf.Variable 'dense_107/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.01584605, -0.04202705, -0.10211115, ..., -0.0346657 ,\n","        -0.10507312, -0.1134552 ],\n","       [ 0.05931932, -0.10490438, -0.0799766 , ...,  0.07762915,\n","         0.07517513, -0.1235584 ],\n","       [-0.00271299,  0.12682208, -0.0411957 , ...,  0.10389288,\n","         0.07175117, -0.00119323],\n","       ...,\n","       [-0.10994293,  0.10476667,  0.05219891, ...,  0.03771931,\n","        -0.03321373, -0.0970529 ],\n","       [ 0.0247531 ,  0.0897017 , -0.05557263, ...,  0.10439144,\n","         0.11638498,  0.11946429],\n","       [-0.09754598, -0.03395153,  0.00372511, ..., -0.01200754,\n","         0.0345344 , -0.0069804 ]], dtype=float32)>, <tf.Variable 'dense_108/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[ 3.6947440e-02, -2.2205027e-02, -3.5775308e-02, ...,\n","         3.3728674e-02,  2.3472955e-02, -2.9407632e-02],\n","       [ 3.7115134e-02,  2.5667431e-02, -4.2174201e-02, ...,\n","         2.6915964e-02, -3.1727392e-05,  1.8796213e-02],\n","       [ 1.9526908e-02, -8.5559171e-03,  1.8129146e-02, ...,\n","         1.6757390e-02,  5.4425267e-03, -1.3568093e-02],\n","       ...,\n","       [ 3.0788528e-03,  1.3847849e-02, -1.1675373e-03, ...,\n","         2.1138765e-02, -3.5713397e-02,  1.9685421e-02],\n","       [ 4.3511294e-02,  3.7984636e-02,  5.9824288e-03, ...,\n","         3.2064512e-02,  8.5421605e-03, -2.6535429e-02],\n","       [ 3.5655592e-02,  1.0259589e-02,  1.2044815e-02, ...,\n","        -3.4240149e-02,  8.4811468e-03,  2.6588632e-02]], dtype=float32)>, <tf.Variable 'dense_109/kernel:0' shape=(2560, 128) dtype=float32, numpy=\n","array([[-0.03410215, -0.00262801, -0.03173272, ...,  0.0319635 ,\n","         0.02070226,  0.02342524],\n","       [-0.04196122, -0.03485041, -0.00430008, ...,  0.03485794,\n","        -0.04429918,  0.01579418],\n","       [-0.04315728,  0.03398854,  0.015163  , ..., -0.01444802,\n","        -0.03358512,  0.00365347],\n","       ...,\n","       [-0.03159091,  0.01830254, -0.03183593, ..., -0.0113064 ,\n","        -0.02308972, -0.04385507],\n","       [-0.04742112, -0.03067945, -0.03679103, ...,  0.0461803 ,\n","        -0.00365058,  0.01336197],\n","       [ 0.02158434,  0.02522087,  0.04690465, ...,  0.00434849,\n","        -0.00678937,  0.00868308]], dtype=float32)>, <tf.Variable 'branch4:0' shape=(12, 128, 256) dtype=float32, numpy=\n","array([[[ 0.01824263, -0.0222909 ,  0.00427048, ..., -0.00268571,\n","         -0.02081816,  0.0094406 ],\n","        [-0.01122868,  0.01596772, -0.03889522, ..., -0.02057607,\n","         -0.03294352, -0.01034914],\n","        [-0.00901121, -0.00829908, -0.00151639, ..., -0.02816658,\n","         -0.00135389, -0.03198109],\n","        ...,\n","        [ 0.02705837,  0.02232918,  0.02633806, ..., -0.02240211,\n","         -0.03001767, -0.01768824],\n","        [-0.01220298, -0.02708496,  0.02611938, ...,  0.00967381,\n","          0.01338903, -0.02197117],\n","        [ 0.03307619, -0.01872401, -0.03308048, ...,  0.00211117,\n","          0.00503429, -0.02640052]],\n","\n","       [[ 0.00079889, -0.00610109, -0.02544001, ..., -0.00460366,\n","         -0.00039667, -0.00549247],\n","        [ 0.02346935, -0.01582175, -0.01929615, ..., -0.02779011,\n","          0.01169899,  0.0152034 ],\n","        [-0.00862917,  0.01631043, -0.02464305, ...,  0.03741077,\n","          0.02323742,  0.01925473],\n","        ...,\n","        [-0.01381266, -0.03494549, -0.02333942, ..., -0.0267597 ,\n","          0.0302248 ,  0.02599424],\n","        [ 0.0223765 , -0.0293018 , -0.02678884, ...,  0.02976532,\n","          0.02776053, -0.03328723],\n","        [-0.00679354,  0.02209476, -0.00334913, ..., -0.0249862 ,\n","         -0.02997001, -0.01902629]],\n","\n","       [[ 0.02660733,  0.03277982, -0.03405818, ...,  0.01690887,\n","         -0.00983113,  0.00903367],\n","        [-0.02577451,  0.01082455, -0.02432298, ...,  0.03147394,\n","         -0.01089102, -0.01508743],\n","        [ 0.01866594, -0.02650203,  0.02260492, ...,  0.03044179,\n","         -0.01109071,  0.01046931],\n","        ...,\n","        [ 0.02752049,  0.0195909 ,  0.03383117, ..., -0.00605342,\n","          0.02075533,  0.02712419],\n","        [-0.0217509 , -0.00985512, -0.03377155, ...,  0.00075637,\n","         -0.01001892,  0.01596759],\n","        [-0.00554483,  0.01478249, -0.00438747, ...,  0.00466364,\n","         -0.02426064,  0.01113267]],\n","\n","       ...,\n","\n","       [[-0.01424357,  0.00347049,  0.01243616, ..., -0.02842536,\n","         -0.02441693,  0.03183663],\n","        [-0.03452813, -0.01625304, -0.01108299, ..., -0.02873199,\n","          0.00349208,  0.02920889],\n","        [-0.03412174,  0.00928347, -0.0038507 , ...,  0.00210332,\n","          0.02639857,  0.00734685],\n","        ...,\n","        [ 0.00548953,  0.01132893, -0.01647513, ...,  0.02170431,\n","         -0.0020344 , -0.00671037],\n","        [-0.02785835,  0.02867817,  0.00864267, ..., -0.0077763 ,\n","          0.02689257,  0.02965877],\n","        [ 0.00626947,  0.02500101, -0.02514628, ...,  0.01839215,\n","          0.03442889, -0.03096977]],\n","\n","       [[ 0.00034442,  0.01888928, -0.02968132, ..., -0.01262942,\n","          0.01043506,  0.00403053],\n","        [-0.00649132, -0.00926191, -0.03559067, ...,  0.03051866,\n","          0.02092627, -0.03027984],\n","        [ 0.0152873 , -0.01306761, -0.0339436 , ..., -0.01750824,\n","          0.00196367,  0.01643266],\n","        ...,\n","        [ 0.00180121,  0.02708211, -0.00787375, ...,  0.00793227,\n","         -0.03296556, -0.01301138],\n","        [-0.01582565, -0.01937042, -0.02537005, ...,  0.02935123,\n","         -0.01842321, -0.02234802],\n","        [-0.00219141, -0.01648943, -0.03279552, ...,  0.01198543,\n","          0.0067161 , -0.00208512]],\n","\n","       [[-0.01065581,  0.0237733 ,  0.02054803, ..., -0.01702958,\n","          0.02944199,  0.01511668],\n","        [-0.0364173 ,  0.01885953,  0.00700712, ...,  0.01835268,\n","          0.00262613, -0.02210349],\n","        [ 0.00251242,  0.00350066, -0.01155064, ..., -0.00636792,\n","         -0.00482406,  0.00207021],\n","        ...,\n","        [-0.03269545,  0.01991174, -0.00935201, ...,  0.02593695,\n","          0.00915125, -0.01454066],\n","        [ 0.01548291,  0.01106196,  0.00745421, ..., -0.02699883,\n","         -0.02194921,  0.01034534],\n","        [ 0.01910491,  0.01193905,  0.0064536 , ...,  0.01846213,\n","          0.02288925, -0.00109087]]], dtype=float32)>, <tf.Variable 'bias4:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[-0.0270979 , -0.01599626,  0.04732615,  0.00639814,\n","          0.00958644, -0.01974326,  0.02443636,  0.04969031,\n","         -0.05378813,  0.02339237,  0.03728084,  0.00485235,\n","         -0.03096958, -0.05997437, -0.04680449,  0.0664471 ,\n","          0.02010495,  0.07318067, -0.00316965, -0.06207525,\n","          0.01695449, -0.05603992, -0.07486816,  0.08496665,\n","         -0.0769624 ,  0.02279414,  0.03816854, -0.07086289,\n","          0.07990939,  0.00086289, -0.07193603,  0.00805427,\n","          0.03241713,  0.07354365,  0.05375078, -0.03499827,\n","          0.06085808,  0.0138976 , -0.07194397,  0.01372741,\n","          0.08278897, -0.08591438,  0.02736236,  0.06200767,\n","          0.085567  ,  0.02661532,  0.00418327, -0.02187026,\n","          0.01696343,  0.08397309, -0.07103949,  0.06219373,\n","          0.06650069,  0.07088063, -0.06445727,  0.07281564,\n","         -0.07420143,  0.03902533,  0.04705041,  0.04963367,\n","          0.03521361, -0.08444583, -0.07476201, -0.04518845,\n","          0.05419165, -0.04333945,  0.08585751,  0.05920973,\n","         -0.00842174, -0.07285284, -0.00151695,  0.00528277,\n","          0.07960822, -0.02687415,  0.02894964, -0.05023142,\n","         -0.03439316,  0.00619487,  0.05554153, -0.07484999,\n","          0.01180861, -0.07930809,  0.02599685, -0.06725644,\n","         -0.08517791,  0.00979336, -0.04071011, -0.05977914,\n","          0.04206687, -0.05041665, -0.08528415,  0.08025663,\n","         -0.00691526,  0.04941748,  0.04335394,  0.00473726,\n","          0.0557132 , -0.08362637,  0.04554147, -0.02701928,\n","         -0.08449972,  0.02104869, -0.05804143, -0.04450812,\n","         -0.00700725,  0.02222714, -0.0614218 , -0.08610939,\n","          0.01952902, -0.07621996, -0.02161817, -0.03481266,\n","          0.08256007, -0.01700378,  0.08476548, -0.08066238,\n","         -0.0219942 , -0.08009386, -0.01187155, -0.02311174,\n","         -0.05024189,  0.08398034, -0.07060216,  0.05845137,\n","         -0.06347834, -0.029724  , -0.0020417 ,  0.05079062],\n","        [-0.04521974,  0.03341009, -0.06107615, -0.08085322,\n","         -0.01755074,  0.08101335, -0.05942802, -0.00910864,\n","         -0.06927702,  0.04413879, -0.07302382, -0.07085212,\n","         -0.08969203, -0.00552272,  0.05211397,  0.05543754,\n","          0.02265122, -0.04993491,  0.01894365, -0.0656937 ,\n","         -0.04331268,  0.01663507, -0.05889081,  0.01306653,\n","          0.00070277,  0.02042819,  0.07275361, -0.01811345,\n","         -0.02923729,  0.04625154, -0.01896352,  0.05547865,\n","         -0.03828657,  0.06593808,  0.05695779,  0.0322471 ,\n","         -0.05856116, -0.05183332,  0.01223667,  0.02481467,\n","         -0.06035418,  0.08457253,  0.03407502,  0.03614951,\n","          0.0622334 , -0.08719178,  0.0575578 , -0.01149901,\n","          0.0223777 , -0.07561924, -0.02166919, -0.08489201,\n","         -0.08569002, -0.06124835,  0.09004179,  0.04354482,\n","          0.04385874, -0.08676427, -0.07999835,  0.07464574,\n","         -0.0789565 , -0.05403132,  0.01054009, -0.06409497,\n","         -0.01239004,  0.07360557, -0.05940704,  0.01173651,\n","         -0.06388247,  0.01359307, -0.08946733, -0.04762823,\n","         -0.03011946, -0.05013901, -0.00695831, -0.02407557,\n","         -0.00611402, -0.01221018,  0.04466553, -0.0256548 ,\n","          0.06029315, -0.05638589, -0.08175973,  0.06134128,\n","          0.03248077, -0.05279303,  0.01994468, -0.08076715,\n","         -0.02794517,  0.06556767, -0.02572648, -0.02987683,\n","          0.06937052, -0.05600566,  0.0813171 ,  0.01751862,\n","         -0.07275187,  0.0229641 , -0.06889135,  0.07037458,\n","          0.07783081,  0.07436661, -0.03393968, -0.02707183,\n","         -0.08423737, -0.06909566, -0.0455502 , -0.03157321,\n","          0.05533975,  0.00628747,  0.00636801, -0.06837228,\n","          0.0038962 , -0.04797835, -0.07019567,  0.03868524,\n","          0.02477102, -0.01906584,  0.03982009,  0.00127002,\n","          0.04138489, -0.04018765, -0.00112396, -0.05952274,\n","          0.00154395, -0.06278067, -0.01749951, -0.03080488]]],\n","      dtype=float32)>, <tf.Variable 'dense_110/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[-0.0654043 ,  0.08244704, -0.00501271, ..., -0.12108425,\n","         0.06044925,  0.14064178],\n","       [-0.13681926, -0.03772493,  0.13484852, ...,  0.14748082,\n","        -0.07673574, -0.08085541],\n","       [-0.15668614, -0.04857316, -0.05100197, ..., -0.14719677,\n","        -0.08091404, -0.09087861],\n","       ...,\n","       [-0.0998982 ,  0.06176172, -0.12688535, ...,  0.10108604,\n","         0.06027563,  0.01534882],\n","       [-0.05378678, -0.15751603,  0.03525223, ..., -0.03011445,\n","         0.12300781, -0.10151854],\n","       [ 0.02239023, -0.07998969, -0.02381962, ...,  0.0723404 ,\n","         0.03289157,  0.07724683]], dtype=float32)>, <tf.Variable 'dense_111/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.05424329, -0.04276657,  0.02617862, ..., -0.09139615,\n","        -0.12035285, -0.0753627 ],\n","       [ 0.07908796, -0.02471675,  0.12372331, ..., -0.12422533,\n","         0.02809896, -0.09828162],\n","       [ 0.01067093, -0.08216842,  0.0554894 , ..., -0.00827903,\n","        -0.01058666,  0.05533658],\n","       ...,\n","       [-0.08893849, -0.0046653 ,  0.01378003, ...,  0.02392055,\n","        -0.06576826, -0.06858338],\n","       [-0.09920163, -0.11653832,  0.0133886 , ...,  0.0636995 ,\n","         0.05294287, -0.12406784],\n","       [ 0.08168178, -0.04564535,  0.04571887, ...,  0.06851649,\n","        -0.10494572, -0.10680813]], dtype=float32)>, <tf.Variable 'dense_112/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.1182487 , -0.03817725,  0.05563525, ..., -0.03565416,\n","         0.09282862,  0.06959452],\n","       [ 0.07606585,  0.10598434, -0.06750003, ..., -0.09845943,\n","         0.07761712, -0.00855015],\n","       [-0.09150907,  0.03490993,  0.03356638, ...,  0.05745693,\n","        -0.05670256, -0.04416921],\n","       ...,\n","       [ 0.07579838, -0.00241659,  0.04204298, ..., -0.08901873,\n","         0.01518859, -0.01216934],\n","       [-0.05443529, -0.04408531, -0.03087957, ..., -0.0053887 ,\n","        -0.08133709, -0.05180596],\n","       [ 0.06020609, -0.056077  , -0.00775235, ..., -0.05921398,\n","        -0.07677862, -0.08105633]], dtype=float32)>, <tf.Variable 'dense_113/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.06243299,  0.11597776, -0.04664877, ..., -0.00780161,\n","        -0.08888288, -0.06171077],\n","       [ 0.02589067,  0.02044241,  0.07759409, ...,  0.0521809 ,\n","        -0.1010812 , -0.09598932],\n","       [ 0.12328671,  0.05407961, -0.09985728, ...,  0.03808495,\n","         0.0058987 , -0.05653593],\n","       ...,\n","       [ 0.09975436, -0.00629623, -0.05128225, ..., -0.01434506,\n","         0.10246649,  0.08104596],\n","       [-0.01826887, -0.07042183,  0.08889592, ..., -0.08635204,\n","         0.07695038, -0.00501336],\n","       [ 0.08857071, -0.00285794,  0.04391384, ...,  0.03162976,\n","         0.07805558,  0.02559124]], dtype=float32)>, <tf.Variable 'dense_114/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[ 0.05598123,  0.10349587, -0.11145543, ...,  0.10080076,\n","         0.15073773,  0.02365956],\n","       [-0.09114631,  0.08901653,  0.12418562, ...,  0.1272698 ,\n","         0.10716204,  0.02072985],\n","       [ 0.02464402,  0.07803281,  0.09134906, ...,  0.10937544,\n","         0.13431846,  0.0977763 ],\n","       ...,\n","       [ 0.13773885,  0.0071658 ,  0.10916907, ..., -0.10006617,\n","         0.02102643, -0.12792778],\n","       [-0.1093807 ,  0.01480789,  0.04545247, ..., -0.01303498,\n","        -0.07899863,  0.12881641],\n","       [ 0.02324763,  0.0472811 , -0.00350512, ..., -0.04629781,\n","        -0.01456363,  0.05916308]], dtype=float32)>, <tf.Variable 'dense_115/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[ 0.00912354, -0.05149776,  0.02689675, ..., -0.03169019,\n","        -0.02994885,  0.04648351],\n","       [-0.02572059, -0.01014476, -0.02636392, ...,  0.05855785,\n","         0.05306827,  0.05428422],\n","       [-0.01733474, -0.05920822, -0.04250101, ..., -0.02437998,\n","        -0.04355887, -0.01646032],\n","       ...,\n","       [ 0.0449321 ,  0.01136704,  0.05418603, ...,  0.04731244,\n","        -0.06206546,  0.0616362 ],\n","       [-0.02500005, -0.00251602, -0.00227506, ..., -0.04557694,\n","        -0.03368302, -0.02110435],\n","       [-0.0106889 ,  0.05867266, -0.05715838, ..., -0.04183307,\n","        -0.00689892, -0.06230009]], dtype=float32)>, <tf.Variable 'dense_116/kernel:0' shape=(1280, 128) dtype=float32, numpy=\n","array([[ 0.00019667,  0.05540073, -0.01299642, ..., -0.04064733,\n","         0.00197803, -0.02046585],\n","       [ 0.03542525, -0.02213539,  0.04086318, ...,  0.00421642,\n","        -0.00720711,  0.015149  ],\n","       [-0.01677837,  0.00819501, -0.04725257, ..., -0.06075473,\n","         0.03002926,  0.04345205],\n","       ...,\n","       [ 0.04714258, -0.06106337, -0.05958724, ...,  0.03941589,\n","        -0.04260186,  0.04453485],\n","       [ 0.02819585, -0.03112084,  0.05833374, ...,  0.03320158,\n","         0.04735794,  0.02393432],\n","       [-0.01611166, -0.01222437,  0.04866181, ...,  0.06182102,\n","        -0.02996935,  0.05027489]], dtype=float32)>, <tf.Variable 'branch5:0' shape=(24, 128, 256) dtype=float32, numpy=\n","array([[[-2.56038997e-02,  1.46684283e-02,  2.83768238e-03, ...,\n","          2.11544707e-02, -1.71876438e-02, -3.86649556e-03],\n","        [-5.53465728e-03,  1.86264534e-02, -1.12158852e-02, ...,\n","         -2.21149679e-02, -9.10957286e-04,  3.75886564e-03],\n","        [ 3.13974521e-03, -2.03042571e-02,  1.15325628e-02, ...,\n","          1.49571598e-02, -2.35362127e-02, -1.50754601e-02],\n","        ...,\n","        [ 2.59801298e-02,  6.37309160e-03, -7.34331226e-03, ...,\n","          1.12585844e-02, -1.81493051e-02,  1.47831431e-02],\n","        [ 1.50152808e-02,  2.47326288e-02, -5.39486436e-03, ...,\n","         -7.28519307e-03, -1.09248869e-02, -7.72570726e-03],\n","        [-1.65101402e-02,  2.54769716e-03,  9.19005740e-03, ...,\n","          4.19286173e-03, -2.14723237e-02, -2.26289295e-02]],\n","\n","       [[-7.74430763e-03, -2.77510658e-02, -1.49157839e-02, ...,\n","         -2.20955368e-02,  5.44676138e-03, -2.03535501e-02],\n","        [ 2.79266271e-03, -9.86365695e-03,  1.93775631e-02, ...,\n","         -1.57524273e-02, -5.80292544e-04, -3.43487109e-03],\n","        [ 1.58247687e-02,  2.54448485e-02, -4.47126059e-03, ...,\n","          6.95740432e-03, -6.38863014e-04,  1.38899460e-02],\n","        ...,\n","        [-1.41079603e-02, -1.54311201e-02,  3.52346664e-03, ...,\n","          2.82065454e-03,  2.33764537e-02,  2.49867104e-02],\n","        [ 6.49649603e-03,  3.98155954e-03, -2.43701823e-02, ...,\n","          1.92462578e-02, -1.39329284e-02,  6.43345155e-03],\n","        [ 1.48091977e-02, -1.52139766e-02,  1.27190221e-02, ...,\n","         -1.57813746e-02,  1.98921412e-02,  8.52829777e-04]],\n","\n","       [[-4.14698292e-03, -1.64798216e-03,  1.80019159e-02, ...,\n","          1.34947579e-02,  1.13636870e-02,  2.13191286e-02],\n","        [ 1.47109954e-02, -2.23153420e-02, -2.13281345e-02, ...,\n","         -1.12135001e-02,  2.78073567e-04,  1.38621693e-02],\n","        [-7.78299198e-03, -5.50153106e-03,  3.88059509e-03, ...,\n","         -9.68804117e-03, -7.72424554e-03,  3.42016923e-04],\n","        ...,\n","        [ 5.59837371e-03,  5.39248390e-03, -8.03470798e-03, ...,\n","          1.98355131e-02, -2.57503428e-02,  7.89382402e-03],\n","        [ 2.38468107e-02,  9.87770408e-03, -1.18413772e-02, ...,\n","          5.58130769e-03,  1.22713251e-02, -1.29424874e-02],\n","        [-2.17878930e-02, -7.91956764e-03,  2.52011535e-03, ...,\n","          2.94021633e-03,  2.00312845e-02, -2.13756468e-02]],\n","\n","       ...,\n","\n","       [[-8.39499477e-03,  2.11546533e-02,  2.64675776e-03, ...,\n","         -1.41564687e-03,  1.74790546e-02, -2.06794441e-02],\n","        [-7.71639775e-03, -1.86530650e-02,  1.12688988e-02, ...,\n","          1.07293017e-02, -1.33224623e-02,  8.51860922e-03],\n","        [-8.34037643e-03,  5.09247882e-03,  9.55638103e-03, ...,\n","         -7.39418203e-03, -2.34420933e-02, -1.45035991e-02],\n","        ...,\n","        [ 8.11698567e-03,  2.46915370e-02,  9.60068032e-03, ...,\n","          7.40223657e-03,  4.45223227e-03,  8.99237674e-03],\n","        [ 2.65910905e-02, -3.87200015e-03,  1.61513835e-02, ...,\n","         -1.86180752e-02, -3.75495874e-03, -8.95014033e-03],\n","        [ 1.62691399e-02,  4.80588572e-03, -1.12968516e-02, ...,\n","         -4.96523222e-03, -2.10214742e-02,  1.57308369e-03]],\n","\n","       [[ 3.94250499e-03, -1.80799663e-02,  2.06943974e-03, ...,\n","         -8.72876262e-04, -1.47500765e-02,  2.78442027e-03],\n","        [ 5.57266455e-03, -9.68816783e-03, -1.97397601e-02, ...,\n","         -2.26044785e-02,  1.84017792e-02,  1.74421072e-02],\n","        [-1.13744671e-02, -1.57091748e-02,  2.55484097e-02, ...,\n","          7.26338336e-03,  2.12794170e-02,  9.90563538e-03],\n","        ...,\n","        [ 1.36500895e-02, -2.48558857e-02, -1.93208754e-02, ...,\n","          2.26944424e-02, -1.49029177e-02,  2.96123046e-03],\n","        [ 2.60689575e-03,  2.49546487e-02, -2.27525495e-02, ...,\n","         -1.88273806e-02, -1.68312304e-02,  2.09082831e-02],\n","        [ 2.40425728e-02,  2.12721787e-02,  1.32309329e-02, ...,\n","         -1.20075736e-02, -1.79438647e-02,  1.63587183e-02]],\n","\n","       [[ 1.62764005e-02, -4.47492255e-03,  1.04826232e-02, ...,\n","         -9.20866092e-04,  5.32742124e-04, -2.42187083e-02],\n","        [ 2.22410429e-02, -1.35636423e-02, -2.57552825e-02, ...,\n","         -2.85438541e-02, -1.60278268e-02, -1.48077421e-02],\n","        [ 2.04072315e-02, -5.10316482e-03, -9.07221809e-03, ...,\n","         -5.39269019e-03, -2.51611695e-02,  3.11464909e-03],\n","        ...,\n","        [-1.30438814e-02,  2.27417108e-02, -2.36352161e-02, ...,\n","          1.27908355e-02,  3.85228684e-03, -1.15681225e-02],\n","        [-8.32512975e-04, -4.10282169e-04,  1.91285554e-02, ...,\n","          2.72768957e-05,  1.53427301e-02,  2.06295419e-02],\n","        [-1.57893710e-02,  9.06231813e-03, -1.91508308e-02, ...,\n","         -1.35914758e-02, -1.43117560e-02, -1.81630515e-02]]],\n","      dtype=float32)>, <tf.Variable 'bias5:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[-6.4806566e-02,  1.3849145e-02,  4.0880572e-02, -5.6626614e-02,\n","          3.7922166e-02,  1.5005561e-02,  7.4923262e-02,  6.8915479e-02,\n","          2.6076416e-02, -7.0651822e-02,  8.7521728e-03, -3.5229433e-02,\n","          3.3717994e-02,  9.5053622e-03, -7.2056435e-02, -3.1808510e-02,\n","         -1.0011962e-02,  3.2878239e-02,  6.0271587e-02, -5.6240153e-03,\n","          8.4141798e-02, -8.8059381e-02,  4.7250319e-02,  4.4314075e-02,\n","         -3.0194666e-02, -4.9844928e-02,  8.6352855e-02, -4.4346418e-02,\n","         -6.0352955e-02,  7.8154474e-02,  8.1770448e-03,  4.6213679e-02,\n","          3.6714286e-02,  7.3143862e-02,  4.6360154e-02, -1.9416623e-03,\n","         -6.8209969e-02,  4.1037682e-03,  3.6397878e-02,  4.2616211e-02,\n","         -7.5971410e-02,  7.3432706e-02, -7.4523091e-02,  7.5398445e-02,\n","          3.4888104e-02, -8.1247002e-02,  9.7035069e-04, -8.2891835e-03,\n","          1.7249051e-02, -4.0483251e-02,  4.9351424e-02, -5.0908655e-02,\n","          5.0926719e-02,  7.0430182e-02, -2.1228984e-02, -8.0175839e-02,\n","          3.0711299e-02,  1.5940499e-02,  2.9659508e-02, -7.4150637e-02,\n","          1.2985942e-02, -8.9250412e-03, -7.7225298e-02,  4.9623657e-02,\n","         -5.3328112e-02,  8.2724482e-02,  1.5363047e-02,  6.7986101e-02,\n","          1.2615169e-02,  7.6666132e-02,  4.2360485e-02, -6.9686823e-02,\n","          3.0924520e-02, -6.7471825e-02, -1.8845921e-02,  1.9975302e-03,\n","          4.9349263e-02,  3.1044916e-03,  7.6282203e-02, -6.8313375e-02,\n","          5.3408455e-02,  3.4589406e-02,  4.1629542e-02,  7.1615651e-02,\n","         -4.3268625e-02, -7.8415394e-02, -7.6400973e-02,  6.5700382e-02,\n","          1.0232556e-02,  9.1530913e-03, -6.2002476e-02, -1.4789181e-02,\n","         -6.3459359e-02, -5.4323625e-02, -5.3362623e-02, -1.6272936e-02,\n","          3.9239950e-02,  3.9081089e-02,  7.4059114e-02,  5.9144747e-02,\n","          2.2955911e-02, -4.5524002e-03,  4.4237800e-02,  4.5050975e-02,\n","          5.2246761e-02,  1.2917066e-02, -4.8939601e-02, -5.4905199e-02,\n","          6.8951845e-02,  3.4538899e-02, -1.4160498e-02,  8.1960268e-02,\n","         -4.5432467e-02, -8.1338897e-02, -4.4325437e-02,  8.8250982e-03,\n","         -2.6394857e-02,  1.9035641e-02, -3.5246763e-02,  4.7367752e-02,\n","         -4.7376040e-02,  9.7087789e-03, -2.7260439e-02,  2.2856550e-02,\n","         -2.0582756e-02,  2.0314764e-02, -5.5311970e-02, -6.3133657e-02],\n","        [-2.6344856e-02, -8.4659293e-02, -2.2449621e-03,  3.4501635e-02,\n","         -7.7725433e-02,  3.3146299e-02, -8.2963690e-02, -5.3552736e-02,\n","          1.9996326e-02, -1.9578746e-02, -2.0124409e-02, -6.3028082e-02,\n","          7.5515576e-02, -5.3182069e-02, -7.4797079e-02, -6.9746852e-02,\n","          3.2656256e-02, -7.1487896e-02, -2.1624718e-02, -4.7014665e-02,\n","          6.3887029e-03, -7.6706847e-03, -8.7787345e-02, -3.6852151e-02,\n","         -5.2780800e-02,  5.6903882e-05,  5.9461284e-02, -6.9958419e-03,\n","          8.0499627e-02, -4.7257554e-02,  1.8895732e-02,  2.6285414e-02,\n","         -9.6907308e-03,  5.2584447e-02,  5.6101680e-02,  5.9868228e-02,\n","          8.4832236e-02,  7.5960003e-02, -6.4907946e-02, -2.8540066e-02,\n","         -7.2979778e-02,  1.7844839e-02, -8.2995236e-02,  3.9150842e-02,\n","         -8.0140725e-02,  2.2003507e-02, -6.5842122e-02,  7.5347289e-02,\n","          6.6531293e-02, -7.9583280e-02, -4.5117911e-02, -5.9540972e-02,\n","         -3.3348515e-03,  9.0950336e-03, -6.4614803e-02, -8.6432733e-02,\n","         -5.2835714e-02, -3.7844744e-02, -5.3147715e-02, -6.6344133e-03,\n","          5.6616917e-02,  1.7361963e-02,  7.7545017e-02, -1.9824907e-02,\n","          5.6321949e-02,  8.3728410e-02, -1.7759476e-02, -3.4170464e-02,\n","          8.5257024e-02, -1.4630646e-03,  9.1681164e-03,  3.7766654e-02,\n","          1.4909088e-02,  8.6335994e-02,  8.2592890e-02, -6.8837687e-02,\n","          4.9229600e-02,  6.8678275e-02, -8.1908882e-02, -5.2599769e-02,\n","          4.4051178e-02,  7.7073351e-02, -6.9677509e-02,  6.3788109e-02,\n","         -4.4557650e-04, -7.8738101e-02,  8.1511907e-02,  2.8863106e-02,\n","         -1.9589693e-03, -6.5784231e-02,  2.8546780e-02,  1.8589042e-02,\n","         -4.4583764e-02,  1.6398372e-03, -5.1683106e-02,  5.4913715e-02,\n","         -8.0432510e-03,  1.7768787e-02,  7.5511599e-04,  5.5907916e-02,\n","         -8.3703458e-02,  8.5884199e-02,  5.1678598e-02,  2.8723665e-02,\n","         -3.6380671e-02,  7.7778995e-02,  4.9522486e-02, -2.5661273e-02,\n","          8.4856212e-02,  3.6453836e-02,  7.4157253e-02,  8.5070215e-02,\n","         -4.4348534e-02,  6.0762875e-02, -8.2063816e-02, -2.0642383e-02,\n","         -6.0427122e-02, -5.1188424e-02,  6.5371167e-04,  1.1347741e-02,\n","         -2.0415680e-03, -6.9200203e-02,  1.1017087e-02,  1.2856352e-02,\n","         -5.0509155e-02, -6.9021247e-02,  1.5254083e-02, -4.7980186e-02]]],\n","      dtype=float32)>, <tf.Variable 'dense_117/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[-0.01488104, -0.05433737,  0.05606295, ...,  0.00586284,\n","         0.07165159,  0.0092068 ],\n","       [ 0.07463093,  0.02792682, -0.08131743, ..., -0.03156505,\n","         0.10245765,  0.08760926],\n","       [ 0.15154552, -0.14853819,  0.14640155, ..., -0.0399689 ,\n","        -0.08539332, -0.06376816],\n","       ...,\n","       [-0.12290996, -0.03568138, -0.059149  , ...,  0.02546031,\n","         0.06370076, -0.06386392],\n","       [ 0.08311605,  0.01628317,  0.13084124, ...,  0.06700725,\n","        -0.06688707,  0.06552897],\n","       [-0.10719705,  0.01844795, -0.05979244, ...,  0.00134805,\n","        -0.10963228, -0.1592981 ]], dtype=float32)>, <tf.Variable 'dense_118/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.03589461,  0.10618624,  0.09053919, ..., -0.0479805 ,\n","         0.0002878 ,  0.0507312 ],\n","       [ 0.02240365,  0.04389418,  0.09571948, ...,  0.00054769,\n","         0.09093645, -0.0217731 ],\n","       [-0.00322651,  0.05851941, -0.0643144 , ...,  0.08321631,\n","         0.01242684, -0.00138417],\n","       ...,\n","       [-0.06497288,  0.0835442 , -0.11048398, ..., -0.04170118,\n","         0.12139631, -0.1193071 ],\n","       [ 0.0935878 , -0.00995523,  0.06269871, ...,  0.04473817,\n","        -0.02361076,  0.04445099],\n","       [ 0.00836863, -0.02303254,  0.11795644, ...,  0.02087543,\n","        -0.02873337, -0.05689361]], dtype=float32)>, <tf.Variable 'dense_119/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.0921576 ,  0.06969289,  0.09280533, ...,  0.10113312,\n","         0.06829885,  0.08557639],\n","       [ 0.12207783, -0.11500805, -0.12299586, ..., -0.07892361,\n","         0.09232457,  0.01126597],\n","       [-0.05202568, -0.09925599,  0.07542346, ...,  0.11621337,\n","        -0.10581256, -0.1047214 ],\n","       ...,\n","       [ 0.11320562,  0.09166039,  0.0356075 , ..., -0.08813409,\n","         0.05122422,  0.11828004],\n","       [ 0.0580807 , -0.11107735, -0.12126653, ..., -0.04284809,\n","         0.09628139, -0.0808261 ],\n","       [-0.0809004 , -0.05657742,  0.01262539, ...,  0.00784746,\n","        -0.05709376, -0.11369843]], dtype=float32)>, <tf.Variable 'dense_120/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.07061637,  0.08200292,  0.05514727, ...,  0.00669137,\n","         0.09786063, -0.12396798],\n","       [ 0.04697229, -0.04459246,  0.01683718, ..., -0.09163297,\n","         0.08159227,  0.09240816],\n","       [ 0.07836886, -0.06395185,  0.07706343, ...,  0.09106047,\n","         0.07450175,  0.05963058],\n","       ...,\n","       [-0.11658999, -0.02422955,  0.04165939, ..., -0.01322024,\n","         0.11845496,  0.11353339],\n","       [ 0.07325686,  0.05592141, -0.03152732, ...,  0.11773629,\n","        -0.0687106 ,  0.04115212],\n","       [-0.12007054, -0.12316589,  0.03552542, ..., -0.03792731,\n","        -0.00978591,  0.07860542]], dtype=float32)>, <tf.Variable 'dense_121/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[-0.04605296, -0.10389222,  0.09350076, ...,  0.03246409,\n","         0.10744669, -0.03340583],\n","       [ 0.08598541,  0.11975572, -0.02353922, ...,  0.01642091,\n","         0.14846826,  0.08625414],\n","       [-0.06589559, -0.07376476, -0.14116481, ...,  0.1362391 ,\n","         0.04485584,  0.09415571],\n","       ...,\n","       [-0.09282649,  0.02312982,  0.03079493, ...,  0.1447821 ,\n","         0.06617223,  0.08127622],\n","       [-0.15291305, -0.03821689, -0.00954104, ..., -0.1486368 ,\n","         0.06587964,  0.03816848],\n","       [ 0.14159574,  0.11826354, -0.03460804, ..., -0.05512104,\n","        -0.0802775 , -0.01531548]], dtype=float32)>, <tf.Variable 'dense_122/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[-0.12469283, -0.12586688,  0.01128692, ..., -0.04943092,\n","        -0.11865944, -0.14447927],\n","       [ 0.055634  , -0.1161612 ,  0.00169386, ...,  0.1540574 ,\n","         0.0492897 , -0.03129867],\n","       [ 0.07619523,  0.062043  , -0.02176576, ..., -0.11765406,\n","         0.08202668, -0.134035  ],\n","       ...,\n","       [-0.12258791,  0.06326383, -0.08795346, ..., -0.03861462,\n","        -0.13267855,  0.15227222],\n","       [ 0.05753136,  0.02738955, -0.11407597, ...,  0.02958991,\n","        -0.11181742,  0.09782175],\n","       [ 0.045343  , -0.10205775,  0.05724078, ..., -0.13765854,\n","         0.068443  , -0.12004016]], dtype=float32)>, <tf.Variable 'dense_123/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[-0.02204311,  0.028145  ,  0.05434563, ...,  0.00695182,\n","         0.06322993, -0.02852198],\n","       [-0.04042033, -0.03262234,  0.01666277, ..., -0.02703782,\n","         0.05855407,  0.01899622],\n","       [-0.02763034, -0.04466559,  0.00743137, ..., -0.00849782,\n","         0.00040481,  0.02823188],\n","       ...,\n","       [ 0.05835246, -0.04050482, -0.04892688, ...,  0.00905355,\n","         0.00883358,  0.03685813],\n","       [ 0.06299819,  0.02052324, -0.0255572 , ..., -0.05790211,\n","         0.01900756, -0.05955438],\n","       [ 0.04519872,  0.03892663, -0.02223307, ..., -0.01439933,\n","         0.01262093,  0.01666342]], dtype=float32)>, <tf.Variable 'dense_124/kernel:0' shape=(1280, 128) dtype=float32, numpy=\n","array([[ 0.03013404,  0.02811481, -0.00532168, ..., -0.04293754,\n","        -0.02640802,  0.06498007],\n","       [-0.06343086,  0.01699611, -0.06673737, ...,  0.02212141,\n","         0.03910946, -0.063422  ],\n","       [ 0.04738826, -0.05038051,  0.03754618, ..., -0.05912961,\n","         0.03138806, -0.03325964],\n","       ...,\n","       [ 0.00283346, -0.00142469, -0.03414457, ..., -0.00186184,\n","        -0.06150363, -0.02401483],\n","       [ 0.04361221,  0.02417737, -0.0351714 , ..., -0.02514357,\n","         0.05151676,  0.04175628],\n","       [-0.0516586 , -0.01847638, -0.02980726, ..., -0.05024159,\n","        -0.00727667, -0.01885377]], dtype=float32)>, <tf.Variable 'branch6:0' shape=(48, 128, 8192) dtype=float32, numpy=\n","array([[[ 4.9258787e-03,  4.5637866e-03,  5.3418782e-03, ...,\n","         -8.0910808e-04, -4.5430232e-03,  8.1907187e-05],\n","        [-5.9172457e-05,  1.8134736e-03,  1.2033889e-03, ...,\n","         -2.7273824e-03,  3.8459466e-03, -2.1156929e-03],\n","        [-3.8242731e-03, -2.0186738e-03, -7.1952930e-03, ...,\n","         -3.7798278e-03, -2.7174130e-04, -2.5361223e-04],\n","        ...,\n","        [-2.8945857e-03,  2.5747967e-04, -2.7703780e-03, ...,\n","          2.8310600e-03,  1.3945453e-03,  8.0017338e-04],\n","        [ 2.6259282e-05, -1.7890367e-03, -4.1570263e-03, ...,\n","          2.2937693e-03, -4.5950580e-03, -4.4860807e-03],\n","        [-5.5937795e-03, -5.0731958e-03, -7.9303206e-04, ...,\n","         -1.0561175e-03, -2.8651643e-03,  1.7822519e-03]],\n","\n","       [[-8.6159641e-03, -7.0260554e-03, -7.4307169e-03, ...,\n","          1.6849586e-03,  5.7184203e-03, -9.6821348e-04],\n","        [-5.2194814e-03, -1.6189197e-03,  9.0408413e-04, ...,\n","         -1.3316494e-03,  1.3435059e-03,  1.2297042e-03],\n","        [ 1.8803518e-03, -4.9953139e-04,  5.0786715e-03, ...,\n","         -2.3454183e-03, -1.6229269e-03, -1.8829271e-03],\n","        ...,\n","        [-9.8278665e-04, -5.7487674e-03,  3.4711882e-03, ...,\n","         -1.5050862e-03,  2.0791264e-03,  8.4421912e-04],\n","        [ 4.5894030e-03,  3.5308933e-04,  2.4670712e-03, ...,\n","          2.2836304e-03, -1.2820901e-03, -4.0418934e-03],\n","        [ 1.6656625e-03,  3.0601176e-03,  3.7860271e-04, ...,\n","          1.8960717e-03,  7.6491979e-04,  1.4146257e-03]],\n","\n","       [[-4.1906764e-03, -3.8740959e-03, -5.6866370e-04, ...,\n","          1.6910486e-03,  7.8230957e-04, -5.9544138e-04],\n","        [-1.6054173e-03,  5.8173359e-04,  2.7277702e-03, ...,\n","         -3.2915848e-03,  2.1432543e-03, -4.3876232e-03],\n","        [-5.2881339e-03, -2.6528048e-03, -4.6460056e-03, ...,\n","         -3.4644601e-03, -5.3529260e-03, -3.4852799e-03],\n","        ...,\n","        [ 8.5989968e-04,  3.0611632e-03,  1.8580590e-03, ...,\n","          3.2663782e-04,  2.9574693e-03, -2.6263408e-03],\n","        [-3.8110337e-04, -3.5251314e-03, -5.5887108e-03, ...,\n","         -9.9445786e-04,  8.1617839e-04, -6.6740462e-03],\n","        [-6.5719746e-03, -5.9852391e-03, -2.2761652e-04, ...,\n","         -2.0920588e-03, -3.1947715e-03, -8.0228848e-03]],\n","\n","       ...,\n","\n","       [[-1.0737831e-03, -5.0374954e-03, -2.9506178e-03, ...,\n","         -1.0442537e-04, -1.5629907e-03, -4.1008405e-03],\n","        [-1.5129661e-03,  1.1224122e-03,  3.2142075e-03, ...,\n","          2.3107659e-03,  1.4027421e-03, -1.4037230e-03],\n","        [-1.7028573e-03, -5.7682727e-04, -1.3171312e-04, ...,\n","         -2.2984692e-03, -1.9033072e-03, -3.8372418e-03],\n","        ...,\n","        [ 7.5488567e-04, -6.2110357e-04, -1.4782309e-03, ...,\n","          4.8393733e-03,  4.9147801e-04, -4.5842910e-04],\n","        [ 7.5442798e-04, -1.8640517e-04,  1.5840865e-03, ...,\n","         -4.2934963e-03, -3.0928464e-03, -3.4666432e-03],\n","        [-1.5247000e-03,  1.1645969e-03, -2.1858697e-03, ...,\n","          9.7258744e-04, -2.2751663e-03,  1.4263478e-03]],\n","\n","       [[ 5.0004869e-04, -8.8462839e-04,  4.0403190e-03, ...,\n","         -7.7027725e-03, -1.1549492e-03, -4.5639933e-03],\n","        [-3.2040518e-04, -2.8936907e-03,  2.1237882e-03, ...,\n","         -1.3495864e-03,  2.7309570e-03, -3.6227494e-03],\n","        [-3.8403918e-03,  1.4859797e-03, -5.1960251e-03, ...,\n","          9.2440838e-04, -1.8477611e-03, -2.5861077e-03],\n","        ...,\n","        [-1.2120047e-03,  3.4096523e-03,  1.2320698e-03, ...,\n","          1.5322805e-03,  2.0630653e-03, -2.8983434e-03],\n","        [-5.0082603e-03,  1.2236118e-03, -1.2324422e-03, ...,\n","         -1.1256479e-04,  3.3439320e-04,  4.8811473e-03],\n","        [-1.4615989e-03,  2.2980017e-03, -8.0402894e-04, ...,\n","         -2.9133523e-03,  4.5765401e-03,  3.5685627e-03]],\n","\n","       [[-5.2805189e-03, -5.7846983e-03, -1.3353992e-03, ...,\n","         -6.6441024e-04, -4.6217320e-03,  3.3326137e-03],\n","        [ 1.1372084e-03,  2.3875581e-03, -6.4349448e-04, ...,\n","          2.0512091e-03,  2.3496023e-03, -1.4441044e-03],\n","        [-8.9777022e-04,  1.3170009e-03,  6.6613097e-04, ...,\n","         -1.2444686e-03,  1.0082753e-03, -6.0688471e-04],\n","        ...,\n","        [ 1.6848929e-03,  2.6819201e-03, -2.8852851e-03, ...,\n","          4.5444951e-03, -2.0299039e-03, -2.6890582e-03],\n","        [-4.5728803e-04, -2.9098634e-03, -2.7229879e-03, ...,\n","          1.3752647e-03, -3.5442154e-05,  6.2724408e-05],\n","        [ 2.5316782e-03,  1.0582539e-03, -3.0734637e-03, ...,\n","          8.9567626e-04,  1.8018826e-03, -2.0752572e-03]]], dtype=float32)>, <tf.Variable 'bias6:0' shape=(1, 64, 3) dtype=float32, numpy=\n","array([[[ 0.4943477 , -0.45298475, -0.5028099 ],\n","        [-0.22590584, -0.23868468,  0.28469068],\n","        [ 0.4110915 ,  0.00126749, -0.51478195],\n","        [-0.30777434, -0.2687866 , -0.18807247],\n","        [ 0.49446332,  0.42605603, -0.489164  ],\n","        [-0.0076918 ,  0.29591626, -0.2656329 ],\n","        [ 0.25033063,  0.309974  ,  0.5265893 ],\n","        [-0.03315532, -0.349571  ,  0.34537536],\n","        [ 0.05704933,  0.17940253, -0.08140117],\n","        [ 0.31831908, -0.04162538,  0.13756967],\n","        [-0.40095267,  0.5160974 ,  0.01891381],\n","        [-0.3245595 , -0.36141062,  0.06747335],\n","        [-0.03155512, -0.26138774,  0.5098537 ],\n","        [-0.2799735 , -0.5551601 , -0.05629379],\n","        [-0.21171829, -0.5026338 , -0.08055064],\n","        [ 0.47513282, -0.49338466, -0.04979044],\n","        [ 0.5018711 ,  0.43338454, -0.51402706],\n","        [-0.31881094,  0.55729914,  0.5067595 ],\n","        [ 0.33554626, -0.3870806 ,  0.22393149],\n","        [ 0.31048536, -0.294975  ,  0.5169177 ],\n","        [ 0.36995792,  0.24402153, -0.16276532],\n","        [ 0.22186273, -0.46210745,  0.48655725],\n","        [ 0.01099187, -0.33244336,  0.16573572],\n","        [-0.55963594,  0.48728395,  0.23699999],\n","        [-0.4735245 , -0.17496106, -0.09280241],\n","        [-0.44575298,  0.07065284, -0.42692465],\n","        [-0.09563717,  0.41172838,  0.47789383],\n","        [ 0.53218544,  0.12687212, -0.2940749 ],\n","        [ 0.16443753, -0.50240326,  0.01281393],\n","        [-0.25534707,  0.40178585,  0.2516023 ],\n","        [ 0.05311501,  0.4644127 ,  0.5751269 ],\n","        [ 0.0561319 ,  0.46162045, -0.49493238],\n","        [-0.29302767, -0.20564899, -0.39008814],\n","        [ 0.2630698 , -0.3026211 , -0.53721535],\n","        [ 0.13955349,  0.36916834, -0.54315555],\n","        [ 0.25016588,  0.3319314 ,  0.19254541],\n","        [ 0.43026698, -0.03924209,  0.5357691 ],\n","        [-0.45871973, -0.11349988, -0.3183732 ],\n","        [ 0.21051836,  0.34875858, -0.07763147],\n","        [-0.19770047,  0.39336175, -0.2849968 ],\n","        [ 0.25014043, -0.3380149 , -0.2260117 ],\n","        [ 0.17787993, -0.2076182 ,  0.14925939],\n","        [ 0.4262401 , -0.48419672, -0.2392799 ],\n","        [ 0.02032059, -0.05258226, -0.32266983],\n","        [ 0.05039114, -0.51851684,  0.15803039],\n","        [-0.49040163,  0.13880497,  0.5395547 ],\n","        [ 0.01801962, -0.22276369,  0.29537678],\n","        [-0.19117704,  0.3656358 ,  0.25798416],\n","        [ 0.51564145,  0.4649682 ,  0.01069659],\n","        [-0.41678834,  0.00723356,  0.06601828],\n","        [ 0.12521452, -0.3794685 ,  0.1601007 ],\n","        [ 0.15827942, -0.53201556,  0.52298415],\n","        [-0.565149  , -0.14728412, -0.2710766 ],\n","        [ 0.10421616,  0.50319517,  0.27200395],\n","        [ 0.14872396, -0.09061843, -0.38452238],\n","        [-0.5306751 , -0.11742857, -0.5420754 ],\n","        [ 0.5463542 ,  0.09169692, -0.04327899],\n","        [-0.1646086 , -0.26328582, -0.31824037],\n","        [-0.33893192,  0.0792464 ,  0.21145111],\n","        [-0.09439942, -0.05267918, -0.24494353],\n","        [-0.1600686 , -0.38561285, -0.15504888],\n","        [-0.48131788, -0.37033412, -0.11468369],\n","        [ 0.45346475, -0.36243322, -0.46919233],\n","        [-0.207964  , -0.41062224,  0.4916638 ]]], dtype=float32)>, <tf.Variable 'dense_125/kernel:0' shape=(96, 3) dtype=float32, numpy=\n","array([[-0.13098393,  0.23404804,  0.11368818],\n","       [ 0.14430311, -0.12909876,  0.17710121],\n","       [-0.15206048,  0.08193802,  0.14498685],\n","       [ 0.24142413,  0.06605994, -0.18312599],\n","       [ 0.12232561, -0.12662491,  0.10536775],\n","       [-0.11626893, -0.06566515,  0.14957418],\n","       [-0.1496621 ,  0.20707305,  0.20332989],\n","       [-0.20479104,  0.19559331,  0.09119263],\n","       [-0.04626346,  0.20962374,  0.11458107],\n","       [-0.03512621,  0.10792553, -0.07210105],\n","       [ 0.17992823,  0.0541518 , -0.17907064],\n","       [ 0.135534  , -0.07517805,  0.03446275],\n","       [-0.11166645, -0.0368545 ,  0.01656757],\n","       [ 0.00338823,  0.0909284 ,  0.03860977],\n","       [ 0.01862007, -0.09889935,  0.07574435],\n","       [-0.233777  , -0.22799762, -0.102695  ],\n","       [-0.12032977,  0.0009399 ,  0.17505482],\n","       [-0.0420074 , -0.13711454, -0.09344454],\n","       [-0.15305847, -0.06614111, -0.08048967],\n","       [ 0.22830619,  0.14597857,  0.00741711],\n","       [-0.11606468,  0.0733974 , -0.11408293],\n","       [ 0.01391096, -0.07276165, -0.13651612],\n","       [-0.1380168 , -0.23156182, -0.02223199],\n","       [-0.16919038,  0.21157528, -0.18413252],\n","       [ 0.10413631, -0.10628875,  0.06885234],\n","       [ 0.12880091,  0.21504535, -0.01799065],\n","       [ 0.16186559, -0.07109689, -0.02908225],\n","       [ 0.09446819, -0.09087249, -0.01543287],\n","       [ 0.04349717,  0.03067109,  0.19251256],\n","       [ 0.10733491, -0.11161215,  0.17111428],\n","       [ 0.09727035, -0.05476533, -0.01897378],\n","       [ 0.06792472, -0.10985316, -0.10962892],\n","       [ 0.17378193, -0.19984071, -0.0066875 ],\n","       [-0.15738074,  0.14314252, -0.15309983],\n","       [-0.06962364,  0.24228768, -0.06528052],\n","       [ 0.18120266,  0.10034335,  0.12494808],\n","       [-0.03076465, -0.05781899,  0.23286396],\n","       [-0.18231207, -0.18222208,  0.23515499],\n","       [-0.00936589,  0.03148895,  0.06742438],\n","       [-0.10296868,  0.11493563,  0.19582003],\n","       [-0.23901781,  0.22853053,  0.23696665],\n","       [ 0.07826745, -0.10290492, -0.16714165],\n","       [ 0.20539442,  0.00760246, -0.16839524],\n","       [-0.00375412, -0.1863336 , -0.12483139],\n","       [ 0.13465124, -0.19670907,  0.21117793],\n","       [ 0.12557213,  0.10915501,  0.03591557],\n","       [ 0.08052881, -0.16261236,  0.05507041],\n","       [-0.22897641,  0.16341618,  0.19240648],\n","       [ 0.13682307, -0.02198514, -0.09764886],\n","       [-0.01794746,  0.2103362 ,  0.13823579],\n","       [ 0.1150362 , -0.17375688, -0.24057953],\n","       [-0.08120901,  0.08402849,  0.21492696],\n","       [-0.03890706, -0.19390082, -0.12636106],\n","       [ 0.17952214,  0.11437407, -0.00255298],\n","       [ 0.03840736, -0.11222234,  0.183099  ],\n","       [-0.12465588,  0.14987956,  0.20876712],\n","       [-0.12443014, -0.08981618, -0.05460338],\n","       [ 0.21181187,  0.19665796, -0.0203854 ],\n","       [ 0.04743288, -0.18882   , -0.0137822 ],\n","       [-0.2239048 ,  0.08520125,  0.01620476],\n","       [-0.05190701, -0.12253234,  0.02159481],\n","       [-0.1178609 , -0.08646245,  0.204364  ],\n","       [-0.06671388,  0.16594064,  0.11666008],\n","       [ 0.06113711,  0.17759654,  0.02624259],\n","       [-0.13403538, -0.10959762,  0.04806395],\n","       [ 0.0510314 ,  0.23210122,  0.1849786 ],\n","       [ 0.02683203, -0.16393076, -0.20716102],\n","       [-0.01288815, -0.17758292, -0.0685171 ],\n","       [ 0.07385577, -0.18158077, -0.1888127 ],\n","       [-0.11086459, -0.07681827, -0.18415502],\n","       [ 0.0560918 ,  0.03993486, -0.11787275],\n","       [-0.13286489,  0.14622894, -0.05891215],\n","       [ 0.08572211, -0.05224155, -0.09872247],\n","       [-0.21751374, -0.03279044, -0.02096226],\n","       [ 0.22267462, -0.0259218 ,  0.08321732],\n","       [ 0.03654681,  0.13164552,  0.11670817],\n","       [-0.01666377,  0.05325934,  0.00641392],\n","       [ 0.08431894, -0.10457743, -0.1823567 ],\n","       [-0.11056168,  0.18751372, -0.18406343],\n","       [-0.15740702,  0.08001935, -0.05942892],\n","       [ 0.14319271, -0.21312849,  0.03406035],\n","       [-0.12450039, -0.18449892,  0.03087745],\n","       [ 0.00736573, -0.04546385, -0.2400114 ],\n","       [-0.14036465,  0.01942537, -0.02066525],\n","       [ 0.13298382, -0.20137642, -0.22287978],\n","       [ 0.23142853,  0.02929998,  0.00175514],\n","       [-0.19036208, -0.16161023,  0.18040863],\n","       [-0.02678839,  0.07756668, -0.04732963],\n","       [ 0.23177797, -0.0651555 , -0.18082428],\n","       [ 0.15409306,  0.15214176,  0.20048876],\n","       [-0.18945052,  0.19118682,  0.18472458],\n","       [-0.13958567, -0.19283375,  0.00097915],\n","       [-0.09575836, -0.22798926,  0.16456121],\n","       [-0.04440936,  0.14355919, -0.07090589],\n","       [-0.07131454, -0.06637056,  0.09830285],\n","       [-0.07813077,  0.12813674, -0.1699559 ]], dtype=float32)>, <tf.Variable 'dense_126/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[ 1.29535804e-02,  6.78731874e-02, -1.05758265e-01],\n","       [-5.63113578e-02,  1.20971546e-01, -1.14963695e-01],\n","       [-1.27413452e-01, -3.64948413e-03, -3.36544216e-02],\n","       [ 1.07456729e-01,  6.43309727e-02,  1.18086375e-01],\n","       [-1.12492383e-01, -4.08745222e-02, -9.64511409e-02],\n","       [-1.08130902e-01, -2.93419976e-02, -3.67468596e-02],\n","       [ 1.49644062e-01, -1.10380866e-01, -1.42482296e-01],\n","       [-8.34252909e-02, -1.11370839e-01,  2.65413299e-02],\n","       [ 1.09200805e-01, -3.71926948e-02, -1.28618911e-01],\n","       [-7.04553127e-02, -5.90890460e-02, -5.21403179e-02],\n","       [-1.14888467e-01, -7.99723566e-02,  3.81560586e-02],\n","       [ 1.44331619e-01,  1.35847971e-01,  6.16335198e-02],\n","       [ 4.87742275e-02, -2.02731825e-02,  4.88480553e-02],\n","       [-7.67556056e-02,  1.27693549e-01, -1.33370504e-01],\n","       [ 5.69970869e-02, -1.16996676e-01, -3.22048478e-02],\n","       [ 4.97780293e-02, -1.50198475e-01,  1.28320634e-01],\n","       [-2.13044751e-02, -2.53214445e-02,  1.18363410e-01],\n","       [-1.31854340e-01, -1.27521604e-01, -1.93088199e-03],\n","       [ 2.74744183e-02,  2.27027535e-02,  3.37785445e-02],\n","       [ 5.00695035e-02,  1.32864058e-01,  1.31776363e-01],\n","       [-7.55824223e-02, -6.74194470e-02, -9.72203612e-02],\n","       [ 2.97583081e-02, -6.55410662e-02,  1.37096316e-01],\n","       [ 4.01697606e-02,  2.28501740e-03,  9.52092037e-02],\n","       [-5.98860532e-02,  5.97871877e-02,  5.33312410e-02],\n","       [ 1.43617555e-01, -4.51979414e-02,  1.53516317e-02],\n","       [-4.75176945e-02, -4.32847179e-02,  4.00599800e-02],\n","       [-5.13805300e-02, -4.89842854e-02,  9.78004709e-02],\n","       [-1.72508489e-02, -8.30184668e-03, -1.16192862e-01],\n","       [ 6.69023767e-02, -5.40530495e-02, -8.17028619e-03],\n","       [-1.04574956e-01, -6.00511283e-02, -6.61105439e-02],\n","       [-6.24669390e-03,  7.61530772e-02,  1.30285263e-01],\n","       [-8.75715574e-04, -1.00513600e-01,  6.39373856e-03],\n","       [-9.22404751e-02,  1.22446775e-01, -1.27866026e-03],\n","       [-1.12085745e-01,  1.39701506e-02,  1.22029155e-01],\n","       [-1.18202582e-01,  1.50195330e-01,  9.27813649e-02],\n","       [ 3.46425711e-03, -1.11825630e-01, -1.38864085e-01],\n","       [ 5.34392670e-02,  1.40394732e-01,  1.44388258e-01],\n","       [ 1.06249496e-01,  9.71363485e-02,  1.00274585e-01],\n","       [-7.62367621e-02, -1.05935089e-01, -7.39839971e-02],\n","       [ 1.53278988e-02, -1.48232803e-02, -1.20513976e-01],\n","       [-1.36406153e-01, -1.37900174e-01, -2.26623397e-02],\n","       [-1.36206791e-01, -1.55675197e-02,  7.36747519e-04],\n","       [-1.32217854e-01, -1.31408364e-01,  1.17274396e-01],\n","       [ 1.08050510e-01,  3.55717950e-02, -9.04231817e-02],\n","       [ 1.55639797e-02,  3.53594571e-02, -9.06747356e-02],\n","       [ 1.29539430e-01,  7.92286992e-02,  1.30423069e-01],\n","       [-6.70648888e-02, -1.31734818e-01,  5.80631495e-02],\n","       [-1.15297176e-01, -8.12345464e-03, -7.08991215e-02],\n","       [ 2.72919424e-02,  4.24885415e-02,  3.28666298e-03],\n","       [-1.44734383e-01, -1.29987160e-03, -1.51024029e-01],\n","       [ 5.41468039e-02,  1.21211722e-01, -1.50665373e-01],\n","       [ 4.40507829e-02, -6.04677461e-02,  1.14401337e-02],\n","       [ 1.07640430e-01, -5.21185473e-02, -1.00881390e-01],\n","       [-4.53332514e-02,  1.27307326e-01,  5.13863228e-02],\n","       [-2.68649193e-03, -8.16723704e-02, -1.05868101e-01],\n","       [-9.14278924e-02, -1.42849475e-01,  3.75917926e-02],\n","       [-1.00115590e-01,  1.33547544e-01,  6.55138940e-02],\n","       [-3.69531959e-02, -1.04610935e-01,  4.61054817e-02],\n","       [ 8.18416700e-02, -2.63111871e-02, -1.11690201e-01],\n","       [ 5.15576713e-02, -1.49561753e-02,  3.54914479e-02],\n","       [ 8.06657225e-02,  1.02429137e-01, -1.34855032e-01],\n","       [ 1.40853196e-01,  2.10984349e-02, -1.17085487e-01],\n","       [ 8.51877034e-02,  3.94857712e-02, -2.87145879e-02],\n","       [ 1.10638648e-01,  5.23601584e-02, -1.50704280e-01],\n","       [-2.27772370e-02, -1.87638041e-04, -6.41756952e-02],\n","       [ 4.49017584e-02,  9.19786002e-03, -4.52303998e-02],\n","       [-5.46580404e-02, -1.08689278e-01, -6.08698465e-03],\n","       [ 6.81058168e-02,  7.46365488e-02, -1.85834989e-02],\n","       [-4.45614606e-02,  4.08137999e-02, -6.79426789e-02],\n","       [-5.87431081e-02, -2.10742671e-02, -1.03281565e-01],\n","       [-1.92965176e-02, -6.93272054e-02,  1.75176021e-02],\n","       [-2.22152541e-03, -7.44829793e-03, -1.20616145e-01],\n","       [ 8.28505978e-02,  1.25345916e-01,  2.37352867e-02],\n","       [-1.02721803e-01,  1.17622644e-01,  1.42154157e-01],\n","       [ 5.97221293e-02, -1.23466343e-01, -7.44480267e-02],\n","       [ 1.24105781e-01,  2.22410671e-02,  9.02437046e-02],\n","       [ 1.20908909e-01, -7.63496161e-02, -6.88637048e-02],\n","       [-3.81604396e-02,  3.99998762e-02,  1.33719102e-01],\n","       [-7.61236921e-02,  1.26095414e-01, -1.29834697e-01],\n","       [-1.04631949e-02, -1.43414065e-01,  4.53934819e-02],\n","       [ 7.31750727e-02,  6.55600652e-02,  4.43944149e-02],\n","       [ 8.76082480e-02, -5.25760129e-02, -5.70392311e-02],\n","       [ 4.22664993e-02, -1.02069594e-01, -1.31183108e-02],\n","       [-3.39194685e-02,  1.14158101e-01, -8.06987099e-03],\n","       [ 8.32302049e-02,  2.44901963e-02,  1.35217935e-01],\n","       [ 2.85672918e-02, -1.46212980e-01, -5.28447218e-02],\n","       [ 4.19145636e-03, -6.78323582e-02,  5.21223173e-02],\n","       [ 1.75374448e-02, -4.18801093e-03, -2.42652278e-02],\n","       [-1.43738031e-01,  3.66044156e-02, -9.53674987e-02],\n","       [-7.69835785e-02, -1.28964737e-01,  6.81244284e-02],\n","       [-2.80953869e-02,  5.28256744e-02, -4.88677025e-02],\n","       [-1.44310787e-01,  2.85305530e-02, -1.36919498e-01],\n","       [ 6.61702156e-02, -1.47879079e-01,  9.51221436e-02],\n","       [ 1.37955889e-01,  1.01410508e-01, -7.89590776e-02],\n","       [ 6.78832084e-02,  1.19182095e-01,  2.74220165e-02],\n","       [ 6.07740730e-02, -6.45146966e-02,  1.40919387e-01],\n","       [-4.86489534e-02,  3.67877947e-04,  1.22961089e-01],\n","       [ 9.66373011e-02,  8.17656070e-02,  5.69557995e-02],\n","       [-5.74770309e-02, -6.61826208e-02, -5.36995791e-02],\n","       [-9.86835510e-02,  1.18249819e-01, -8.75716731e-02],\n","       [-3.86353210e-02, -4.70106192e-02, -1.42856538e-01],\n","       [-1.33997068e-01, -7.09130093e-02, -4.78896424e-02],\n","       [ 6.53460026e-02,  5.01047005e-04, -1.07840225e-01],\n","       [ 1.14243180e-01, -4.30996306e-02, -3.96206826e-02],\n","       [-8.83521046e-03,  1.54696952e-03,  5.49134612e-02],\n","       [-4.39597806e-03, -1.08254254e-02, -9.78213772e-02],\n","       [ 5.80004081e-02, -1.02355577e-01,  1.93873644e-02],\n","       [-3.23573984e-02,  1.17537983e-01, -5.42025529e-02],\n","       [ 9.86611471e-02,  1.46295289e-02,  7.44731799e-02],\n","       [ 1.25415221e-01, -7.61189219e-03,  3.46765518e-02],\n","       [-1.52653247e-01, -7.83660561e-02,  6.55423775e-02],\n","       [-5.84442392e-02, -3.96503471e-02, -1.69380661e-02],\n","       [-1.22021846e-01, -5.80875240e-02, -7.64191672e-02],\n","       [ 8.72129481e-03, -1.25178725e-01,  1.24735564e-01],\n","       [-8.69849473e-02,  4.52678241e-02, -3.20282392e-03],\n","       [ 1.03806816e-01, -8.43444392e-02,  1.89180616e-02],\n","       [-2.34709084e-02,  7.60194212e-02,  8.38762820e-02],\n","       [-1.32280394e-01,  1.50057524e-01, -1.33814529e-01],\n","       [ 3.29345390e-02,  1.41058177e-01, -4.02699858e-02],\n","       [-1.05655221e-02, -1.30153000e-01,  6.70840638e-03],\n","       [ 1.07440390e-01,  2.08744314e-02,  1.09336399e-01],\n","       [ 6.07615113e-02,  8.55847821e-02,  1.06479175e-01],\n","       [-1.01045400e-01,  1.05589509e-01,  3.83235849e-02],\n","       [ 1.47510722e-01, -1.01128332e-01, -1.43793851e-01],\n","       [-2.20396388e-02,  1.23081906e-02, -5.01831509e-02],\n","       [ 1.28969133e-01,  1.39268667e-01,  1.45734698e-01],\n","       [ 5.85516840e-02,  8.45560282e-02, -1.17374182e-01],\n","       [-1.31279126e-01, -1.51489314e-03, -1.14278547e-01],\n","       [-4.06566076e-02, -1.10951714e-01, -1.25409231e-01],\n","       [ 2.27265321e-02,  6.27165884e-02, -5.82305714e-02],\n","       [-2.10639760e-02,  1.07636124e-01,  1.58453546e-02],\n","       [-2.35887058e-02, -7.65559869e-03,  7.43890479e-02],\n","       [-3.54905203e-02, -2.97360439e-02,  5.48487529e-02],\n","       [-1.10155329e-01,  1.30497813e-01,  2.63350792e-02],\n","       [ 1.04030378e-01, -8.03434290e-03,  2.03579795e-02],\n","       [-4.88632619e-02, -2.66357418e-02,  6.04486354e-02],\n","       [-9.65182930e-02,  3.95560227e-02, -6.53967336e-02],\n","       [-8.47183987e-02,  1.39077380e-01, -1.07819095e-01],\n","       [-2.74531008e-03,  1.06767155e-01, -1.34259105e-01],\n","       [-3.96662466e-02, -9.09862593e-02,  4.95915152e-02],\n","       [ 1.17541235e-02,  1.06755577e-01, -6.04133643e-02],\n","       [ 1.19416319e-01,  1.11640068e-02,  8.75452682e-02],\n","       [-1.34331271e-01,  8.27394649e-02, -9.69174504e-03],\n","       [-7.18849376e-02, -1.39727339e-01, -1.38755307e-01],\n","       [-1.27118230e-01, -9.67405140e-02, -1.58797000e-02],\n","       [-4.35087159e-02, -4.53398749e-02, -2.45437846e-02],\n","       [-1.05899476e-01, -1.86930895e-02, -4.78075258e-02],\n","       [ 1.29791573e-01, -1.41580537e-01,  4.00521755e-02],\n","       [-5.63462675e-02, -1.12363882e-01, -2.38668025e-02],\n","       [ 1.01339549e-01,  5.39794229e-02, -2.34997831e-02],\n","       [-3.45764602e-05, -4.81685661e-02, -4.46760841e-02],\n","       [-4.87991534e-02,  4.09351438e-02,  5.84038300e-03],\n","       [ 8.46557394e-02, -2.97799557e-02,  4.37799059e-02],\n","       [-4.27622274e-02, -5.45548797e-02, -4.25362438e-02],\n","       [ 1.25671089e-01, -1.35821581e-01, -2.65594237e-02],\n","       [ 1.19717093e-02,  8.74948353e-02,  9.43775252e-02],\n","       [ 4.51004319e-02,  7.59815946e-02, -7.98426103e-03],\n","       [-9.41310823e-02,  2.25540251e-02, -1.10505119e-01],\n","       [-8.40529427e-02, -6.28328919e-02, -3.28694633e-03],\n","       [-1.03722692e-01, -1.17504008e-01,  3.80714908e-02],\n","       [-1.63825564e-02,  9.37334523e-02,  1.48072883e-01],\n","       [-1.47920032e-03,  6.86024204e-02,  1.67365726e-02],\n","       [ 1.15719169e-01,  9.01123136e-02, -6.49028569e-02],\n","       [-5.97554371e-02, -1.06957145e-01,  4.59148474e-02],\n","       [ 8.63525644e-02, -2.26646364e-02, -8.39422196e-02],\n","       [ 1.40996307e-01, -1.17077634e-01, -1.25835498e-03],\n","       [-4.35460778e-03,  1.07495919e-01, -1.13106482e-01],\n","       [-8.17434117e-02,  1.20879360e-01,  9.44770798e-02],\n","       [-5.43962866e-02,  3.95285971e-02,  1.25869140e-01],\n","       [-5.81960604e-02,  1.53044090e-01, -2.37575434e-02],\n","       [ 8.52082744e-02,  1.27704158e-01, -1.13637306e-01],\n","       [-1.27979532e-01, -6.84164986e-02,  8.46291929e-02],\n","       [-4.17766422e-02,  4.59397770e-02, -4.65099961e-02],\n","       [-6.89470842e-02,  1.02428347e-01,  8.52917656e-02],\n","       [ 1.47108540e-01, -1.38304919e-01,  1.07157245e-01],\n","       [-5.42307347e-02, -1.00812949e-01, -7.25359097e-03],\n","       [ 7.33526051e-02,  1.48199182e-02,  3.65397409e-02],\n","       [-1.03442051e-01, -4.51980438e-03, -5.31702824e-02],\n","       [ 5.52412942e-02,  1.14986859e-01, -1.51103571e-01],\n","       [-1.06870927e-01,  3.14271636e-02, -5.06556369e-02],\n","       [-1.14427425e-01, -1.45871446e-01,  1.18949771e-01],\n","       [ 7.75793195e-02,  1.38915390e-01, -1.02091186e-01],\n","       [ 1.38799742e-01, -7.76583999e-02, -3.04459594e-03],\n","       [ 1.36352509e-01, -1.27004564e-01,  8.77117913e-04],\n","       [ 3.86574529e-02,  1.04625374e-01,  1.21276945e-01],\n","       [-4.76126894e-02, -2.08172314e-02,  9.64654982e-02],\n","       [-1.10279910e-01,  3.60226333e-02, -2.17845887e-02],\n","       [-1.39933541e-01,  5.81262521e-02, -8.55618566e-02],\n","       [-1.41504601e-01,  1.03051383e-02, -9.45356563e-02],\n","       [-3.78823723e-03,  1.23913348e-01,  1.37817100e-01],\n","       [ 1.57081559e-02,  7.10850134e-02,  6.62337318e-02],\n","       [-9.24890637e-02, -2.30668187e-02,  2.28678398e-02],\n","       [ 1.41084135e-01, -4.19676974e-02, -1.25058210e-02],\n","       [-9.48532075e-02,  6.82475567e-02, -1.25169838e-02],\n","       [ 3.13279256e-02, -4.15856838e-02,  2.30779624e-04],\n","       [-1.39067009e-01,  4.52399738e-02, -1.52402565e-01],\n","       [ 5.10154068e-02, -7.03755990e-02,  3.26415189e-02],\n","       [ 7.16432035e-02, -7.89331365e-03,  1.40454918e-01],\n","       [ 1.41803637e-01,  5.18326722e-02,  3.85408923e-02],\n","       [ 1.32439032e-01, -1.11908212e-01, -1.27737194e-01],\n","       [-5.44658974e-02,  1.38713285e-01,  9.68411043e-02],\n","       [ 6.03195354e-02, -3.15166824e-02, -3.58601660e-02],\n","       [ 1.37716413e-01, -3.02826762e-02,  1.70085225e-02],\n","       [-1.21005438e-01, -5.43212220e-02, -3.44720040e-03],\n","       [-9.09049734e-02,  1.59563925e-02,  1.26437604e-01],\n","       [ 9.50542390e-02,  1.17940426e-01,  5.12349792e-03],\n","       [ 1.74045116e-02, -1.30104780e-01, -1.44228965e-01],\n","       [-6.82661459e-02, -9.98536870e-02, -1.13603756e-01],\n","       [ 4.13416885e-02, -7.20019937e-02, -2.22312845e-02],\n","       [-8.92923325e-02, -1.27292171e-01, -7.20221624e-02],\n","       [-1.22665748e-01, -1.36085421e-01, -5.42686693e-03],\n","       [-5.65213636e-02,  7.89015647e-03, -5.10349358e-03],\n","       [-8.76055658e-02, -1.38977066e-01, -1.26040071e-01],\n","       [-4.42951992e-02, -6.36420622e-02,  2.79287938e-02],\n","       [ 7.42768943e-02,  1.24018125e-01,  7.09636211e-02],\n","       [-1.23494100e-02,  1.16397329e-01, -6.47636801e-02],\n","       [-4.64743283e-03, -1.43421888e-01, -1.42023370e-01],\n","       [ 9.56623778e-02, -3.97213909e-04, -1.36451488e-02],\n","       [ 6.18811883e-02,  4.19528410e-02, -3.37135158e-02],\n","       [ 7.14822710e-02, -1.13426879e-01,  1.41958192e-01],\n","       [ 4.36235555e-02, -1.18272856e-01, -7.96314701e-02],\n","       [ 1.42914802e-01, -7.46626258e-02, -2.64908578e-02],\n","       [ 1.13163069e-01, -1.48732737e-01, -1.84131991e-02],\n","       [-5.49817458e-02, -8.16564187e-02,  1.24279417e-01],\n","       [-7.82607868e-02,  2.61513758e-02, -1.42461076e-01],\n","       [-9.83198080e-03,  4.37586084e-02,  1.30588889e-01],\n","       [-1.49172666e-02, -1.30057216e-01, -1.49805695e-01],\n","       [ 6.26003146e-02,  1.40888885e-01, -5.84508479e-02],\n","       [ 6.01855330e-02,  8.30539130e-03,  2.77920477e-02],\n","       [ 1.15126513e-01,  2.49895323e-02, -2.18140297e-02],\n","       [ 2.54535489e-02, -4.35171984e-02,  1.95445437e-02],\n","       [ 1.49413660e-01, -9.03813019e-02, -9.21520442e-02],\n","       [ 2.42348500e-02, -8.51021111e-02,  9.28789824e-02],\n","       [-1.16075926e-01, -9.71070603e-02, -6.71790121e-03],\n","       [ 1.35270625e-01,  9.43603665e-02, -2.17191465e-02],\n","       [-1.37004837e-01,  1.98832676e-02,  3.97135541e-02],\n","       [-7.42575824e-02, -1.15324920e-02, -1.37805581e-01],\n","       [-7.83524290e-02,  1.02467619e-01,  3.84781659e-02],\n","       [-1.01306856e-01,  9.04771909e-02, -1.82912424e-02],\n","       [-1.39140129e-01,  5.03313690e-02, -5.07918708e-02],\n","       [-1.16052829e-01, -1.25647068e-01,  3.35894115e-02],\n","       [-9.68992710e-03,  1.41468301e-01, -9.88762826e-02],\n","       [-5.88494092e-02, -4.92969081e-02,  9.40728709e-02],\n","       [-1.26471356e-01,  8.12484398e-02,  1.40897900e-01],\n","       [-5.72337992e-02, -8.85729715e-02,  1.33155644e-01],\n","       [-1.15457848e-01, -4.51947525e-02,  1.30502984e-01],\n","       [ 1.51348501e-01,  6.78290427e-02,  1.22824786e-02],\n","       [ 3.48940864e-02,  6.33928627e-02,  6.16378449e-02],\n","       [ 8.48429501e-02, -2.21193098e-02,  1.49517721e-02],\n","       [ 1.02749839e-01,  7.50357062e-02,  1.05843902e-01],\n","       [ 4.29666750e-02, -3.96782439e-03, -2.48441007e-02],\n","       [-6.51063696e-02, -1.21063620e-01, -6.68463483e-02],\n","       [-6.06872514e-02,  6.00253195e-02,  1.35827884e-01],\n","       [-1.19349085e-01,  2.72242408e-02, -5.81812393e-03],\n","       [-7.78507665e-02, -3.50207202e-02, -3.09441965e-02],\n","       [-8.79394338e-02, -1.53629303e-01, -1.31319627e-01]], dtype=float32)>, <tf.Variable 'dense_127/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[-6.95848837e-02, -8.71745646e-02, -1.00191742e-01],\n","       [ 1.36507019e-01,  1.25065520e-01, -4.52249199e-02],\n","       [-6.05452359e-02,  1.17920369e-01, -2.93346271e-02],\n","       [-1.50774315e-01, -6.15371801e-02, -4.11541900e-03],\n","       [-9.17379335e-02, -1.20991603e-01,  7.23127052e-02],\n","       [ 9.08598602e-02, -1.33637702e-02, -1.44708306e-01],\n","       [ 6.96394518e-02,  6.03062995e-02,  3.68227847e-02],\n","       [ 4.19844687e-02, -5.07848077e-02, -1.51442289e-01],\n","       [ 5.72963506e-02, -8.49458799e-02,  4.04505199e-03],\n","       [ 1.29444584e-01,  1.05109187e-02, -9.84882712e-02],\n","       [ 9.38809663e-03,  1.12753630e-01, -5.12568699e-03],\n","       [ 1.48457244e-01,  6.98194802e-02,  1.40181974e-01],\n","       [-1.20277710e-01,  1.03629440e-01,  1.10226519e-01],\n","       [ 7.00595677e-02,  4.94695641e-02,  4.92635034e-02],\n","       [ 4.15823050e-02,  1.34338319e-01, -4.20978852e-03],\n","       [ 1.16141409e-01, -4.03563213e-03, -1.39592171e-01],\n","       [ 1.33291572e-01, -4.47949441e-03, -1.27524450e-01],\n","       [-8.58810693e-02,  1.79542750e-02, -1.29607052e-01],\n","       [-1.42261982e-01,  3.56448218e-02,  3.96963805e-02],\n","       [-7.26142377e-02,  8.48077685e-02, -1.33770645e-01],\n","       [-6.74054474e-02, -2.92587578e-02, -6.38945550e-02],\n","       [ 9.62346941e-02,  1.73323583e-02,  1.28479689e-01],\n","       [ 4.16939668e-02, -1.19699538e-01,  4.44893427e-02],\n","       [-1.05513297e-01,  6.26276582e-02, -1.10638522e-01],\n","       [-4.76356298e-02, -1.40496809e-03,  5.70988469e-02],\n","       [ 1.43679634e-01,  1.24928340e-01,  6.53772354e-02],\n","       [-3.75518203e-02,  1.41405359e-01, -8.34262893e-02],\n","       [-2.32554264e-02, -1.32770777e-01, -1.23186409e-01],\n","       [ 1.37770623e-01, -1.41616926e-01, -6.86020702e-02],\n","       [ 1.52189480e-02, -9.79282334e-03, -1.14942552e-03],\n","       [-3.79380807e-02, -6.97968304e-02,  1.17687806e-01],\n","       [ 1.25137284e-01, -1.10742912e-01, -4.41552140e-02],\n","       [-1.15581691e-01, -5.57413511e-02,  4.41495255e-02],\n","       [ 4.96287867e-02, -3.06898216e-03,  2.14688033e-02],\n","       [-3.81768830e-02,  2.05505677e-02, -3.29246819e-02],\n","       [-9.14020985e-02,  3.45823653e-02,  8.77971351e-02],\n","       [ 9.60716754e-02,  3.48284021e-02,  1.48991093e-01],\n","       [-7.61561170e-02, -1.33570030e-01,  8.77398476e-02],\n","       [ 3.85201201e-02,  2.83826180e-02, -1.25880390e-01],\n","       [-4.05845270e-02,  5.02996594e-02,  1.44464388e-01],\n","       [ 1.78989097e-02, -1.74798574e-02, -1.00874037e-01],\n","       [-1.07546963e-01,  1.18548892e-01,  4.37301621e-02],\n","       [-7.57167637e-02,  1.14204727e-01, -9.05707255e-02],\n","       [-6.93671405e-02,  3.82999964e-02, -1.49828345e-01],\n","       [-1.18202396e-01, -1.11200832e-01,  1.15541205e-01],\n","       [-1.34351656e-01, -1.40313432e-01,  8.28930140e-02],\n","       [-1.95336435e-02,  1.21529162e-01,  6.47185594e-02],\n","       [ 1.46720245e-01,  1.05157375e-01, -4.39687259e-02],\n","       [-2.57885046e-02,  1.27656445e-01, -6.38021976e-02],\n","       [ 3.98123488e-02,  1.33544788e-01,  4.44407500e-02],\n","       [-1.49124473e-01, -5.09020612e-02, -1.11651540e-01],\n","       [-1.81324221e-02, -1.06531121e-01,  9.57571864e-02],\n","       [-1.62263811e-02,  5.75408190e-02, -5.20461090e-02],\n","       [-1.28443241e-01,  6.21238388e-02, -1.50369242e-01],\n","       [ 1.35214150e-01,  8.85109007e-02,  4.85590138e-02],\n","       [ 6.19140156e-02,  1.44562200e-01,  3.46499495e-02],\n","       [-7.21257478e-02,  3.11455317e-02,  1.39229193e-01],\n","       [-1.20623037e-01,  1.16298743e-01,  1.49645435e-04],\n","       [-7.20878243e-02, -1.15500405e-01, -7.25695789e-02],\n","       [-9.46916491e-02,  1.11911416e-01,  6.19879849e-02],\n","       [-1.08923107e-01,  1.43809304e-01,  8.97575393e-02],\n","       [-3.61669436e-02, -4.78161080e-03,  2.45218514e-03],\n","       [ 6.92680106e-02, -1.06944643e-01,  1.29886478e-01],\n","       [ 1.41392276e-01,  9.40918475e-02, -1.28466263e-01],\n","       [ 6.03959784e-02,  9.43794288e-03, -6.87519535e-02],\n","       [-5.19428886e-02, -1.06250018e-01,  7.25499615e-02],\n","       [-8.01469982e-02,  8.53807330e-02,  8.56958702e-02],\n","       [-1.15613781e-01,  5.50122485e-02,  4.22407612e-02],\n","       [-1.27989035e-02,  3.54616699e-04,  1.26291782e-01],\n","       [-1.36926353e-01, -9.24383551e-02,  1.38373196e-01],\n","       [-7.82701094e-03,  1.21288836e-01,  1.45678490e-01],\n","       [-1.11235805e-01,  1.27404243e-01,  2.46968344e-02],\n","       [-9.41833481e-02,  7.37486333e-02, -4.14466970e-02],\n","       [-7.84476697e-02,  4.62730266e-02,  2.66201934e-03],\n","       [ 9.72269773e-02,  4.37600091e-02,  1.44186661e-01],\n","       [ 1.64179318e-02, -1.16944648e-01,  8.06378387e-03],\n","       [ 1.42221123e-01, -4.70167398e-02,  9.29978341e-02],\n","       [ 7.21241385e-02,  5.62541895e-02, -4.93025780e-02],\n","       [ 4.38448712e-02, -3.17203701e-02, -1.27441511e-01],\n","       [-7.18543753e-02, -1.44649208e-01, -2.92109903e-02],\n","       [ 1.02586262e-01,  2.49510054e-02, -7.39006400e-02],\n","       [ 1.00511201e-01, -1.02310926e-01, -1.33515716e-01],\n","       [-4.78555355e-03, -6.83907047e-02, -1.27451112e-02],\n","       [ 1.33781403e-01, -2.21575927e-02,  5.22576272e-02],\n","       [-6.74590245e-02,  3.45714912e-02,  1.48265541e-01],\n","       [-1.59465522e-03, -6.14310540e-02, -7.03810677e-02],\n","       [ 1.14196628e-01, -1.09608606e-01,  9.05088633e-02],\n","       [ 8.82574394e-02, -2.00831573e-02,  5.77440821e-02],\n","       [-8.91264677e-02, -4.79673333e-02, -5.25922775e-02],\n","       [ 8.84362161e-02, -1.17535122e-01, -8.14106837e-02],\n","       [-1.61587447e-02,  1.05636626e-01,  1.40213251e-01],\n","       [ 7.55769908e-02,  7.18688369e-02, -9.86009371e-03],\n","       [-2.52720714e-03, -1.13852963e-01, -9.12563428e-02],\n","       [ 1.33342231e-02,  7.25275874e-02,  9.62995749e-04],\n","       [ 7.14504942e-02,  8.59399289e-02,  1.05851680e-01],\n","       [-1.78851392e-02, -4.51394022e-02,  9.88685340e-02],\n","       [ 4.43216041e-02, -1.09190382e-01, -3.53899226e-02],\n","       [-3.86475474e-02,  1.10256724e-01, -1.06045930e-02],\n","       [-6.20116852e-02,  6.81320354e-02, -1.35742314e-03],\n","       [ 7.03025237e-02,  6.29572272e-02, -8.25390443e-02],\n","       [ 3.82585675e-02,  1.25012115e-01, -1.16524197e-01],\n","       [-5.53263212e-03, -1.19288452e-01, -9.91691798e-02],\n","       [-8.88156146e-02, -7.32527897e-02,  2.84999292e-02],\n","       [-4.07796986e-02,  1.16775826e-01, -2.73809899e-02],\n","       [ 1.12772267e-02,  9.96062160e-02, -6.77255541e-02],\n","       [ 3.54394875e-02, -9.80713144e-02,  3.86436284e-02],\n","       [-1.16007235e-02, -6.13249280e-02,  1.49849042e-01],\n","       [ 7.38928616e-02,  3.00013665e-02, -1.04183443e-02],\n","       [-9.53060016e-02, -8.11503157e-02,  1.14753537e-01],\n","       [ 1.12508774e-01, -3.66119854e-02, -1.38429701e-01],\n","       [ 1.50502548e-01,  1.06067648e-02,  3.50702293e-02],\n","       [-3.34290485e-03,  7.53402412e-02, -7.11097717e-02],\n","       [ 6.05726354e-02,  4.75445949e-02, -1.37113035e-01],\n","       [-3.11933029e-02, -9.59684476e-02, -1.69609003e-02],\n","       [-9.83755365e-02, -1.40699565e-01, -1.27593651e-01],\n","       [-8.70273709e-02,  5.28605506e-02, -1.14754088e-01],\n","       [-1.32689431e-01,  1.08654998e-01,  3.05577964e-02],\n","       [-6.22122474e-02, -4.69797254e-02, -1.49885908e-01],\n","       [ 2.37557031e-02,  1.29007593e-01, -8.27523042e-03],\n","       [-9.09772236e-03,  8.64099804e-03, -8.16268288e-03],\n","       [ 4.29244749e-02, -6.96201697e-02, -1.45462140e-01],\n","       [ 8.51556435e-02, -3.40849273e-02, -1.00297183e-01],\n","       [-9.97365192e-02,  1.26210585e-01, -1.04641505e-01],\n","       [-8.53033960e-02,  9.35584605e-02,  6.16310164e-02],\n","       [-4.73739840e-02, -2.80022249e-02,  1.97891630e-02],\n","       [ 7.18244761e-02,  1.28340170e-01, -6.28878623e-02],\n","       [-6.16965704e-02,  6.51042014e-02, -2.89719575e-03],\n","       [-1.07739843e-01,  1.38459042e-01,  9.43006128e-02],\n","       [-9.43716392e-02, -8.83122683e-02,  1.05361030e-01],\n","       [ 6.91955090e-02, -1.30664930e-01,  8.81917309e-03],\n","       [-1.39297321e-01, -3.65104340e-02,  1.03317633e-01],\n","       [ 1.53303385e-01,  1.46311745e-01, -1.35591999e-01],\n","       [-1.89285912e-02, -2.61077974e-02, -1.14565700e-01],\n","       [ 1.26938090e-01, -8.69487063e-04,  1.41575441e-01],\n","       [-2.33070254e-02, -9.92280543e-02,  1.15315787e-01],\n","       [ 9.15127024e-02, -1.29405916e-01,  1.64340977e-02],\n","       [ 5.46168983e-02, -5.78367300e-02,  1.32076547e-01],\n","       [-1.23987734e-01, -1.15826912e-01,  1.10050097e-01],\n","       [ 5.20647541e-02, -7.67421797e-02, -1.03872374e-01],\n","       [-9.72237438e-02, -8.22474658e-02, -8.67062360e-02],\n","       [-7.92048350e-02, -2.95445807e-02,  1.95080191e-02],\n","       [-1.32198125e-01,  1.08478919e-01,  9.17988718e-02],\n","       [ 2.20934357e-02, -4.55685481e-02,  3.56407277e-02],\n","       [-5.90166226e-02,  6.60035610e-02,  1.07457556e-01],\n","       [-6.84903413e-02,  5.03107533e-02, -6.20326288e-02],\n","       [-4.01858687e-02, -9.54233557e-02, -1.87516175e-02],\n","       [-1.20572582e-01,  8.17129463e-02,  1.62612069e-02],\n","       [ 7.33489543e-02,  1.01440676e-01,  2.83293277e-02],\n","       [ 7.00708181e-02, -3.68173122e-02, -1.48301031e-02],\n","       [ 6.16040267e-02,  2.62461379e-02,  9.75795835e-03],\n","       [ 1.66473240e-02, -1.36730298e-01,  1.42453328e-01],\n","       [-1.30218655e-01, -1.93722248e-02,  1.09584585e-01],\n","       [-4.28507552e-02,  5.59572689e-02, -1.10248653e-02],\n","       [ 8.92598927e-02,  4.94530722e-02, -3.97760281e-03],\n","       [-1.48627609e-01, -1.29914880e-01,  1.06979720e-01],\n","       [ 2.63332180e-03,  1.11022577e-01,  4.98728678e-02],\n","       [ 1.18571974e-01,  2.77196113e-02, -1.15240358e-01],\n","       [ 1.18883327e-01,  2.14953497e-02, -1.42569885e-01],\n","       [-1.27401128e-01, -1.47381485e-01, -9.95802954e-02],\n","       [-1.43588468e-01,  8.85685831e-02, -2.37598848e-02],\n","       [-5.63185439e-02,  8.81790742e-02,  8.04259703e-02],\n","       [-8.66380930e-02, -1.42010540e-01, -1.00731373e-01],\n","       [-1.44307300e-01,  1.52382523e-01, -1.54055338e-02],\n","       [-1.51510746e-03, -6.23441935e-02,  1.17047116e-01],\n","       [ 2.94841211e-02, -1.21835083e-01,  5.50193824e-02],\n","       [-1.17540479e-01,  8.20362121e-02,  6.15548976e-02],\n","       [-1.25161260e-01,  6.21101558e-02,  1.11086667e-01],\n","       [ 1.04444444e-01,  4.02331278e-02,  1.28123745e-01],\n","       [ 6.56172782e-02,  1.08211525e-01, -1.01858549e-01],\n","       [ 3.46755871e-04, -1.06534787e-01,  3.95056196e-02],\n","       [-9.42556933e-02, -1.20122917e-01,  1.09188452e-01],\n","       [ 1.26973391e-01,  1.08094238e-01, -3.54939848e-02],\n","       [ 2.98616532e-02,  6.13950565e-02, -7.98416957e-02],\n","       [ 1.99528830e-03, -1.32086873e-01, -1.08374238e-01],\n","       [ 1.38746455e-01,  5.40339947e-02, -8.75201970e-02],\n","       [ 2.30848026e-02, -1.15220062e-02,  3.90504822e-02],\n","       [ 1.42849281e-01, -7.88750872e-02, -1.95561685e-02],\n","       [-1.03094123e-01, -9.62123796e-02,  1.09605966e-02],\n","       [ 1.27119675e-01,  1.16680264e-01,  2.49535069e-02],\n","       [-6.64308220e-02,  4.54079323e-02,  9.47179645e-03],\n","       [ 7.29694143e-02,  5.55556305e-02, -7.52914548e-02],\n","       [ 1.13118038e-01, -1.35626435e-01,  6.97688907e-02],\n","       [ 6.15491569e-02, -1.23474859e-01,  1.22675516e-01],\n","       [-1.61155835e-02, -6.34817546e-03, -8.66399985e-03],\n","       [-8.91615599e-02,  1.19679503e-01,  2.85751130e-02],\n","       [ 1.24819458e-01,  5.21659758e-03,  2.55264575e-03],\n","       [-1.39450282e-01, -9.06707644e-02, -4.28813808e-02],\n","       [-1.37948617e-02,  1.09931961e-01, -6.21603057e-02],\n","       [-1.14300035e-01,  1.10756062e-01,  9.53794196e-02],\n","       [-9.69549567e-02, -1.48314923e-01,  1.32439792e-01],\n","       [-3.19730453e-02,  1.28327701e-02, -1.07016057e-01],\n","       [ 1.21694043e-01,  8.19935203e-02, -1.22489400e-01],\n","       [-9.84842703e-02,  9.81579423e-02, -8.35224167e-02],\n","       [ 9.80497226e-02,  1.20360613e-01, -1.13786161e-01],\n","       [ 5.75555079e-02,  1.08494647e-01,  1.18265949e-01],\n","       [-1.08253747e-01,  1.50253132e-01, -8.04079175e-02],\n","       [ 1.38475016e-01, -1.05869882e-01, -7.47333989e-02],\n","       [-3.33697498e-02,  3.80628742e-02,  2.36364435e-02],\n","       [ 4.46495861e-02, -1.32720798e-01, -5.68115525e-02],\n","       [ 9.57417935e-02, -8.23718458e-02,  8.05659518e-02],\n","       [-5.42628989e-02, -4.59735394e-02, -1.18863165e-01],\n","       [-1.08055837e-01, -1.10351369e-01,  1.19814828e-01],\n","       [ 8.70757252e-02,  1.39774069e-01, -6.50830343e-02],\n","       [-8.01006481e-02,  1.38403863e-01, -2.54218001e-02],\n","       [ 4.00235318e-02,  1.05382189e-01,  6.05495274e-02],\n","       [ 1.25477701e-01, -1.47938490e-01, -7.95355067e-02],\n","       [ 6.15112036e-02, -5.72553314e-02, -1.33321807e-01],\n","       [-1.18082084e-01, -4.31307442e-02,  1.22353323e-01],\n","       [ 1.45163149e-01, -1.02112688e-01, -8.88084993e-02],\n","       [-1.37177050e-01, -6.02556276e-04,  3.50162163e-02],\n","       [ 4.64893691e-02,  1.40111297e-01, -9.18269902e-02],\n","       [ 1.45601481e-01, -1.19217195e-01, -1.29576689e-02],\n","       [-1.38841495e-01, -5.09335585e-02, -7.06827268e-02],\n","       [-1.15706220e-01,  7.54650384e-02,  4.31807972e-02],\n","       [ 1.42169192e-01,  1.50745496e-01, -6.03934713e-02],\n","       [ 1.08800411e-01,  9.38048735e-02,  1.51444906e-02],\n","       [-1.47763431e-01, -1.09005742e-01,  9.16956887e-02],\n","       [ 7.98065886e-02, -1.22903511e-01,  4.42190580e-02],\n","       [ 1.56706329e-02,  1.51767302e-02, -7.05289990e-02],\n","       [-1.27434745e-01,  1.24245510e-01,  3.45781706e-02],\n","       [-5.00291139e-02,  4.81154099e-02,  9.32303146e-02],\n","       [-1.49417132e-01, -6.98532760e-02, -8.00507590e-02],\n","       [ 1.31490067e-01, -1.16922185e-01, -7.89162889e-02],\n","       [-2.62392517e-02,  1.16963975e-01, -7.27294385e-02],\n","       [ 1.34211704e-01, -4.10731845e-02, -1.01451479e-01],\n","       [-1.49359941e-01, -2.54998542e-03, -1.02158733e-01],\n","       [-8.32785219e-02, -1.45378321e-01, -1.62948482e-02],\n","       [-6.95122555e-02,  1.36850685e-01, -3.87144163e-02],\n","       [-3.91482078e-02,  1.30158991e-01,  2.81673744e-02],\n","       [-1.10871628e-01,  1.07234027e-02, -2.52718441e-02],\n","       [ 6.23018593e-02,  1.51414618e-01,  7.21130595e-02],\n","       [-1.95139628e-02,  1.27370849e-01, -8.82349685e-02],\n","       [ 2.27725618e-02,  2.75704395e-02, -2.65547819e-03],\n","       [ 1.42502084e-01, -1.00439519e-01, -1.50550798e-01],\n","       [-1.39423385e-01,  1.40580684e-01,  1.47547647e-01],\n","       [ 4.25703786e-02,  2.79796477e-02, -9.39375088e-02],\n","       [ 7.88600072e-02, -8.86969566e-02,  6.67489916e-02],\n","       [-9.72284973e-02,  3.04439534e-02,  8.34804773e-02],\n","       [-5.50068356e-02,  9.41506103e-02, -1.35909170e-01],\n","       [ 1.08461127e-01,  8.38812664e-02, -9.53953415e-02],\n","       [ 1.35593757e-01,  5.40347658e-02,  9.64484271e-03],\n","       [ 5.06951474e-03,  3.40338536e-02, -1.01457939e-01],\n","       [-6.20972179e-02, -1.29693737e-02, -2.56567094e-02],\n","       [ 1.03709638e-01, -1.81578975e-02, -5.10055125e-02],\n","       [ 5.93040995e-02,  6.94120005e-02, -6.87776729e-02],\n","       [ 3.82519588e-02, -1.37738734e-02, -1.50921270e-01],\n","       [ 2.05381121e-02,  1.78891011e-02, -8.13985616e-02],\n","       [ 1.06116407e-01,  4.04712334e-02, -7.68731767e-03],\n","       [-2.00166684e-02, -6.37835916e-03,  2.57812310e-02],\n","       [-3.22388373e-02, -1.72904283e-02,  1.45895690e-01],\n","       [-5.29901274e-02,  6.44156411e-02,  1.16237953e-01],\n","       [ 5.79683557e-02, -1.35849699e-01,  7.02286065e-02],\n","       [-8.54462981e-02,  4.72911447e-02, -7.67242461e-02],\n","       [ 1.32495865e-01,  2.75528971e-02,  4.16479334e-02],\n","       [-5.41122779e-02, -1.13327123e-01, -1.48411170e-01],\n","       [ 2.10630391e-02, -1.26417935e-01,  1.54160187e-02]], dtype=float32)>, <tf.Variable 'dense_128/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[-1.25771090e-01,  1.02698952e-01,  1.44924536e-01],\n","       [ 5.20544201e-02, -1.38307288e-01, -5.32918144e-03],\n","       [-6.93333820e-02, -1.38286680e-01,  6.60744384e-02],\n","       [ 5.20919710e-02, -1.10230558e-01,  8.85865465e-02],\n","       [ 1.49033755e-01,  7.68457130e-02,  3.17493156e-02],\n","       [-1.49703935e-01,  1.20985143e-01, -5.90129383e-02],\n","       [ 1.44263506e-01, -5.80512695e-02,  9.47310850e-02],\n","       [-9.87085700e-02, -2.07728073e-02, -1.14351939e-02],\n","       [-1.47968024e-01, -6.03915229e-02, -9.76062119e-02],\n","       [ 1.15228057e-01,  1.26785412e-01,  2.48749536e-02],\n","       [ 7.42241219e-02, -1.16023617e-02, -1.42038465e-01],\n","       [-1.40699029e-01,  3.36153321e-02, -2.79457923e-02],\n","       [ 9.81790349e-02,  1.02494806e-02,  1.47387221e-01],\n","       [ 1.21913008e-01, -4.25511226e-02, -1.24699309e-01],\n","       [ 1.19151942e-01, -6.00041747e-02, -6.05545789e-02],\n","       [-1.16245054e-01, -2.70480532e-02, -1.20278016e-01],\n","       [-5.11330832e-03,  2.04661787e-02,  6.81102723e-02],\n","       [ 6.22581132e-02, -9.09391418e-03,  6.46704286e-02],\n","       [ 5.32828234e-02, -1.84377320e-02,  1.32973492e-02],\n","       [-1.29950996e-02, -1.00879148e-01, -5.17792515e-02],\n","       [-1.00582582e-03,  2.89353374e-02,  4.65209223e-02],\n","       [ 6.80870488e-02, -5.60402265e-03,  9.31335464e-02],\n","       [-5.19344769e-02,  3.14474665e-02,  1.29783630e-01],\n","       [-1.26075089e-01,  2.08248477e-02,  1.36938673e-02],\n","       [-9.44688022e-02, -5.53902201e-02,  1.19394161e-01],\n","       [-4.19786088e-02,  8.28888044e-02, -1.47587359e-01],\n","       [ 6.86959643e-03, -4.57734726e-02, -1.35924250e-01],\n","       [-9.46160927e-02, -7.85455629e-02, -5.19737117e-02],\n","       [ 1.47859797e-01,  1.40822589e-01, -8.92359018e-02],\n","       [-4.93511483e-02,  1.00291163e-01,  7.26668397e-03],\n","       [-2.14733295e-02, -8.25160816e-02,  2.29235254e-02],\n","       [ 7.31938854e-02, -3.28930095e-02,  9.13472027e-02],\n","       [ 3.90615724e-02, -2.50078216e-02,  1.01076812e-01],\n","       [ 4.61888276e-02, -6.83501139e-02,  3.57251093e-02],\n","       [ 9.06230435e-02, -1.12487778e-01,  8.57911110e-02],\n","       [ 7.54972398e-02, -9.36276466e-02,  1.39184222e-01],\n","       [-1.74469911e-02, -1.04520023e-02, -1.79661755e-02],\n","       [-5.72686717e-02, -1.43381227e-02,  1.18732668e-01],\n","       [-1.49979919e-01, -5.63739752e-03,  1.62294004e-02],\n","       [-7.55244121e-02, -4.63814028e-02, -7.35915154e-02],\n","       [ 8.99202973e-02,  1.15411887e-02,  7.01607987e-02],\n","       [ 1.92421619e-02, -9.04141888e-02, -2.38608313e-03],\n","       [ 2.80001014e-02,  5.66411763e-02,  5.98878749e-02],\n","       [-6.75322711e-02, -1.88137796e-02,  1.36232063e-01],\n","       [ 1.32126063e-01,  6.17888931e-04, -5.36927655e-02],\n","       [ 8.71577635e-02,  6.10224232e-02, -1.43970009e-02],\n","       [ 1.59205031e-02, -7.84577727e-02, -7.71101117e-02],\n","       [ 1.22809149e-01,  8.01484063e-02, -1.17413744e-01],\n","       [ 2.41762940e-02,  1.01183401e-02,  1.28266364e-01],\n","       [-4.69913520e-02,  1.31000385e-01, -1.10895179e-01],\n","       [ 2.06771344e-02,  4.40003537e-02,  1.41411811e-01],\n","       [ 3.02958507e-02, -1.43839717e-01,  1.33480251e-01],\n","       [-6.52545020e-02, -1.17854454e-01, -1.35697290e-01],\n","       [ 8.81078094e-02,  3.31344120e-02, -4.64323200e-02],\n","       [ 7.27810413e-02,  2.91776494e-03, -1.25143066e-01],\n","       [-1.48277238e-01, -1.07988127e-01, -3.45352106e-02],\n","       [ 1.24917865e-01, -8.23182687e-02, -4.59646806e-02],\n","       [ 7.61184841e-02,  7.13877976e-02, -1.06722082e-03],\n","       [-1.27449650e-02, -1.96623709e-02, -7.68149421e-02],\n","       [ 6.92042336e-03,  2.04521473e-02, -4.40849625e-02],\n","       [ 8.69152173e-02,  1.20137401e-01, -1.37678996e-01],\n","       [-5.16415983e-02,  1.05001897e-01, -1.42492816e-01],\n","       [ 8.42933878e-02,  6.83132038e-02,  1.28601387e-01],\n","       [-1.52202817e-02, -1.25602081e-01,  2.94295279e-03],\n","       [ 4.71089967e-02,  8.74345079e-02, -1.26135841e-01],\n","       [-9.26887766e-02, -6.04090206e-02,  1.27668083e-01],\n","       [ 7.92040676e-02, -1.10738799e-01, -6.23486564e-02],\n","       [-6.21827729e-02,  1.30430982e-01, -1.04209565e-01],\n","       [-7.89686814e-02,  1.12442300e-01,  1.44965440e-01],\n","       [-1.27169251e-01, -2.17329781e-03,  1.02952287e-01],\n","       [-1.03807740e-01, -2.21834965e-02,  4.26352099e-02],\n","       [ 1.14349006e-02,  6.45160601e-02,  4.79507335e-02],\n","       [-8.65236670e-02, -8.00594315e-02,  9.58822444e-02],\n","       [ 7.52909482e-02,  1.24432720e-01,  1.29785374e-01],\n","       [ 5.18415384e-02,  4.34363857e-02, -1.10607529e-02],\n","       [-4.73601930e-02,  6.69935495e-02,  2.23412123e-02],\n","       [ 3.45092677e-02,  1.39378548e-01,  1.82049926e-02],\n","       [ 5.77939302e-02, -6.52630925e-02, -4.58390899e-02],\n","       [-6.69429228e-02, -8.29892000e-04,  5.89430369e-02],\n","       [ 7.97940344e-02,  3.46702486e-02, -1.35534778e-01],\n","       [ 3.73188034e-02,  2.50492208e-02,  1.39685988e-01],\n","       [ 2.83234939e-02, -1.32484570e-01,  1.33946210e-01],\n","       [-1.00591779e-01,  1.61554590e-02,  3.95857878e-02],\n","       [ 1.18013568e-01,  1.36985943e-01, -7.22471103e-02],\n","       [-1.40594169e-01,  7.31260628e-02, -6.02101348e-02],\n","       [-4.36937958e-02, -9.50098932e-02,  1.01185471e-01],\n","       [-5.75381219e-02,  1.36638388e-01, -1.24322377e-01],\n","       [ 1.14210919e-01,  3.88910472e-02,  8.40859190e-02],\n","       [-1.33435458e-01,  5.43258227e-02,  5.57930730e-02],\n","       [ 9.19798668e-03, -1.99146923e-02,  4.98467907e-02],\n","       [ 1.86463054e-02, -2.40168832e-02,  2.07681227e-02],\n","       [-2.69784741e-02,  1.11484624e-01, -1.45192847e-01],\n","       [ 9.25763324e-02,  1.52024269e-01,  8.28049437e-04],\n","       [ 3.85621227e-02, -6.13537803e-02,  4.57575992e-02],\n","       [-2.16046837e-03,  5.61964698e-02,  5.18241562e-02],\n","       [-7.45785907e-02,  3.47996019e-02,  6.98584542e-02],\n","       [ 1.13589309e-01, -1.25023142e-01, -1.32131264e-01],\n","       [ 7.35493228e-02, -1.12980023e-01, -4.22246894e-03],\n","       [ 1.39642894e-01, -1.34483635e-01, -9.02606696e-02],\n","       [ 3.01640350e-02,  1.21148152e-03,  1.01907797e-01],\n","       [ 4.74392734e-02, -4.54057045e-02, -5.03304414e-02],\n","       [-1.02887070e-02,  1.03014484e-02, -1.14732072e-01],\n","       [ 1.36331141e-01,  1.33915126e-01, -1.42059013e-01],\n","       [-6.37216121e-02, -1.24891795e-01, -1.17632568e-01],\n","       [ 1.51584353e-02, -3.53092104e-02, -3.26944441e-02],\n","       [ 7.14064464e-02, -3.20435166e-02, -4.29261923e-02],\n","       [ 4.93690856e-02,  5.56856431e-02, -1.47024632e-01],\n","       [ 3.47677469e-02,  1.33593857e-01, -6.67136535e-02],\n","       [ 3.99207436e-02,  1.38172181e-02,  8.56720805e-02],\n","       [-3.14141577e-03,  7.71749243e-02, -4.62847427e-02],\n","       [-3.79645564e-02,  8.12100247e-02, -1.94621347e-02],\n","       [-5.71889654e-02,  1.42668918e-01, -2.52512507e-02],\n","       [ 1.22634796e-02, -8.56127441e-02, -7.69236386e-02],\n","       [ 7.75033832e-02, -4.63949889e-02,  6.42463043e-02],\n","       [ 1.35200635e-01,  1.17824301e-01, -7.55843520e-03],\n","       [ 3.22765596e-02, -7.83769414e-03,  1.40043542e-01],\n","       [ 3.97837870e-02,  1.07753016e-01, -1.32085696e-01],\n","       [-1.32148996e-01, -6.89879730e-02,  1.11065648e-01],\n","       [-6.15487881e-02,  4.01307158e-02,  8.08875933e-02],\n","       [-6.71383962e-02, -4.60857227e-02,  9.24704820e-02],\n","       [ 2.35347282e-02,  1.10120609e-01, -5.24660945e-02],\n","       [-1.03731550e-01,  1.15517654e-01,  8.23177993e-02],\n","       [-7.00529814e-02,  1.09020397e-01, -1.04548961e-01],\n","       [-1.25230312e-01,  6.85865507e-02, -6.50078133e-02],\n","       [-8.23166072e-02, -1.14442661e-01,  1.28648147e-01],\n","       [ 1.23248458e-01, -7.53506348e-02,  1.09468199e-01],\n","       [-8.14555064e-02, -1.10222124e-01,  3.73434871e-02],\n","       [ 1.46822799e-02,  4.24088575e-02,  1.02357708e-01],\n","       [-5.64021319e-02,  3.63651887e-02,  2.57289410e-03],\n","       [ 4.04040031e-02, -4.76467013e-02, -3.32230031e-02],\n","       [ 1.98389255e-02,  1.26458257e-01,  5.42642437e-02],\n","       [ 7.84937516e-02,  1.27874240e-01, -3.91334184e-02],\n","       [ 8.29364955e-02,  1.09306134e-01, -2.36949418e-02],\n","       [ 1.50004074e-01, -1.16203837e-01,  7.46418163e-02],\n","       [ 9.46043879e-02, -1.43831193e-01, -1.27784207e-01],\n","       [-5.42395413e-02,  1.42525792e-01,  2.08709966e-02],\n","       [ 1.28291130e-01,  1.13575570e-01, -1.60425380e-02],\n","       [-6.29500374e-02, -1.45510077e-01, -5.96784763e-02],\n","       [ 6.56875595e-02, -2.19344161e-02,  6.62827492e-02],\n","       [ 5.26306108e-02,  9.68361422e-02, -9.68075991e-02],\n","       [-3.86315845e-02, -1.42156348e-01, -8.20113793e-02],\n","       [ 1.20520808e-01,  1.17201507e-01, -1.15892269e-01],\n","       [-1.28005743e-01, -3.35241109e-02, -8.93630460e-02],\n","       [-5.42403534e-02, -5.89399540e-04, -2.87433900e-02],\n","       [ 1.99708752e-02, -1.63992085e-02, -3.72563489e-02],\n","       [ 4.72799316e-02,  2.22061835e-02,  3.03480979e-02],\n","       [-6.46580011e-02,  1.60278976e-02, -6.87164143e-02],\n","       [ 5.90828359e-02, -8.80325586e-02,  1.31621519e-02],\n","       [-1.42158851e-01,  5.88881038e-02,  1.44748554e-01],\n","       [ 1.02462061e-01, -5.00949547e-02, -2.64758263e-02],\n","       [-8.82386118e-02,  1.30993545e-01,  7.23128840e-02],\n","       [-1.93652622e-02, -6.87981248e-02,  9.49028805e-02],\n","       [ 4.55680229e-02,  1.10102013e-01,  9.59464908e-02],\n","       [ 3.41079794e-02, -5.08251414e-02, -5.04534878e-02],\n","       [-8.73831287e-02,  6.39691874e-02, -4.68840636e-02],\n","       [ 1.94966663e-02,  1.04093522e-01, -1.44202814e-01],\n","       [-1.05089299e-01, -1.20504141e-01,  7.33713806e-02],\n","       [-6.38313219e-03, -8.41919407e-02, -8.21349546e-02],\n","       [-1.36605456e-01, -1.39591143e-01,  9.17246789e-02],\n","       [ 9.17747989e-02, -3.28186378e-02,  7.99397305e-02],\n","       [-1.34536698e-01,  1.49655193e-01, -1.12776577e-01],\n","       [-1.43807575e-01,  1.19708836e-01,  3.81187983e-02],\n","       [-1.37287408e-01, -7.39530846e-02,  7.63294250e-02],\n","       [ 1.28275648e-01, -4.10148203e-02, -1.23371519e-01],\n","       [ 3.33081372e-02,  1.28214136e-01, -6.02826960e-02],\n","       [ 4.54025827e-02,  1.09561935e-01, -2.79118400e-02],\n","       [ 1.32302552e-01,  8.48704949e-02,  1.34701535e-01],\n","       [ 1.06844872e-01, -6.35624155e-02,  1.43744662e-01],\n","       [-7.78660504e-03,  8.45984370e-02,  1.13172978e-01],\n","       [-1.34478584e-01, -1.23875201e-01,  8.91425684e-02],\n","       [ 1.14631042e-01,  8.45129834e-05,  4.64955233e-02],\n","       [-1.43691808e-01, -1.28129065e-01, -9.50599089e-03],\n","       [ 1.69463493e-02, -1.20065147e-02, -8.16680118e-02],\n","       [ 1.30416960e-01, -1.29934162e-01, -5.54553457e-02],\n","       [-9.91798639e-02,  1.21889085e-01, -4.15938534e-02],\n","       [ 1.19077809e-01,  2.04573628e-02,  7.38750771e-02],\n","       [-9.45372209e-02,  5.71545772e-02,  8.96428823e-02],\n","       [ 9.20557901e-02, -1.48774117e-01, -1.36329293e-01],\n","       [ 2.79506575e-02,  1.04973227e-01,  7.70065859e-02],\n","       [-3.29998806e-02,  1.06720969e-01, -4.18490432e-02],\n","       [ 1.23122446e-01, -3.61825712e-02,  6.93769157e-02],\n","       [ 5.05331680e-02, -6.65839091e-02, -1.46715313e-01],\n","       [ 8.12003613e-02, -8.50389898e-02,  6.70657381e-02],\n","       [-8.78179967e-02, -1.99282635e-02, -6.68487102e-02],\n","       [-1.19566694e-01, -9.24358889e-02, -1.48408547e-01],\n","       [ 2.48606168e-02, -1.46739230e-01,  8.12217444e-02],\n","       [-8.61170813e-02,  1.39809340e-01, -1.22139290e-01],\n","       [-9.26610008e-02,  9.70658585e-02, -1.48876578e-01],\n","       [ 2.40896679e-02, -1.00175813e-01, -3.79424803e-02],\n","       [-1.42202266e-02,  7.64169395e-02,  8.44655484e-02],\n","       [-1.27056718e-01,  6.18903078e-02, -9.63338763e-02],\n","       [ 6.89418614e-02,  1.20204613e-01, -4.56386283e-02],\n","       [ 1.51687674e-02, -1.18821025e-01, -3.74355912e-03],\n","       [ 1.60640422e-02, -6.35097697e-02,  9.82844234e-02],\n","       [-9.62122306e-02,  1.97371338e-02,  5.43858483e-02],\n","       [ 8.49104449e-02, -8.37488994e-02,  9.36105847e-02],\n","       [-6.61160499e-02,  1.37737781e-01, -6.84811175e-02],\n","       [-5.54900542e-02,  1.35782957e-01, -8.00179690e-02],\n","       [-8.88721347e-02,  3.63274524e-03,  3.02619301e-02],\n","       [ 6.23397529e-02,  1.39966458e-01,  4.19326760e-02],\n","       [-7.87554234e-02, -1.36583120e-01, -1.44520253e-01],\n","       [-6.85145259e-02,  7.00723901e-02, -1.47133559e-01],\n","       [ 1.03016056e-01,  1.69535484e-02,  1.14653930e-01],\n","       [ 1.25349551e-01,  9.99600887e-02, -6.89426512e-02],\n","       [-2.37796549e-02, -1.24590716e-03, -1.37046307e-01],\n","       [ 9.57419202e-02, -7.46317655e-02,  6.65483847e-02],\n","       [ 7.33280629e-02, -1.51082382e-01, -8.86205435e-02],\n","       [-5.51837198e-02, -1.39814764e-01,  6.07254840e-02],\n","       [-5.11277542e-02, -1.01831518e-01,  2.59528030e-02],\n","       [ 7.02388436e-02, -5.40591851e-02, -3.76243815e-02],\n","       [-1.37825757e-01, -9.51488987e-02,  2.29836311e-02],\n","       [ 1.19744405e-01,  2.86983475e-02,  1.93537511e-02],\n","       [-1.77411065e-02, -1.00784510e-01, -2.23530401e-02],\n","       [-1.06892765e-01,  1.48463145e-01,  1.38419852e-01],\n","       [ 7.91417900e-04,  7.78255388e-02, -2.38888562e-02],\n","       [-1.01266414e-01, -2.63505410e-02, -8.82633328e-02],\n","       [ 2.08351593e-02,  4.22987193e-02,  1.13554865e-01],\n","       [-2.67350618e-02,  1.41517833e-01,  1.23571992e-01],\n","       [ 1.31157905e-01,  3.26865129e-02, -2.96041146e-02],\n","       [-1.10324591e-01,  9.56771225e-02, -1.18941590e-01],\n","       [-2.02206487e-04, -7.03859404e-02,  1.30194470e-01],\n","       [ 1.30199164e-01,  1.35234490e-01,  3.26693878e-02],\n","       [-1.36069283e-01, -1.15938857e-01,  7.83616528e-02],\n","       [ 1.73500199e-02,  1.40986666e-01, -3.19593884e-02],\n","       [-1.02209166e-01,  1.41176537e-01, -1.21149413e-01],\n","       [ 1.69420522e-02,  1.95952505e-02, -6.38668463e-02],\n","       [ 1.57421753e-02, -7.20756501e-02,  1.42897919e-01],\n","       [ 6.93926662e-02, -9.92336273e-02, -1.03226088e-01],\n","       [-5.27997389e-02,  1.46367624e-01,  1.51642919e-01],\n","       [ 3.82190682e-02,  2.06560623e-02, -7.78514799e-03],\n","       [-5.67420237e-02, -7.50221871e-03, -5.73123693e-02],\n","       [-5.97885698e-02, -7.64901340e-02, -6.59157634e-02],\n","       [-2.33685095e-02,  1.12903051e-01,  1.27477258e-01],\n","       [ 6.82593361e-02, -1.04552919e-05, -5.78808673e-02],\n","       [ 7.38298222e-02,  5.45626208e-02,  7.73755461e-02],\n","       [-1.24372743e-01,  4.25963961e-02, -1.00365818e-01],\n","       [-3.39724533e-02, -1.08604304e-01, -4.31393906e-02],\n","       [-3.78796197e-02,  1.67710073e-02, -1.37981409e-02],\n","       [ 6.69045970e-02,  7.97847509e-02, -1.05781958e-01],\n","       [-1.10599458e-01,  6.91529363e-02, -8.46680924e-02],\n","       [-6.21629208e-02, -8.78953189e-02, -6.33777902e-02],\n","       [ 3.01529653e-02, -2.11939048e-02,  4.70884554e-02],\n","       [-1.29740864e-01,  3.46490927e-02, -1.04978479e-01],\n","       [ 1.21233305e-02, -6.24079965e-02, -5.23763299e-02],\n","       [-8.55904073e-02,  3.75756361e-02,  1.30838126e-01],\n","       [ 3.74879986e-02, -1.19623445e-01, -3.30207571e-02],\n","       [-2.43097674e-02, -1.45158798e-01, -1.19450934e-01],\n","       [ 1.39147222e-01, -1.33792236e-01, -1.38460636e-01],\n","       [-3.54953147e-02, -1.32888481e-01, -2.61495877e-02],\n","       [ 3.46011855e-03,  1.23811632e-01,  1.00938611e-01],\n","       [ 6.01627529e-02,  4.32640798e-02,  1.01642758e-01],\n","       [-1.25833407e-01, -9.22421813e-02, -1.38349637e-01],\n","       [-1.11653671e-01,  1.35839328e-01,  5.23540042e-02],\n","       [-9.43206400e-02,  1.47427432e-02,  1.07460484e-01],\n","       [ 1.18649304e-01,  2.19570976e-02,  8.98677185e-02],\n","       [ 9.45835114e-02,  3.94375958e-02, -1.44835159e-01]], dtype=float32)>, <tf.Variable 'dense_129/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[-6.76404834e-02, -4.96870987e-02, -1.24830576e-02],\n","       [ 2.18858826e-03, -1.67809948e-01, -1.93576008e-01],\n","       [ 1.34922370e-01, -8.67040232e-02, -1.40379861e-01],\n","       [-1.37971520e-01, -1.71312943e-01,  7.74456784e-02],\n","       [-1.81346223e-01,  4.74121980e-02,  1.00205012e-01],\n","       [ 9.17574987e-02,  2.77253315e-02, -1.29313454e-01],\n","       [ 3.93212624e-02,  4.36550453e-02,  1.53346926e-01],\n","       [-3.64865214e-02, -1.56036830e-02,  1.61256850e-01],\n","       [-7.22440407e-02, -2.07137629e-01,  1.45236835e-01],\n","       [ 1.20124042e-01, -1.27066774e-02, -6.01176433e-02],\n","       [ 1.26100048e-01, -1.95129305e-01, -1.35721296e-01],\n","       [-1.37798995e-01, -1.46161914e-01,  1.30313709e-02],\n","       [-2.08825752e-01, -8.81883278e-02, -1.72940135e-01],\n","       [-1.77513868e-01,  1.50958925e-01, -1.80353373e-01],\n","       [-2.03088060e-01, -1.50850743e-01, -6.84966221e-02],\n","       [-9.20128152e-02,  1.52301863e-01,  1.70881435e-01],\n","       [-2.09308788e-02,  8.36160034e-02,  1.26096755e-01],\n","       [-1.37675092e-01, -5.84451435e-03, -1.99196056e-01],\n","       [-1.65374175e-01, -2.10342467e-01, -9.73299071e-02],\n","       [-1.78214580e-01, -7.82644451e-02, -2.07971722e-01],\n","       [-3.89465317e-02, -2.35583521e-02,  5.90849444e-02],\n","       [-4.82417122e-02, -4.70267497e-02,  1.25334710e-01],\n","       [ 2.03182578e-01,  8.97162706e-02,  1.77497774e-01],\n","       [-1.52011931e-01,  8.73178989e-02, -1.84581771e-01],\n","       [ 1.25835001e-01, -1.80192962e-01, -1.87688038e-01],\n","       [-6.21968806e-02, -1.91710964e-01,  1.77908480e-01],\n","       [-2.67879274e-02,  4.01462913e-02,  1.50456671e-02],\n","       [-1.87738448e-01, -1.11067392e-01, -1.60143241e-01],\n","       [ 1.10863641e-01, -1.03199616e-01, -1.84023499e-01],\n","       [ 1.35621116e-01,  9.44667608e-02,  9.12109837e-02],\n","       [-8.10397044e-02, -1.17022723e-01,  1.58334747e-01],\n","       [-8.19614157e-02,  4.20568250e-02,  4.57677990e-02],\n","       [-2.48265844e-02,  7.18599046e-03, -1.71663001e-01],\n","       [-2.21004207e-02,  1.42609864e-01, -3.82374376e-02],\n","       [ 1.06459692e-01,  1.21032111e-01,  1.11729793e-01],\n","       [-2.01120168e-01,  1.75670192e-01, -9.65492055e-02],\n","       [-4.53633182e-02,  1.11731216e-01, -1.74080491e-01],\n","       [ 1.00365162e-01,  1.16734676e-01, -5.54106683e-02],\n","       [-3.66418846e-02, -4.01072726e-02,  7.56539591e-03],\n","       [ 1.84707314e-01, -8.27955306e-02,  1.77657530e-01],\n","       [ 6.64725229e-02,  1.18280150e-01,  7.45339617e-02],\n","       [ 8.06977227e-02, -8.68711527e-03, -1.83235124e-01],\n","       [ 1.14661679e-01,  1.94801971e-01, -2.01149866e-01],\n","       [ 2.04700500e-01, -1.74968883e-01, -1.16233185e-01],\n","       [-1.12887688e-01, -1.75463602e-01, -6.51406273e-02],\n","       [-1.33569568e-01,  1.49188429e-01,  1.44645557e-01],\n","       [-1.09292798e-01,  1.57740459e-01, -1.18032686e-01],\n","       [-1.99263826e-01,  1.87840700e-01, -1.42781183e-01],\n","       [ 5.34032285e-02,  7.20711499e-02, -5.76494895e-02],\n","       [ 4.11497429e-02,  5.02919629e-02, -8.88772383e-02],\n","       [ 1.83445603e-01, -1.39864996e-01, -1.99766889e-01],\n","       [ 1.59784496e-01, -1.83835566e-01,  1.95141435e-01],\n","       [-1.48591042e-01, -9.31420922e-02,  1.68219149e-01],\n","       [ 1.10082559e-01, -4.20563519e-02, -1.41179636e-01],\n","       [-1.00189060e-01,  1.81498423e-01, -9.29895714e-02],\n","       [-1.80816770e-01,  1.14644520e-01, -2.77463831e-02],\n","       [ 2.41827425e-02, -4.41308841e-02, -1.84863687e-01],\n","       [ 4.28251773e-02,  1.25281841e-01, -6.75405636e-02],\n","       [ 7.88887590e-02, -1.07481107e-01,  7.67068714e-02],\n","       [-5.67079410e-02,  5.85784353e-02,  1.19041353e-04],\n","       [ 1.60826594e-02, -1.50696605e-01,  1.12659141e-01],\n","       [-1.12311348e-01, -7.96808675e-02,  1.82240456e-01],\n","       [-1.58083722e-01,  1.40557513e-01, -2.28142180e-02],\n","       [-8.96906704e-02, -4.19519423e-03, -5.79746775e-02],\n","       [ 3.24258097e-02,  1.81784362e-01,  4.92382050e-02],\n","       [-1.17806822e-01, -6.41684979e-02, -1.65767044e-01],\n","       [ 9.37713683e-02, -1.27436802e-01, -2.02678889e-01],\n","       [-1.49127558e-01,  1.56520888e-01,  2.00504035e-01],\n","       [-6.59345910e-02,  1.70105353e-01, -2.13467807e-01],\n","       [ 7.03968853e-02, -1.33070126e-01, -1.11021347e-01],\n","       [-1.12555355e-01, -2.03130350e-01,  1.02485023e-01],\n","       [ 1.97699040e-01,  1.63348675e-01,  1.68887571e-01],\n","       [-1.88333079e-01,  1.52078196e-01, -9.68595222e-02],\n","       [ 2.48344173e-03,  1.29288062e-01, -3.56862843e-02],\n","       [ 6.52883053e-02,  6.88644275e-02,  1.89274147e-01],\n","       [ 1.84424996e-01, -7.79867172e-02, -2.08111793e-01],\n","       [-2.03040153e-01, -3.02089266e-02, -2.10498273e-02],\n","       [-1.85844660e-01, -6.84810579e-02,  1.56354040e-01],\n","       [-7.41931424e-02, -9.95046943e-02,  6.69087917e-02],\n","       [-9.49327871e-02, -1.94378898e-01, -4.76672016e-02],\n","       [ 1.42853037e-01,  1.41898826e-01, -5.34048639e-02],\n","       [-1.85786352e-01,  1.73722714e-01, -1.03996415e-02],\n","       [ 4.24065888e-02, -1.52413934e-01,  1.87530458e-01],\n","       [-2.67163143e-02, -1.71409488e-01,  2.02873990e-01],\n","       [ 2.04920173e-01,  2.07462251e-01, -8.81134868e-02],\n","       [-2.12811843e-01, -9.19697806e-02, -2.04185665e-01],\n","       [ 1.29172117e-01, -2.02546135e-01, -1.48678139e-01],\n","       [-1.33440318e-02,  1.97940022e-01, -4.47789356e-02],\n","       [-1.56937987e-01, -1.34966865e-01,  1.38051018e-01],\n","       [-1.14438206e-01,  1.51871645e-03,  2.06619725e-01],\n","       [ 1.29815698e-01, -7.99825191e-02,  2.04843327e-01],\n","       [ 1.47283107e-01,  9.95321125e-02, -9.85493809e-02],\n","       [ 1.45993486e-01, -6.01186678e-02,  1.85830131e-01],\n","       [-1.91699997e-01,  1.70697108e-01, -1.38374701e-01],\n","       [ 1.38739929e-01, -2.11152181e-01, -6.68330193e-02],\n","       [-1.62473783e-01,  1.50541604e-01,  2.01561794e-01],\n","       [-1.09395817e-01,  2.14232150e-02,  8.35151821e-02],\n","       [ 1.55592948e-01, -4.81262570e-03, -1.68009460e-01],\n","       [ 1.25668719e-01, -6.94614798e-02,  1.32321134e-01],\n","       [-1.73951223e-01,  1.03594594e-01, -4.35892493e-02],\n","       [ 2.93897446e-02,  1.44359795e-02, -7.74413794e-02],\n","       [-8.50893632e-02,  1.46646336e-01, -5.31538650e-02],\n","       [ 2.00004548e-01,  5.02839535e-02, -6.77923635e-02],\n","       [-2.06478760e-01,  2.13981152e-01,  3.27925459e-02],\n","       [ 1.27129972e-01,  1.42693713e-01, -1.34587511e-01],\n","       [-1.74171656e-01, -1.90323651e-01, -1.63348854e-01],\n","       [ 7.46595636e-02, -2.64353678e-02,  1.67088196e-01],\n","       [ 3.82380337e-02,  3.88613231e-02,  5.42887896e-02],\n","       [ 9.49101374e-02, -1.21052116e-01, -2.12583020e-02],\n","       [ 5.25479317e-02, -2.02681169e-01, -2.08119035e-01],\n","       [-1.27893418e-01, -2.48306617e-02, -2.41056941e-02],\n","       [ 1.05859712e-01,  1.50587142e-01, -1.89836264e-01],\n","       [-1.22225508e-01,  8.86136740e-02, -1.13689192e-01],\n","       [ 8.27887878e-02,  1.53827816e-01,  6.61066175e-02],\n","       [ 1.42818913e-01,  1.75817728e-01,  1.49304003e-01],\n","       [ 1.17743246e-01, -2.80705765e-02, -1.54589385e-01],\n","       [ 6.31539077e-02,  1.37770921e-01,  7.11058304e-02],\n","       [-2.31581591e-02, -1.21797323e-01, -9.19876471e-02],\n","       [-1.07794084e-01,  9.48167294e-02,  7.27392733e-02],\n","       [ 1.42558739e-01, -1.15607001e-01,  1.91065460e-01],\n","       [ 1.05900459e-01, -9.56128985e-02, -5.80937266e-02],\n","       [-1.56860307e-01, -1.74921721e-01,  9.05375034e-02],\n","       [-5.45801176e-03, -8.18008382e-04,  1.24849841e-01],\n","       [-1.86143652e-01, -1.75409377e-01, -3.69549990e-02],\n","       [-1.11327596e-01,  2.53973585e-02, -1.02149405e-01],\n","       [-2.96806432e-02, -5.00418581e-02,  2.02576920e-01],\n","       [ 3.67690064e-02, -3.07874158e-02,  1.37240188e-02],\n","       [ 1.20452084e-01,  1.27817556e-01,  9.25339311e-02]], dtype=float32)>, <tf.Variable 'dense_130/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[-3.36810872e-02, -6.02033772e-02,  4.87429947e-02],\n","       [ 1.27512142e-01,  6.40282705e-02, -6.38049841e-03],\n","       [ 1.78150028e-01, -8.66123661e-03,  2.08679527e-01],\n","       [ 1.95135385e-01, -1.44045204e-01,  1.69344202e-01],\n","       [-1.69981733e-01,  1.42333463e-01,  2.00156301e-01],\n","       [ 2.07740553e-02, -1.00682169e-01,  7.67744556e-02],\n","       [-2.09434777e-01,  1.58752203e-01,  1.24935694e-01],\n","       [ 1.45923361e-01, -5.11710271e-02, -9.01366100e-02],\n","       [-1.71262518e-01, -1.55259222e-01, -2.04613775e-01],\n","       [ 6.76656663e-02, -1.28824720e-02,  9.32503343e-02],\n","       [ 4.03330475e-02, -5.48162684e-02,  1.10019352e-02],\n","       [ 1.32811829e-01,  1.03000939e-01,  6.65860921e-02],\n","       [ 1.69031352e-01, -1.84268489e-01,  1.03716686e-01],\n","       [-7.32386038e-02, -1.76032797e-01, -2.03866035e-01],\n","       [ 8.50833803e-02,  1.01667210e-01, -1.98740438e-01],\n","       [-1.95535541e-01, -7.97585994e-02,  8.68871734e-02],\n","       [ 8.01420361e-02, -1.43072769e-01, -1.26090482e-01],\n","       [-1.13360494e-01, -1.62058830e-01,  3.22955586e-02],\n","       [ 1.82571709e-01, -1.81964189e-01,  1.06459722e-01],\n","       [-8.83751959e-02,  8.22391286e-02,  5.02772480e-02],\n","       [-1.80221096e-01,  1.28905877e-01, -1.64385006e-01],\n","       [ 1.56303525e-01, -1.57178953e-01,  3.45190987e-02],\n","       [-1.33618236e-01,  1.12163797e-01,  1.55965343e-01],\n","       [-5.32076694e-02, -1.28949031e-01,  2.25291289e-02],\n","       [ 1.34451017e-01,  1.77287310e-01, -9.40121263e-02],\n","       [-1.76064402e-01,  2.31115166e-02, -1.21123403e-01],\n","       [ 1.30411625e-01, -1.43849537e-01,  4.80892770e-02],\n","       [-8.07814077e-02,  1.30512729e-01,  1.63649678e-01],\n","       [ 6.07987400e-03,  1.00344509e-01,  5.62025607e-02],\n","       [ 5.86597249e-02,  1.49417385e-01, -1.16655245e-01],\n","       [ 1.25518709e-01,  1.67400897e-01,  1.14249267e-01],\n","       [-1.73370585e-01, -5.58214448e-02, -8.35121423e-02],\n","       [-1.81925502e-02,  7.68477395e-02,  1.50004640e-01],\n","       [-1.86794639e-01, -1.36836886e-01,  9.01279226e-02],\n","       [ 1.87823102e-01, -6.49262145e-02,  1.88730419e-01],\n","       [-2.03558803e-01,  1.44710347e-01,  9.86562967e-02],\n","       [ 4.10974845e-02, -2.01401159e-01,  2.95107067e-02],\n","       [-3.14209983e-02, -6.82348609e-02, -1.47127494e-01],\n","       [ 1.40373111e-01, -8.74826610e-02, -1.39616117e-01],\n","       [-2.03952551e-01, -1.02434037e-02, -1.52203053e-01],\n","       [-1.08723275e-01,  2.07276955e-01, -1.74196362e-01],\n","       [ 1.04676373e-02,  7.63933733e-02, -8.15916583e-02],\n","       [-1.10345423e-01,  1.70256048e-01, -2.06876602e-02],\n","       [-1.29209802e-01, -1.56991452e-01,  9.76518616e-02],\n","       [-3.84767056e-02,  3.56493369e-02, -1.10874763e-02],\n","       [ 7.71946982e-02,  1.81333140e-01, -2.75276368e-03],\n","       [-1.59388348e-01, -1.51535302e-01,  1.54284388e-01],\n","       [ 1.65629476e-01, -1.57543078e-01,  1.00966908e-01],\n","       [ 3.99975888e-02,  2.07845774e-02,  1.54952362e-01],\n","       [-1.73817039e-01, -2.10354850e-02, -1.33703193e-02],\n","       [-1.71137571e-01, -1.07990652e-01,  2.02404752e-01],\n","       [-1.11970626e-01, -2.13963926e-01,  1.46711305e-01],\n","       [ 1.25550568e-01,  1.96718171e-01, -6.07822053e-02],\n","       [-1.05375186e-01,  1.17780514e-01,  1.88023120e-01],\n","       [ 1.23512447e-01, -1.77604035e-01,  8.69787037e-02],\n","       [ 9.71083865e-02,  2.32596640e-02, -7.90798441e-02],\n","       [ 2.05769181e-01,  5.48755676e-02, -2.29854006e-02],\n","       [ 1.36111453e-01,  1.61840245e-01, -4.81894910e-02],\n","       [ 1.39959380e-01,  5.50536402e-02, -1.04303099e-01],\n","       [ 8.63577574e-02,  4.48693074e-02,  2.65483912e-02],\n","       [ 6.44048629e-03, -1.76112011e-01, -1.35005653e-01],\n","       [ 1.24232091e-01,  1.36276349e-01,  1.57412171e-01],\n","       [-5.51918484e-02,  1.35214269e-01,  2.03671679e-01],\n","       [ 3.95533778e-02,  2.13375520e-02,  1.80246726e-01],\n","       [-1.37771204e-01, -1.12515651e-01, -6.56842291e-02],\n","       [-1.17418148e-01, -2.01033533e-01, -3.54870073e-02],\n","       [ 1.30575215e-02,  2.20494848e-02, -1.51413353e-02],\n","       [-1.29956424e-01, -1.59876019e-01,  2.75457073e-02],\n","       [ 4.94683385e-02,  4.75433730e-02, -8.24468806e-02],\n","       [ 1.75663769e-01,  1.38407484e-01,  5.33711463e-02],\n","       [-8.07446986e-02,  1.98060229e-01,  9.25547183e-02],\n","       [-2.05626667e-01, -4.79587317e-02, -1.80073325e-02],\n","       [-6.86780810e-02, -3.65818515e-02,  1.86984509e-01],\n","       [-1.11226290e-01, -6.63548037e-02,  8.06059316e-02],\n","       [-7.52209574e-02,  3.18135656e-02, -8.46618786e-02],\n","       [-1.02223054e-01, -9.54723582e-02, -1.51056126e-01],\n","       [-1.04972638e-01, -2.15544011e-02, -6.66160658e-02],\n","       [ 4.29210402e-02,  1.86137035e-01, -4.39100387e-03],\n","       [-3.06228995e-02, -2.11367175e-01,  1.15503326e-01],\n","       [-1.18896641e-01,  1.22056007e-01, -2.04267621e-01],\n","       [ 1.76028565e-01,  1.12978473e-01, -1.90390483e-01],\n","       [-7.22772181e-02, -3.73264439e-02, -1.39839366e-01],\n","       [ 1.06467776e-01, -4.99230139e-02,  1.23097626e-02],\n","       [ 1.18276346e-02, -4.72898334e-02, -8.55724290e-02],\n","       [ 1.55160502e-01,  1.54204778e-02,  1.47000169e-02],\n","       [-6.23793788e-02, -1.84781581e-01, -6.41632527e-02],\n","       [ 1.17893189e-01, -1.44432649e-01, -1.62095681e-01],\n","       [-1.58704802e-01,  2.12178588e-01, -1.63368404e-01],\n","       [ 2.92810407e-02, -1.48701340e-01,  9.57441702e-02],\n","       [ 2.10063811e-02,  8.01768526e-02, -4.80188727e-02],\n","       [-7.88415223e-03,  5.84154762e-02,  1.66601706e-02],\n","       [ 1.43356621e-01,  1.87770233e-01,  1.52648896e-01],\n","       [-2.11529527e-02, -3.50036211e-02,  1.54747833e-02],\n","       [ 1.29325390e-01, -1.49445653e-01, -2.03650340e-01],\n","       [ 8.94028470e-02,  1.72714010e-01,  7.30830850e-03],\n","       [-1.07779875e-01, -1.27480283e-01, -9.70826596e-02],\n","       [-1.30304620e-01,  5.33225387e-02, -1.50910541e-01],\n","       [-6.14449047e-02,  1.54263586e-01, -3.52042392e-02],\n","       [ 1.31863654e-01,  1.02739044e-01, -1.48658693e-01],\n","       [ 1.21896230e-01, -1.32704884e-01,  1.89009547e-01],\n","       [ 1.31793797e-01,  2.04052906e-02, -9.08413157e-02],\n","       [-9.12824050e-02,  4.38713655e-02, -1.86864480e-01],\n","       [-1.27013981e-01,  1.32598832e-01,  1.84830040e-01],\n","       [-2.05511332e-01, -9.94736403e-02, -1.20464183e-01],\n","       [-1.56123668e-01,  1.45971000e-01, -8.49879831e-02],\n","       [-1.85029939e-01, -7.65354484e-02,  9.98823717e-02],\n","       [-1.61201566e-01, -1.72644764e-01, -1.93990871e-01],\n","       [-8.43644813e-02, -1.33494705e-01, -4.86493576e-03],\n","       [-6.65309727e-02, -7.63787702e-02, -2.96831504e-02],\n","       [ 1.77822277e-01, -1.95743173e-01, -7.66565055e-02],\n","       [ 7.13019222e-02, -2.11762451e-02,  6.32739291e-02],\n","       [ 1.56468034e-01, -9.79569852e-02,  8.36348757e-02],\n","       [ 4.49454375e-02, -1.34674147e-01, -2.00711325e-01],\n","       [-1.84089422e-01,  1.50553867e-01,  1.86478440e-02],\n","       [-1.36703208e-01,  1.71465710e-01,  8.34025964e-02],\n","       [-1.04527652e-01,  1.85206905e-01, -9.29453373e-02],\n","       [ 2.06512481e-01, -5.44922519e-03, -1.87239587e-01],\n","       [-1.51246767e-02, -1.33231953e-01,  2.96918303e-02],\n","       [ 1.68625727e-01, -1.79352731e-01, -1.62234351e-01],\n","       [-1.99952672e-04, -1.44877927e-02,  1.84674814e-01],\n","       [-2.04401150e-01, -5.19357100e-02,  2.07738772e-01],\n","       [ 1.95693389e-01,  1.18431687e-01,  2.05045953e-01],\n","       [-5.43433167e-02,  1.60129994e-01,  2.03215644e-01],\n","       [-7.38962926e-03, -7.69954622e-02, -1.42964333e-01],\n","       [ 2.86204703e-02,  1.79633930e-01,  1.28067210e-01],\n","       [-1.16803534e-01,  3.60964276e-02,  1.87511966e-01],\n","       [ 1.88417763e-01,  6.76118806e-02, -1.82859644e-01],\n","       [ 1.80391371e-01, -1.48817867e-01,  1.24780476e-01]], dtype=float32)>, <tf.Variable 'dense_131/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[ 0.06118993, -0.15809001, -0.18828884],\n","       [-0.19624548, -0.00976523,  0.00413788],\n","       [-0.20723441,  0.16331485, -0.0287495 ],\n","       [-0.16219392,  0.01675832, -0.02723372],\n","       [ 0.13408543, -0.00103862,  0.18210101],\n","       [-0.02161189, -0.18040131, -0.03314308],\n","       [ 0.10468523,  0.15852611,  0.0705016 ],\n","       [ 0.19228674, -0.21042445,  0.00060676],\n","       [-0.13517869, -0.13782677, -0.08210872],\n","       [ 0.06946868,  0.20348987,  0.12704931],\n","       [-0.05564392,  0.11797707,  0.19749738],\n","       [-0.01317437, -0.15199773,  0.12992485],\n","       [-0.06062251, -0.16306132, -0.15300165],\n","       [ 0.03960696, -0.03168929,  0.08579112],\n","       [ 0.09761971,  0.1738854 ,  0.10224018],\n","       [-0.15079272,  0.19212338,  0.1936574 ],\n","       [ 0.16694975,  0.19903259, -0.20437977],\n","       [ 0.11523075,  0.18564878, -0.15913391],\n","       [ 0.19873148,  0.05136516, -0.07185496],\n","       [ 0.20665435,  0.15347354,  0.20488495],\n","       [ 0.03328421,  0.17031454, -0.14209569],\n","       [ 0.11819186,  0.02772846,  0.11988968],\n","       [-0.14468126,  0.05105388, -0.19240183],\n","       [ 0.07545459,  0.08805932,  0.0159427 ],\n","       [ 0.18497069, -0.02334871, -0.07853378],\n","       [ 0.09516135,  0.1485557 ,  0.11659806],\n","       [ 0.09509026, -0.17126876,  0.0058795 ],\n","       [ 0.13237382,  0.15533617,  0.14375319],\n","       [-0.03907912,  0.06248843,  0.10448884],\n","       [ 0.03870471, -0.03668778, -0.12929122],\n","       [-0.10170995, -0.08280257, -0.16448635],\n","       [ 0.06344037, -0.12256184,  0.18386884],\n","       [ 0.02077974, -0.04295468,  0.02057552],\n","       [-0.13614799,  0.01429213, -0.19236825],\n","       [-0.15376252, -0.12201715,  0.19705498],\n","       [ 0.1463745 , -0.16589974, -0.14231452],\n","       [ 0.18814991, -0.18606672,  0.04074464],\n","       [ 0.19342001, -0.1289229 , -0.13740505],\n","       [ 0.01166935,  0.03492612,  0.09579627],\n","       [-0.01147151, -0.15545532,  0.07308272],\n","       [ 0.10897694,  0.12083974, -0.16927959],\n","       [ 0.03421663, -0.15116884, -0.2000492 ],\n","       [ 0.10774167,  0.12107281, -0.00817201],\n","       [ 0.05119511, -0.16002853, -0.09114603],\n","       [ 0.06732386,  0.09507647, -0.12931551],\n","       [ 0.18849073,  0.08888156, -0.01781341],\n","       [ 0.18534026, -0.05639114,  0.16208848],\n","       [-0.13980891,  0.02898623, -0.14920144],\n","       [-0.166638  ,  0.02204145,  0.07179575],\n","       [-0.12674393, -0.19086596, -0.13575804],\n","       [-0.09558296, -0.03806797, -0.0892114 ],\n","       [ 0.07804815,  0.16880542, -0.0616497 ],\n","       [-0.03216724,  0.15281612, -0.08608757],\n","       [ 0.02083831, -0.12320894, -0.09501442],\n","       [ 0.16300115,  0.19708085, -0.05852567],\n","       [ 0.0081009 , -0.16452275, -0.14735062],\n","       [-0.11307003,  0.13295342,  0.02637333],\n","       [ 0.05119918, -0.12205672, -0.1393659 ],\n","       [-0.1850778 ,  0.01673073,  0.04149875],\n","       [-0.03131472,  0.04130309, -0.15172887],\n","       [-0.06710181,  0.00477003,  0.00070241],\n","       [-0.07432178,  0.09352695,  0.17387809],\n","       [-0.02190592,  0.08528083,  0.16425216],\n","       [-0.1055304 , -0.13082796, -0.04653072],\n","       [-0.17826486, -0.02819398,  0.06164234],\n","       [-0.21134514,  0.19615823,  0.06378543],\n","       [-0.00246889, -0.16843113,  0.03835037],\n","       [-0.01226195, -0.10429173,  0.15445812],\n","       [-0.00899018,  0.03081247,  0.10136221],\n","       [-0.07522023,  0.09485407, -0.07371601],\n","       [-0.04436092, -0.12915386,  0.09379709],\n","       [ 0.15497781,  0.16584651,  0.12747636],\n","       [-0.13070945, -0.00966904,  0.1673473 ],\n","       [-0.148461  ,  0.06330262,  0.11688409],\n","       [-0.14754745,  0.06154979,  0.051447  ],\n","       [-0.01624683, -0.1996125 ,  0.03449176],\n","       [-0.09765878,  0.08098301,  0.06690023],\n","       [ 0.07599903, -0.18115784,  0.18859208],\n","       [ 0.02418706, -0.19672287,  0.06476865],\n","       [ 0.11248892,  0.0741623 ,  0.13165537],\n","       [ 0.146945  , -0.13534571, -0.0332397 ],\n","       [-0.03480676,  0.14467743, -0.07037748],\n","       [ 0.17717932, -0.14999254, -0.0735002 ],\n","       [-0.00638662,  0.10675383, -0.15207662],\n","       [ 0.0293676 ,  0.15724832, -0.0269517 ],\n","       [ 0.06809361, -0.02028014, -0.06913843],\n","       [ 0.15250471, -0.01322651, -0.04139084],\n","       [-0.20295401,  0.19997047,  0.05431615],\n","       [-0.08506301,  0.11915254, -0.06009953],\n","       [-0.12574665, -0.07381695, -0.11196271],\n","       [-0.12356204, -0.0428177 ,  0.15773028],\n","       [ 0.13643312, -0.16421904, -0.01733479],\n","       [ 0.15544645, -0.05487134, -0.0714099 ],\n","       [ 0.08326377,  0.10505628, -0.06023994],\n","       [ 0.15856281,  0.00080378, -0.17375687],\n","       [-0.07319082,  0.01601836, -0.04493979],\n","       [ 0.14282091,  0.09844106,  0.14095783],\n","       [ 0.00311547,  0.09753758,  0.04041353],\n","       [-0.19532582, -0.11161833, -0.1953765 ],\n","       [ 0.03092827,  0.07085422, -0.12183218],\n","       [-0.10704155, -0.13116018, -0.1349472 ],\n","       [ 0.14855173, -0.11869327, -0.11427613],\n","       [-0.13985898,  0.19359855, -0.05266134],\n","       [ 0.09687617,  0.1166005 ,  0.12148438],\n","       [-0.02427248, -0.06158177,  0.07839098],\n","       [ 0.16627647, -0.01434179,  0.05628324],\n","       [-0.12405894,  0.05634732,  0.05922383],\n","       [-0.14155623,  0.12405796, -0.0605303 ],\n","       [ 0.20743027, -0.0963484 ,  0.18553138],\n","       [-0.03728152,  0.00819675,  0.09078767],\n","       [-0.00634591,  0.03511527, -0.12417816],\n","       [ 0.12073428, -0.09375086, -0.12571174],\n","       [-0.09608697, -0.12528455,  0.00649611],\n","       [ 0.16546991,  0.1648097 , -0.00585364],\n","       [-0.18393338, -0.07531264, -0.04067252],\n","       [ 0.09376461,  0.17673853, -0.14459857],\n","       [-0.0980662 , -0.06682856, -0.2110788 ],\n","       [-0.00390841, -0.13637668, -0.08413567],\n","       [ 0.06864355,  0.04035426,  0.15873583],\n","       [ 0.06862523, -0.00461643,  0.17380133],\n","       [ 0.19300085, -0.10866123,  0.08079984],\n","       [ 0.00746024, -0.06498488, -0.18462034],\n","       [-0.12728529,  0.17552502,  0.03721866],\n","       [ 0.10274288, -0.15804043,  0.10166321],\n","       [-0.0210062 ,  0.08491688,  0.13606119],\n","       [-0.17505828, -0.12031839,  0.03096972],\n","       [ 0.01378576,  0.07478374,  0.19277038],\n","       [ 0.09635428, -0.18760003,  0.02448948]], dtype=float32)>, <tf.Variable 'dense_132/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[-0.00258342,  0.05486742,  0.00288201, ..., -0.06435577,\n","        -0.02337978,  0.00769655],\n","       [ 0.01353177, -0.01460615, -0.04049063, ..., -0.05990133,\n","         0.06366189, -0.03790674],\n","       [ 0.00923676, -0.00455665,  0.00766419, ..., -0.01158787,\n","        -0.00086735, -0.02780791],\n","       ...,\n","       [-0.03590259,  0.00172065, -0.04465123, ..., -0.01586409,\n","        -0.04678613,  0.0480087 ],\n","       [-0.05537404, -0.06075775, -0.05222946, ..., -0.01708882,\n","         0.03727218, -0.01158393],\n","       [ 0.03130388,  0.03295323, -0.0615468 , ...,  0.0213319 ,\n","         0.04070033,  0.0193569 ]], dtype=float32)>, <tf.Variable 'dense_133/kernel:0' shape=(1280, 3) dtype=float32, numpy=\n","array([[ 0.01003648,  0.02610929,  0.00082986],\n","       [-0.04110801,  0.0436352 , -0.00849191],\n","       [-0.04087521,  0.01545643,  0.04013965],\n","       ...,\n","       [ 0.05990741, -0.05156167, -0.05899484],\n","       [-0.02154053,  0.02122727, -0.03248093],\n","       [ 0.00669023, -0.06359323,  0.0352909 ]], dtype=float32)>]\n","Model2 [<tf.Variable 'branch0:0' shape=(1, 96, 96) dtype=float32, numpy=\n","array([[[-0.09113833,  0.00637048,  0.00273504, ..., -0.02233632,\n","          0.07612789,  0.1681011 ],\n","        [-0.0863949 ,  0.09558821, -0.11816139, ..., -0.12054993,\n","          0.03731355, -0.05206116],\n","        [ 0.09493602,  0.17383781, -0.0259747 , ..., -0.11810359,\n","         -0.05699228, -0.00552481],\n","        ...,\n","        [-0.11689179, -0.01659395,  0.06843378, ...,  0.06722234,\n","         -0.03064468,  0.06023005],\n","        [ 0.1306257 ,  0.04455487,  0.12420452, ...,  0.00460504,\n","         -0.15308738,  0.15982324],\n","        [-0.10438699,  0.04121909,  0.10257611, ..., -0.02354545,\n","         -0.04438749,  0.02514369]]], dtype=float32)>, <tf.Variable 'bias0:0' shape=(1, 1, 256) dtype=float32, numpy=\n","array([[[ 0.00784864,  0.02217077,  0.05681929,  0.00058315,\n","         -0.0473245 , -0.01485409,  0.03273953,  0.01602115,\n","          0.01285859,  0.0415198 ,  0.04354558, -0.02738688,\n","          0.0560503 , -0.04716441, -0.01139435,  0.03448059,\n","          0.03433698, -0.04155906, -0.05540401, -0.04376579,\n","         -0.02240005, -0.02718948,  0.02487051,  0.01536939,\n","         -0.04261   ,  0.00035121, -0.01366006, -0.05123275,\n","          0.05100376, -0.01814385,  0.00594551, -0.02436759,\n","          0.03603712, -0.03879362,  0.02459519, -0.02114928,\n","         -0.04775289,  0.0406821 ,  0.02527048,  0.04933678,\n","         -0.04698025, -0.03725204,  0.03495843, -0.00086691,\n","         -0.04258982, -0.02508385, -0.04493647,  0.05110788,\n","         -0.00585394,  0.04052312, -0.0282245 , -0.03409056,\n","         -0.04207867, -0.02710697,  0.00050016,  0.03541546,\n","         -0.05949809, -0.02287924,  0.04002292,  0.05070595,\n","         -0.04468413, -0.01232594, -0.04855973, -0.0512095 ,\n","         -0.04109873,  0.05806271, -0.00384177,  0.04466127,\n","         -0.06077332, -0.02367342,  0.03279489, -0.0152684 ,\n","         -0.03313744, -0.05807365,  0.03397631, -0.01609924,\n","         -0.03608542,  0.00534362,  0.00287708,  0.03684875,\n","          0.04538016,  0.03599466,  0.02521478, -0.05868443,\n","          0.03104221, -0.00506522, -0.0322545 ,  0.01158982,\n","         -0.06023579, -0.00825623, -0.04296074,  0.01938375,\n","          0.05968726,  0.0218005 , -0.00508303,  0.04357837,\n","         -0.0132326 ,  0.04019772, -0.03013862,  0.03151462,\n","         -0.02993253, -0.05679624,  0.05094079, -0.01067585,\n","         -0.03350163,  0.02763689,  0.03609493,  0.01779495,\n","          0.05728591,  0.02626787,  0.01116539, -0.03375737,\n","         -0.01690941, -0.03077351,  0.06113918, -0.01042291,\n","         -0.00793891, -0.03080478,  0.05969091, -0.06088153,\n","         -0.03167634, -0.04475414, -0.03067608, -0.04040232,\n","          0.01155647,  0.04932081, -0.02001713, -0.03350482,\n","          0.04467211,  0.03897892,  0.00547154,  0.03036124,\n","          0.05650809, -0.00543763, -0.02886355, -0.01397322,\n","          0.02192695, -0.04251022, -0.03165893, -0.02675366,\n","         -0.03688911,  0.00988802, -0.02524981, -0.01864475,\n","          0.03077257, -0.05466883, -0.00331969,  0.03863527,\n","         -0.0118438 , -0.02699904,  0.00477252,  0.01141034,\n","          0.02611437,  0.01868005,  0.04352517, -0.05668385,\n","          0.06128432,  0.02103999,  0.03531729,  0.0580767 ,\n","         -0.02062801,  0.02202245, -0.03026943,  0.03684025,\n","          0.02931627, -0.01746486, -0.02839956, -0.0098814 ,\n","         -0.05358506, -0.04512461, -0.04826848, -0.02671001,\n","          0.04217253, -0.03113061, -0.0254379 , -0.00724078,\n","          0.04639261, -0.03022966, -0.02976659, -0.01714919,\n","         -0.0163766 , -0.0503288 ,  0.01708094,  0.02733298,\n","          0.03668339, -0.02931848,  0.02986836, -0.00170316,\n","          0.01638829,  0.04326379,  0.02173973, -0.04102562,\n","         -0.05936589,  0.0277181 ,  0.0195176 , -0.03153256,\n","         -0.03618662,  0.02069168, -0.02441743, -0.04850822,\n","         -0.02925244, -0.03903461,  0.03079621, -0.015753  ,\n","         -0.00568204,  0.04262738,  0.02843134, -0.03480274,\n","          0.0472045 , -0.0190989 , -0.00018957,  0.00723379,\n","         -0.0347911 ,  0.01312887,  0.00884946,  0.00116881,\n","          0.02004538, -0.00229979,  0.00929373,  0.02303683,\n","          0.01466297, -0.00032127, -0.02694117, -0.00599743,\n","          0.02804699, -0.04310758, -0.02128501, -0.04305404,\n","         -0.03290664,  0.02953485, -0.04459396,  0.03069203,\n","         -0.05069423, -0.05131168, -0.0105553 ,  0.04876317,\n","         -0.03149108, -0.05316975,  0.05403512, -0.01028274,\n","         -0.02585362, -0.04216237, -0.05374978, -0.01950027,\n","         -0.01223676, -0.03160451, -0.03937554, -0.00862277,\n","          0.01562162,  0.05613797,  0.04601865,  0.02857623,\n","          0.04603654, -0.02776469, -0.01385498, -0.04118744]]],\n","      dtype=float32)>, <tf.Variable 'dense_184/kernel:0' shape=(96, 256) dtype=float32, numpy=\n","array([[-0.02275015,  0.06233727, -0.0964158 , ..., -0.09762894,\n","         0.07623321, -0.12154669],\n","       [-0.07371811,  0.07217301, -0.10759956, ..., -0.06763096,\n","        -0.11475649,  0.05862634],\n","       [ 0.02899805, -0.03549326, -0.01953903, ...,  0.12379181,\n","         0.05602462,  0.11085274],\n","       ...,\n","       [ 0.12596102,  0.12294399,  0.06778544, ...,  0.04689987,\n","        -0.06352024,  0.08891123],\n","       [ 0.06545649,  0.07423035,  0.03896038, ..., -0.07349877,\n","         0.07906879,  0.04936728],\n","       [ 0.12486671, -0.08811866,  0.12615854, ..., -0.09174626,\n","         0.04148467,  0.04715061]], dtype=float32)>, <tf.Variable 'dense_185/kernel:0' shape=(96, 960) dtype=float32, numpy=\n","array([[ 0.05565869,  0.02320975, -0.05918439, ...,  0.06062761,\n","        -0.0687994 ,  0.03928912],\n","       [ 0.06850892, -0.03335182,  0.03921354, ..., -0.00321609,\n","        -0.01338655,  0.03143989],\n","       [-0.036882  ,  0.0524784 , -0.02814305, ..., -0.04287689,\n","        -0.00734098, -0.00923777],\n","       ...,\n","       [ 0.03057696, -0.05389061, -0.00401097, ..., -0.05685351,\n","         0.00939516, -0.04285385],\n","       [-0.01475143, -0.00437341,  0.03161532, ...,  0.06491955,\n","        -0.00721969,  0.01305222],\n","       [-0.019495  , -0.03943856, -0.0616098 , ...,  0.02945951,\n","         0.00337433, -0.04106925]], dtype=float32)>, <tf.Variable 'dense_186/kernel:0' shape=(960, 256) dtype=float32, numpy=\n","array([[-0.05984677,  0.00768731, -0.00886308, ...,  0.06277407,\n","         0.02483835, -0.05950015],\n","       [-0.00657812,  0.05091401, -0.02644202, ..., -0.03648356,\n","         0.04556381,  0.00932513],\n","       [ 0.06390496, -0.02240302, -0.00212504, ...,  0.06510632,\n","        -0.04118982,  0.05245747],\n","       ...,\n","       [ 0.02395828, -0.00708611,  0.03315455, ..., -0.01218563,\n","         0.00415444, -0.02950758],\n","       [ 0.03885351, -0.02461534, -0.06310381, ...,  0.05179953,\n","         0.01962189, -0.01824969],\n","       [ 0.05947718, -0.05285656,  0.06729292, ...,  0.03849783,\n","        -0.03979264,  0.01275289]], dtype=float32)>, <tf.Variable 'branch1:0' shape=(1, 256, 512) dtype=float32, numpy=\n","array([[[-0.03240713,  0.0343133 , -0.08397374, ..., -0.03624871,\n","          0.01425986, -0.06948382],\n","        [-0.03019967, -0.0706015 ,  0.07022081, ..., -0.01960156,\n","          0.05037131,  0.05083969],\n","        [-0.01582459,  0.06748745,  0.02584341, ...,  0.06751289,\n","         -0.07687419, -0.03618438],\n","        ...,\n","        [-0.08327922, -0.02399471,  0.08115977, ..., -0.03590954,\n","         -0.02884979,  0.00084854],\n","        [-0.02084378, -0.08119994,  0.02564614, ..., -0.04359516,\n","         -0.04310147, -0.05132086],\n","        [-0.06668675,  0.00501795, -0.01712712, ...,  0.08525708,\n","          0.06704041, -0.0752922 ]]], dtype=float32)>, <tf.Variable 'bias1:0' shape=(1, 2, 256) dtype=float32, numpy=\n","array([[[ 1.34922536e-02, -2.81244691e-04, -5.12489397e-03,\n","          2.86939442e-02,  2.18783971e-02,  1.30987382e-02,\n","         -8.93182401e-03,  1.68057100e-03,  5.02277315e-02,\n","         -4.90587614e-02,  5.95816523e-02,  6.08604625e-02,\n","          4.22107875e-02, -6.06840104e-03,  4.67738509e-02,\n","          2.96812933e-02,  6.84650103e-03, -2.31923796e-02,\n","          2.81154597e-03,  2.00485718e-02, -1.44353062e-02,\n","         -1.32308984e-02,  1.94561034e-02,  4.02895361e-03,\n","          3.09903529e-02, -2.36568432e-02,  3.59034282e-03,\n","          4.21122536e-02,  1.91399250e-02, -2.57853419e-02,\n","         -2.04699002e-02,  6.24262616e-02,  2.81483904e-02,\n","         -3.57793421e-02, -4.26321328e-02,  6.65003434e-03,\n","         -2.02557910e-02,  6.38278425e-02, -3.81720141e-02,\n","         -1.21153556e-02, -5.94509915e-02, -9.74476989e-03,\n","         -4.95525189e-02, -4.13415171e-02,  2.29762141e-02,\n","          3.62582952e-02, -3.99368107e-02, -1.63858533e-02,\n","         -5.07166721e-02,  4.95533161e-02, -1.77156515e-02,\n","         -3.95867229e-02,  2.37899832e-02, -5.49189281e-03,\n","          5.81206530e-02,  2.45469771e-02,  7.97405839e-03,\n","          3.02595105e-02, -3.92419361e-02,  3.30365598e-02,\n","          2.60023810e-02, -2.01240797e-02, -4.67801467e-02,\n","          4.78269299e-03, -3.59058306e-02,  3.13164778e-02,\n","          2.35149749e-02, -1.88961215e-02, -3.14295292e-02,\n","         -3.46381888e-02, -4.30140905e-02, -6.25368133e-02,\n","         -5.42226108e-03, -6.81930454e-03, -2.12619882e-02,\n","          3.90666500e-02, -4.42730747e-02, -5.30194864e-03,\n","         -2.16403175e-02,  4.33111861e-02,  3.08868941e-02,\n","          1.74184125e-02,  6.25978410e-03,  1.27749136e-02,\n","          3.91279608e-02, -8.77170917e-03,  3.59895229e-02,\n","          4.81013544e-02,  1.91492289e-02,  2.00658161e-02,\n","         -4.38780114e-02, -3.58176157e-02, -3.03994808e-02,\n","         -3.56727764e-02, -5.18181957e-02,  1.84230898e-02,\n","          2.28277631e-02,  2.61509474e-02, -5.63056953e-02,\n","         -1.95921939e-02, -3.38627212e-02,  5.70295937e-03,\n","          3.41098011e-02, -3.87110561e-02, -1.35634970e-02,\n","          2.35425308e-03, -9.92699061e-03,  2.93940715e-02,\n","         -4.05494682e-02,  7.18045165e-04,  2.81133112e-02,\n","          3.07084825e-02, -5.12497351e-02, -2.48653884e-03,\n","          3.65059897e-02,  3.78641039e-02,  2.82923896e-02,\n","         -8.87499191e-03, -4.15104302e-03, -3.76879945e-02,\n","         -6.01401478e-02, -1.99632943e-02, -4.16796431e-02,\n","          4.31790948e-02, -9.64125153e-03, -9.49489232e-03,\n","          1.72488075e-02,  5.56858815e-02, -1.29688242e-02,\n","         -4.80476804e-02, -2.16747560e-02,  5.41007034e-02,\n","          1.21578984e-02,  1.82805452e-02, -5.25934771e-02,\n","          5.50947562e-02, -3.01091277e-05,  5.01150545e-03,\n","          1.73741803e-02,  5.51691465e-02, -9.96173546e-03,\n","         -2.17068475e-02,  2.15508305e-02,  1.24244830e-02,\n","         -5.79228103e-02,  4.78035472e-02,  3.87712792e-02,\n","         -3.11098397e-02, -1.08170593e-02,  1.61150452e-02,\n","          4.64140438e-02, -5.53773604e-02, -4.61370051e-02,\n","          7.65959732e-03, -2.30204081e-03,  2.70145983e-02,\n","          2.38594897e-02,  7.96511490e-03,  5.40456772e-02,\n","         -3.72782797e-02,  9.91438050e-03, -4.81619015e-02,\n","         -5.03013432e-02, -4.61443029e-02, -5.08817397e-02,\n","         -2.86001451e-02, -2.13360712e-02,  2.58253962e-02,\n","         -1.04768742e-02,  5.58352238e-03,  7.87841901e-03,\n","          5.03062159e-02,  2.65204435e-04,  2.18918789e-02,\n","          2.61324681e-02, -1.52004138e-02, -6.07951544e-02,\n","         -4.53042053e-02, -3.30105191e-03,  4.21908200e-02,\n","         -2.52108332e-02,  4.30843197e-02, -3.76401655e-02,\n","         -6.14985563e-02,  4.23496366e-02,  4.95216809e-02,\n","          3.63068543e-02, -4.01389077e-02, -4.68041115e-02,\n","          8.14469811e-03,  4.16611023e-02, -4.44151796e-02,\n","          2.03528330e-02, -3.83437499e-02,  8.73562414e-03,\n","         -7.52437487e-03,  5.34185395e-02, -1.63593423e-02,\n","          3.56476009e-02,  1.20142205e-02,  3.78948748e-02,\n","         -3.93888392e-02, -3.41628753e-02,  1.38509842e-02,\n","         -1.45799173e-02,  6.02852404e-02,  2.44684797e-02,\n","          5.77819385e-02, -2.93205362e-02,  6.01868182e-02,\n","         -4.11852598e-02,  2.79447958e-02, -3.39441327e-03,\n","         -4.93065827e-02,  1.58691278e-03,  6.39991369e-03,\n","         -4.28632088e-02,  5.31195290e-03,  1.05595179e-02,\n","          2.46091597e-02,  3.06460932e-02, -9.92088206e-03,\n","          3.09415832e-02,  2.17265263e-03, -8.21467116e-03,\n","          5.47735654e-02, -4.98607121e-02, -4.37213480e-02,\n","          1.53940227e-02,  4.51011620e-02,  4.58598360e-02,\n","          1.75519288e-02,  2.48301644e-02, -3.29622328e-02,\n","         -2.01543327e-02, -4.09316458e-03, -4.57010493e-02,\n","          4.73066196e-02, -3.26560065e-02,  2.85452344e-02,\n","          9.88188572e-03,  4.64069545e-02, -2.07417719e-02,\n","          5.13082631e-02,  5.59261478e-02,  7.04394002e-03,\n","         -1.33393835e-02,  5.14741279e-02, -3.22407251e-03,\n","          2.59918254e-02,  2.94875191e-03,  1.57765523e-02,\n","         -4.26368713e-02,  9.25697759e-03, -5.56524470e-02,\n","          3.79080884e-02],\n","        [ 3.88420559e-02, -3.80879007e-02,  4.02910598e-02,\n","         -5.63315265e-02,  4.58649881e-02, -6.63302327e-03,\n","         -3.59908752e-02, -1.12798158e-02, -4.63771215e-03,\n","         -2.17585638e-02, -2.06697304e-02,  4.96516600e-02,\n","          1.34098055e-02,  5.97056635e-02,  2.12617009e-03,\n","          9.95278452e-03,  4.56946976e-02,  2.64897440e-02,\n","          1.60256401e-02,  5.62684499e-02, -5.34840375e-02,\n","         -5.08722849e-02,  4.09200415e-03, -3.47352144e-03,\n","          5.25701828e-02, -3.70988846e-02, -5.04421853e-02,\n","          5.16516678e-02,  1.16739627e-02,  5.05136028e-02,\n","          5.00191040e-02, -4.05666456e-02,  7.89953209e-03,\n","          3.09070926e-02,  1.85505711e-02,  1.19443154e-02,\n","          2.19913237e-02,  4.28536497e-02, -1.35275712e-02,\n","          2.71053668e-02,  2.35106871e-02,  3.69623341e-02,\n","          1.49234105e-02,  4.75255959e-03, -1.14937164e-02,\n","          4.15736698e-02, -5.75120859e-02,  3.31211984e-02,\n","          1.06222043e-02, -5.98259307e-02, -2.63448209e-02,\n","          5.61719574e-02, -4.92321812e-02, -2.86264066e-02,\n","          5.48110045e-02,  2.75171231e-02,  1.31384023e-02,\n","          5.66684008e-02, -5.06040640e-02,  4.36950587e-02,\n","          4.85193953e-02, -5.96203618e-02, -7.93863554e-03,\n","         -7.53431395e-03,  4.98134121e-02,  4.30136845e-02,\n","         -3.46207595e-03,  1.71338711e-02, -5.10984659e-02,\n","          2.95969602e-02,  6.17581373e-03,  9.60056949e-03,\n","          5.59768714e-02,  5.41482642e-02, -1.05684577e-02,\n","          1.00245569e-02,  2.77577117e-02, -4.75659110e-02,\n","          1.71374120e-02,  2.75605102e-03,  3.55283320e-02,\n","         -7.40884151e-03,  5.39633185e-02,  5.78678735e-02,\n","          1.04123931e-02, -6.75125048e-03,  5.69945611e-02,\n","          6.08352236e-02, -1.65556259e-02,  3.05595938e-02,\n","          1.85640901e-02,  2.47023497e-02, -3.62435244e-02,\n","         -4.35728878e-02,  3.44665982e-02, -3.42915766e-02,\n","          8.96328315e-03, -3.14948633e-02,  1.96140129e-02,\n","         -2.70383302e-02,  1.27722528e-02, -5.03932610e-02,\n","          4.65765633e-02, -6.05547279e-02, -4.19343635e-02,\n","          3.70609686e-02, -4.18338999e-02, -3.08833551e-02,\n","         -4.12877314e-02,  5.62741607e-02, -6.35147318e-02,\n","          2.22648662e-02,  1.44551424e-02, -3.09710279e-02,\n","         -5.03228828e-02, -3.11293676e-02,  4.11127182e-03,\n","          4.38577449e-03, -4.00181115e-02,  5.59739247e-02,\n","         -1.39481472e-02,  1.13902809e-02, -9.49366298e-03,\n","         -6.04432411e-02,  5.69237582e-02, -3.58621627e-02,\n","         -4.50913683e-02, -5.09865442e-03,  3.96039672e-02,\n","         -5.41594345e-03, -1.95949785e-02,  5.61081283e-02,\n","         -5.23454435e-02,  3.77061479e-02, -1.91298537e-02,\n","         -9.85382777e-03, -4.89005595e-02,  1.03515824e-02,\n","         -2.67140511e-02, -2.10490432e-02,  5.42636923e-02,\n","          5.43903671e-02, -3.73421311e-02,  4.80160862e-02,\n","          5.88942803e-02,  2.74823178e-02,  4.67499606e-02,\n","          2.79692207e-02,  9.44036990e-03,  4.74207625e-02,\n","         -2.60441266e-02,  1.92977693e-02, -5.69005590e-03,\n","         -5.01012281e-02, -1.74974706e-02, -9.22195241e-03,\n","         -5.28781349e-03,  2.08447520e-02,  2.15779990e-02,\n","          4.29901341e-03, -9.60249733e-03, -1.90209467e-02,\n","          4.24576961e-02, -3.59717719e-02,  4.33855839e-02,\n","          3.20695937e-02,  3.81122380e-02,  2.54257321e-02,\n","          4.64276224e-02,  1.05236573e-02,  3.81833725e-02,\n","         -5.21216691e-02,  3.86253931e-02,  7.04580033e-03,\n","          5.33846878e-02,  2.85281688e-02, -4.42792438e-02,\n","          5.43722212e-02, -7.39992177e-03,  3.27241048e-02,\n","         -2.93464325e-02,  2.89356639e-03,  5.50240129e-02,\n","         -5.77168800e-02, -2.27185758e-03, -5.38092703e-02,\n","          2.99111605e-02,  4.48808782e-02,  3.90725918e-02,\n","          3.83307189e-02, -2.24893279e-02, -8.73607025e-03,\n","          5.51203303e-02, -4.55357544e-02,  6.06586076e-02,\n","          4.05852571e-02,  5.20476215e-02,  5.47625460e-02,\n","         -4.48726937e-02, -5.44078127e-02,  8.02756473e-03,\n","         -5.55269606e-02,  5.43862022e-02,  1.58321168e-02,\n","         -5.97894154e-02,  5.44428676e-02,  4.01494792e-03,\n","          2.79891156e-02, -4.47285511e-02,  4.52284748e-03,\n","         -6.93351822e-03, -5.35158440e-02, -5.21313287e-02,\n","         -4.38975915e-03, -3.75602432e-02, -4.78799008e-02,\n","          4.07709666e-02, -3.00057195e-02, -3.38138565e-02,\n","         -2.64033340e-02,  6.03355877e-02, -4.46581393e-02,\n","          2.94231568e-02, -1.71902794e-02, -3.05202976e-02,\n","          2.78156549e-02, -2.00005751e-02,  3.70319933e-02,\n","         -1.37996273e-02,  2.55763941e-02, -7.37711973e-03,\n","         -1.69644561e-02, -1.60116740e-02, -1.23433238e-02,\n","          4.62368131e-02, -3.80892567e-02,  4.67738733e-02,\n","          4.60124761e-02,  5.34157343e-02,  5.34049177e-04,\n","         -4.79289405e-02, -2.68675629e-02, -1.81705281e-02,\n","          3.13103199e-02, -4.43213172e-02,  2.00508442e-02,\n","         -4.64723036e-02, -5.62056303e-02,  2.13290844e-02,\n","          9.69410688e-03, -8.51195492e-03,  2.61516664e-02,\n","          3.15077677e-02,  3.28199603e-02, -3.74409696e-03,\n","         -4.19137208e-03]]], dtype=float32)>, <tf.Variable 'dense_187/kernel:0' shape=(96, 256) dtype=float32, numpy=\n","array([[ 0.12702404,  0.02011877, -0.11036018, ...,  0.03003139,\n","        -0.01062548,  0.10485318],\n","       [-0.06857543,  0.11332455, -0.10529436, ...,  0.11726695,\n","        -0.00997956,  0.02248029],\n","       [-0.12520483, -0.08642827,  0.02184306, ..., -0.0380546 ,\n","        -0.07509191, -0.01583947],\n","       ...,\n","       [-0.02292313,  0.05102451,  0.09955953, ...,  0.0986486 ,\n","        -0.02272298,  0.09451138],\n","       [ 0.0149529 ,  0.09812847, -0.05078351, ..., -0.08961845,\n","         0.01731673,  0.11866278],\n","       [-0.03449283,  0.01241013,  0.00721661, ...,  0.04518426,\n","         0.04850444, -0.07875811]], dtype=float32)>, <tf.Variable 'dense_188/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[ 0.08128283, -0.00638378, -0.06634326, ..., -0.04473277,\n","        -0.10089348, -0.06454534],\n","       [ 0.01701235, -0.08602203,  0.06284761, ..., -0.01649457,\n","        -0.10617722, -0.10348419],\n","       [ 0.08667615,  0.01512705, -0.07498036, ...,  0.08892428,\n","         0.02704248,  0.01390482],\n","       ...,\n","       [-0.02300195,  0.05223425, -0.08072341, ...,  0.00323057,\n","        -0.09314575,  0.03722936],\n","       [-0.07157502,  0.00663338,  0.00331442, ..., -0.10744175,\n","         0.03027995, -0.00943263],\n","       [-0.04780586,  0.09873131, -0.07148414, ...,  0.03089884,\n","        -0.0254926 ,  0.06689738]], dtype=float32)>, <tf.Variable 'dense_189/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[-0.04749273,  0.04507331,  0.01958096, ...,  0.04304885,\n","        -0.02231196,  0.00385744],\n","       [-0.01049249,  0.00672522, -0.03945335, ..., -0.01967258,\n","         0.01186664, -0.00701478],\n","       [-0.02097481, -0.00873829, -0.00034786, ..., -0.02646345,\n","         0.00507458, -0.04113933],\n","       ...,\n","       [-0.02615117,  0.01438247, -0.01325976, ...,  0.01445906,\n","        -0.00022308, -0.01730439],\n","       [ 0.02095403, -0.03304614,  0.0027671 , ...,  0.02553115,\n","         0.03090191, -0.02696593],\n","       [-0.04825152, -0.0187124 , -0.02030754, ..., -0.01808583,\n","         0.00080892,  0.02398463]], dtype=float32)>, <tf.Variable 'dense_190/kernel:0' shape=(2560, 256) dtype=float32, numpy=\n","array([[ 0.03982278,  0.04095873,  0.00327418, ..., -0.00286671,\n","        -0.01972371,  0.02048318],\n","       [ 0.04220753,  0.03394606,  0.03007202, ...,  0.00401257,\n","         0.01512284,  0.02625473],\n","       [ 0.02945063, -0.02638273,  0.03718655, ...,  0.01749853,\n","         0.04464276, -0.0265621 ],\n","       ...,\n","       [-0.01789294, -0.01970724,  0.00648052, ..., -0.03465626,\n","         0.00743076,  0.03297861],\n","       [ 0.0203002 , -0.02870396,  0.03515444, ...,  0.04310328,\n","        -0.00675772,  0.0119464 ],\n","       [-0.00742789, -0.04535772,  0.04327982, ..., -0.02994581,\n","         0.03776302, -0.04356296]], dtype=float32)>, <tf.Variable 'branch2:0' shape=(2, 256, 512) dtype=float32, numpy=\n","array([[[-0.0563444 ,  0.05430143,  0.04771774, ...,  0.0081454 ,\n","         -0.04060025, -0.0146662 ],\n","        [-0.04511563, -0.02441125, -0.0046542 , ...,  0.00444726,\n","         -0.06197638, -0.00117837],\n","        [ 0.00729844, -0.03378344, -0.06135524, ...,  0.05144288,\n","         -0.05025268, -0.01290674],\n","        ...,\n","        [ 0.03360365,  0.04984912,  0.02175323, ...,  0.05228799,\n","         -0.02556126,  0.06403757],\n","        [-0.02355237,  0.05946125,  0.00702519, ..., -0.05523834,\n","          0.00506939, -0.05990375],\n","        [ 0.02953017,  0.05132993,  0.00450946, ...,  0.01550404,\n","          0.01934332,  0.01429062]],\n","\n","       [[-0.03606457,  0.03732555,  0.0388541 , ...,  0.03525133,\n","         -0.04493717, -0.04515366],\n","        [ 0.02152412,  0.05274203, -0.03400687, ...,  0.02817768,\n","         -0.01647406,  0.02608429],\n","        [ 0.05144289,  0.0532746 ,  0.04564288, ..., -0.0070619 ,\n","          0.03204594, -0.02478536],\n","        ...,\n","        [ 0.05822603,  0.01061888, -0.0053921 , ..., -0.01138197,\n","          0.02057633, -0.04761083],\n","        [-0.0394529 ,  0.05620177,  0.02589588, ..., -0.03478992,\n","          0.03558924, -0.00341072],\n","        [-0.02274967, -0.01803455,  0.04622586, ..., -0.03335218,\n","          0.04455616, -0.04829201]]], dtype=float32)>, <tf.Variable 'bias2:0' shape=(1, 2, 256) dtype=float32, numpy=\n","array([[[-0.04674513,  0.03585948, -0.01045552, -0.00277816,\n","         -0.01780519, -0.02770237, -0.02857306, -0.04208401,\n","          0.0603826 , -0.05583786, -0.00159306,  0.01541602,\n","          0.06276513, -0.03408715, -0.05774866, -0.02759909,\n","          0.00496418, -0.01399802,  0.04230244,  0.00540271,\n","         -0.02957498,  0.01058515, -0.00703812,  0.02533633,\n","         -0.03039487,  0.05802596, -0.05583441, -0.05001921,\n","         -0.04351701, -0.05979409,  0.05832371, -0.00134716,\n","          0.06145567, -0.01462365,  0.03595085, -0.0338075 ,\n","          0.05455119, -0.04195183, -0.05980839,  0.05474339,\n","          0.05784717, -0.05072322, -0.04606681,  0.04154713,\n","          0.02753163,  0.0361281 , -0.01870762,  0.02944863,\n","          0.03862408,  0.04058181,  0.04685624, -0.05105546,\n","         -0.04054912, -0.02714389,  0.01383057,  0.04998106,\n","          0.05358837,  0.00379709, -0.04986293,  0.05975486,\n","          0.04315982, -0.00821636,  0.04682513,  0.02546794,\n","          0.05229615,  0.0499259 , -0.04030249,  0.04452717,\n","         -0.02154054, -0.0218117 ,  0.02057394, -0.04758873,\n","          0.00396011,  0.01862805, -0.00076144,  0.00693527,\n","         -0.0340944 ,  0.01952649, -0.00636302, -0.00586626,\n","         -0.04919954, -0.02957812,  0.0500484 ,  0.01877973,\n","         -0.02043818, -0.01761355,  0.02127977,  0.00433761,\n","          0.01231778,  0.02800721,  0.05032692, -0.06058326,\n","         -0.0273509 , -0.0124039 , -0.01366082, -0.06211685,\n","          0.05645069, -0.05367557, -0.00335966, -0.0124118 ,\n","         -0.04444328, -0.05313192,  0.01020515,  0.02469945,\n","          0.03050218,  0.05025873, -0.05549525,  0.05845925,\n","          0.05832827, -0.01603139, -0.04838478, -0.02908689,\n","          0.00928341, -0.04738985,  0.05468416,  0.05177289,\n","          0.05112708,  0.00940987, -0.03846842,  0.00314252,\n","          0.01784317,  0.03794318,  0.00676186, -0.0433192 ,\n","         -0.02825262, -0.05518791,  0.01124961,  0.03764424,\n","         -0.02372132,  0.03295064,  0.04047655, -0.02408863,\n","         -0.0193159 , -0.00818256,  0.00623561, -0.04996401,\n","         -0.03095946,  0.04832001, -0.0348729 , -0.02990813,\n","          0.03833758, -0.01686864, -0.03193989,  0.04513239,\n","          0.03262475,  0.00979437, -0.04493209, -0.02707885,\n","          0.04994399,  0.04234322,  0.00271765,  0.00772505,\n","          0.00609307,  0.00139083, -0.04037558, -0.01559066,\n","          0.04926124, -0.04348429,  0.00585961, -0.02907261,\n","         -0.06079046, -0.03426431, -0.00538845, -0.00144018,\n","          0.00468065,  0.042186  ,  0.0060574 ,  0.05475713,\n","         -0.0554758 , -0.03721799,  0.02850443, -0.01149205,\n","          0.04226651,  0.00935277,  0.00152482, -0.01210787,\n","         -0.03233588,  0.03155034, -0.0280071 ,  0.00142624,\n","         -0.05887559,  0.05944026, -0.04287486,  0.00989688,\n","          0.0076652 , -0.04360756,  0.04196849, -0.02318374,\n","         -0.0266885 , -0.02263152,  0.02355394,  0.00990393,\n","          0.05323472,  0.02677426,  0.02447334,  0.05724275,\n","         -0.00488447, -0.02372363,  0.03738837, -0.02577298,\n","          0.02518226,  0.05987459,  0.01757354,  0.05459674,\n","         -0.0537592 ,  0.02296068, -0.01591473,  0.00962787,\n","         -0.02656322, -0.04211145, -0.05867754, -0.03890888,\n","          0.03868847,  0.05014504,  0.0108175 ,  0.06051551,\n","          0.05182388, -0.01456782, -0.00033049,  0.0477949 ,\n","          0.01117381,  0.0365275 , -0.03582543,  0.0411079 ,\n","          0.05172013,  0.05439574, -0.04262165,  0.03123333,\n","         -0.04035519, -0.0337803 ,  0.01901002,  0.05383895,\n","          0.00401743,  0.05892237,  0.05317504, -0.05333544,\n","          0.04583832, -0.05961495,  0.03239198,  0.00641273,\n","         -0.01757636, -0.04225505,  0.0095505 , -0.04096653,\n","         -0.02104567,  0.03744185, -0.03372666, -0.01346496,\n","         -0.03107395,  0.01474391, -0.05553752,  0.04932202,\n","         -0.04188412, -0.0544083 ,  0.01077228, -0.0272481 ],\n","        [-0.01725648, -0.00563066, -0.03834386, -0.06216302,\n","         -0.03096004,  0.04422218,  0.00207201,  0.04765581,\n","          0.06065127, -0.04629595,  0.0605631 ,  0.03321254,\n","         -0.0580611 ,  0.00969821,  0.02579394, -0.03662082,\n","          0.03097125, -0.03377077, -0.04514841, -0.04274591,\n","          0.0244335 ,  0.04024693, -0.0153524 , -0.05479556,\n","         -0.06239074, -0.01629759, -0.01308654,  0.02694043,\n","          0.01374841, -0.02578443,  0.0392315 , -0.00080083,\n","          0.05309027, -0.03109206,  0.01637409,  0.00410225,\n","         -0.05167555,  0.00981575,  0.01505969,  0.04323092,\n","         -0.00647129, -0.03960614,  0.01780731, -0.02436424,\n","         -0.00862525,  0.01209195, -0.05571   ,  0.05703761,\n","         -0.02201812,  0.02966912, -0.03246683,  0.02417113,\n","          0.04419063, -0.04056788,  0.03141976,  0.00466466,\n","         -0.02898107, -0.0050794 ,  0.05872126, -0.04181157,\n","         -0.05656622, -0.01227034, -0.02818225, -0.06348162,\n","          0.04522953, -0.00302819,  0.05027967, -0.02119636,\n","          0.05319335, -0.01491634,  0.02049506,  0.0146432 ,\n","         -0.03723869,  0.03416541, -0.06404492, -0.00024009,\n","          0.05006101,  0.01066707,  0.01332225,  0.04250252,\n","         -0.03847496,  0.03464805,  0.01385943,  0.00267359,\n","         -0.06179352,  0.0211281 , -0.02208113, -0.02078665,\n","         -0.01386622,  0.03602402, -0.04880543, -0.03834594,\n","         -0.02013259, -0.01538331, -0.04220078, -0.06143294,\n","          0.02335986,  0.03193076, -0.04695211, -0.03955469,\n","          0.05070663,  0.00833515,  0.05619171, -0.03427547,\n","         -0.02156251,  0.06211275,  0.02734596,  0.02139066,\n","          0.03578303,  0.04239621, -0.05355034, -0.04428725,\n","         -0.02287129,  0.00368285,  0.03894898,  0.02582019,\n","         -0.05662815,  0.02795697, -0.04158449, -0.04429867,\n","          0.06120475,  0.05826214,  0.0011826 ,  0.04632804,\n","          0.01059381,  0.05868853, -0.02916252,  0.05679736,\n","          0.0060181 , -0.03933907, -0.05202184,  0.03766335,\n","          0.03060506, -0.05754177,  0.05106151,  0.0125281 ,\n","         -0.03471197,  0.01964708,  0.00122603, -0.02175792,\n","         -0.01123021, -0.02449585,  0.06088763,  0.05205509,\n","          0.02215676,  0.01221266,  0.00779143,  0.04655312,\n","          0.01184078, -0.0422303 ,  0.04322788, -0.01250899,\n","          0.05156768, -0.05975584,  0.06081637,  0.01249517,\n","          0.0504831 ,  0.02344519,  0.03221968,  0.00393211,\n","         -0.04207132, -0.04841089, -0.02405739, -0.01848624,\n","         -0.04330851,  0.0434767 , -0.00090254, -0.02605934,\n","          0.03979011,  0.021052  , -0.03650683, -0.00339518,\n","         -0.00407155,  0.0259764 , -0.05952606, -0.01108627,\n","          0.00747609,  0.04408707, -0.01127222,  0.00045466,\n","         -0.03686358, -0.03652939, -0.03913738, -0.00568352,\n","         -0.03593649, -0.05727329,  0.0117813 ,  0.05466966,\n","          0.0068629 ,  0.02531727, -0.00802622, -0.04416739,\n","          0.02105649, -0.00909224, -0.05634666,  0.01801453,\n","          0.00488559, -0.00934478, -0.00352976, -0.05776354,\n","         -0.05719715, -0.0356518 , -0.05236075, -0.047247  ,\n","          0.04660604, -0.03862333, -0.01073518, -0.04664015,\n","         -0.04126133, -0.05286197, -0.04059696,  0.0083252 ,\n","          0.01680423,  0.02009842, -0.00017785,  0.01781044,\n","          0.03323563, -0.02378669,  0.0330603 ,  0.03679267,\n","         -0.01293233, -0.04174531,  0.03418037, -0.00779217,\n","         -0.00777221, -0.05761841,  0.03986576,  0.0132005 ,\n","         -0.01667752, -0.04121991,  0.02782422,  0.04780002,\n","          0.01969668,  0.02266746, -0.05643562, -0.00673726,\n","         -0.06357911, -0.06133455,  0.00020296, -0.00236826,\n","         -0.01223738, -0.03918181,  0.04606792, -0.00179956,\n","         -0.05431848,  0.01494424, -0.00946932,  0.02107131,\n","          0.04174285,  0.03432243, -0.01378136,  0.01696687,\n","         -0.02373981,  0.05567751,  0.03354984,  0.00029264]]],\n","      dtype=float32)>, <tf.Variable 'dense_191/kernel:0' shape=(96, 256) dtype=float32, numpy=\n","array([[-0.09739899, -0.13025889, -0.12035018, ...,  0.01140693,\n","         0.11692663,  0.06106129],\n","       [ 0.04116393,  0.0860467 ,  0.12065399, ..., -0.05844325,\n","        -0.00180621, -0.06195508],\n","       [ 0.1104893 ,  0.04502698,  0.11505762, ...,  0.04387947,\n","        -0.07242703, -0.10434368],\n","       ...,\n","       [ 0.06440482, -0.09411471, -0.05707778, ...,  0.0490198 ,\n","        -0.09479151, -0.13075277],\n","       [ 0.12688506,  0.02353051, -0.10353474, ...,  0.03603563,\n","        -0.01809956, -0.08878884],\n","       [-0.08376311,  0.04773676,  0.03333021, ..., -0.04961055,\n","         0.13005574, -0.09731243]], dtype=float32)>, <tf.Variable 'dense_192/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[-0.10017354,  0.06170798,  0.03300967, ..., -0.0652581 ,\n","         0.02444748, -0.08531592],\n","       [ 0.03994995, -0.1023453 ,  0.04360989, ...,  0.0819817 ,\n","         0.10115474,  0.04971376],\n","       [ 0.08005267,  0.10381325, -0.00606651, ..., -0.02003239,\n","        -0.02159635, -0.10567459],\n","       ...,\n","       [-0.05033389, -0.06906796, -0.04942266, ...,  0.05176851,\n","         0.10472336,  0.03805351],\n","       [ 0.02985754, -0.08652861,  0.07706703, ..., -0.01049207,\n","         0.05218913,  0.05885396],\n","       [ 0.06581765,  0.06069366, -0.05695751, ..., -0.09238882,\n","        -0.01371567,  0.06152188]], dtype=float32)>, <tf.Variable 'dense_193/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[-0.06169   , -0.00556312, -0.02917129, ...,  0.01605481,\n","         0.03414463,  0.06672268],\n","       [-0.07668096,  0.07880238,  0.06145543, ..., -0.08839779,\n","         0.0829457 ,  0.03354944],\n","       [ 0.00649484,  0.04210104,  0.07108685, ...,  0.0085452 ,\n","         0.00630143,  0.04108372],\n","       ...,\n","       [-0.00143533, -0.01287334,  0.02982481, ..., -0.08979022,\n","         0.05548995, -0.09838253],\n","       [ 0.09979702, -0.09753756,  0.02995286, ..., -0.01984732,\n","         0.06048414,  0.00892361],\n","       [ 0.07349636, -0.1021708 , -0.0772859 , ..., -0.08715671,\n","        -0.08637319,  0.08200949]], dtype=float32)>, <tf.Variable 'dense_194/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[-0.01865826,  0.03591511, -0.00663586, ...,  0.02568613,\n","         0.0062669 , -0.03475317],\n","       [ 0.0050615 , -0.02637897,  0.03077742, ..., -0.0084155 ,\n","         0.03908883, -0.03415943],\n","       [ 0.00257031, -0.01221294, -0.01138738, ...,  0.00703126,\n","         0.00835627, -0.02295435],\n","       ...,\n","       [-0.04451935, -0.03345425, -0.04063169, ...,  0.03960349,\n","         0.02758398,  0.01987173],\n","       [-0.04483561, -0.00652729,  0.01642455, ..., -0.03406894,\n","        -0.04584883,  0.02648583],\n","       [-0.01060003,  0.02630966, -0.04399138, ..., -0.01485901,\n","        -0.03560781, -0.02267521]], dtype=float32)>, <tf.Variable 'dense_195/kernel:0' shape=(2560, 256) dtype=float32, numpy=\n","array([[-0.00514854, -0.01890207, -0.00340231, ..., -0.03817935,\n","         0.0113937 ,  0.04015946],\n","       [ 0.01891679, -0.02643198, -0.00306967, ..., -0.03373956,\n","        -0.001579  , -0.01085821],\n","       [ 0.03359025, -0.01329856,  0.0211578 , ..., -0.00391524,\n","        -0.01876942,  0.0223019 ],\n","       ...,\n","       [ 0.03369665, -0.00447073, -0.00511747, ..., -0.04070548,\n","        -0.04139595, -0.01958253],\n","       [-0.01237512,  0.02819242, -0.0020678 , ...,  0.00234072,\n","         0.03344894, -0.0060506 ],\n","       [-0.03429585, -0.03466303,  0.03272067, ...,  0.01996873,\n","         0.02948453,  0.00469905]], dtype=float32)>, <tf.Variable 'branch3:0' shape=(4, 256, 768) dtype=float32, numpy=\n","array([[[-0.0360182 ,  0.03167838,  0.02948195, ..., -0.02782009,\n","          0.0017646 , -0.00352701],\n","        [ 0.02910357, -0.0300224 ,  0.01505985, ..., -0.02375098,\n","          0.01048895,  0.02438298],\n","        [-0.02841219, -0.03677503, -0.00797758, ..., -0.01000279,\n","          0.02180456, -0.01718596],\n","        ...,\n","        [ 0.01615583, -0.01954172,  0.01344432, ..., -0.02512797,\n","          0.03972906, -0.0402951 ],\n","        [-0.0261596 , -0.02362129, -0.00718993, ..., -0.01104768,\n","         -0.01643074, -0.01199542],\n","        [-0.02526634, -0.03084963,  0.00899966, ..., -0.00120709,\n","          0.02699381, -0.00108439]],\n","\n","       [[ 0.0193261 ,  0.03893007,  0.03001237, ...,  0.00854367,\n","         -0.00949517, -0.0391679 ],\n","        [ 0.02549387, -0.02370414,  0.00250519, ..., -0.02683023,\n","          0.00211091,  0.02245214],\n","        [ 0.02360766,  0.01583728, -0.03338089, ...,  0.0302862 ,\n","         -0.00881903, -0.03490588],\n","        ...,\n","        [-0.02958889,  0.03954687,  0.00987176, ..., -0.02054532,\n","          0.01649158, -0.02701342],\n","        [-0.00780359,  0.0233427 ,  0.01430223, ..., -0.00037523,\n","          0.02888579,  0.02478104],\n","        [-0.01797616, -0.0337058 , -0.01407617, ...,  0.02537994,\n","         -0.02691267,  0.01013145]],\n","\n","       [[ 0.01110279,  0.02078325, -0.00953118, ...,  0.01613094,\n","          0.00061624, -0.01709788],\n","        [ 0.02017759,  0.03995953, -0.00167558, ...,  0.01765514,\n","         -0.02460291, -0.03048488],\n","        [-0.00782889, -0.00889615,  0.02513274, ...,  0.03332903,\n","         -0.01404201, -0.0280965 ],\n","        ...,\n","        [-0.00878078, -0.00999576, -0.02074144, ..., -0.01696743,\n","         -0.02598067, -0.03347441],\n","        [-0.01383718,  0.02638197,  0.0198249 , ...,  0.01636848,\n","         -0.0171539 ,  0.0228622 ],\n","        [-0.01081507, -0.01750443, -0.03098853, ...,  0.00921757,\n","         -0.01959517, -0.00329225]],\n","\n","       [[ 0.03198532,  0.02401438, -0.03589596, ..., -0.0316892 ,\n","          0.02669718,  0.00062877],\n","        [ 0.025903  , -0.03701739, -0.01387738, ..., -0.00236414,\n","          0.0339319 , -0.01943348],\n","        [ 0.02260599,  0.03120217,  0.0086136 , ...,  0.03364794,\n","         -0.02730314, -0.03719779],\n","        ...,\n","        [ 0.03092322,  0.01920233, -0.0020004 , ..., -0.03062234,\n","         -0.01405834,  0.00141632],\n","        [-0.0004653 , -0.0246098 ,  0.00204756, ..., -0.01349667,\n","         -0.03561966, -0.02684077],\n","        [-0.00287339,  0.00765637,  0.01138186, ...,  0.01494616,\n","         -0.03246992,  0.03993271]]], dtype=float32)>, <tf.Variable 'bias3:0' shape=(1, 3, 128) dtype=float32, numpy=\n","array([[[ 0.04634103,  0.02720437,  0.01193692,  0.05490629,\n","         -0.00950426,  0.0335086 ,  0.05847668,  0.07229882,\n","          0.04334614, -0.01194647, -0.03823023,  0.06693035,\n","          0.08136687, -0.00657124, -0.02250013,  0.0447565 ,\n","          0.03495789,  0.05493969, -0.00771009,  0.0161814 ,\n","         -0.01293831,  0.00468238, -0.02560127,  0.00834316,\n","          0.04510961,  0.01450809, -0.05424883, -0.01593298,\n","         -0.02744883, -0.00574748,  0.03731198, -0.00974939,\n","         -0.07990453,  0.04128021, -0.03395059, -0.04887639,\n","          0.0828681 ,  0.02079985, -0.01176505, -0.01294739,\n","         -0.06504694,  0.05320704, -0.02277394, -0.07281233,\n","          0.08157752,  0.03439125,  0.04127866, -0.04441702,\n","         -0.00118872,  0.00598545, -0.05326395, -0.00293707,\n","         -0.07770939, -0.03538711,  0.00820873,  0.07309026,\n","          0.02813836, -0.06562829,  0.02993288,  0.00526367,\n","         -0.02140023,  0.02978454,  0.06855702, -0.05318634,\n","          0.03941833,  0.04425956,  0.04461828,  0.08778622,\n","          0.03007651, -0.08875619,  0.02179649,  0.04207109,\n","          0.00826595, -0.08382361,  0.03683051, -0.06936184,\n","          0.0291544 , -0.07314449, -0.04462419,  0.02674854,\n","         -0.06917435,  0.06930309, -0.05467991, -0.06871071,\n","          0.01451224,  0.05889408,  0.06770641,  0.04400721,\n","          0.03033103,  0.06304793, -0.02310013,  0.03838625,\n","         -0.05357364,  0.02235715, -0.07741695, -0.04593771,\n","         -0.08353613,  0.07637538,  0.07203849, -0.00463704,\n","         -0.02744108, -0.07593668,  0.0397174 , -0.04239862,\n","          0.02022567,  0.00917404, -0.08786801,  0.00982738,\n","          0.01960512,  0.03229909, -0.07260887, -0.08492571,\n","         -0.08052768,  0.04240155, -0.03632296, -0.04839914,\n","          0.05053069,  0.04802104, -0.04333637, -0.0866385 ,\n","         -0.02904262,  0.04917845,  0.04680907, -0.05321964,\n","          0.03934541, -0.06722732, -0.05268626, -0.07617298],\n","        [-0.08957338, -0.01759384,  0.04449338,  0.00972872,\n","          0.00912703,  0.06445634,  0.08286131, -0.01384744,\n","          0.03032115, -0.07375181, -0.06075938, -0.03553306,\n","         -0.00195502, -0.07104284, -0.08759425,  0.06392097,\n","          0.05070242, -0.03780909, -0.03747442, -0.01522202,\n","          0.05087367, -0.04858892,  0.03148258,  0.01209378,\n","         -0.0637251 ,  0.06453532, -0.01365125,  0.00755405,\n","         -0.02764228, -0.07899664, -0.03168031, -0.08166769,\n","         -0.08700135, -0.08337002, -0.0696567 , -0.04174385,\n","          0.05158224, -0.0022421 ,  0.0155097 ,  0.05963966,\n","          0.05425929, -0.06886198, -0.00348797, -0.01370661,\n","         -0.04743099,  0.07430899,  0.06227495, -0.00039534,\n","         -0.03009494, -0.06192334,  0.06961071,  0.05828529,\n","          0.01247398, -0.07475799,  0.04574407,  0.06988733,\n","          0.08678797,  0.06043648,  0.00639344, -0.07784368,\n","         -0.07919414,  0.08438872,  0.01425503,  0.0418306 ,\n","          0.00974876,  0.04251967, -0.04171151, -0.02627138,\n","          0.07774816, -0.08998163,  0.00404744, -0.03735642,\n","         -0.06809098,  0.0583815 , -0.0684193 , -0.04105501,\n","          0.08136009, -0.05519766,  0.05384197, -0.08748513,\n","          0.06120737,  0.08425508, -0.07701072,  0.0193243 ,\n","         -0.04506827,  0.01413996, -0.02105198,  0.01715542,\n","          0.03169798,  0.07005164, -0.03860802,  0.00667487,\n","         -0.02244732, -0.02406092,  0.03987132, -0.0825977 ,\n","          0.07317249, -0.04847979, -0.0014075 ,  0.02734903,\n","          0.03234548,  0.00305505,  0.03536218,  0.03327337,\n","          0.07676686,  0.07041183,  0.02121424, -0.08311057,\n","          0.04115425,  0.00363699, -0.00113157, -0.07965519,\n","         -0.0825571 ,  0.04620492, -0.03804759,  0.0284082 ,\n","          0.05559434,  0.0273691 ,  0.01626934, -0.0644104 ,\n","         -0.00237276,  0.02688436,  0.05270332, -0.02574918,\n","          0.06861866,  0.03605694,  0.07237253,  0.03559139],\n","        [ 0.00077839, -0.02358013, -0.05667056,  0.05504069,\n","         -0.04064786, -0.05010494, -0.06448337, -0.00200351,\n","          0.0040057 , -0.04069502,  0.07024623, -0.04769859,\n","          0.05624159,  0.01892546, -0.04534045,  0.0032221 ,\n","         -0.01715143,  0.08065107, -0.03382434,  0.03228641,\n","         -0.0303791 , -0.03494138,  0.04603163,  0.08166162,\n","         -0.08382702, -0.08718895,  0.00660766, -0.02891628,\n","         -0.02716233,  0.0652825 ,  0.01497349,  0.04509449,\n","         -0.07281428, -0.02359448,  0.03603888, -0.05002807,\n","         -0.08870869,  0.01195987, -0.06151645, -0.07999817,\n","         -0.01489216,  0.02474531, -0.00609919, -0.07294287,\n","         -0.00535793,  0.0022754 ,  0.08449177,  0.07552891,\n","          0.0366312 ,  0.02202318,  0.00728292, -0.07307369,\n","         -0.04597808, -0.03508451,  0.01173956,  0.0557733 ,\n","         -0.0123817 , -0.0157373 ,  0.01351829,  0.00087411,\n","          0.08145143,  0.07980371, -0.0404509 ,  0.01113257,\n","         -0.04347964,  0.02800928, -0.05947873,  0.02096776,\n","          0.05444201, -0.02722191, -0.02550862, -0.07888101,\n","         -0.00413837,  0.03953076, -0.05386929,  0.00862681,\n","          0.01260093, -0.05786153,  0.06636225, -0.06394072,\n","          0.00117445, -0.0283879 ,  0.05072307, -0.06328954,\n","         -0.07107162, -0.03466193,  0.08280484, -0.01347031,\n","          0.03537709,  0.03765247,  0.08381937,  0.05702018,\n","          0.04489143, -0.05339779,  0.01388083,  0.02132739,\n","         -0.02020671,  0.05212324,  0.01949212, -0.03228089,\n","          0.04062882,  0.0265575 , -0.02844628,  0.03846696,\n","         -0.06570923, -0.05090246, -0.06931178,  0.07926259,\n","          0.00377478,  0.00010859, -0.01021696,  0.03262249,\n","          0.04303188, -0.07001013, -0.01589519,  0.08472649,\n","          0.06505841,  0.0872607 , -0.05272499, -0.07033797,\n","          0.0758028 , -0.07769713, -0.00631334,  0.0675677 ,\n","         -0.08300004,  0.00668959, -0.0529277 ,  0.01165446]]],\n","      dtype=float32)>, <tf.Variable 'dense_196/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[-0.16347922,  0.15881972,  0.14321025, ...,  0.05843497,\n","         0.01205291,  0.02381265],\n","       [ 0.09456233, -0.10315389, -0.0422026 , ..., -0.14538985,\n","         0.16179158,  0.03355367],\n","       [-0.0877778 , -0.05910852, -0.03341557, ...,  0.03685634,\n","        -0.13591133, -0.09362165],\n","       ...,\n","       [-0.07874357,  0.12425136, -0.05547371, ..., -0.10754333,\n","         0.00412877,  0.01326108],\n","       [-0.03151532,  0.04779917, -0.12773964, ...,  0.11068282,\n","        -0.0126535 ,  0.05803245],\n","       [ 0.1581596 , -0.02044338, -0.06437758, ..., -0.04121003,\n","         0.11861183,  0.08296925]], dtype=float32)>, <tf.Variable 'dense_197/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.09804297,  0.07734857,  0.07218462, ...,  0.08147936,\n","        -0.04991472,  0.05239867],\n","       [ 0.07232708, -0.09070755,  0.03022682, ...,  0.1183114 ,\n","         0.08786003, -0.02719322],\n","       [-0.05403371,  0.10961819, -0.10301477, ...,  0.0888712 ,\n","         0.11113347, -0.04304576],\n","       ...,\n","       [-0.03021172, -0.03499157, -0.07959042, ..., -0.10731421,\n","        -0.09665866, -0.09004173],\n","       [-0.05037158,  0.06071015, -0.10893636, ...,  0.06505703,\n","         0.04775197, -0.01936116],\n","       [-0.01742276,  0.0898591 , -0.04717904, ..., -0.00794149,\n","         0.10113354,  0.01831636]], dtype=float32)>, <tf.Variable 'dense_198/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.06555793,  0.05088718,  0.02909757, ..., -0.07611503,\n","        -0.02340306, -0.10544302],\n","       [ 0.06433959,  0.02902587, -0.05736057, ...,  0.07196891,\n","        -0.10544583,  0.0580183 ],\n","       [-0.06177134,  0.00279943, -0.12050352, ...,  0.04546612,\n","        -0.07727043,  0.02968721],\n","       ...,\n","       [-0.10456152, -0.01041036, -0.00116802, ...,  0.11377615,\n","         0.01712133, -0.09812535],\n","       [ 0.05147739,  0.12057787,  0.09183155, ...,  0.08015604,\n","        -0.10236701,  0.08648501],\n","       [-0.11719682, -0.07241688, -0.09776108, ..., -0.0514675 ,\n","         0.0332412 , -0.10067768]], dtype=float32)>, <tf.Variable 'dense_199/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.01584605, -0.04202705, -0.10211115, ..., -0.0346657 ,\n","        -0.10507312, -0.1134552 ],\n","       [ 0.05931932, -0.10490438, -0.0799766 , ...,  0.07762915,\n","         0.07517513, -0.1235584 ],\n","       [-0.00271299,  0.12682208, -0.0411957 , ...,  0.10389288,\n","         0.07175117, -0.00119323],\n","       ...,\n","       [-0.10994293,  0.10476667,  0.05219891, ...,  0.03771931,\n","        -0.03321373, -0.0970529 ],\n","       [ 0.0247531 ,  0.0897017 , -0.05557263, ...,  0.10439144,\n","         0.11638498,  0.11946429],\n","       [-0.09754598, -0.03395153,  0.00372511, ..., -0.01200754,\n","         0.0345344 , -0.0069804 ]], dtype=float32)>, <tf.Variable 'dense_200/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[ 3.6947440e-02, -2.2205027e-02, -3.5775308e-02, ...,\n","         3.3728674e-02,  2.3472955e-02, -2.9407632e-02],\n","       [ 3.7115134e-02,  2.5667431e-02, -4.2174201e-02, ...,\n","         2.6915964e-02, -3.1727392e-05,  1.8796213e-02],\n","       [ 1.9526908e-02, -8.5559171e-03,  1.8129146e-02, ...,\n","         1.6757390e-02,  5.4425267e-03, -1.3568093e-02],\n","       ...,\n","       [ 3.0788528e-03,  1.3847849e-02, -1.1675373e-03, ...,\n","         2.1138765e-02, -3.5713397e-02,  1.9685421e-02],\n","       [ 4.3511294e-02,  3.7984636e-02,  5.9824288e-03, ...,\n","         3.2064512e-02,  8.5421605e-03, -2.6535429e-02],\n","       [ 3.5655592e-02,  1.0259589e-02,  1.2044815e-02, ...,\n","        -3.4240149e-02,  8.4811468e-03,  2.6588632e-02]], dtype=float32)>, <tf.Variable 'dense_201/kernel:0' shape=(2560, 128) dtype=float32, numpy=\n","array([[-0.03410215, -0.00262801, -0.03173272, ...,  0.0319635 ,\n","         0.02070226,  0.02342524],\n","       [-0.04196122, -0.03485041, -0.00430008, ...,  0.03485794,\n","        -0.04429918,  0.01579418],\n","       [-0.04315728,  0.03398854,  0.015163  , ..., -0.01444802,\n","        -0.03358512,  0.00365347],\n","       ...,\n","       [-0.03159091,  0.01830254, -0.03183593, ..., -0.0113064 ,\n","        -0.02308972, -0.04385507],\n","       [-0.04742112, -0.03067945, -0.03679103, ...,  0.0461803 ,\n","        -0.00365058,  0.01336197],\n","       [ 0.02158434,  0.02522087,  0.04690465, ...,  0.00434849,\n","        -0.00678937,  0.00868308]], dtype=float32)>, <tf.Variable 'branch4:0' shape=(12, 128, 256) dtype=float32, numpy=\n","array([[[ 0.01824263, -0.0222909 ,  0.00427048, ..., -0.00268571,\n","         -0.02081816,  0.0094406 ],\n","        [-0.01122868,  0.01596772, -0.03889522, ..., -0.02057607,\n","         -0.03294352, -0.01034914],\n","        [-0.00901121, -0.00829908, -0.00151639, ..., -0.02816658,\n","         -0.00135389, -0.03198109],\n","        ...,\n","        [ 0.02705837,  0.02232918,  0.02633806, ..., -0.02240211,\n","         -0.03001767, -0.01768824],\n","        [-0.01220298, -0.02708496,  0.02611938, ...,  0.00967381,\n","          0.01338903, -0.02197117],\n","        [ 0.03307619, -0.01872401, -0.03308048, ...,  0.00211117,\n","          0.00503429, -0.02640052]],\n","\n","       [[ 0.00079889, -0.00610109, -0.02544001, ..., -0.00460366,\n","         -0.00039667, -0.00549247],\n","        [ 0.02346935, -0.01582175, -0.01929615, ..., -0.02779011,\n","          0.01169899,  0.0152034 ],\n","        [-0.00862917,  0.01631043, -0.02464305, ...,  0.03741077,\n","          0.02323742,  0.01925473],\n","        ...,\n","        [-0.01381266, -0.03494549, -0.02333942, ..., -0.0267597 ,\n","          0.0302248 ,  0.02599424],\n","        [ 0.0223765 , -0.0293018 , -0.02678884, ...,  0.02976532,\n","          0.02776053, -0.03328723],\n","        [-0.00679354,  0.02209476, -0.00334913, ..., -0.0249862 ,\n","         -0.02997001, -0.01902629]],\n","\n","       [[ 0.02660733,  0.03277982, -0.03405818, ...,  0.01690887,\n","         -0.00983113,  0.00903367],\n","        [-0.02577451,  0.01082455, -0.02432298, ...,  0.03147394,\n","         -0.01089102, -0.01508743],\n","        [ 0.01866594, -0.02650203,  0.02260492, ...,  0.03044179,\n","         -0.01109071,  0.01046931],\n","        ...,\n","        [ 0.02752049,  0.0195909 ,  0.03383117, ..., -0.00605342,\n","          0.02075533,  0.02712419],\n","        [-0.0217509 , -0.00985512, -0.03377155, ...,  0.00075637,\n","         -0.01001892,  0.01596759],\n","        [-0.00554483,  0.01478249, -0.00438747, ...,  0.00466364,\n","         -0.02426064,  0.01113267]],\n","\n","       ...,\n","\n","       [[-0.01424357,  0.00347049,  0.01243616, ..., -0.02842536,\n","         -0.02441693,  0.03183663],\n","        [-0.03452813, -0.01625304, -0.01108299, ..., -0.02873199,\n","          0.00349208,  0.02920889],\n","        [-0.03412174,  0.00928347, -0.0038507 , ...,  0.00210332,\n","          0.02639857,  0.00734685],\n","        ...,\n","        [ 0.00548953,  0.01132893, -0.01647513, ...,  0.02170431,\n","         -0.0020344 , -0.00671037],\n","        [-0.02785835,  0.02867817,  0.00864267, ..., -0.0077763 ,\n","          0.02689257,  0.02965877],\n","        [ 0.00626947,  0.02500101, -0.02514628, ...,  0.01839215,\n","          0.03442889, -0.03096977]],\n","\n","       [[ 0.00034442,  0.01888928, -0.02968132, ..., -0.01262942,\n","          0.01043506,  0.00403053],\n","        [-0.00649132, -0.00926191, -0.03559067, ...,  0.03051866,\n","          0.02092627, -0.03027984],\n","        [ 0.0152873 , -0.01306761, -0.0339436 , ..., -0.01750824,\n","          0.00196367,  0.01643266],\n","        ...,\n","        [ 0.00180121,  0.02708211, -0.00787375, ...,  0.00793227,\n","         -0.03296556, -0.01301138],\n","        [-0.01582565, -0.01937042, -0.02537005, ...,  0.02935123,\n","         -0.01842321, -0.02234802],\n","        [-0.00219141, -0.01648943, -0.03279552, ...,  0.01198543,\n","          0.0067161 , -0.00208512]],\n","\n","       [[-0.01065581,  0.0237733 ,  0.02054803, ..., -0.01702958,\n","          0.02944199,  0.01511668],\n","        [-0.0364173 ,  0.01885953,  0.00700712, ...,  0.01835268,\n","          0.00262613, -0.02210349],\n","        [ 0.00251242,  0.00350066, -0.01155064, ..., -0.00636792,\n","         -0.00482406,  0.00207021],\n","        ...,\n","        [-0.03269545,  0.01991174, -0.00935201, ...,  0.02593695,\n","          0.00915125, -0.01454066],\n","        [ 0.01548291,  0.01106196,  0.00745421, ..., -0.02699883,\n","         -0.02194921,  0.01034534],\n","        [ 0.01910491,  0.01193905,  0.0064536 , ...,  0.01846213,\n","          0.02288925, -0.00109087]]], dtype=float32)>, <tf.Variable 'bias4:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[-0.0270979 , -0.01599626,  0.04732615,  0.00639814,\n","          0.00958644, -0.01974326,  0.02443636,  0.04969031,\n","         -0.05378813,  0.02339237,  0.03728084,  0.00485235,\n","         -0.03096958, -0.05997437, -0.04680449,  0.0664471 ,\n","          0.02010495,  0.07318067, -0.00316965, -0.06207525,\n","          0.01695449, -0.05603992, -0.07486816,  0.08496665,\n","         -0.0769624 ,  0.02279414,  0.03816854, -0.07086289,\n","          0.07990939,  0.00086289, -0.07193603,  0.00805427,\n","          0.03241713,  0.07354365,  0.05375078, -0.03499827,\n","          0.06085808,  0.0138976 , -0.07194397,  0.01372741,\n","          0.08278897, -0.08591438,  0.02736236,  0.06200767,\n","          0.085567  ,  0.02661532,  0.00418327, -0.02187026,\n","          0.01696343,  0.08397309, -0.07103949,  0.06219373,\n","          0.06650069,  0.07088063, -0.06445727,  0.07281564,\n","         -0.07420143,  0.03902533,  0.04705041,  0.04963367,\n","          0.03521361, -0.08444583, -0.07476201, -0.04518845,\n","          0.05419165, -0.04333945,  0.08585751,  0.05920973,\n","         -0.00842174, -0.07285284, -0.00151695,  0.00528277,\n","          0.07960822, -0.02687415,  0.02894964, -0.05023142,\n","         -0.03439316,  0.00619487,  0.05554153, -0.07484999,\n","          0.01180861, -0.07930809,  0.02599685, -0.06725644,\n","         -0.08517791,  0.00979336, -0.04071011, -0.05977914,\n","          0.04206687, -0.05041665, -0.08528415,  0.08025663,\n","         -0.00691526,  0.04941748,  0.04335394,  0.00473726,\n","          0.0557132 , -0.08362637,  0.04554147, -0.02701928,\n","         -0.08449972,  0.02104869, -0.05804143, -0.04450812,\n","         -0.00700725,  0.02222714, -0.0614218 , -0.08610939,\n","          0.01952902, -0.07621996, -0.02161817, -0.03481266,\n","          0.08256007, -0.01700378,  0.08476548, -0.08066238,\n","         -0.0219942 , -0.08009386, -0.01187155, -0.02311174,\n","         -0.05024189,  0.08398034, -0.07060216,  0.05845137,\n","         -0.06347834, -0.029724  , -0.0020417 ,  0.05079062],\n","        [-0.04521974,  0.03341009, -0.06107615, -0.08085322,\n","         -0.01755074,  0.08101335, -0.05942802, -0.00910864,\n","         -0.06927702,  0.04413879, -0.07302382, -0.07085212,\n","         -0.08969203, -0.00552272,  0.05211397,  0.05543754,\n","          0.02265122, -0.04993491,  0.01894365, -0.0656937 ,\n","         -0.04331268,  0.01663507, -0.05889081,  0.01306653,\n","          0.00070277,  0.02042819,  0.07275361, -0.01811345,\n","         -0.02923729,  0.04625154, -0.01896352,  0.05547865,\n","         -0.03828657,  0.06593808,  0.05695779,  0.0322471 ,\n","         -0.05856116, -0.05183332,  0.01223667,  0.02481467,\n","         -0.06035418,  0.08457253,  0.03407502,  0.03614951,\n","          0.0622334 , -0.08719178,  0.0575578 , -0.01149901,\n","          0.0223777 , -0.07561924, -0.02166919, -0.08489201,\n","         -0.08569002, -0.06124835,  0.09004179,  0.04354482,\n","          0.04385874, -0.08676427, -0.07999835,  0.07464574,\n","         -0.0789565 , -0.05403132,  0.01054009, -0.06409497,\n","         -0.01239004,  0.07360557, -0.05940704,  0.01173651,\n","         -0.06388247,  0.01359307, -0.08946733, -0.04762823,\n","         -0.03011946, -0.05013901, -0.00695831, -0.02407557,\n","         -0.00611402, -0.01221018,  0.04466553, -0.0256548 ,\n","          0.06029315, -0.05638589, -0.08175973,  0.06134128,\n","          0.03248077, -0.05279303,  0.01994468, -0.08076715,\n","         -0.02794517,  0.06556767, -0.02572648, -0.02987683,\n","          0.06937052, -0.05600566,  0.0813171 ,  0.01751862,\n","         -0.07275187,  0.0229641 , -0.06889135,  0.07037458,\n","          0.07783081,  0.07436661, -0.03393968, -0.02707183,\n","         -0.08423737, -0.06909566, -0.0455502 , -0.03157321,\n","          0.05533975,  0.00628747,  0.00636801, -0.06837228,\n","          0.0038962 , -0.04797835, -0.07019567,  0.03868524,\n","          0.02477102, -0.01906584,  0.03982009,  0.00127002,\n","          0.04138489, -0.04018765, -0.00112396, -0.05952274,\n","          0.00154395, -0.06278067, -0.01749951, -0.03080488]]],\n","      dtype=float32)>, <tf.Variable 'dense_202/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[-0.0654043 ,  0.08244704, -0.00501271, ..., -0.12108425,\n","         0.06044925,  0.14064178],\n","       [-0.13681926, -0.03772493,  0.13484852, ...,  0.14748082,\n","        -0.07673574, -0.08085541],\n","       [-0.15668614, -0.04857316, -0.05100197, ..., -0.14719677,\n","        -0.08091404, -0.09087861],\n","       ...,\n","       [-0.0998982 ,  0.06176172, -0.12688535, ...,  0.10108604,\n","         0.06027563,  0.01534882],\n","       [-0.05378678, -0.15751603,  0.03525223, ..., -0.03011445,\n","         0.12300781, -0.10151854],\n","       [ 0.02239023, -0.07998969, -0.02381962, ...,  0.0723404 ,\n","         0.03289157,  0.07724683]], dtype=float32)>, <tf.Variable 'dense_203/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.05424329, -0.04276657,  0.02617862, ..., -0.09139615,\n","        -0.12035285, -0.0753627 ],\n","       [ 0.07908796, -0.02471675,  0.12372331, ..., -0.12422533,\n","         0.02809896, -0.09828162],\n","       [ 0.01067093, -0.08216842,  0.0554894 , ..., -0.00827903,\n","        -0.01058666,  0.05533658],\n","       ...,\n","       [-0.08893849, -0.0046653 ,  0.01378003, ...,  0.02392055,\n","        -0.06576826, -0.06858338],\n","       [-0.09920163, -0.11653832,  0.0133886 , ...,  0.0636995 ,\n","         0.05294287, -0.12406784],\n","       [ 0.08168178, -0.04564535,  0.04571887, ...,  0.06851649,\n","        -0.10494572, -0.10680813]], dtype=float32)>, <tf.Variable 'dense_204/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.1182487 , -0.03817725,  0.05563525, ..., -0.03565416,\n","         0.09282862,  0.06959452],\n","       [ 0.07606585,  0.10598434, -0.06750003, ..., -0.09845943,\n","         0.07761712, -0.00855015],\n","       [-0.09150907,  0.03490993,  0.03356638, ...,  0.05745693,\n","        -0.05670256, -0.04416921],\n","       ...,\n","       [ 0.07579838, -0.00241659,  0.04204298, ..., -0.08901873,\n","         0.01518859, -0.01216934],\n","       [-0.05443529, -0.04408531, -0.03087957, ..., -0.0053887 ,\n","        -0.08133709, -0.05180596],\n","       [ 0.06020609, -0.056077  , -0.00775235, ..., -0.05921398,\n","        -0.07677862, -0.08105633]], dtype=float32)>, <tf.Variable 'dense_205/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.06243299,  0.11597776, -0.04664877, ..., -0.00780161,\n","        -0.08888288, -0.06171077],\n","       [ 0.02589067,  0.02044241,  0.07759409, ...,  0.0521809 ,\n","        -0.1010812 , -0.09598932],\n","       [ 0.12328671,  0.05407961, -0.09985728, ...,  0.03808495,\n","         0.0058987 , -0.05653593],\n","       ...,\n","       [ 0.09975436, -0.00629623, -0.05128225, ..., -0.01434506,\n","         0.10246649,  0.08104596],\n","       [-0.01826887, -0.07042183,  0.08889592, ..., -0.08635204,\n","         0.07695038, -0.00501336],\n","       [ 0.08857071, -0.00285794,  0.04391384, ...,  0.03162976,\n","         0.07805558,  0.02559124]], dtype=float32)>, <tf.Variable 'dense_206/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[ 0.05598123,  0.10349587, -0.11145543, ...,  0.10080076,\n","         0.15073773,  0.02365956],\n","       [-0.09114631,  0.08901653,  0.12418562, ...,  0.1272698 ,\n","         0.10716204,  0.02072985],\n","       [ 0.02464402,  0.07803281,  0.09134906, ...,  0.10937544,\n","         0.13431846,  0.0977763 ],\n","       ...,\n","       [ 0.13773885,  0.0071658 ,  0.10916907, ..., -0.10006617,\n","         0.02102643, -0.12792778],\n","       [-0.1093807 ,  0.01480789,  0.04545247, ..., -0.01303498,\n","        -0.07899863,  0.12881641],\n","       [ 0.02324763,  0.0472811 , -0.00350512, ..., -0.04629781,\n","        -0.01456363,  0.05916308]], dtype=float32)>, <tf.Variable 'dense_207/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[ 0.00912354, -0.05149776,  0.02689675, ..., -0.03169019,\n","        -0.02994885,  0.04648351],\n","       [-0.02572059, -0.01014476, -0.02636392, ...,  0.05855785,\n","         0.05306827,  0.05428422],\n","       [-0.01733474, -0.05920822, -0.04250101, ..., -0.02437998,\n","        -0.04355887, -0.01646032],\n","       ...,\n","       [ 0.0449321 ,  0.01136704,  0.05418603, ...,  0.04731244,\n","        -0.06206546,  0.0616362 ],\n","       [-0.02500005, -0.00251602, -0.00227506, ..., -0.04557694,\n","        -0.03368302, -0.02110435],\n","       [-0.0106889 ,  0.05867266, -0.05715838, ..., -0.04183307,\n","        -0.00689892, -0.06230009]], dtype=float32)>, <tf.Variable 'dense_208/kernel:0' shape=(1280, 128) dtype=float32, numpy=\n","array([[ 0.00019667,  0.05540073, -0.01299642, ..., -0.04064733,\n","         0.00197803, -0.02046585],\n","       [ 0.03542525, -0.02213539,  0.04086318, ...,  0.00421642,\n","        -0.00720711,  0.015149  ],\n","       [-0.01677837,  0.00819501, -0.04725257, ..., -0.06075473,\n","         0.03002926,  0.04345205],\n","       ...,\n","       [ 0.04714258, -0.06106337, -0.05958724, ...,  0.03941589,\n","        -0.04260186,  0.04453485],\n","       [ 0.02819585, -0.03112084,  0.05833374, ...,  0.03320158,\n","         0.04735794,  0.02393432],\n","       [-0.01611166, -0.01222437,  0.04866181, ...,  0.06182102,\n","        -0.02996935,  0.05027489]], dtype=float32)>, <tf.Variable 'branch5:0' shape=(24, 128, 256) dtype=float32, numpy=\n","array([[[-2.56038997e-02,  1.46684283e-02,  2.83768238e-03, ...,\n","          2.11544707e-02, -1.71876438e-02, -3.86649556e-03],\n","        [-5.53465728e-03,  1.86264534e-02, -1.12158852e-02, ...,\n","         -2.21149679e-02, -9.10957286e-04,  3.75886564e-03],\n","        [ 3.13974521e-03, -2.03042571e-02,  1.15325628e-02, ...,\n","          1.49571598e-02, -2.35362127e-02, -1.50754601e-02],\n","        ...,\n","        [ 2.59801298e-02,  6.37309160e-03, -7.34331226e-03, ...,\n","          1.12585844e-02, -1.81493051e-02,  1.47831431e-02],\n","        [ 1.50152808e-02,  2.47326288e-02, -5.39486436e-03, ...,\n","         -7.28519307e-03, -1.09248869e-02, -7.72570726e-03],\n","        [-1.65101402e-02,  2.54769716e-03,  9.19005740e-03, ...,\n","          4.19286173e-03, -2.14723237e-02, -2.26289295e-02]],\n","\n","       [[-7.74430763e-03, -2.77510658e-02, -1.49157839e-02, ...,\n","         -2.20955368e-02,  5.44676138e-03, -2.03535501e-02],\n","        [ 2.79266271e-03, -9.86365695e-03,  1.93775631e-02, ...,\n","         -1.57524273e-02, -5.80292544e-04, -3.43487109e-03],\n","        [ 1.58247687e-02,  2.54448485e-02, -4.47126059e-03, ...,\n","          6.95740432e-03, -6.38863014e-04,  1.38899460e-02],\n","        ...,\n","        [-1.41079603e-02, -1.54311201e-02,  3.52346664e-03, ...,\n","          2.82065454e-03,  2.33764537e-02,  2.49867104e-02],\n","        [ 6.49649603e-03,  3.98155954e-03, -2.43701823e-02, ...,\n","          1.92462578e-02, -1.39329284e-02,  6.43345155e-03],\n","        [ 1.48091977e-02, -1.52139766e-02,  1.27190221e-02, ...,\n","         -1.57813746e-02,  1.98921412e-02,  8.52829777e-04]],\n","\n","       [[-4.14698292e-03, -1.64798216e-03,  1.80019159e-02, ...,\n","          1.34947579e-02,  1.13636870e-02,  2.13191286e-02],\n","        [ 1.47109954e-02, -2.23153420e-02, -2.13281345e-02, ...,\n","         -1.12135001e-02,  2.78073567e-04,  1.38621693e-02],\n","        [-7.78299198e-03, -5.50153106e-03,  3.88059509e-03, ...,\n","         -9.68804117e-03, -7.72424554e-03,  3.42016923e-04],\n","        ...,\n","        [ 5.59837371e-03,  5.39248390e-03, -8.03470798e-03, ...,\n","          1.98355131e-02, -2.57503428e-02,  7.89382402e-03],\n","        [ 2.38468107e-02,  9.87770408e-03, -1.18413772e-02, ...,\n","          5.58130769e-03,  1.22713251e-02, -1.29424874e-02],\n","        [-2.17878930e-02, -7.91956764e-03,  2.52011535e-03, ...,\n","          2.94021633e-03,  2.00312845e-02, -2.13756468e-02]],\n","\n","       ...,\n","\n","       [[-8.39499477e-03,  2.11546533e-02,  2.64675776e-03, ...,\n","         -1.41564687e-03,  1.74790546e-02, -2.06794441e-02],\n","        [-7.71639775e-03, -1.86530650e-02,  1.12688988e-02, ...,\n","          1.07293017e-02, -1.33224623e-02,  8.51860922e-03],\n","        [-8.34037643e-03,  5.09247882e-03,  9.55638103e-03, ...,\n","         -7.39418203e-03, -2.34420933e-02, -1.45035991e-02],\n","        ...,\n","        [ 8.11698567e-03,  2.46915370e-02,  9.60068032e-03, ...,\n","          7.40223657e-03,  4.45223227e-03,  8.99237674e-03],\n","        [ 2.65910905e-02, -3.87200015e-03,  1.61513835e-02, ...,\n","         -1.86180752e-02, -3.75495874e-03, -8.95014033e-03],\n","        [ 1.62691399e-02,  4.80588572e-03, -1.12968516e-02, ...,\n","         -4.96523222e-03, -2.10214742e-02,  1.57308369e-03]],\n","\n","       [[ 3.94250499e-03, -1.80799663e-02,  2.06943974e-03, ...,\n","         -8.72876262e-04, -1.47500765e-02,  2.78442027e-03],\n","        [ 5.57266455e-03, -9.68816783e-03, -1.97397601e-02, ...,\n","         -2.26044785e-02,  1.84017792e-02,  1.74421072e-02],\n","        [-1.13744671e-02, -1.57091748e-02,  2.55484097e-02, ...,\n","          7.26338336e-03,  2.12794170e-02,  9.90563538e-03],\n","        ...,\n","        [ 1.36500895e-02, -2.48558857e-02, -1.93208754e-02, ...,\n","          2.26944424e-02, -1.49029177e-02,  2.96123046e-03],\n","        [ 2.60689575e-03,  2.49546487e-02, -2.27525495e-02, ...,\n","         -1.88273806e-02, -1.68312304e-02,  2.09082831e-02],\n","        [ 2.40425728e-02,  2.12721787e-02,  1.32309329e-02, ...,\n","         -1.20075736e-02, -1.79438647e-02,  1.63587183e-02]],\n","\n","       [[ 1.62764005e-02, -4.47492255e-03,  1.04826232e-02, ...,\n","         -9.20866092e-04,  5.32742124e-04, -2.42187083e-02],\n","        [ 2.22410429e-02, -1.35636423e-02, -2.57552825e-02, ...,\n","         -2.85438541e-02, -1.60278268e-02, -1.48077421e-02],\n","        [ 2.04072315e-02, -5.10316482e-03, -9.07221809e-03, ...,\n","         -5.39269019e-03, -2.51611695e-02,  3.11464909e-03],\n","        ...,\n","        [-1.30438814e-02,  2.27417108e-02, -2.36352161e-02, ...,\n","          1.27908355e-02,  3.85228684e-03, -1.15681225e-02],\n","        [-8.32512975e-04, -4.10282169e-04,  1.91285554e-02, ...,\n","          2.72768957e-05,  1.53427301e-02,  2.06295419e-02],\n","        [-1.57893710e-02,  9.06231813e-03, -1.91508308e-02, ...,\n","         -1.35914758e-02, -1.43117560e-02, -1.81630515e-02]]],\n","      dtype=float32)>, <tf.Variable 'bias5:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[-6.4806566e-02,  1.3849145e-02,  4.0880572e-02, -5.6626614e-02,\n","          3.7922166e-02,  1.5005561e-02,  7.4923262e-02,  6.8915479e-02,\n","          2.6076416e-02, -7.0651822e-02,  8.7521728e-03, -3.5229433e-02,\n","          3.3717994e-02,  9.5053622e-03, -7.2056435e-02, -3.1808510e-02,\n","         -1.0011962e-02,  3.2878239e-02,  6.0271587e-02, -5.6240153e-03,\n","          8.4141798e-02, -8.8059381e-02,  4.7250319e-02,  4.4314075e-02,\n","         -3.0194666e-02, -4.9844928e-02,  8.6352855e-02, -4.4346418e-02,\n","         -6.0352955e-02,  7.8154474e-02,  8.1770448e-03,  4.6213679e-02,\n","          3.6714286e-02,  7.3143862e-02,  4.6360154e-02, -1.9416623e-03,\n","         -6.8209969e-02,  4.1037682e-03,  3.6397878e-02,  4.2616211e-02,\n","         -7.5971410e-02,  7.3432706e-02, -7.4523091e-02,  7.5398445e-02,\n","          3.4888104e-02, -8.1247002e-02,  9.7035069e-04, -8.2891835e-03,\n","          1.7249051e-02, -4.0483251e-02,  4.9351424e-02, -5.0908655e-02,\n","          5.0926719e-02,  7.0430182e-02, -2.1228984e-02, -8.0175839e-02,\n","          3.0711299e-02,  1.5940499e-02,  2.9659508e-02, -7.4150637e-02,\n","          1.2985942e-02, -8.9250412e-03, -7.7225298e-02,  4.9623657e-02,\n","         -5.3328112e-02,  8.2724482e-02,  1.5363047e-02,  6.7986101e-02,\n","          1.2615169e-02,  7.6666132e-02,  4.2360485e-02, -6.9686823e-02,\n","          3.0924520e-02, -6.7471825e-02, -1.8845921e-02,  1.9975302e-03,\n","          4.9349263e-02,  3.1044916e-03,  7.6282203e-02, -6.8313375e-02,\n","          5.3408455e-02,  3.4589406e-02,  4.1629542e-02,  7.1615651e-02,\n","         -4.3268625e-02, -7.8415394e-02, -7.6400973e-02,  6.5700382e-02,\n","          1.0232556e-02,  9.1530913e-03, -6.2002476e-02, -1.4789181e-02,\n","         -6.3459359e-02, -5.4323625e-02, -5.3362623e-02, -1.6272936e-02,\n","          3.9239950e-02,  3.9081089e-02,  7.4059114e-02,  5.9144747e-02,\n","          2.2955911e-02, -4.5524002e-03,  4.4237800e-02,  4.5050975e-02,\n","          5.2246761e-02,  1.2917066e-02, -4.8939601e-02, -5.4905199e-02,\n","          6.8951845e-02,  3.4538899e-02, -1.4160498e-02,  8.1960268e-02,\n","         -4.5432467e-02, -8.1338897e-02, -4.4325437e-02,  8.8250982e-03,\n","         -2.6394857e-02,  1.9035641e-02, -3.5246763e-02,  4.7367752e-02,\n","         -4.7376040e-02,  9.7087789e-03, -2.7260439e-02,  2.2856550e-02,\n","         -2.0582756e-02,  2.0314764e-02, -5.5311970e-02, -6.3133657e-02],\n","        [-2.6344856e-02, -8.4659293e-02, -2.2449621e-03,  3.4501635e-02,\n","         -7.7725433e-02,  3.3146299e-02, -8.2963690e-02, -5.3552736e-02,\n","          1.9996326e-02, -1.9578746e-02, -2.0124409e-02, -6.3028082e-02,\n","          7.5515576e-02, -5.3182069e-02, -7.4797079e-02, -6.9746852e-02,\n","          3.2656256e-02, -7.1487896e-02, -2.1624718e-02, -4.7014665e-02,\n","          6.3887029e-03, -7.6706847e-03, -8.7787345e-02, -3.6852151e-02,\n","         -5.2780800e-02,  5.6903882e-05,  5.9461284e-02, -6.9958419e-03,\n","          8.0499627e-02, -4.7257554e-02,  1.8895732e-02,  2.6285414e-02,\n","         -9.6907308e-03,  5.2584447e-02,  5.6101680e-02,  5.9868228e-02,\n","          8.4832236e-02,  7.5960003e-02, -6.4907946e-02, -2.8540066e-02,\n","         -7.2979778e-02,  1.7844839e-02, -8.2995236e-02,  3.9150842e-02,\n","         -8.0140725e-02,  2.2003507e-02, -6.5842122e-02,  7.5347289e-02,\n","          6.6531293e-02, -7.9583280e-02, -4.5117911e-02, -5.9540972e-02,\n","         -3.3348515e-03,  9.0950336e-03, -6.4614803e-02, -8.6432733e-02,\n","         -5.2835714e-02, -3.7844744e-02, -5.3147715e-02, -6.6344133e-03,\n","          5.6616917e-02,  1.7361963e-02,  7.7545017e-02, -1.9824907e-02,\n","          5.6321949e-02,  8.3728410e-02, -1.7759476e-02, -3.4170464e-02,\n","          8.5257024e-02, -1.4630646e-03,  9.1681164e-03,  3.7766654e-02,\n","          1.4909088e-02,  8.6335994e-02,  8.2592890e-02, -6.8837687e-02,\n","          4.9229600e-02,  6.8678275e-02, -8.1908882e-02, -5.2599769e-02,\n","          4.4051178e-02,  7.7073351e-02, -6.9677509e-02,  6.3788109e-02,\n","         -4.4557650e-04, -7.8738101e-02,  8.1511907e-02,  2.8863106e-02,\n","         -1.9589693e-03, -6.5784231e-02,  2.8546780e-02,  1.8589042e-02,\n","         -4.4583764e-02,  1.6398372e-03, -5.1683106e-02,  5.4913715e-02,\n","         -8.0432510e-03,  1.7768787e-02,  7.5511599e-04,  5.5907916e-02,\n","         -8.3703458e-02,  8.5884199e-02,  5.1678598e-02,  2.8723665e-02,\n","         -3.6380671e-02,  7.7778995e-02,  4.9522486e-02, -2.5661273e-02,\n","          8.4856212e-02,  3.6453836e-02,  7.4157253e-02,  8.5070215e-02,\n","         -4.4348534e-02,  6.0762875e-02, -8.2063816e-02, -2.0642383e-02,\n","         -6.0427122e-02, -5.1188424e-02,  6.5371167e-04,  1.1347741e-02,\n","         -2.0415680e-03, -6.9200203e-02,  1.1017087e-02,  1.2856352e-02,\n","         -5.0509155e-02, -6.9021247e-02,  1.5254083e-02, -4.7980186e-02]]],\n","      dtype=float32)>, <tf.Variable 'dense_209/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[-0.01488104, -0.05433737,  0.05606295, ...,  0.00586284,\n","         0.07165159,  0.0092068 ],\n","       [ 0.07463093,  0.02792682, -0.08131743, ..., -0.03156505,\n","         0.10245765,  0.08760926],\n","       [ 0.15154552, -0.14853819,  0.14640155, ..., -0.0399689 ,\n","        -0.08539332, -0.06376816],\n","       ...,\n","       [-0.12290996, -0.03568138, -0.059149  , ...,  0.02546031,\n","         0.06370076, -0.06386392],\n","       [ 0.08311605,  0.01628317,  0.13084124, ...,  0.06700725,\n","        -0.06688707,  0.06552897],\n","       [-0.10719705,  0.01844795, -0.05979244, ...,  0.00134805,\n","        -0.10963228, -0.1592981 ]], dtype=float32)>, <tf.Variable 'dense_210/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.03589461,  0.10618624,  0.09053919, ..., -0.0479805 ,\n","         0.0002878 ,  0.0507312 ],\n","       [ 0.02240365,  0.04389418,  0.09571948, ...,  0.00054769,\n","         0.09093645, -0.0217731 ],\n","       [-0.00322651,  0.05851941, -0.0643144 , ...,  0.08321631,\n","         0.01242684, -0.00138417],\n","       ...,\n","       [-0.06497288,  0.0835442 , -0.11048398, ..., -0.04170118,\n","         0.12139631, -0.1193071 ],\n","       [ 0.0935878 , -0.00995523,  0.06269871, ...,  0.04473817,\n","        -0.02361076,  0.04445099],\n","       [ 0.00836863, -0.02303254,  0.11795644, ...,  0.02087543,\n","        -0.02873337, -0.05689361]], dtype=float32)>, <tf.Variable 'dense_211/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.0921576 ,  0.06969289,  0.09280533, ...,  0.10113312,\n","         0.06829885,  0.08557639],\n","       [ 0.12207783, -0.11500805, -0.12299586, ..., -0.07892361,\n","         0.09232457,  0.01126597],\n","       [-0.05202568, -0.09925599,  0.07542346, ...,  0.11621337,\n","        -0.10581256, -0.1047214 ],\n","       ...,\n","       [ 0.11320562,  0.09166039,  0.0356075 , ..., -0.08813409,\n","         0.05122422,  0.11828004],\n","       [ 0.0580807 , -0.11107735, -0.12126653, ..., -0.04284809,\n","         0.09628139, -0.0808261 ],\n","       [-0.0809004 , -0.05657742,  0.01262539, ...,  0.00784746,\n","        -0.05709376, -0.11369843]], dtype=float32)>, <tf.Variable 'dense_212/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.07061637,  0.08200292,  0.05514727, ...,  0.00669137,\n","         0.09786063, -0.12396798],\n","       [ 0.04697229, -0.04459246,  0.01683718, ..., -0.09163297,\n","         0.08159227,  0.09240816],\n","       [ 0.07836886, -0.06395185,  0.07706343, ...,  0.09106047,\n","         0.07450175,  0.05963058],\n","       ...,\n","       [-0.11658999, -0.02422955,  0.04165939, ..., -0.01322024,\n","         0.11845496,  0.11353339],\n","       [ 0.07325686,  0.05592141, -0.03152732, ...,  0.11773629,\n","        -0.0687106 ,  0.04115212],\n","       [-0.12007054, -0.12316589,  0.03552542, ..., -0.03792731,\n","        -0.00978591,  0.07860542]], dtype=float32)>, <tf.Variable 'dense_213/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[-0.04605296, -0.10389222,  0.09350076, ...,  0.03246409,\n","         0.10744669, -0.03340583],\n","       [ 0.08598541,  0.11975572, -0.02353922, ...,  0.01642091,\n","         0.14846826,  0.08625414],\n","       [-0.06589559, -0.07376476, -0.14116481, ...,  0.1362391 ,\n","         0.04485584,  0.09415571],\n","       ...,\n","       [-0.09282649,  0.02312982,  0.03079493, ...,  0.1447821 ,\n","         0.06617223,  0.08127622],\n","       [-0.15291305, -0.03821689, -0.00954104, ..., -0.1486368 ,\n","         0.06587964,  0.03816848],\n","       [ 0.14159574,  0.11826354, -0.03460804, ..., -0.05512104,\n","        -0.0802775 , -0.01531548]], dtype=float32)>, <tf.Variable 'dense_214/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[-0.12469283, -0.12586688,  0.01128692, ..., -0.04943092,\n","        -0.11865944, -0.14447927],\n","       [ 0.055634  , -0.1161612 ,  0.00169386, ...,  0.1540574 ,\n","         0.0492897 , -0.03129867],\n","       [ 0.07619523,  0.062043  , -0.02176576, ..., -0.11765406,\n","         0.08202668, -0.134035  ],\n","       ...,\n","       [-0.12258791,  0.06326383, -0.08795346, ..., -0.03861462,\n","        -0.13267855,  0.15227222],\n","       [ 0.05753136,  0.02738955, -0.11407597, ...,  0.02958991,\n","        -0.11181742,  0.09782175],\n","       [ 0.045343  , -0.10205775,  0.05724078, ..., -0.13765854,\n","         0.068443  , -0.12004016]], dtype=float32)>, <tf.Variable 'dense_215/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[-0.02204311,  0.028145  ,  0.05434563, ...,  0.00695182,\n","         0.06322993, -0.02852198],\n","       [-0.04042033, -0.03262234,  0.01666277, ..., -0.02703782,\n","         0.05855407,  0.01899622],\n","       [-0.02763034, -0.04466559,  0.00743137, ..., -0.00849782,\n","         0.00040481,  0.02823188],\n","       ...,\n","       [ 0.05835246, -0.04050482, -0.04892688, ...,  0.00905355,\n","         0.00883358,  0.03685813],\n","       [ 0.06299819,  0.02052324, -0.0255572 , ..., -0.05790211,\n","         0.01900756, -0.05955438],\n","       [ 0.04519872,  0.03892663, -0.02223307, ..., -0.01439933,\n","         0.01262093,  0.01666342]], dtype=float32)>, <tf.Variable 'dense_216/kernel:0' shape=(1280, 128) dtype=float32, numpy=\n","array([[ 0.03013404,  0.02811481, -0.00532168, ..., -0.04293754,\n","        -0.02640802,  0.06498007],\n","       [-0.06343086,  0.01699611, -0.06673737, ...,  0.02212141,\n","         0.03910946, -0.063422  ],\n","       [ 0.04738826, -0.05038051,  0.03754618, ..., -0.05912961,\n","         0.03138806, -0.03325964],\n","       ...,\n","       [ 0.00283346, -0.00142469, -0.03414457, ..., -0.00186184,\n","        -0.06150363, -0.02401483],\n","       [ 0.04361221,  0.02417737, -0.0351714 , ..., -0.02514357,\n","         0.05151676,  0.04175628],\n","       [-0.0516586 , -0.01847638, -0.02980726, ..., -0.05024159,\n","        -0.00727667, -0.01885377]], dtype=float32)>, <tf.Variable 'branch6:0' shape=(48, 128, 8192) dtype=float32, numpy=\n","array([[[ 4.9258787e-03,  4.5637866e-03,  5.3418782e-03, ...,\n","         -8.0910808e-04, -4.5430232e-03,  8.1907187e-05],\n","        [-5.9172457e-05,  1.8134736e-03,  1.2033889e-03, ...,\n","         -2.7273824e-03,  3.8459466e-03, -2.1156929e-03],\n","        [-3.8242731e-03, -2.0186738e-03, -7.1952930e-03, ...,\n","         -3.7798278e-03, -2.7174130e-04, -2.5361223e-04],\n","        ...,\n","        [-2.8945857e-03,  2.5747967e-04, -2.7703780e-03, ...,\n","          2.8310600e-03,  1.3945453e-03,  8.0017338e-04],\n","        [ 2.6259282e-05, -1.7890367e-03, -4.1570263e-03, ...,\n","          2.2937693e-03, -4.5950580e-03, -4.4860807e-03],\n","        [-5.5937795e-03, -5.0731958e-03, -7.9303206e-04, ...,\n","         -1.0561175e-03, -2.8651643e-03,  1.7822519e-03]],\n","\n","       [[-8.6159641e-03, -7.0260554e-03, -7.4307169e-03, ...,\n","          1.6849586e-03,  5.7184203e-03, -9.6821348e-04],\n","        [-5.2194814e-03, -1.6189197e-03,  9.0408413e-04, ...,\n","         -1.3316494e-03,  1.3435059e-03,  1.2297042e-03],\n","        [ 1.8803518e-03, -4.9953139e-04,  5.0786715e-03, ...,\n","         -2.3454183e-03, -1.6229269e-03, -1.8829271e-03],\n","        ...,\n","        [-9.8278665e-04, -5.7487674e-03,  3.4711882e-03, ...,\n","         -1.5050862e-03,  2.0791264e-03,  8.4421912e-04],\n","        [ 4.5894030e-03,  3.5308933e-04,  2.4670712e-03, ...,\n","          2.2836304e-03, -1.2820901e-03, -4.0418934e-03],\n","        [ 1.6656625e-03,  3.0601176e-03,  3.7860271e-04, ...,\n","          1.8960717e-03,  7.6491979e-04,  1.4146257e-03]],\n","\n","       [[-4.1906764e-03, -3.8740959e-03, -5.6866370e-04, ...,\n","          1.6910486e-03,  7.8230957e-04, -5.9544138e-04],\n","        [-1.6054173e-03,  5.8173359e-04,  2.7277702e-03, ...,\n","         -3.2915848e-03,  2.1432543e-03, -4.3876232e-03],\n","        [-5.2881339e-03, -2.6528048e-03, -4.6460056e-03, ...,\n","         -3.4644601e-03, -5.3529260e-03, -3.4852799e-03],\n","        ...,\n","        [ 8.5989968e-04,  3.0611632e-03,  1.8580590e-03, ...,\n","          3.2663782e-04,  2.9574693e-03, -2.6263408e-03],\n","        [-3.8110337e-04, -3.5251314e-03, -5.5887108e-03, ...,\n","         -9.9445786e-04,  8.1617839e-04, -6.6740462e-03],\n","        [-6.5719746e-03, -5.9852391e-03, -2.2761652e-04, ...,\n","         -2.0920588e-03, -3.1947715e-03, -8.0228848e-03]],\n","\n","       ...,\n","\n","       [[-1.0737831e-03, -5.0374954e-03, -2.9506178e-03, ...,\n","         -1.0442537e-04, -1.5629907e-03, -4.1008405e-03],\n","        [-1.5129661e-03,  1.1224122e-03,  3.2142075e-03, ...,\n","          2.3107659e-03,  1.4027421e-03, -1.4037230e-03],\n","        [-1.7028573e-03, -5.7682727e-04, -1.3171312e-04, ...,\n","         -2.2984692e-03, -1.9033072e-03, -3.8372418e-03],\n","        ...,\n","        [ 7.5488567e-04, -6.2110357e-04, -1.4782309e-03, ...,\n","          4.8393733e-03,  4.9147801e-04, -4.5842910e-04],\n","        [ 7.5442798e-04, -1.8640517e-04,  1.5840865e-03, ...,\n","         -4.2934963e-03, -3.0928464e-03, -3.4666432e-03],\n","        [-1.5247000e-03,  1.1645969e-03, -2.1858697e-03, ...,\n","          9.7258744e-04, -2.2751663e-03,  1.4263478e-03]],\n","\n","       [[ 5.0004869e-04, -8.8462839e-04,  4.0403190e-03, ...,\n","         -7.7027725e-03, -1.1549492e-03, -4.5639933e-03],\n","        [-3.2040518e-04, -2.8936907e-03,  2.1237882e-03, ...,\n","         -1.3495864e-03,  2.7309570e-03, -3.6227494e-03],\n","        [-3.8403918e-03,  1.4859797e-03, -5.1960251e-03, ...,\n","          9.2440838e-04, -1.8477611e-03, -2.5861077e-03],\n","        ...,\n","        [-1.2120047e-03,  3.4096523e-03,  1.2320698e-03, ...,\n","          1.5322805e-03,  2.0630653e-03, -2.8983434e-03],\n","        [-5.0082603e-03,  1.2236118e-03, -1.2324422e-03, ...,\n","         -1.1256479e-04,  3.3439320e-04,  4.8811473e-03],\n","        [-1.4615989e-03,  2.2980017e-03, -8.0402894e-04, ...,\n","         -2.9133523e-03,  4.5765401e-03,  3.5685627e-03]],\n","\n","       [[-5.2805189e-03, -5.7846983e-03, -1.3353992e-03, ...,\n","         -6.6441024e-04, -4.6217320e-03,  3.3326137e-03],\n","        [ 1.1372084e-03,  2.3875581e-03, -6.4349448e-04, ...,\n","          2.0512091e-03,  2.3496023e-03, -1.4441044e-03],\n","        [-8.9777022e-04,  1.3170009e-03,  6.6613097e-04, ...,\n","         -1.2444686e-03,  1.0082753e-03, -6.0688471e-04],\n","        ...,\n","        [ 1.6848929e-03,  2.6819201e-03, -2.8852851e-03, ...,\n","          4.5444951e-03, -2.0299039e-03, -2.6890582e-03],\n","        [-4.5728803e-04, -2.9098634e-03, -2.7229879e-03, ...,\n","          1.3752647e-03, -3.5442154e-05,  6.2724408e-05],\n","        [ 2.5316782e-03,  1.0582539e-03, -3.0734637e-03, ...,\n","          8.9567626e-04,  1.8018826e-03, -2.0752572e-03]]], dtype=float32)>, <tf.Variable 'bias6:0' shape=(1, 64, 3) dtype=float32, numpy=\n","array([[[ 0.4943477 , -0.45298475, -0.5028099 ],\n","        [-0.22590584, -0.23868468,  0.28469068],\n","        [ 0.4110915 ,  0.00126749, -0.51478195],\n","        [-0.30777434, -0.2687866 , -0.18807247],\n","        [ 0.49446332,  0.42605603, -0.489164  ],\n","        [-0.0076918 ,  0.29591626, -0.2656329 ],\n","        [ 0.25033063,  0.309974  ,  0.5265893 ],\n","        [-0.03315532, -0.349571  ,  0.34537536],\n","        [ 0.05704933,  0.17940253, -0.08140117],\n","        [ 0.31831908, -0.04162538,  0.13756967],\n","        [-0.40095267,  0.5160974 ,  0.01891381],\n","        [-0.3245595 , -0.36141062,  0.06747335],\n","        [-0.03155512, -0.26138774,  0.5098537 ],\n","        [-0.2799735 , -0.5551601 , -0.05629379],\n","        [-0.21171829, -0.5026338 , -0.08055064],\n","        [ 0.47513282, -0.49338466, -0.04979044],\n","        [ 0.5018711 ,  0.43338454, -0.51402706],\n","        [-0.31881094,  0.55729914,  0.5067595 ],\n","        [ 0.33554626, -0.3870806 ,  0.22393149],\n","        [ 0.31048536, -0.294975  ,  0.5169177 ],\n","        [ 0.36995792,  0.24402153, -0.16276532],\n","        [ 0.22186273, -0.46210745,  0.48655725],\n","        [ 0.01099187, -0.33244336,  0.16573572],\n","        [-0.55963594,  0.48728395,  0.23699999],\n","        [-0.4735245 , -0.17496106, -0.09280241],\n","        [-0.44575298,  0.07065284, -0.42692465],\n","        [-0.09563717,  0.41172838,  0.47789383],\n","        [ 0.53218544,  0.12687212, -0.2940749 ],\n","        [ 0.16443753, -0.50240326,  0.01281393],\n","        [-0.25534707,  0.40178585,  0.2516023 ],\n","        [ 0.05311501,  0.4644127 ,  0.5751269 ],\n","        [ 0.0561319 ,  0.46162045, -0.49493238],\n","        [-0.29302767, -0.20564899, -0.39008814],\n","        [ 0.2630698 , -0.3026211 , -0.53721535],\n","        [ 0.13955349,  0.36916834, -0.54315555],\n","        [ 0.25016588,  0.3319314 ,  0.19254541],\n","        [ 0.43026698, -0.03924209,  0.5357691 ],\n","        [-0.45871973, -0.11349988, -0.3183732 ],\n","        [ 0.21051836,  0.34875858, -0.07763147],\n","        [-0.19770047,  0.39336175, -0.2849968 ],\n","        [ 0.25014043, -0.3380149 , -0.2260117 ],\n","        [ 0.17787993, -0.2076182 ,  0.14925939],\n","        [ 0.4262401 , -0.48419672, -0.2392799 ],\n","        [ 0.02032059, -0.05258226, -0.32266983],\n","        [ 0.05039114, -0.51851684,  0.15803039],\n","        [-0.49040163,  0.13880497,  0.5395547 ],\n","        [ 0.01801962, -0.22276369,  0.29537678],\n","        [-0.19117704,  0.3656358 ,  0.25798416],\n","        [ 0.51564145,  0.4649682 ,  0.01069659],\n","        [-0.41678834,  0.00723356,  0.06601828],\n","        [ 0.12521452, -0.3794685 ,  0.1601007 ],\n","        [ 0.15827942, -0.53201556,  0.52298415],\n","        [-0.565149  , -0.14728412, -0.2710766 ],\n","        [ 0.10421616,  0.50319517,  0.27200395],\n","        [ 0.14872396, -0.09061843, -0.38452238],\n","        [-0.5306751 , -0.11742857, -0.5420754 ],\n","        [ 0.5463542 ,  0.09169692, -0.04327899],\n","        [-0.1646086 , -0.26328582, -0.31824037],\n","        [-0.33893192,  0.0792464 ,  0.21145111],\n","        [-0.09439942, -0.05267918, -0.24494353],\n","        [-0.1600686 , -0.38561285, -0.15504888],\n","        [-0.48131788, -0.37033412, -0.11468369],\n","        [ 0.45346475, -0.36243322, -0.46919233],\n","        [-0.207964  , -0.41062224,  0.4916638 ]]], dtype=float32)>, <tf.Variable 'dense_217/kernel:0' shape=(96, 3) dtype=float32, numpy=\n","array([[-0.13098393,  0.23404804,  0.11368818],\n","       [ 0.14430311, -0.12909876,  0.17710121],\n","       [-0.15206048,  0.08193802,  0.14498685],\n","       [ 0.24142413,  0.06605994, -0.18312599],\n","       [ 0.12232561, -0.12662491,  0.10536775],\n","       [-0.11626893, -0.06566515,  0.14957418],\n","       [-0.1496621 ,  0.20707305,  0.20332989],\n","       [-0.20479104,  0.19559331,  0.09119263],\n","       [-0.04626346,  0.20962374,  0.11458107],\n","       [-0.03512621,  0.10792553, -0.07210105],\n","       [ 0.17992823,  0.0541518 , -0.17907064],\n","       [ 0.135534  , -0.07517805,  0.03446275],\n","       [-0.11166645, -0.0368545 ,  0.01656757],\n","       [ 0.00338823,  0.0909284 ,  0.03860977],\n","       [ 0.01862007, -0.09889935,  0.07574435],\n","       [-0.233777  , -0.22799762, -0.102695  ],\n","       [-0.12032977,  0.0009399 ,  0.17505482],\n","       [-0.0420074 , -0.13711454, -0.09344454],\n","       [-0.15305847, -0.06614111, -0.08048967],\n","       [ 0.22830619,  0.14597857,  0.00741711],\n","       [-0.11606468,  0.0733974 , -0.11408293],\n","       [ 0.01391096, -0.07276165, -0.13651612],\n","       [-0.1380168 , -0.23156182, -0.02223199],\n","       [-0.16919038,  0.21157528, -0.18413252],\n","       [ 0.10413631, -0.10628875,  0.06885234],\n","       [ 0.12880091,  0.21504535, -0.01799065],\n","       [ 0.16186559, -0.07109689, -0.02908225],\n","       [ 0.09446819, -0.09087249, -0.01543287],\n","       [ 0.04349717,  0.03067109,  0.19251256],\n","       [ 0.10733491, -0.11161215,  0.17111428],\n","       [ 0.09727035, -0.05476533, -0.01897378],\n","       [ 0.06792472, -0.10985316, -0.10962892],\n","       [ 0.17378193, -0.19984071, -0.0066875 ],\n","       [-0.15738074,  0.14314252, -0.15309983],\n","       [-0.06962364,  0.24228768, -0.06528052],\n","       [ 0.18120266,  0.10034335,  0.12494808],\n","       [-0.03076465, -0.05781899,  0.23286396],\n","       [-0.18231207, -0.18222208,  0.23515499],\n","       [-0.00936589,  0.03148895,  0.06742438],\n","       [-0.10296868,  0.11493563,  0.19582003],\n","       [-0.23901781,  0.22853053,  0.23696665],\n","       [ 0.07826745, -0.10290492, -0.16714165],\n","       [ 0.20539442,  0.00760246, -0.16839524],\n","       [-0.00375412, -0.1863336 , -0.12483139],\n","       [ 0.13465124, -0.19670907,  0.21117793],\n","       [ 0.12557213,  0.10915501,  0.03591557],\n","       [ 0.08052881, -0.16261236,  0.05507041],\n","       [-0.22897641,  0.16341618,  0.19240648],\n","       [ 0.13682307, -0.02198514, -0.09764886],\n","       [-0.01794746,  0.2103362 ,  0.13823579],\n","       [ 0.1150362 , -0.17375688, -0.24057953],\n","       [-0.08120901,  0.08402849,  0.21492696],\n","       [-0.03890706, -0.19390082, -0.12636106],\n","       [ 0.17952214,  0.11437407, -0.00255298],\n","       [ 0.03840736, -0.11222234,  0.183099  ],\n","       [-0.12465588,  0.14987956,  0.20876712],\n","       [-0.12443014, -0.08981618, -0.05460338],\n","       [ 0.21181187,  0.19665796, -0.0203854 ],\n","       [ 0.04743288, -0.18882   , -0.0137822 ],\n","       [-0.2239048 ,  0.08520125,  0.01620476],\n","       [-0.05190701, -0.12253234,  0.02159481],\n","       [-0.1178609 , -0.08646245,  0.204364  ],\n","       [-0.06671388,  0.16594064,  0.11666008],\n","       [ 0.06113711,  0.17759654,  0.02624259],\n","       [-0.13403538, -0.10959762,  0.04806395],\n","       [ 0.0510314 ,  0.23210122,  0.1849786 ],\n","       [ 0.02683203, -0.16393076, -0.20716102],\n","       [-0.01288815, -0.17758292, -0.0685171 ],\n","       [ 0.07385577, -0.18158077, -0.1888127 ],\n","       [-0.11086459, -0.07681827, -0.18415502],\n","       [ 0.0560918 ,  0.03993486, -0.11787275],\n","       [-0.13286489,  0.14622894, -0.05891215],\n","       [ 0.08572211, -0.05224155, -0.09872247],\n","       [-0.21751374, -0.03279044, -0.02096226],\n","       [ 0.22267462, -0.0259218 ,  0.08321732],\n","       [ 0.03654681,  0.13164552,  0.11670817],\n","       [-0.01666377,  0.05325934,  0.00641392],\n","       [ 0.08431894, -0.10457743, -0.1823567 ],\n","       [-0.11056168,  0.18751372, -0.18406343],\n","       [-0.15740702,  0.08001935, -0.05942892],\n","       [ 0.14319271, -0.21312849,  0.03406035],\n","       [-0.12450039, -0.18449892,  0.03087745],\n","       [ 0.00736573, -0.04546385, -0.2400114 ],\n","       [-0.14036465,  0.01942537, -0.02066525],\n","       [ 0.13298382, -0.20137642, -0.22287978],\n","       [ 0.23142853,  0.02929998,  0.00175514],\n","       [-0.19036208, -0.16161023,  0.18040863],\n","       [-0.02678839,  0.07756668, -0.04732963],\n","       [ 0.23177797, -0.0651555 , -0.18082428],\n","       [ 0.15409306,  0.15214176,  0.20048876],\n","       [-0.18945052,  0.19118682,  0.18472458],\n","       [-0.13958567, -0.19283375,  0.00097915],\n","       [-0.09575836, -0.22798926,  0.16456121],\n","       [-0.04440936,  0.14355919, -0.07090589],\n","       [-0.07131454, -0.06637056,  0.09830285],\n","       [-0.07813077,  0.12813674, -0.1699559 ]], dtype=float32)>, <tf.Variable 'dense_218/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[ 1.29535804e-02,  6.78731874e-02, -1.05758265e-01],\n","       [-5.63113578e-02,  1.20971546e-01, -1.14963695e-01],\n","       [-1.27413452e-01, -3.64948413e-03, -3.36544216e-02],\n","       [ 1.07456729e-01,  6.43309727e-02,  1.18086375e-01],\n","       [-1.12492383e-01, -4.08745222e-02, -9.64511409e-02],\n","       [-1.08130902e-01, -2.93419976e-02, -3.67468596e-02],\n","       [ 1.49644062e-01, -1.10380866e-01, -1.42482296e-01],\n","       [-8.34252909e-02, -1.11370839e-01,  2.65413299e-02],\n","       [ 1.09200805e-01, -3.71926948e-02, -1.28618911e-01],\n","       [-7.04553127e-02, -5.90890460e-02, -5.21403179e-02],\n","       [-1.14888467e-01, -7.99723566e-02,  3.81560586e-02],\n","       [ 1.44331619e-01,  1.35847971e-01,  6.16335198e-02],\n","       [ 4.87742275e-02, -2.02731825e-02,  4.88480553e-02],\n","       [-7.67556056e-02,  1.27693549e-01, -1.33370504e-01],\n","       [ 5.69970869e-02, -1.16996676e-01, -3.22048478e-02],\n","       [ 4.97780293e-02, -1.50198475e-01,  1.28320634e-01],\n","       [-2.13044751e-02, -2.53214445e-02,  1.18363410e-01],\n","       [-1.31854340e-01, -1.27521604e-01, -1.93088199e-03],\n","       [ 2.74744183e-02,  2.27027535e-02,  3.37785445e-02],\n","       [ 5.00695035e-02,  1.32864058e-01,  1.31776363e-01],\n","       [-7.55824223e-02, -6.74194470e-02, -9.72203612e-02],\n","       [ 2.97583081e-02, -6.55410662e-02,  1.37096316e-01],\n","       [ 4.01697606e-02,  2.28501740e-03,  9.52092037e-02],\n","       [-5.98860532e-02,  5.97871877e-02,  5.33312410e-02],\n","       [ 1.43617555e-01, -4.51979414e-02,  1.53516317e-02],\n","       [-4.75176945e-02, -4.32847179e-02,  4.00599800e-02],\n","       [-5.13805300e-02, -4.89842854e-02,  9.78004709e-02],\n","       [-1.72508489e-02, -8.30184668e-03, -1.16192862e-01],\n","       [ 6.69023767e-02, -5.40530495e-02, -8.17028619e-03],\n","       [-1.04574956e-01, -6.00511283e-02, -6.61105439e-02],\n","       [-6.24669390e-03,  7.61530772e-02,  1.30285263e-01],\n","       [-8.75715574e-04, -1.00513600e-01,  6.39373856e-03],\n","       [-9.22404751e-02,  1.22446775e-01, -1.27866026e-03],\n","       [-1.12085745e-01,  1.39701506e-02,  1.22029155e-01],\n","       [-1.18202582e-01,  1.50195330e-01,  9.27813649e-02],\n","       [ 3.46425711e-03, -1.11825630e-01, -1.38864085e-01],\n","       [ 5.34392670e-02,  1.40394732e-01,  1.44388258e-01],\n","       [ 1.06249496e-01,  9.71363485e-02,  1.00274585e-01],\n","       [-7.62367621e-02, -1.05935089e-01, -7.39839971e-02],\n","       [ 1.53278988e-02, -1.48232803e-02, -1.20513976e-01],\n","       [-1.36406153e-01, -1.37900174e-01, -2.26623397e-02],\n","       [-1.36206791e-01, -1.55675197e-02,  7.36747519e-04],\n","       [-1.32217854e-01, -1.31408364e-01,  1.17274396e-01],\n","       [ 1.08050510e-01,  3.55717950e-02, -9.04231817e-02],\n","       [ 1.55639797e-02,  3.53594571e-02, -9.06747356e-02],\n","       [ 1.29539430e-01,  7.92286992e-02,  1.30423069e-01],\n","       [-6.70648888e-02, -1.31734818e-01,  5.80631495e-02],\n","       [-1.15297176e-01, -8.12345464e-03, -7.08991215e-02],\n","       [ 2.72919424e-02,  4.24885415e-02,  3.28666298e-03],\n","       [-1.44734383e-01, -1.29987160e-03, -1.51024029e-01],\n","       [ 5.41468039e-02,  1.21211722e-01, -1.50665373e-01],\n","       [ 4.40507829e-02, -6.04677461e-02,  1.14401337e-02],\n","       [ 1.07640430e-01, -5.21185473e-02, -1.00881390e-01],\n","       [-4.53332514e-02,  1.27307326e-01,  5.13863228e-02],\n","       [-2.68649193e-03, -8.16723704e-02, -1.05868101e-01],\n","       [-9.14278924e-02, -1.42849475e-01,  3.75917926e-02],\n","       [-1.00115590e-01,  1.33547544e-01,  6.55138940e-02],\n","       [-3.69531959e-02, -1.04610935e-01,  4.61054817e-02],\n","       [ 8.18416700e-02, -2.63111871e-02, -1.11690201e-01],\n","       [ 5.15576713e-02, -1.49561753e-02,  3.54914479e-02],\n","       [ 8.06657225e-02,  1.02429137e-01, -1.34855032e-01],\n","       [ 1.40853196e-01,  2.10984349e-02, -1.17085487e-01],\n","       [ 8.51877034e-02,  3.94857712e-02, -2.87145879e-02],\n","       [ 1.10638648e-01,  5.23601584e-02, -1.50704280e-01],\n","       [-2.27772370e-02, -1.87638041e-04, -6.41756952e-02],\n","       [ 4.49017584e-02,  9.19786002e-03, -4.52303998e-02],\n","       [-5.46580404e-02, -1.08689278e-01, -6.08698465e-03],\n","       [ 6.81058168e-02,  7.46365488e-02, -1.85834989e-02],\n","       [-4.45614606e-02,  4.08137999e-02, -6.79426789e-02],\n","       [-5.87431081e-02, -2.10742671e-02, -1.03281565e-01],\n","       [-1.92965176e-02, -6.93272054e-02,  1.75176021e-02],\n","       [-2.22152541e-03, -7.44829793e-03, -1.20616145e-01],\n","       [ 8.28505978e-02,  1.25345916e-01,  2.37352867e-02],\n","       [-1.02721803e-01,  1.17622644e-01,  1.42154157e-01],\n","       [ 5.97221293e-02, -1.23466343e-01, -7.44480267e-02],\n","       [ 1.24105781e-01,  2.22410671e-02,  9.02437046e-02],\n","       [ 1.20908909e-01, -7.63496161e-02, -6.88637048e-02],\n","       [-3.81604396e-02,  3.99998762e-02,  1.33719102e-01],\n","       [-7.61236921e-02,  1.26095414e-01, -1.29834697e-01],\n","       [-1.04631949e-02, -1.43414065e-01,  4.53934819e-02],\n","       [ 7.31750727e-02,  6.55600652e-02,  4.43944149e-02],\n","       [ 8.76082480e-02, -5.25760129e-02, -5.70392311e-02],\n","       [ 4.22664993e-02, -1.02069594e-01, -1.31183108e-02],\n","       [-3.39194685e-02,  1.14158101e-01, -8.06987099e-03],\n","       [ 8.32302049e-02,  2.44901963e-02,  1.35217935e-01],\n","       [ 2.85672918e-02, -1.46212980e-01, -5.28447218e-02],\n","       [ 4.19145636e-03, -6.78323582e-02,  5.21223173e-02],\n","       [ 1.75374448e-02, -4.18801093e-03, -2.42652278e-02],\n","       [-1.43738031e-01,  3.66044156e-02, -9.53674987e-02],\n","       [-7.69835785e-02, -1.28964737e-01,  6.81244284e-02],\n","       [-2.80953869e-02,  5.28256744e-02, -4.88677025e-02],\n","       [-1.44310787e-01,  2.85305530e-02, -1.36919498e-01],\n","       [ 6.61702156e-02, -1.47879079e-01,  9.51221436e-02],\n","       [ 1.37955889e-01,  1.01410508e-01, -7.89590776e-02],\n","       [ 6.78832084e-02,  1.19182095e-01,  2.74220165e-02],\n","       [ 6.07740730e-02, -6.45146966e-02,  1.40919387e-01],\n","       [-4.86489534e-02,  3.67877947e-04,  1.22961089e-01],\n","       [ 9.66373011e-02,  8.17656070e-02,  5.69557995e-02],\n","       [-5.74770309e-02, -6.61826208e-02, -5.36995791e-02],\n","       [-9.86835510e-02,  1.18249819e-01, -8.75716731e-02],\n","       [-3.86353210e-02, -4.70106192e-02, -1.42856538e-01],\n","       [-1.33997068e-01, -7.09130093e-02, -4.78896424e-02],\n","       [ 6.53460026e-02,  5.01047005e-04, -1.07840225e-01],\n","       [ 1.14243180e-01, -4.30996306e-02, -3.96206826e-02],\n","       [-8.83521046e-03,  1.54696952e-03,  5.49134612e-02],\n","       [-4.39597806e-03, -1.08254254e-02, -9.78213772e-02],\n","       [ 5.80004081e-02, -1.02355577e-01,  1.93873644e-02],\n","       [-3.23573984e-02,  1.17537983e-01, -5.42025529e-02],\n","       [ 9.86611471e-02,  1.46295289e-02,  7.44731799e-02],\n","       [ 1.25415221e-01, -7.61189219e-03,  3.46765518e-02],\n","       [-1.52653247e-01, -7.83660561e-02,  6.55423775e-02],\n","       [-5.84442392e-02, -3.96503471e-02, -1.69380661e-02],\n","       [-1.22021846e-01, -5.80875240e-02, -7.64191672e-02],\n","       [ 8.72129481e-03, -1.25178725e-01,  1.24735564e-01],\n","       [-8.69849473e-02,  4.52678241e-02, -3.20282392e-03],\n","       [ 1.03806816e-01, -8.43444392e-02,  1.89180616e-02],\n","       [-2.34709084e-02,  7.60194212e-02,  8.38762820e-02],\n","       [-1.32280394e-01,  1.50057524e-01, -1.33814529e-01],\n","       [ 3.29345390e-02,  1.41058177e-01, -4.02699858e-02],\n","       [-1.05655221e-02, -1.30153000e-01,  6.70840638e-03],\n","       [ 1.07440390e-01,  2.08744314e-02,  1.09336399e-01],\n","       [ 6.07615113e-02,  8.55847821e-02,  1.06479175e-01],\n","       [-1.01045400e-01,  1.05589509e-01,  3.83235849e-02],\n","       [ 1.47510722e-01, -1.01128332e-01, -1.43793851e-01],\n","       [-2.20396388e-02,  1.23081906e-02, -5.01831509e-02],\n","       [ 1.28969133e-01,  1.39268667e-01,  1.45734698e-01],\n","       [ 5.85516840e-02,  8.45560282e-02, -1.17374182e-01],\n","       [-1.31279126e-01, -1.51489314e-03, -1.14278547e-01],\n","       [-4.06566076e-02, -1.10951714e-01, -1.25409231e-01],\n","       [ 2.27265321e-02,  6.27165884e-02, -5.82305714e-02],\n","       [-2.10639760e-02,  1.07636124e-01,  1.58453546e-02],\n","       [-2.35887058e-02, -7.65559869e-03,  7.43890479e-02],\n","       [-3.54905203e-02, -2.97360439e-02,  5.48487529e-02],\n","       [-1.10155329e-01,  1.30497813e-01,  2.63350792e-02],\n","       [ 1.04030378e-01, -8.03434290e-03,  2.03579795e-02],\n","       [-4.88632619e-02, -2.66357418e-02,  6.04486354e-02],\n","       [-9.65182930e-02,  3.95560227e-02, -6.53967336e-02],\n","       [-8.47183987e-02,  1.39077380e-01, -1.07819095e-01],\n","       [-2.74531008e-03,  1.06767155e-01, -1.34259105e-01],\n","       [-3.96662466e-02, -9.09862593e-02,  4.95915152e-02],\n","       [ 1.17541235e-02,  1.06755577e-01, -6.04133643e-02],\n","       [ 1.19416319e-01,  1.11640068e-02,  8.75452682e-02],\n","       [-1.34331271e-01,  8.27394649e-02, -9.69174504e-03],\n","       [-7.18849376e-02, -1.39727339e-01, -1.38755307e-01],\n","       [-1.27118230e-01, -9.67405140e-02, -1.58797000e-02],\n","       [-4.35087159e-02, -4.53398749e-02, -2.45437846e-02],\n","       [-1.05899476e-01, -1.86930895e-02, -4.78075258e-02],\n","       [ 1.29791573e-01, -1.41580537e-01,  4.00521755e-02],\n","       [-5.63462675e-02, -1.12363882e-01, -2.38668025e-02],\n","       [ 1.01339549e-01,  5.39794229e-02, -2.34997831e-02],\n","       [-3.45764602e-05, -4.81685661e-02, -4.46760841e-02],\n","       [-4.87991534e-02,  4.09351438e-02,  5.84038300e-03],\n","       [ 8.46557394e-02, -2.97799557e-02,  4.37799059e-02],\n","       [-4.27622274e-02, -5.45548797e-02, -4.25362438e-02],\n","       [ 1.25671089e-01, -1.35821581e-01, -2.65594237e-02],\n","       [ 1.19717093e-02,  8.74948353e-02,  9.43775252e-02],\n","       [ 4.51004319e-02,  7.59815946e-02, -7.98426103e-03],\n","       [-9.41310823e-02,  2.25540251e-02, -1.10505119e-01],\n","       [-8.40529427e-02, -6.28328919e-02, -3.28694633e-03],\n","       [-1.03722692e-01, -1.17504008e-01,  3.80714908e-02],\n","       [-1.63825564e-02,  9.37334523e-02,  1.48072883e-01],\n","       [-1.47920032e-03,  6.86024204e-02,  1.67365726e-02],\n","       [ 1.15719169e-01,  9.01123136e-02, -6.49028569e-02],\n","       [-5.97554371e-02, -1.06957145e-01,  4.59148474e-02],\n","       [ 8.63525644e-02, -2.26646364e-02, -8.39422196e-02],\n","       [ 1.40996307e-01, -1.17077634e-01, -1.25835498e-03],\n","       [-4.35460778e-03,  1.07495919e-01, -1.13106482e-01],\n","       [-8.17434117e-02,  1.20879360e-01,  9.44770798e-02],\n","       [-5.43962866e-02,  3.95285971e-02,  1.25869140e-01],\n","       [-5.81960604e-02,  1.53044090e-01, -2.37575434e-02],\n","       [ 8.52082744e-02,  1.27704158e-01, -1.13637306e-01],\n","       [-1.27979532e-01, -6.84164986e-02,  8.46291929e-02],\n","       [-4.17766422e-02,  4.59397770e-02, -4.65099961e-02],\n","       [-6.89470842e-02,  1.02428347e-01,  8.52917656e-02],\n","       [ 1.47108540e-01, -1.38304919e-01,  1.07157245e-01],\n","       [-5.42307347e-02, -1.00812949e-01, -7.25359097e-03],\n","       [ 7.33526051e-02,  1.48199182e-02,  3.65397409e-02],\n","       [-1.03442051e-01, -4.51980438e-03, -5.31702824e-02],\n","       [ 5.52412942e-02,  1.14986859e-01, -1.51103571e-01],\n","       [-1.06870927e-01,  3.14271636e-02, -5.06556369e-02],\n","       [-1.14427425e-01, -1.45871446e-01,  1.18949771e-01],\n","       [ 7.75793195e-02,  1.38915390e-01, -1.02091186e-01],\n","       [ 1.38799742e-01, -7.76583999e-02, -3.04459594e-03],\n","       [ 1.36352509e-01, -1.27004564e-01,  8.77117913e-04],\n","       [ 3.86574529e-02,  1.04625374e-01,  1.21276945e-01],\n","       [-4.76126894e-02, -2.08172314e-02,  9.64654982e-02],\n","       [-1.10279910e-01,  3.60226333e-02, -2.17845887e-02],\n","       [-1.39933541e-01,  5.81262521e-02, -8.55618566e-02],\n","       [-1.41504601e-01,  1.03051383e-02, -9.45356563e-02],\n","       [-3.78823723e-03,  1.23913348e-01,  1.37817100e-01],\n","       [ 1.57081559e-02,  7.10850134e-02,  6.62337318e-02],\n","       [-9.24890637e-02, -2.30668187e-02,  2.28678398e-02],\n","       [ 1.41084135e-01, -4.19676974e-02, -1.25058210e-02],\n","       [-9.48532075e-02,  6.82475567e-02, -1.25169838e-02],\n","       [ 3.13279256e-02, -4.15856838e-02,  2.30779624e-04],\n","       [-1.39067009e-01,  4.52399738e-02, -1.52402565e-01],\n","       [ 5.10154068e-02, -7.03755990e-02,  3.26415189e-02],\n","       [ 7.16432035e-02, -7.89331365e-03,  1.40454918e-01],\n","       [ 1.41803637e-01,  5.18326722e-02,  3.85408923e-02],\n","       [ 1.32439032e-01, -1.11908212e-01, -1.27737194e-01],\n","       [-5.44658974e-02,  1.38713285e-01,  9.68411043e-02],\n","       [ 6.03195354e-02, -3.15166824e-02, -3.58601660e-02],\n","       [ 1.37716413e-01, -3.02826762e-02,  1.70085225e-02],\n","       [-1.21005438e-01, -5.43212220e-02, -3.44720040e-03],\n","       [-9.09049734e-02,  1.59563925e-02,  1.26437604e-01],\n","       [ 9.50542390e-02,  1.17940426e-01,  5.12349792e-03],\n","       [ 1.74045116e-02, -1.30104780e-01, -1.44228965e-01],\n","       [-6.82661459e-02, -9.98536870e-02, -1.13603756e-01],\n","       [ 4.13416885e-02, -7.20019937e-02, -2.22312845e-02],\n","       [-8.92923325e-02, -1.27292171e-01, -7.20221624e-02],\n","       [-1.22665748e-01, -1.36085421e-01, -5.42686693e-03],\n","       [-5.65213636e-02,  7.89015647e-03, -5.10349358e-03],\n","       [-8.76055658e-02, -1.38977066e-01, -1.26040071e-01],\n","       [-4.42951992e-02, -6.36420622e-02,  2.79287938e-02],\n","       [ 7.42768943e-02,  1.24018125e-01,  7.09636211e-02],\n","       [-1.23494100e-02,  1.16397329e-01, -6.47636801e-02],\n","       [-4.64743283e-03, -1.43421888e-01, -1.42023370e-01],\n","       [ 9.56623778e-02, -3.97213909e-04, -1.36451488e-02],\n","       [ 6.18811883e-02,  4.19528410e-02, -3.37135158e-02],\n","       [ 7.14822710e-02, -1.13426879e-01,  1.41958192e-01],\n","       [ 4.36235555e-02, -1.18272856e-01, -7.96314701e-02],\n","       [ 1.42914802e-01, -7.46626258e-02, -2.64908578e-02],\n","       [ 1.13163069e-01, -1.48732737e-01, -1.84131991e-02],\n","       [-5.49817458e-02, -8.16564187e-02,  1.24279417e-01],\n","       [-7.82607868e-02,  2.61513758e-02, -1.42461076e-01],\n","       [-9.83198080e-03,  4.37586084e-02,  1.30588889e-01],\n","       [-1.49172666e-02, -1.30057216e-01, -1.49805695e-01],\n","       [ 6.26003146e-02,  1.40888885e-01, -5.84508479e-02],\n","       [ 6.01855330e-02,  8.30539130e-03,  2.77920477e-02],\n","       [ 1.15126513e-01,  2.49895323e-02, -2.18140297e-02],\n","       [ 2.54535489e-02, -4.35171984e-02,  1.95445437e-02],\n","       [ 1.49413660e-01, -9.03813019e-02, -9.21520442e-02],\n","       [ 2.42348500e-02, -8.51021111e-02,  9.28789824e-02],\n","       [-1.16075926e-01, -9.71070603e-02, -6.71790121e-03],\n","       [ 1.35270625e-01,  9.43603665e-02, -2.17191465e-02],\n","       [-1.37004837e-01,  1.98832676e-02,  3.97135541e-02],\n","       [-7.42575824e-02, -1.15324920e-02, -1.37805581e-01],\n","       [-7.83524290e-02,  1.02467619e-01,  3.84781659e-02],\n","       [-1.01306856e-01,  9.04771909e-02, -1.82912424e-02],\n","       [-1.39140129e-01,  5.03313690e-02, -5.07918708e-02],\n","       [-1.16052829e-01, -1.25647068e-01,  3.35894115e-02],\n","       [-9.68992710e-03,  1.41468301e-01, -9.88762826e-02],\n","       [-5.88494092e-02, -4.92969081e-02,  9.40728709e-02],\n","       [-1.26471356e-01,  8.12484398e-02,  1.40897900e-01],\n","       [-5.72337992e-02, -8.85729715e-02,  1.33155644e-01],\n","       [-1.15457848e-01, -4.51947525e-02,  1.30502984e-01],\n","       [ 1.51348501e-01,  6.78290427e-02,  1.22824786e-02],\n","       [ 3.48940864e-02,  6.33928627e-02,  6.16378449e-02],\n","       [ 8.48429501e-02, -2.21193098e-02,  1.49517721e-02],\n","       [ 1.02749839e-01,  7.50357062e-02,  1.05843902e-01],\n","       [ 4.29666750e-02, -3.96782439e-03, -2.48441007e-02],\n","       [-6.51063696e-02, -1.21063620e-01, -6.68463483e-02],\n","       [-6.06872514e-02,  6.00253195e-02,  1.35827884e-01],\n","       [-1.19349085e-01,  2.72242408e-02, -5.81812393e-03],\n","       [-7.78507665e-02, -3.50207202e-02, -3.09441965e-02],\n","       [-8.79394338e-02, -1.53629303e-01, -1.31319627e-01]], dtype=float32)>, <tf.Variable 'dense_219/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[-6.95848837e-02, -8.71745646e-02, -1.00191742e-01],\n","       [ 1.36507019e-01,  1.25065520e-01, -4.52249199e-02],\n","       [-6.05452359e-02,  1.17920369e-01, -2.93346271e-02],\n","       [-1.50774315e-01, -6.15371801e-02, -4.11541900e-03],\n","       [-9.17379335e-02, -1.20991603e-01,  7.23127052e-02],\n","       [ 9.08598602e-02, -1.33637702e-02, -1.44708306e-01],\n","       [ 6.96394518e-02,  6.03062995e-02,  3.68227847e-02],\n","       [ 4.19844687e-02, -5.07848077e-02, -1.51442289e-01],\n","       [ 5.72963506e-02, -8.49458799e-02,  4.04505199e-03],\n","       [ 1.29444584e-01,  1.05109187e-02, -9.84882712e-02],\n","       [ 9.38809663e-03,  1.12753630e-01, -5.12568699e-03],\n","       [ 1.48457244e-01,  6.98194802e-02,  1.40181974e-01],\n","       [-1.20277710e-01,  1.03629440e-01,  1.10226519e-01],\n","       [ 7.00595677e-02,  4.94695641e-02,  4.92635034e-02],\n","       [ 4.15823050e-02,  1.34338319e-01, -4.20978852e-03],\n","       [ 1.16141409e-01, -4.03563213e-03, -1.39592171e-01],\n","       [ 1.33291572e-01, -4.47949441e-03, -1.27524450e-01],\n","       [-8.58810693e-02,  1.79542750e-02, -1.29607052e-01],\n","       [-1.42261982e-01,  3.56448218e-02,  3.96963805e-02],\n","       [-7.26142377e-02,  8.48077685e-02, -1.33770645e-01],\n","       [-6.74054474e-02, -2.92587578e-02, -6.38945550e-02],\n","       [ 9.62346941e-02,  1.73323583e-02,  1.28479689e-01],\n","       [ 4.16939668e-02, -1.19699538e-01,  4.44893427e-02],\n","       [-1.05513297e-01,  6.26276582e-02, -1.10638522e-01],\n","       [-4.76356298e-02, -1.40496809e-03,  5.70988469e-02],\n","       [ 1.43679634e-01,  1.24928340e-01,  6.53772354e-02],\n","       [-3.75518203e-02,  1.41405359e-01, -8.34262893e-02],\n","       [-2.32554264e-02, -1.32770777e-01, -1.23186409e-01],\n","       [ 1.37770623e-01, -1.41616926e-01, -6.86020702e-02],\n","       [ 1.52189480e-02, -9.79282334e-03, -1.14942552e-03],\n","       [-3.79380807e-02, -6.97968304e-02,  1.17687806e-01],\n","       [ 1.25137284e-01, -1.10742912e-01, -4.41552140e-02],\n","       [-1.15581691e-01, -5.57413511e-02,  4.41495255e-02],\n","       [ 4.96287867e-02, -3.06898216e-03,  2.14688033e-02],\n","       [-3.81768830e-02,  2.05505677e-02, -3.29246819e-02],\n","       [-9.14020985e-02,  3.45823653e-02,  8.77971351e-02],\n","       [ 9.60716754e-02,  3.48284021e-02,  1.48991093e-01],\n","       [-7.61561170e-02, -1.33570030e-01,  8.77398476e-02],\n","       [ 3.85201201e-02,  2.83826180e-02, -1.25880390e-01],\n","       [-4.05845270e-02,  5.02996594e-02,  1.44464388e-01],\n","       [ 1.78989097e-02, -1.74798574e-02, -1.00874037e-01],\n","       [-1.07546963e-01,  1.18548892e-01,  4.37301621e-02],\n","       [-7.57167637e-02,  1.14204727e-01, -9.05707255e-02],\n","       [-6.93671405e-02,  3.82999964e-02, -1.49828345e-01],\n","       [-1.18202396e-01, -1.11200832e-01,  1.15541205e-01],\n","       [-1.34351656e-01, -1.40313432e-01,  8.28930140e-02],\n","       [-1.95336435e-02,  1.21529162e-01,  6.47185594e-02],\n","       [ 1.46720245e-01,  1.05157375e-01, -4.39687259e-02],\n","       [-2.57885046e-02,  1.27656445e-01, -6.38021976e-02],\n","       [ 3.98123488e-02,  1.33544788e-01,  4.44407500e-02],\n","       [-1.49124473e-01, -5.09020612e-02, -1.11651540e-01],\n","       [-1.81324221e-02, -1.06531121e-01,  9.57571864e-02],\n","       [-1.62263811e-02,  5.75408190e-02, -5.20461090e-02],\n","       [-1.28443241e-01,  6.21238388e-02, -1.50369242e-01],\n","       [ 1.35214150e-01,  8.85109007e-02,  4.85590138e-02],\n","       [ 6.19140156e-02,  1.44562200e-01,  3.46499495e-02],\n","       [-7.21257478e-02,  3.11455317e-02,  1.39229193e-01],\n","       [-1.20623037e-01,  1.16298743e-01,  1.49645435e-04],\n","       [-7.20878243e-02, -1.15500405e-01, -7.25695789e-02],\n","       [-9.46916491e-02,  1.11911416e-01,  6.19879849e-02],\n","       [-1.08923107e-01,  1.43809304e-01,  8.97575393e-02],\n","       [-3.61669436e-02, -4.78161080e-03,  2.45218514e-03],\n","       [ 6.92680106e-02, -1.06944643e-01,  1.29886478e-01],\n","       [ 1.41392276e-01,  9.40918475e-02, -1.28466263e-01],\n","       [ 6.03959784e-02,  9.43794288e-03, -6.87519535e-02],\n","       [-5.19428886e-02, -1.06250018e-01,  7.25499615e-02],\n","       [-8.01469982e-02,  8.53807330e-02,  8.56958702e-02],\n","       [-1.15613781e-01,  5.50122485e-02,  4.22407612e-02],\n","       [-1.27989035e-02,  3.54616699e-04,  1.26291782e-01],\n","       [-1.36926353e-01, -9.24383551e-02,  1.38373196e-01],\n","       [-7.82701094e-03,  1.21288836e-01,  1.45678490e-01],\n","       [-1.11235805e-01,  1.27404243e-01,  2.46968344e-02],\n","       [-9.41833481e-02,  7.37486333e-02, -4.14466970e-02],\n","       [-7.84476697e-02,  4.62730266e-02,  2.66201934e-03],\n","       [ 9.72269773e-02,  4.37600091e-02,  1.44186661e-01],\n","       [ 1.64179318e-02, -1.16944648e-01,  8.06378387e-03],\n","       [ 1.42221123e-01, -4.70167398e-02,  9.29978341e-02],\n","       [ 7.21241385e-02,  5.62541895e-02, -4.93025780e-02],\n","       [ 4.38448712e-02, -3.17203701e-02, -1.27441511e-01],\n","       [-7.18543753e-02, -1.44649208e-01, -2.92109903e-02],\n","       [ 1.02586262e-01,  2.49510054e-02, -7.39006400e-02],\n","       [ 1.00511201e-01, -1.02310926e-01, -1.33515716e-01],\n","       [-4.78555355e-03, -6.83907047e-02, -1.27451112e-02],\n","       [ 1.33781403e-01, -2.21575927e-02,  5.22576272e-02],\n","       [-6.74590245e-02,  3.45714912e-02,  1.48265541e-01],\n","       [-1.59465522e-03, -6.14310540e-02, -7.03810677e-02],\n","       [ 1.14196628e-01, -1.09608606e-01,  9.05088633e-02],\n","       [ 8.82574394e-02, -2.00831573e-02,  5.77440821e-02],\n","       [-8.91264677e-02, -4.79673333e-02, -5.25922775e-02],\n","       [ 8.84362161e-02, -1.17535122e-01, -8.14106837e-02],\n","       [-1.61587447e-02,  1.05636626e-01,  1.40213251e-01],\n","       [ 7.55769908e-02,  7.18688369e-02, -9.86009371e-03],\n","       [-2.52720714e-03, -1.13852963e-01, -9.12563428e-02],\n","       [ 1.33342231e-02,  7.25275874e-02,  9.62995749e-04],\n","       [ 7.14504942e-02,  8.59399289e-02,  1.05851680e-01],\n","       [-1.78851392e-02, -4.51394022e-02,  9.88685340e-02],\n","       [ 4.43216041e-02, -1.09190382e-01, -3.53899226e-02],\n","       [-3.86475474e-02,  1.10256724e-01, -1.06045930e-02],\n","       [-6.20116852e-02,  6.81320354e-02, -1.35742314e-03],\n","       [ 7.03025237e-02,  6.29572272e-02, -8.25390443e-02],\n","       [ 3.82585675e-02,  1.25012115e-01, -1.16524197e-01],\n","       [-5.53263212e-03, -1.19288452e-01, -9.91691798e-02],\n","       [-8.88156146e-02, -7.32527897e-02,  2.84999292e-02],\n","       [-4.07796986e-02,  1.16775826e-01, -2.73809899e-02],\n","       [ 1.12772267e-02,  9.96062160e-02, -6.77255541e-02],\n","       [ 3.54394875e-02, -9.80713144e-02,  3.86436284e-02],\n","       [-1.16007235e-02, -6.13249280e-02,  1.49849042e-01],\n","       [ 7.38928616e-02,  3.00013665e-02, -1.04183443e-02],\n","       [-9.53060016e-02, -8.11503157e-02,  1.14753537e-01],\n","       [ 1.12508774e-01, -3.66119854e-02, -1.38429701e-01],\n","       [ 1.50502548e-01,  1.06067648e-02,  3.50702293e-02],\n","       [-3.34290485e-03,  7.53402412e-02, -7.11097717e-02],\n","       [ 6.05726354e-02,  4.75445949e-02, -1.37113035e-01],\n","       [-3.11933029e-02, -9.59684476e-02, -1.69609003e-02],\n","       [-9.83755365e-02, -1.40699565e-01, -1.27593651e-01],\n","       [-8.70273709e-02,  5.28605506e-02, -1.14754088e-01],\n","       [-1.32689431e-01,  1.08654998e-01,  3.05577964e-02],\n","       [-6.22122474e-02, -4.69797254e-02, -1.49885908e-01],\n","       [ 2.37557031e-02,  1.29007593e-01, -8.27523042e-03],\n","       [-9.09772236e-03,  8.64099804e-03, -8.16268288e-03],\n","       [ 4.29244749e-02, -6.96201697e-02, -1.45462140e-01],\n","       [ 8.51556435e-02, -3.40849273e-02, -1.00297183e-01],\n","       [-9.97365192e-02,  1.26210585e-01, -1.04641505e-01],\n","       [-8.53033960e-02,  9.35584605e-02,  6.16310164e-02],\n","       [-4.73739840e-02, -2.80022249e-02,  1.97891630e-02],\n","       [ 7.18244761e-02,  1.28340170e-01, -6.28878623e-02],\n","       [-6.16965704e-02,  6.51042014e-02, -2.89719575e-03],\n","       [-1.07739843e-01,  1.38459042e-01,  9.43006128e-02],\n","       [-9.43716392e-02, -8.83122683e-02,  1.05361030e-01],\n","       [ 6.91955090e-02, -1.30664930e-01,  8.81917309e-03],\n","       [-1.39297321e-01, -3.65104340e-02,  1.03317633e-01],\n","       [ 1.53303385e-01,  1.46311745e-01, -1.35591999e-01],\n","       [-1.89285912e-02, -2.61077974e-02, -1.14565700e-01],\n","       [ 1.26938090e-01, -8.69487063e-04,  1.41575441e-01],\n","       [-2.33070254e-02, -9.92280543e-02,  1.15315787e-01],\n","       [ 9.15127024e-02, -1.29405916e-01,  1.64340977e-02],\n","       [ 5.46168983e-02, -5.78367300e-02,  1.32076547e-01],\n","       [-1.23987734e-01, -1.15826912e-01,  1.10050097e-01],\n","       [ 5.20647541e-02, -7.67421797e-02, -1.03872374e-01],\n","       [-9.72237438e-02, -8.22474658e-02, -8.67062360e-02],\n","       [-7.92048350e-02, -2.95445807e-02,  1.95080191e-02],\n","       [-1.32198125e-01,  1.08478919e-01,  9.17988718e-02],\n","       [ 2.20934357e-02, -4.55685481e-02,  3.56407277e-02],\n","       [-5.90166226e-02,  6.60035610e-02,  1.07457556e-01],\n","       [-6.84903413e-02,  5.03107533e-02, -6.20326288e-02],\n","       [-4.01858687e-02, -9.54233557e-02, -1.87516175e-02],\n","       [-1.20572582e-01,  8.17129463e-02,  1.62612069e-02],\n","       [ 7.33489543e-02,  1.01440676e-01,  2.83293277e-02],\n","       [ 7.00708181e-02, -3.68173122e-02, -1.48301031e-02],\n","       [ 6.16040267e-02,  2.62461379e-02,  9.75795835e-03],\n","       [ 1.66473240e-02, -1.36730298e-01,  1.42453328e-01],\n","       [-1.30218655e-01, -1.93722248e-02,  1.09584585e-01],\n","       [-4.28507552e-02,  5.59572689e-02, -1.10248653e-02],\n","       [ 8.92598927e-02,  4.94530722e-02, -3.97760281e-03],\n","       [-1.48627609e-01, -1.29914880e-01,  1.06979720e-01],\n","       [ 2.63332180e-03,  1.11022577e-01,  4.98728678e-02],\n","       [ 1.18571974e-01,  2.77196113e-02, -1.15240358e-01],\n","       [ 1.18883327e-01,  2.14953497e-02, -1.42569885e-01],\n","       [-1.27401128e-01, -1.47381485e-01, -9.95802954e-02],\n","       [-1.43588468e-01,  8.85685831e-02, -2.37598848e-02],\n","       [-5.63185439e-02,  8.81790742e-02,  8.04259703e-02],\n","       [-8.66380930e-02, -1.42010540e-01, -1.00731373e-01],\n","       [-1.44307300e-01,  1.52382523e-01, -1.54055338e-02],\n","       [-1.51510746e-03, -6.23441935e-02,  1.17047116e-01],\n","       [ 2.94841211e-02, -1.21835083e-01,  5.50193824e-02],\n","       [-1.17540479e-01,  8.20362121e-02,  6.15548976e-02],\n","       [-1.25161260e-01,  6.21101558e-02,  1.11086667e-01],\n","       [ 1.04444444e-01,  4.02331278e-02,  1.28123745e-01],\n","       [ 6.56172782e-02,  1.08211525e-01, -1.01858549e-01],\n","       [ 3.46755871e-04, -1.06534787e-01,  3.95056196e-02],\n","       [-9.42556933e-02, -1.20122917e-01,  1.09188452e-01],\n","       [ 1.26973391e-01,  1.08094238e-01, -3.54939848e-02],\n","       [ 2.98616532e-02,  6.13950565e-02, -7.98416957e-02],\n","       [ 1.99528830e-03, -1.32086873e-01, -1.08374238e-01],\n","       [ 1.38746455e-01,  5.40339947e-02, -8.75201970e-02],\n","       [ 2.30848026e-02, -1.15220062e-02,  3.90504822e-02],\n","       [ 1.42849281e-01, -7.88750872e-02, -1.95561685e-02],\n","       [-1.03094123e-01, -9.62123796e-02,  1.09605966e-02],\n","       [ 1.27119675e-01,  1.16680264e-01,  2.49535069e-02],\n","       [-6.64308220e-02,  4.54079323e-02,  9.47179645e-03],\n","       [ 7.29694143e-02,  5.55556305e-02, -7.52914548e-02],\n","       [ 1.13118038e-01, -1.35626435e-01,  6.97688907e-02],\n","       [ 6.15491569e-02, -1.23474859e-01,  1.22675516e-01],\n","       [-1.61155835e-02, -6.34817546e-03, -8.66399985e-03],\n","       [-8.91615599e-02,  1.19679503e-01,  2.85751130e-02],\n","       [ 1.24819458e-01,  5.21659758e-03,  2.55264575e-03],\n","       [-1.39450282e-01, -9.06707644e-02, -4.28813808e-02],\n","       [-1.37948617e-02,  1.09931961e-01, -6.21603057e-02],\n","       [-1.14300035e-01,  1.10756062e-01,  9.53794196e-02],\n","       [-9.69549567e-02, -1.48314923e-01,  1.32439792e-01],\n","       [-3.19730453e-02,  1.28327701e-02, -1.07016057e-01],\n","       [ 1.21694043e-01,  8.19935203e-02, -1.22489400e-01],\n","       [-9.84842703e-02,  9.81579423e-02, -8.35224167e-02],\n","       [ 9.80497226e-02,  1.20360613e-01, -1.13786161e-01],\n","       [ 5.75555079e-02,  1.08494647e-01,  1.18265949e-01],\n","       [-1.08253747e-01,  1.50253132e-01, -8.04079175e-02],\n","       [ 1.38475016e-01, -1.05869882e-01, -7.47333989e-02],\n","       [-3.33697498e-02,  3.80628742e-02,  2.36364435e-02],\n","       [ 4.46495861e-02, -1.32720798e-01, -5.68115525e-02],\n","       [ 9.57417935e-02, -8.23718458e-02,  8.05659518e-02],\n","       [-5.42628989e-02, -4.59735394e-02, -1.18863165e-01],\n","       [-1.08055837e-01, -1.10351369e-01,  1.19814828e-01],\n","       [ 8.70757252e-02,  1.39774069e-01, -6.50830343e-02],\n","       [-8.01006481e-02,  1.38403863e-01, -2.54218001e-02],\n","       [ 4.00235318e-02,  1.05382189e-01,  6.05495274e-02],\n","       [ 1.25477701e-01, -1.47938490e-01, -7.95355067e-02],\n","       [ 6.15112036e-02, -5.72553314e-02, -1.33321807e-01],\n","       [-1.18082084e-01, -4.31307442e-02,  1.22353323e-01],\n","       [ 1.45163149e-01, -1.02112688e-01, -8.88084993e-02],\n","       [-1.37177050e-01, -6.02556276e-04,  3.50162163e-02],\n","       [ 4.64893691e-02,  1.40111297e-01, -9.18269902e-02],\n","       [ 1.45601481e-01, -1.19217195e-01, -1.29576689e-02],\n","       [-1.38841495e-01, -5.09335585e-02, -7.06827268e-02],\n","       [-1.15706220e-01,  7.54650384e-02,  4.31807972e-02],\n","       [ 1.42169192e-01,  1.50745496e-01, -6.03934713e-02],\n","       [ 1.08800411e-01,  9.38048735e-02,  1.51444906e-02],\n","       [-1.47763431e-01, -1.09005742e-01,  9.16956887e-02],\n","       [ 7.98065886e-02, -1.22903511e-01,  4.42190580e-02],\n","       [ 1.56706329e-02,  1.51767302e-02, -7.05289990e-02],\n","       [-1.27434745e-01,  1.24245510e-01,  3.45781706e-02],\n","       [-5.00291139e-02,  4.81154099e-02,  9.32303146e-02],\n","       [-1.49417132e-01, -6.98532760e-02, -8.00507590e-02],\n","       [ 1.31490067e-01, -1.16922185e-01, -7.89162889e-02],\n","       [-2.62392517e-02,  1.16963975e-01, -7.27294385e-02],\n","       [ 1.34211704e-01, -4.10731845e-02, -1.01451479e-01],\n","       [-1.49359941e-01, -2.54998542e-03, -1.02158733e-01],\n","       [-8.32785219e-02, -1.45378321e-01, -1.62948482e-02],\n","       [-6.95122555e-02,  1.36850685e-01, -3.87144163e-02],\n","       [-3.91482078e-02,  1.30158991e-01,  2.81673744e-02],\n","       [-1.10871628e-01,  1.07234027e-02, -2.52718441e-02],\n","       [ 6.23018593e-02,  1.51414618e-01,  7.21130595e-02],\n","       [-1.95139628e-02,  1.27370849e-01, -8.82349685e-02],\n","       [ 2.27725618e-02,  2.75704395e-02, -2.65547819e-03],\n","       [ 1.42502084e-01, -1.00439519e-01, -1.50550798e-01],\n","       [-1.39423385e-01,  1.40580684e-01,  1.47547647e-01],\n","       [ 4.25703786e-02,  2.79796477e-02, -9.39375088e-02],\n","       [ 7.88600072e-02, -8.86969566e-02,  6.67489916e-02],\n","       [-9.72284973e-02,  3.04439534e-02,  8.34804773e-02],\n","       [-5.50068356e-02,  9.41506103e-02, -1.35909170e-01],\n","       [ 1.08461127e-01,  8.38812664e-02, -9.53953415e-02],\n","       [ 1.35593757e-01,  5.40347658e-02,  9.64484271e-03],\n","       [ 5.06951474e-03,  3.40338536e-02, -1.01457939e-01],\n","       [-6.20972179e-02, -1.29693737e-02, -2.56567094e-02],\n","       [ 1.03709638e-01, -1.81578975e-02, -5.10055125e-02],\n","       [ 5.93040995e-02,  6.94120005e-02, -6.87776729e-02],\n","       [ 3.82519588e-02, -1.37738734e-02, -1.50921270e-01],\n","       [ 2.05381121e-02,  1.78891011e-02, -8.13985616e-02],\n","       [ 1.06116407e-01,  4.04712334e-02, -7.68731767e-03],\n","       [-2.00166684e-02, -6.37835916e-03,  2.57812310e-02],\n","       [-3.22388373e-02, -1.72904283e-02,  1.45895690e-01],\n","       [-5.29901274e-02,  6.44156411e-02,  1.16237953e-01],\n","       [ 5.79683557e-02, -1.35849699e-01,  7.02286065e-02],\n","       [-8.54462981e-02,  4.72911447e-02, -7.67242461e-02],\n","       [ 1.32495865e-01,  2.75528971e-02,  4.16479334e-02],\n","       [-5.41122779e-02, -1.13327123e-01, -1.48411170e-01],\n","       [ 2.10630391e-02, -1.26417935e-01,  1.54160187e-02]], dtype=float32)>, <tf.Variable 'dense_220/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[-1.25771090e-01,  1.02698952e-01,  1.44924536e-01],\n","       [ 5.20544201e-02, -1.38307288e-01, -5.32918144e-03],\n","       [-6.93333820e-02, -1.38286680e-01,  6.60744384e-02],\n","       [ 5.20919710e-02, -1.10230558e-01,  8.85865465e-02],\n","       [ 1.49033755e-01,  7.68457130e-02,  3.17493156e-02],\n","       [-1.49703935e-01,  1.20985143e-01, -5.90129383e-02],\n","       [ 1.44263506e-01, -5.80512695e-02,  9.47310850e-02],\n","       [-9.87085700e-02, -2.07728073e-02, -1.14351939e-02],\n","       [-1.47968024e-01, -6.03915229e-02, -9.76062119e-02],\n","       [ 1.15228057e-01,  1.26785412e-01,  2.48749536e-02],\n","       [ 7.42241219e-02, -1.16023617e-02, -1.42038465e-01],\n","       [-1.40699029e-01,  3.36153321e-02, -2.79457923e-02],\n","       [ 9.81790349e-02,  1.02494806e-02,  1.47387221e-01],\n","       [ 1.21913008e-01, -4.25511226e-02, -1.24699309e-01],\n","       [ 1.19151942e-01, -6.00041747e-02, -6.05545789e-02],\n","       [-1.16245054e-01, -2.70480532e-02, -1.20278016e-01],\n","       [-5.11330832e-03,  2.04661787e-02,  6.81102723e-02],\n","       [ 6.22581132e-02, -9.09391418e-03,  6.46704286e-02],\n","       [ 5.32828234e-02, -1.84377320e-02,  1.32973492e-02],\n","       [-1.29950996e-02, -1.00879148e-01, -5.17792515e-02],\n","       [-1.00582582e-03,  2.89353374e-02,  4.65209223e-02],\n","       [ 6.80870488e-02, -5.60402265e-03,  9.31335464e-02],\n","       [-5.19344769e-02,  3.14474665e-02,  1.29783630e-01],\n","       [-1.26075089e-01,  2.08248477e-02,  1.36938673e-02],\n","       [-9.44688022e-02, -5.53902201e-02,  1.19394161e-01],\n","       [-4.19786088e-02,  8.28888044e-02, -1.47587359e-01],\n","       [ 6.86959643e-03, -4.57734726e-02, -1.35924250e-01],\n","       [-9.46160927e-02, -7.85455629e-02, -5.19737117e-02],\n","       [ 1.47859797e-01,  1.40822589e-01, -8.92359018e-02],\n","       [-4.93511483e-02,  1.00291163e-01,  7.26668397e-03],\n","       [-2.14733295e-02, -8.25160816e-02,  2.29235254e-02],\n","       [ 7.31938854e-02, -3.28930095e-02,  9.13472027e-02],\n","       [ 3.90615724e-02, -2.50078216e-02,  1.01076812e-01],\n","       [ 4.61888276e-02, -6.83501139e-02,  3.57251093e-02],\n","       [ 9.06230435e-02, -1.12487778e-01,  8.57911110e-02],\n","       [ 7.54972398e-02, -9.36276466e-02,  1.39184222e-01],\n","       [-1.74469911e-02, -1.04520023e-02, -1.79661755e-02],\n","       [-5.72686717e-02, -1.43381227e-02,  1.18732668e-01],\n","       [-1.49979919e-01, -5.63739752e-03,  1.62294004e-02],\n","       [-7.55244121e-02, -4.63814028e-02, -7.35915154e-02],\n","       [ 8.99202973e-02,  1.15411887e-02,  7.01607987e-02],\n","       [ 1.92421619e-02, -9.04141888e-02, -2.38608313e-03],\n","       [ 2.80001014e-02,  5.66411763e-02,  5.98878749e-02],\n","       [-6.75322711e-02, -1.88137796e-02,  1.36232063e-01],\n","       [ 1.32126063e-01,  6.17888931e-04, -5.36927655e-02],\n","       [ 8.71577635e-02,  6.10224232e-02, -1.43970009e-02],\n","       [ 1.59205031e-02, -7.84577727e-02, -7.71101117e-02],\n","       [ 1.22809149e-01,  8.01484063e-02, -1.17413744e-01],\n","       [ 2.41762940e-02,  1.01183401e-02,  1.28266364e-01],\n","       [-4.69913520e-02,  1.31000385e-01, -1.10895179e-01],\n","       [ 2.06771344e-02,  4.40003537e-02,  1.41411811e-01],\n","       [ 3.02958507e-02, -1.43839717e-01,  1.33480251e-01],\n","       [-6.52545020e-02, -1.17854454e-01, -1.35697290e-01],\n","       [ 8.81078094e-02,  3.31344120e-02, -4.64323200e-02],\n","       [ 7.27810413e-02,  2.91776494e-03, -1.25143066e-01],\n","       [-1.48277238e-01, -1.07988127e-01, -3.45352106e-02],\n","       [ 1.24917865e-01, -8.23182687e-02, -4.59646806e-02],\n","       [ 7.61184841e-02,  7.13877976e-02, -1.06722082e-03],\n","       [-1.27449650e-02, -1.96623709e-02, -7.68149421e-02],\n","       [ 6.92042336e-03,  2.04521473e-02, -4.40849625e-02],\n","       [ 8.69152173e-02,  1.20137401e-01, -1.37678996e-01],\n","       [-5.16415983e-02,  1.05001897e-01, -1.42492816e-01],\n","       [ 8.42933878e-02,  6.83132038e-02,  1.28601387e-01],\n","       [-1.52202817e-02, -1.25602081e-01,  2.94295279e-03],\n","       [ 4.71089967e-02,  8.74345079e-02, -1.26135841e-01],\n","       [-9.26887766e-02, -6.04090206e-02,  1.27668083e-01],\n","       [ 7.92040676e-02, -1.10738799e-01, -6.23486564e-02],\n","       [-6.21827729e-02,  1.30430982e-01, -1.04209565e-01],\n","       [-7.89686814e-02,  1.12442300e-01,  1.44965440e-01],\n","       [-1.27169251e-01, -2.17329781e-03,  1.02952287e-01],\n","       [-1.03807740e-01, -2.21834965e-02,  4.26352099e-02],\n","       [ 1.14349006e-02,  6.45160601e-02,  4.79507335e-02],\n","       [-8.65236670e-02, -8.00594315e-02,  9.58822444e-02],\n","       [ 7.52909482e-02,  1.24432720e-01,  1.29785374e-01],\n","       [ 5.18415384e-02,  4.34363857e-02, -1.10607529e-02],\n","       [-4.73601930e-02,  6.69935495e-02,  2.23412123e-02],\n","       [ 3.45092677e-02,  1.39378548e-01,  1.82049926e-02],\n","       [ 5.77939302e-02, -6.52630925e-02, -4.58390899e-02],\n","       [-6.69429228e-02, -8.29892000e-04,  5.89430369e-02],\n","       [ 7.97940344e-02,  3.46702486e-02, -1.35534778e-01],\n","       [ 3.73188034e-02,  2.50492208e-02,  1.39685988e-01],\n","       [ 2.83234939e-02, -1.32484570e-01,  1.33946210e-01],\n","       [-1.00591779e-01,  1.61554590e-02,  3.95857878e-02],\n","       [ 1.18013568e-01,  1.36985943e-01, -7.22471103e-02],\n","       [-1.40594169e-01,  7.31260628e-02, -6.02101348e-02],\n","       [-4.36937958e-02, -9.50098932e-02,  1.01185471e-01],\n","       [-5.75381219e-02,  1.36638388e-01, -1.24322377e-01],\n","       [ 1.14210919e-01,  3.88910472e-02,  8.40859190e-02],\n","       [-1.33435458e-01,  5.43258227e-02,  5.57930730e-02],\n","       [ 9.19798668e-03, -1.99146923e-02,  4.98467907e-02],\n","       [ 1.86463054e-02, -2.40168832e-02,  2.07681227e-02],\n","       [-2.69784741e-02,  1.11484624e-01, -1.45192847e-01],\n","       [ 9.25763324e-02,  1.52024269e-01,  8.28049437e-04],\n","       [ 3.85621227e-02, -6.13537803e-02,  4.57575992e-02],\n","       [-2.16046837e-03,  5.61964698e-02,  5.18241562e-02],\n","       [-7.45785907e-02,  3.47996019e-02,  6.98584542e-02],\n","       [ 1.13589309e-01, -1.25023142e-01, -1.32131264e-01],\n","       [ 7.35493228e-02, -1.12980023e-01, -4.22246894e-03],\n","       [ 1.39642894e-01, -1.34483635e-01, -9.02606696e-02],\n","       [ 3.01640350e-02,  1.21148152e-03,  1.01907797e-01],\n","       [ 4.74392734e-02, -4.54057045e-02, -5.03304414e-02],\n","       [-1.02887070e-02,  1.03014484e-02, -1.14732072e-01],\n","       [ 1.36331141e-01,  1.33915126e-01, -1.42059013e-01],\n","       [-6.37216121e-02, -1.24891795e-01, -1.17632568e-01],\n","       [ 1.51584353e-02, -3.53092104e-02, -3.26944441e-02],\n","       [ 7.14064464e-02, -3.20435166e-02, -4.29261923e-02],\n","       [ 4.93690856e-02,  5.56856431e-02, -1.47024632e-01],\n","       [ 3.47677469e-02,  1.33593857e-01, -6.67136535e-02],\n","       [ 3.99207436e-02,  1.38172181e-02,  8.56720805e-02],\n","       [-3.14141577e-03,  7.71749243e-02, -4.62847427e-02],\n","       [-3.79645564e-02,  8.12100247e-02, -1.94621347e-02],\n","       [-5.71889654e-02,  1.42668918e-01, -2.52512507e-02],\n","       [ 1.22634796e-02, -8.56127441e-02, -7.69236386e-02],\n","       [ 7.75033832e-02, -4.63949889e-02,  6.42463043e-02],\n","       [ 1.35200635e-01,  1.17824301e-01, -7.55843520e-03],\n","       [ 3.22765596e-02, -7.83769414e-03,  1.40043542e-01],\n","       [ 3.97837870e-02,  1.07753016e-01, -1.32085696e-01],\n","       [-1.32148996e-01, -6.89879730e-02,  1.11065648e-01],\n","       [-6.15487881e-02,  4.01307158e-02,  8.08875933e-02],\n","       [-6.71383962e-02, -4.60857227e-02,  9.24704820e-02],\n","       [ 2.35347282e-02,  1.10120609e-01, -5.24660945e-02],\n","       [-1.03731550e-01,  1.15517654e-01,  8.23177993e-02],\n","       [-7.00529814e-02,  1.09020397e-01, -1.04548961e-01],\n","       [-1.25230312e-01,  6.85865507e-02, -6.50078133e-02],\n","       [-8.23166072e-02, -1.14442661e-01,  1.28648147e-01],\n","       [ 1.23248458e-01, -7.53506348e-02,  1.09468199e-01],\n","       [-8.14555064e-02, -1.10222124e-01,  3.73434871e-02],\n","       [ 1.46822799e-02,  4.24088575e-02,  1.02357708e-01],\n","       [-5.64021319e-02,  3.63651887e-02,  2.57289410e-03],\n","       [ 4.04040031e-02, -4.76467013e-02, -3.32230031e-02],\n","       [ 1.98389255e-02,  1.26458257e-01,  5.42642437e-02],\n","       [ 7.84937516e-02,  1.27874240e-01, -3.91334184e-02],\n","       [ 8.29364955e-02,  1.09306134e-01, -2.36949418e-02],\n","       [ 1.50004074e-01, -1.16203837e-01,  7.46418163e-02],\n","       [ 9.46043879e-02, -1.43831193e-01, -1.27784207e-01],\n","       [-5.42395413e-02,  1.42525792e-01,  2.08709966e-02],\n","       [ 1.28291130e-01,  1.13575570e-01, -1.60425380e-02],\n","       [-6.29500374e-02, -1.45510077e-01, -5.96784763e-02],\n","       [ 6.56875595e-02, -2.19344161e-02,  6.62827492e-02],\n","       [ 5.26306108e-02,  9.68361422e-02, -9.68075991e-02],\n","       [-3.86315845e-02, -1.42156348e-01, -8.20113793e-02],\n","       [ 1.20520808e-01,  1.17201507e-01, -1.15892269e-01],\n","       [-1.28005743e-01, -3.35241109e-02, -8.93630460e-02],\n","       [-5.42403534e-02, -5.89399540e-04, -2.87433900e-02],\n","       [ 1.99708752e-02, -1.63992085e-02, -3.72563489e-02],\n","       [ 4.72799316e-02,  2.22061835e-02,  3.03480979e-02],\n","       [-6.46580011e-02,  1.60278976e-02, -6.87164143e-02],\n","       [ 5.90828359e-02, -8.80325586e-02,  1.31621519e-02],\n","       [-1.42158851e-01,  5.88881038e-02,  1.44748554e-01],\n","       [ 1.02462061e-01, -5.00949547e-02, -2.64758263e-02],\n","       [-8.82386118e-02,  1.30993545e-01,  7.23128840e-02],\n","       [-1.93652622e-02, -6.87981248e-02,  9.49028805e-02],\n","       [ 4.55680229e-02,  1.10102013e-01,  9.59464908e-02],\n","       [ 3.41079794e-02, -5.08251414e-02, -5.04534878e-02],\n","       [-8.73831287e-02,  6.39691874e-02, -4.68840636e-02],\n","       [ 1.94966663e-02,  1.04093522e-01, -1.44202814e-01],\n","       [-1.05089299e-01, -1.20504141e-01,  7.33713806e-02],\n","       [-6.38313219e-03, -8.41919407e-02, -8.21349546e-02],\n","       [-1.36605456e-01, -1.39591143e-01,  9.17246789e-02],\n","       [ 9.17747989e-02, -3.28186378e-02,  7.99397305e-02],\n","       [-1.34536698e-01,  1.49655193e-01, -1.12776577e-01],\n","       [-1.43807575e-01,  1.19708836e-01,  3.81187983e-02],\n","       [-1.37287408e-01, -7.39530846e-02,  7.63294250e-02],\n","       [ 1.28275648e-01, -4.10148203e-02, -1.23371519e-01],\n","       [ 3.33081372e-02,  1.28214136e-01, -6.02826960e-02],\n","       [ 4.54025827e-02,  1.09561935e-01, -2.79118400e-02],\n","       [ 1.32302552e-01,  8.48704949e-02,  1.34701535e-01],\n","       [ 1.06844872e-01, -6.35624155e-02,  1.43744662e-01],\n","       [-7.78660504e-03,  8.45984370e-02,  1.13172978e-01],\n","       [-1.34478584e-01, -1.23875201e-01,  8.91425684e-02],\n","       [ 1.14631042e-01,  8.45129834e-05,  4.64955233e-02],\n","       [-1.43691808e-01, -1.28129065e-01, -9.50599089e-03],\n","       [ 1.69463493e-02, -1.20065147e-02, -8.16680118e-02],\n","       [ 1.30416960e-01, -1.29934162e-01, -5.54553457e-02],\n","       [-9.91798639e-02,  1.21889085e-01, -4.15938534e-02],\n","       [ 1.19077809e-01,  2.04573628e-02,  7.38750771e-02],\n","       [-9.45372209e-02,  5.71545772e-02,  8.96428823e-02],\n","       [ 9.20557901e-02, -1.48774117e-01, -1.36329293e-01],\n","       [ 2.79506575e-02,  1.04973227e-01,  7.70065859e-02],\n","       [-3.29998806e-02,  1.06720969e-01, -4.18490432e-02],\n","       [ 1.23122446e-01, -3.61825712e-02,  6.93769157e-02],\n","       [ 5.05331680e-02, -6.65839091e-02, -1.46715313e-01],\n","       [ 8.12003613e-02, -8.50389898e-02,  6.70657381e-02],\n","       [-8.78179967e-02, -1.99282635e-02, -6.68487102e-02],\n","       [-1.19566694e-01, -9.24358889e-02, -1.48408547e-01],\n","       [ 2.48606168e-02, -1.46739230e-01,  8.12217444e-02],\n","       [-8.61170813e-02,  1.39809340e-01, -1.22139290e-01],\n","       [-9.26610008e-02,  9.70658585e-02, -1.48876578e-01],\n","       [ 2.40896679e-02, -1.00175813e-01, -3.79424803e-02],\n","       [-1.42202266e-02,  7.64169395e-02,  8.44655484e-02],\n","       [-1.27056718e-01,  6.18903078e-02, -9.63338763e-02],\n","       [ 6.89418614e-02,  1.20204613e-01, -4.56386283e-02],\n","       [ 1.51687674e-02, -1.18821025e-01, -3.74355912e-03],\n","       [ 1.60640422e-02, -6.35097697e-02,  9.82844234e-02],\n","       [-9.62122306e-02,  1.97371338e-02,  5.43858483e-02],\n","       [ 8.49104449e-02, -8.37488994e-02,  9.36105847e-02],\n","       [-6.61160499e-02,  1.37737781e-01, -6.84811175e-02],\n","       [-5.54900542e-02,  1.35782957e-01, -8.00179690e-02],\n","       [-8.88721347e-02,  3.63274524e-03,  3.02619301e-02],\n","       [ 6.23397529e-02,  1.39966458e-01,  4.19326760e-02],\n","       [-7.87554234e-02, -1.36583120e-01, -1.44520253e-01],\n","       [-6.85145259e-02,  7.00723901e-02, -1.47133559e-01],\n","       [ 1.03016056e-01,  1.69535484e-02,  1.14653930e-01],\n","       [ 1.25349551e-01,  9.99600887e-02, -6.89426512e-02],\n","       [-2.37796549e-02, -1.24590716e-03, -1.37046307e-01],\n","       [ 9.57419202e-02, -7.46317655e-02,  6.65483847e-02],\n","       [ 7.33280629e-02, -1.51082382e-01, -8.86205435e-02],\n","       [-5.51837198e-02, -1.39814764e-01,  6.07254840e-02],\n","       [-5.11277542e-02, -1.01831518e-01,  2.59528030e-02],\n","       [ 7.02388436e-02, -5.40591851e-02, -3.76243815e-02],\n","       [-1.37825757e-01, -9.51488987e-02,  2.29836311e-02],\n","       [ 1.19744405e-01,  2.86983475e-02,  1.93537511e-02],\n","       [-1.77411065e-02, -1.00784510e-01, -2.23530401e-02],\n","       [-1.06892765e-01,  1.48463145e-01,  1.38419852e-01],\n","       [ 7.91417900e-04,  7.78255388e-02, -2.38888562e-02],\n","       [-1.01266414e-01, -2.63505410e-02, -8.82633328e-02],\n","       [ 2.08351593e-02,  4.22987193e-02,  1.13554865e-01],\n","       [-2.67350618e-02,  1.41517833e-01,  1.23571992e-01],\n","       [ 1.31157905e-01,  3.26865129e-02, -2.96041146e-02],\n","       [-1.10324591e-01,  9.56771225e-02, -1.18941590e-01],\n","       [-2.02206487e-04, -7.03859404e-02,  1.30194470e-01],\n","       [ 1.30199164e-01,  1.35234490e-01,  3.26693878e-02],\n","       [-1.36069283e-01, -1.15938857e-01,  7.83616528e-02],\n","       [ 1.73500199e-02,  1.40986666e-01, -3.19593884e-02],\n","       [-1.02209166e-01,  1.41176537e-01, -1.21149413e-01],\n","       [ 1.69420522e-02,  1.95952505e-02, -6.38668463e-02],\n","       [ 1.57421753e-02, -7.20756501e-02,  1.42897919e-01],\n","       [ 6.93926662e-02, -9.92336273e-02, -1.03226088e-01],\n","       [-5.27997389e-02,  1.46367624e-01,  1.51642919e-01],\n","       [ 3.82190682e-02,  2.06560623e-02, -7.78514799e-03],\n","       [-5.67420237e-02, -7.50221871e-03, -5.73123693e-02],\n","       [-5.97885698e-02, -7.64901340e-02, -6.59157634e-02],\n","       [-2.33685095e-02,  1.12903051e-01,  1.27477258e-01],\n","       [ 6.82593361e-02, -1.04552919e-05, -5.78808673e-02],\n","       [ 7.38298222e-02,  5.45626208e-02,  7.73755461e-02],\n","       [-1.24372743e-01,  4.25963961e-02, -1.00365818e-01],\n","       [-3.39724533e-02, -1.08604304e-01, -4.31393906e-02],\n","       [-3.78796197e-02,  1.67710073e-02, -1.37981409e-02],\n","       [ 6.69045970e-02,  7.97847509e-02, -1.05781958e-01],\n","       [-1.10599458e-01,  6.91529363e-02, -8.46680924e-02],\n","       [-6.21629208e-02, -8.78953189e-02, -6.33777902e-02],\n","       [ 3.01529653e-02, -2.11939048e-02,  4.70884554e-02],\n","       [-1.29740864e-01,  3.46490927e-02, -1.04978479e-01],\n","       [ 1.21233305e-02, -6.24079965e-02, -5.23763299e-02],\n","       [-8.55904073e-02,  3.75756361e-02,  1.30838126e-01],\n","       [ 3.74879986e-02, -1.19623445e-01, -3.30207571e-02],\n","       [-2.43097674e-02, -1.45158798e-01, -1.19450934e-01],\n","       [ 1.39147222e-01, -1.33792236e-01, -1.38460636e-01],\n","       [-3.54953147e-02, -1.32888481e-01, -2.61495877e-02],\n","       [ 3.46011855e-03,  1.23811632e-01,  1.00938611e-01],\n","       [ 6.01627529e-02,  4.32640798e-02,  1.01642758e-01],\n","       [-1.25833407e-01, -9.22421813e-02, -1.38349637e-01],\n","       [-1.11653671e-01,  1.35839328e-01,  5.23540042e-02],\n","       [-9.43206400e-02,  1.47427432e-02,  1.07460484e-01],\n","       [ 1.18649304e-01,  2.19570976e-02,  8.98677185e-02],\n","       [ 9.45835114e-02,  3.94375958e-02, -1.44835159e-01]], dtype=float32)>, <tf.Variable 'dense_221/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[-6.76404834e-02, -4.96870987e-02, -1.24830576e-02],\n","       [ 2.18858826e-03, -1.67809948e-01, -1.93576008e-01],\n","       [ 1.34922370e-01, -8.67040232e-02, -1.40379861e-01],\n","       [-1.37971520e-01, -1.71312943e-01,  7.74456784e-02],\n","       [-1.81346223e-01,  4.74121980e-02,  1.00205012e-01],\n","       [ 9.17574987e-02,  2.77253315e-02, -1.29313454e-01],\n","       [ 3.93212624e-02,  4.36550453e-02,  1.53346926e-01],\n","       [-3.64865214e-02, -1.56036830e-02,  1.61256850e-01],\n","       [-7.22440407e-02, -2.07137629e-01,  1.45236835e-01],\n","       [ 1.20124042e-01, -1.27066774e-02, -6.01176433e-02],\n","       [ 1.26100048e-01, -1.95129305e-01, -1.35721296e-01],\n","       [-1.37798995e-01, -1.46161914e-01,  1.30313709e-02],\n","       [-2.08825752e-01, -8.81883278e-02, -1.72940135e-01],\n","       [-1.77513868e-01,  1.50958925e-01, -1.80353373e-01],\n","       [-2.03088060e-01, -1.50850743e-01, -6.84966221e-02],\n","       [-9.20128152e-02,  1.52301863e-01,  1.70881435e-01],\n","       [-2.09308788e-02,  8.36160034e-02,  1.26096755e-01],\n","       [-1.37675092e-01, -5.84451435e-03, -1.99196056e-01],\n","       [-1.65374175e-01, -2.10342467e-01, -9.73299071e-02],\n","       [-1.78214580e-01, -7.82644451e-02, -2.07971722e-01],\n","       [-3.89465317e-02, -2.35583521e-02,  5.90849444e-02],\n","       [-4.82417122e-02, -4.70267497e-02,  1.25334710e-01],\n","       [ 2.03182578e-01,  8.97162706e-02,  1.77497774e-01],\n","       [-1.52011931e-01,  8.73178989e-02, -1.84581771e-01],\n","       [ 1.25835001e-01, -1.80192962e-01, -1.87688038e-01],\n","       [-6.21968806e-02, -1.91710964e-01,  1.77908480e-01],\n","       [-2.67879274e-02,  4.01462913e-02,  1.50456671e-02],\n","       [-1.87738448e-01, -1.11067392e-01, -1.60143241e-01],\n","       [ 1.10863641e-01, -1.03199616e-01, -1.84023499e-01],\n","       [ 1.35621116e-01,  9.44667608e-02,  9.12109837e-02],\n","       [-8.10397044e-02, -1.17022723e-01,  1.58334747e-01],\n","       [-8.19614157e-02,  4.20568250e-02,  4.57677990e-02],\n","       [-2.48265844e-02,  7.18599046e-03, -1.71663001e-01],\n","       [-2.21004207e-02,  1.42609864e-01, -3.82374376e-02],\n","       [ 1.06459692e-01,  1.21032111e-01,  1.11729793e-01],\n","       [-2.01120168e-01,  1.75670192e-01, -9.65492055e-02],\n","       [-4.53633182e-02,  1.11731216e-01, -1.74080491e-01],\n","       [ 1.00365162e-01,  1.16734676e-01, -5.54106683e-02],\n","       [-3.66418846e-02, -4.01072726e-02,  7.56539591e-03],\n","       [ 1.84707314e-01, -8.27955306e-02,  1.77657530e-01],\n","       [ 6.64725229e-02,  1.18280150e-01,  7.45339617e-02],\n","       [ 8.06977227e-02, -8.68711527e-03, -1.83235124e-01],\n","       [ 1.14661679e-01,  1.94801971e-01, -2.01149866e-01],\n","       [ 2.04700500e-01, -1.74968883e-01, -1.16233185e-01],\n","       [-1.12887688e-01, -1.75463602e-01, -6.51406273e-02],\n","       [-1.33569568e-01,  1.49188429e-01,  1.44645557e-01],\n","       [-1.09292798e-01,  1.57740459e-01, -1.18032686e-01],\n","       [-1.99263826e-01,  1.87840700e-01, -1.42781183e-01],\n","       [ 5.34032285e-02,  7.20711499e-02, -5.76494895e-02],\n","       [ 4.11497429e-02,  5.02919629e-02, -8.88772383e-02],\n","       [ 1.83445603e-01, -1.39864996e-01, -1.99766889e-01],\n","       [ 1.59784496e-01, -1.83835566e-01,  1.95141435e-01],\n","       [-1.48591042e-01, -9.31420922e-02,  1.68219149e-01],\n","       [ 1.10082559e-01, -4.20563519e-02, -1.41179636e-01],\n","       [-1.00189060e-01,  1.81498423e-01, -9.29895714e-02],\n","       [-1.80816770e-01,  1.14644520e-01, -2.77463831e-02],\n","       [ 2.41827425e-02, -4.41308841e-02, -1.84863687e-01],\n","       [ 4.28251773e-02,  1.25281841e-01, -6.75405636e-02],\n","       [ 7.88887590e-02, -1.07481107e-01,  7.67068714e-02],\n","       [-5.67079410e-02,  5.85784353e-02,  1.19041353e-04],\n","       [ 1.60826594e-02, -1.50696605e-01,  1.12659141e-01],\n","       [-1.12311348e-01, -7.96808675e-02,  1.82240456e-01],\n","       [-1.58083722e-01,  1.40557513e-01, -2.28142180e-02],\n","       [-8.96906704e-02, -4.19519423e-03, -5.79746775e-02],\n","       [ 3.24258097e-02,  1.81784362e-01,  4.92382050e-02],\n","       [-1.17806822e-01, -6.41684979e-02, -1.65767044e-01],\n","       [ 9.37713683e-02, -1.27436802e-01, -2.02678889e-01],\n","       [-1.49127558e-01,  1.56520888e-01,  2.00504035e-01],\n","       [-6.59345910e-02,  1.70105353e-01, -2.13467807e-01],\n","       [ 7.03968853e-02, -1.33070126e-01, -1.11021347e-01],\n","       [-1.12555355e-01, -2.03130350e-01,  1.02485023e-01],\n","       [ 1.97699040e-01,  1.63348675e-01,  1.68887571e-01],\n","       [-1.88333079e-01,  1.52078196e-01, -9.68595222e-02],\n","       [ 2.48344173e-03,  1.29288062e-01, -3.56862843e-02],\n","       [ 6.52883053e-02,  6.88644275e-02,  1.89274147e-01],\n","       [ 1.84424996e-01, -7.79867172e-02, -2.08111793e-01],\n","       [-2.03040153e-01, -3.02089266e-02, -2.10498273e-02],\n","       [-1.85844660e-01, -6.84810579e-02,  1.56354040e-01],\n","       [-7.41931424e-02, -9.95046943e-02,  6.69087917e-02],\n","       [-9.49327871e-02, -1.94378898e-01, -4.76672016e-02],\n","       [ 1.42853037e-01,  1.41898826e-01, -5.34048639e-02],\n","       [-1.85786352e-01,  1.73722714e-01, -1.03996415e-02],\n","       [ 4.24065888e-02, -1.52413934e-01,  1.87530458e-01],\n","       [-2.67163143e-02, -1.71409488e-01,  2.02873990e-01],\n","       [ 2.04920173e-01,  2.07462251e-01, -8.81134868e-02],\n","       [-2.12811843e-01, -9.19697806e-02, -2.04185665e-01],\n","       [ 1.29172117e-01, -2.02546135e-01, -1.48678139e-01],\n","       [-1.33440318e-02,  1.97940022e-01, -4.47789356e-02],\n","       [-1.56937987e-01, -1.34966865e-01,  1.38051018e-01],\n","       [-1.14438206e-01,  1.51871645e-03,  2.06619725e-01],\n","       [ 1.29815698e-01, -7.99825191e-02,  2.04843327e-01],\n","       [ 1.47283107e-01,  9.95321125e-02, -9.85493809e-02],\n","       [ 1.45993486e-01, -6.01186678e-02,  1.85830131e-01],\n","       [-1.91699997e-01,  1.70697108e-01, -1.38374701e-01],\n","       [ 1.38739929e-01, -2.11152181e-01, -6.68330193e-02],\n","       [-1.62473783e-01,  1.50541604e-01,  2.01561794e-01],\n","       [-1.09395817e-01,  2.14232150e-02,  8.35151821e-02],\n","       [ 1.55592948e-01, -4.81262570e-03, -1.68009460e-01],\n","       [ 1.25668719e-01, -6.94614798e-02,  1.32321134e-01],\n","       [-1.73951223e-01,  1.03594594e-01, -4.35892493e-02],\n","       [ 2.93897446e-02,  1.44359795e-02, -7.74413794e-02],\n","       [-8.50893632e-02,  1.46646336e-01, -5.31538650e-02],\n","       [ 2.00004548e-01,  5.02839535e-02, -6.77923635e-02],\n","       [-2.06478760e-01,  2.13981152e-01,  3.27925459e-02],\n","       [ 1.27129972e-01,  1.42693713e-01, -1.34587511e-01],\n","       [-1.74171656e-01, -1.90323651e-01, -1.63348854e-01],\n","       [ 7.46595636e-02, -2.64353678e-02,  1.67088196e-01],\n","       [ 3.82380337e-02,  3.88613231e-02,  5.42887896e-02],\n","       [ 9.49101374e-02, -1.21052116e-01, -2.12583020e-02],\n","       [ 5.25479317e-02, -2.02681169e-01, -2.08119035e-01],\n","       [-1.27893418e-01, -2.48306617e-02, -2.41056941e-02],\n","       [ 1.05859712e-01,  1.50587142e-01, -1.89836264e-01],\n","       [-1.22225508e-01,  8.86136740e-02, -1.13689192e-01],\n","       [ 8.27887878e-02,  1.53827816e-01,  6.61066175e-02],\n","       [ 1.42818913e-01,  1.75817728e-01,  1.49304003e-01],\n","       [ 1.17743246e-01, -2.80705765e-02, -1.54589385e-01],\n","       [ 6.31539077e-02,  1.37770921e-01,  7.11058304e-02],\n","       [-2.31581591e-02, -1.21797323e-01, -9.19876471e-02],\n","       [-1.07794084e-01,  9.48167294e-02,  7.27392733e-02],\n","       [ 1.42558739e-01, -1.15607001e-01,  1.91065460e-01],\n","       [ 1.05900459e-01, -9.56128985e-02, -5.80937266e-02],\n","       [-1.56860307e-01, -1.74921721e-01,  9.05375034e-02],\n","       [-5.45801176e-03, -8.18008382e-04,  1.24849841e-01],\n","       [-1.86143652e-01, -1.75409377e-01, -3.69549990e-02],\n","       [-1.11327596e-01,  2.53973585e-02, -1.02149405e-01],\n","       [-2.96806432e-02, -5.00418581e-02,  2.02576920e-01],\n","       [ 3.67690064e-02, -3.07874158e-02,  1.37240188e-02],\n","       [ 1.20452084e-01,  1.27817556e-01,  9.25339311e-02]], dtype=float32)>, <tf.Variable 'dense_222/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[-3.36810872e-02, -6.02033772e-02,  4.87429947e-02],\n","       [ 1.27512142e-01,  6.40282705e-02, -6.38049841e-03],\n","       [ 1.78150028e-01, -8.66123661e-03,  2.08679527e-01],\n","       [ 1.95135385e-01, -1.44045204e-01,  1.69344202e-01],\n","       [-1.69981733e-01,  1.42333463e-01,  2.00156301e-01],\n","       [ 2.07740553e-02, -1.00682169e-01,  7.67744556e-02],\n","       [-2.09434777e-01,  1.58752203e-01,  1.24935694e-01],\n","       [ 1.45923361e-01, -5.11710271e-02, -9.01366100e-02],\n","       [-1.71262518e-01, -1.55259222e-01, -2.04613775e-01],\n","       [ 6.76656663e-02, -1.28824720e-02,  9.32503343e-02],\n","       [ 4.03330475e-02, -5.48162684e-02,  1.10019352e-02],\n","       [ 1.32811829e-01,  1.03000939e-01,  6.65860921e-02],\n","       [ 1.69031352e-01, -1.84268489e-01,  1.03716686e-01],\n","       [-7.32386038e-02, -1.76032797e-01, -2.03866035e-01],\n","       [ 8.50833803e-02,  1.01667210e-01, -1.98740438e-01],\n","       [-1.95535541e-01, -7.97585994e-02,  8.68871734e-02],\n","       [ 8.01420361e-02, -1.43072769e-01, -1.26090482e-01],\n","       [-1.13360494e-01, -1.62058830e-01,  3.22955586e-02],\n","       [ 1.82571709e-01, -1.81964189e-01,  1.06459722e-01],\n","       [-8.83751959e-02,  8.22391286e-02,  5.02772480e-02],\n","       [-1.80221096e-01,  1.28905877e-01, -1.64385006e-01],\n","       [ 1.56303525e-01, -1.57178953e-01,  3.45190987e-02],\n","       [-1.33618236e-01,  1.12163797e-01,  1.55965343e-01],\n","       [-5.32076694e-02, -1.28949031e-01,  2.25291289e-02],\n","       [ 1.34451017e-01,  1.77287310e-01, -9.40121263e-02],\n","       [-1.76064402e-01,  2.31115166e-02, -1.21123403e-01],\n","       [ 1.30411625e-01, -1.43849537e-01,  4.80892770e-02],\n","       [-8.07814077e-02,  1.30512729e-01,  1.63649678e-01],\n","       [ 6.07987400e-03,  1.00344509e-01,  5.62025607e-02],\n","       [ 5.86597249e-02,  1.49417385e-01, -1.16655245e-01],\n","       [ 1.25518709e-01,  1.67400897e-01,  1.14249267e-01],\n","       [-1.73370585e-01, -5.58214448e-02, -8.35121423e-02],\n","       [-1.81925502e-02,  7.68477395e-02,  1.50004640e-01],\n","       [-1.86794639e-01, -1.36836886e-01,  9.01279226e-02],\n","       [ 1.87823102e-01, -6.49262145e-02,  1.88730419e-01],\n","       [-2.03558803e-01,  1.44710347e-01,  9.86562967e-02],\n","       [ 4.10974845e-02, -2.01401159e-01,  2.95107067e-02],\n","       [-3.14209983e-02, -6.82348609e-02, -1.47127494e-01],\n","       [ 1.40373111e-01, -8.74826610e-02, -1.39616117e-01],\n","       [-2.03952551e-01, -1.02434037e-02, -1.52203053e-01],\n","       [-1.08723275e-01,  2.07276955e-01, -1.74196362e-01],\n","       [ 1.04676373e-02,  7.63933733e-02, -8.15916583e-02],\n","       [-1.10345423e-01,  1.70256048e-01, -2.06876602e-02],\n","       [-1.29209802e-01, -1.56991452e-01,  9.76518616e-02],\n","       [-3.84767056e-02,  3.56493369e-02, -1.10874763e-02],\n","       [ 7.71946982e-02,  1.81333140e-01, -2.75276368e-03],\n","       [-1.59388348e-01, -1.51535302e-01,  1.54284388e-01],\n","       [ 1.65629476e-01, -1.57543078e-01,  1.00966908e-01],\n","       [ 3.99975888e-02,  2.07845774e-02,  1.54952362e-01],\n","       [-1.73817039e-01, -2.10354850e-02, -1.33703193e-02],\n","       [-1.71137571e-01, -1.07990652e-01,  2.02404752e-01],\n","       [-1.11970626e-01, -2.13963926e-01,  1.46711305e-01],\n","       [ 1.25550568e-01,  1.96718171e-01, -6.07822053e-02],\n","       [-1.05375186e-01,  1.17780514e-01,  1.88023120e-01],\n","       [ 1.23512447e-01, -1.77604035e-01,  8.69787037e-02],\n","       [ 9.71083865e-02,  2.32596640e-02, -7.90798441e-02],\n","       [ 2.05769181e-01,  5.48755676e-02, -2.29854006e-02],\n","       [ 1.36111453e-01,  1.61840245e-01, -4.81894910e-02],\n","       [ 1.39959380e-01,  5.50536402e-02, -1.04303099e-01],\n","       [ 8.63577574e-02,  4.48693074e-02,  2.65483912e-02],\n","       [ 6.44048629e-03, -1.76112011e-01, -1.35005653e-01],\n","       [ 1.24232091e-01,  1.36276349e-01,  1.57412171e-01],\n","       [-5.51918484e-02,  1.35214269e-01,  2.03671679e-01],\n","       [ 3.95533778e-02,  2.13375520e-02,  1.80246726e-01],\n","       [-1.37771204e-01, -1.12515651e-01, -6.56842291e-02],\n","       [-1.17418148e-01, -2.01033533e-01, -3.54870073e-02],\n","       [ 1.30575215e-02,  2.20494848e-02, -1.51413353e-02],\n","       [-1.29956424e-01, -1.59876019e-01,  2.75457073e-02],\n","       [ 4.94683385e-02,  4.75433730e-02, -8.24468806e-02],\n","       [ 1.75663769e-01,  1.38407484e-01,  5.33711463e-02],\n","       [-8.07446986e-02,  1.98060229e-01,  9.25547183e-02],\n","       [-2.05626667e-01, -4.79587317e-02, -1.80073325e-02],\n","       [-6.86780810e-02, -3.65818515e-02,  1.86984509e-01],\n","       [-1.11226290e-01, -6.63548037e-02,  8.06059316e-02],\n","       [-7.52209574e-02,  3.18135656e-02, -8.46618786e-02],\n","       [-1.02223054e-01, -9.54723582e-02, -1.51056126e-01],\n","       [-1.04972638e-01, -2.15544011e-02, -6.66160658e-02],\n","       [ 4.29210402e-02,  1.86137035e-01, -4.39100387e-03],\n","       [-3.06228995e-02, -2.11367175e-01,  1.15503326e-01],\n","       [-1.18896641e-01,  1.22056007e-01, -2.04267621e-01],\n","       [ 1.76028565e-01,  1.12978473e-01, -1.90390483e-01],\n","       [-7.22772181e-02, -3.73264439e-02, -1.39839366e-01],\n","       [ 1.06467776e-01, -4.99230139e-02,  1.23097626e-02],\n","       [ 1.18276346e-02, -4.72898334e-02, -8.55724290e-02],\n","       [ 1.55160502e-01,  1.54204778e-02,  1.47000169e-02],\n","       [-6.23793788e-02, -1.84781581e-01, -6.41632527e-02],\n","       [ 1.17893189e-01, -1.44432649e-01, -1.62095681e-01],\n","       [-1.58704802e-01,  2.12178588e-01, -1.63368404e-01],\n","       [ 2.92810407e-02, -1.48701340e-01,  9.57441702e-02],\n","       [ 2.10063811e-02,  8.01768526e-02, -4.80188727e-02],\n","       [-7.88415223e-03,  5.84154762e-02,  1.66601706e-02],\n","       [ 1.43356621e-01,  1.87770233e-01,  1.52648896e-01],\n","       [-2.11529527e-02, -3.50036211e-02,  1.54747833e-02],\n","       [ 1.29325390e-01, -1.49445653e-01, -2.03650340e-01],\n","       [ 8.94028470e-02,  1.72714010e-01,  7.30830850e-03],\n","       [-1.07779875e-01, -1.27480283e-01, -9.70826596e-02],\n","       [-1.30304620e-01,  5.33225387e-02, -1.50910541e-01],\n","       [-6.14449047e-02,  1.54263586e-01, -3.52042392e-02],\n","       [ 1.31863654e-01,  1.02739044e-01, -1.48658693e-01],\n","       [ 1.21896230e-01, -1.32704884e-01,  1.89009547e-01],\n","       [ 1.31793797e-01,  2.04052906e-02, -9.08413157e-02],\n","       [-9.12824050e-02,  4.38713655e-02, -1.86864480e-01],\n","       [-1.27013981e-01,  1.32598832e-01,  1.84830040e-01],\n","       [-2.05511332e-01, -9.94736403e-02, -1.20464183e-01],\n","       [-1.56123668e-01,  1.45971000e-01, -8.49879831e-02],\n","       [-1.85029939e-01, -7.65354484e-02,  9.98823717e-02],\n","       [-1.61201566e-01, -1.72644764e-01, -1.93990871e-01],\n","       [-8.43644813e-02, -1.33494705e-01, -4.86493576e-03],\n","       [-6.65309727e-02, -7.63787702e-02, -2.96831504e-02],\n","       [ 1.77822277e-01, -1.95743173e-01, -7.66565055e-02],\n","       [ 7.13019222e-02, -2.11762451e-02,  6.32739291e-02],\n","       [ 1.56468034e-01, -9.79569852e-02,  8.36348757e-02],\n","       [ 4.49454375e-02, -1.34674147e-01, -2.00711325e-01],\n","       [-1.84089422e-01,  1.50553867e-01,  1.86478440e-02],\n","       [-1.36703208e-01,  1.71465710e-01,  8.34025964e-02],\n","       [-1.04527652e-01,  1.85206905e-01, -9.29453373e-02],\n","       [ 2.06512481e-01, -5.44922519e-03, -1.87239587e-01],\n","       [-1.51246767e-02, -1.33231953e-01,  2.96918303e-02],\n","       [ 1.68625727e-01, -1.79352731e-01, -1.62234351e-01],\n","       [-1.99952672e-04, -1.44877927e-02,  1.84674814e-01],\n","       [-2.04401150e-01, -5.19357100e-02,  2.07738772e-01],\n","       [ 1.95693389e-01,  1.18431687e-01,  2.05045953e-01],\n","       [-5.43433167e-02,  1.60129994e-01,  2.03215644e-01],\n","       [-7.38962926e-03, -7.69954622e-02, -1.42964333e-01],\n","       [ 2.86204703e-02,  1.79633930e-01,  1.28067210e-01],\n","       [-1.16803534e-01,  3.60964276e-02,  1.87511966e-01],\n","       [ 1.88417763e-01,  6.76118806e-02, -1.82859644e-01],\n","       [ 1.80391371e-01, -1.48817867e-01,  1.24780476e-01]], dtype=float32)>, <tf.Variable 'dense_223/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[ 0.06118993, -0.15809001, -0.18828884],\n","       [-0.19624548, -0.00976523,  0.00413788],\n","       [-0.20723441,  0.16331485, -0.0287495 ],\n","       [-0.16219392,  0.01675832, -0.02723372],\n","       [ 0.13408543, -0.00103862,  0.18210101],\n","       [-0.02161189, -0.18040131, -0.03314308],\n","       [ 0.10468523,  0.15852611,  0.0705016 ],\n","       [ 0.19228674, -0.21042445,  0.00060676],\n","       [-0.13517869, -0.13782677, -0.08210872],\n","       [ 0.06946868,  0.20348987,  0.12704931],\n","       [-0.05564392,  0.11797707,  0.19749738],\n","       [-0.01317437, -0.15199773,  0.12992485],\n","       [-0.06062251, -0.16306132, -0.15300165],\n","       [ 0.03960696, -0.03168929,  0.08579112],\n","       [ 0.09761971,  0.1738854 ,  0.10224018],\n","       [-0.15079272,  0.19212338,  0.1936574 ],\n","       [ 0.16694975,  0.19903259, -0.20437977],\n","       [ 0.11523075,  0.18564878, -0.15913391],\n","       [ 0.19873148,  0.05136516, -0.07185496],\n","       [ 0.20665435,  0.15347354,  0.20488495],\n","       [ 0.03328421,  0.17031454, -0.14209569],\n","       [ 0.11819186,  0.02772846,  0.11988968],\n","       [-0.14468126,  0.05105388, -0.19240183],\n","       [ 0.07545459,  0.08805932,  0.0159427 ],\n","       [ 0.18497069, -0.02334871, -0.07853378],\n","       [ 0.09516135,  0.1485557 ,  0.11659806],\n","       [ 0.09509026, -0.17126876,  0.0058795 ],\n","       [ 0.13237382,  0.15533617,  0.14375319],\n","       [-0.03907912,  0.06248843,  0.10448884],\n","       [ 0.03870471, -0.03668778, -0.12929122],\n","       [-0.10170995, -0.08280257, -0.16448635],\n","       [ 0.06344037, -0.12256184,  0.18386884],\n","       [ 0.02077974, -0.04295468,  0.02057552],\n","       [-0.13614799,  0.01429213, -0.19236825],\n","       [-0.15376252, -0.12201715,  0.19705498],\n","       [ 0.1463745 , -0.16589974, -0.14231452],\n","       [ 0.18814991, -0.18606672,  0.04074464],\n","       [ 0.19342001, -0.1289229 , -0.13740505],\n","       [ 0.01166935,  0.03492612,  0.09579627],\n","       [-0.01147151, -0.15545532,  0.07308272],\n","       [ 0.10897694,  0.12083974, -0.16927959],\n","       [ 0.03421663, -0.15116884, -0.2000492 ],\n","       [ 0.10774167,  0.12107281, -0.00817201],\n","       [ 0.05119511, -0.16002853, -0.09114603],\n","       [ 0.06732386,  0.09507647, -0.12931551],\n","       [ 0.18849073,  0.08888156, -0.01781341],\n","       [ 0.18534026, -0.05639114,  0.16208848],\n","       [-0.13980891,  0.02898623, -0.14920144],\n","       [-0.166638  ,  0.02204145,  0.07179575],\n","       [-0.12674393, -0.19086596, -0.13575804],\n","       [-0.09558296, -0.03806797, -0.0892114 ],\n","       [ 0.07804815,  0.16880542, -0.0616497 ],\n","       [-0.03216724,  0.15281612, -0.08608757],\n","       [ 0.02083831, -0.12320894, -0.09501442],\n","       [ 0.16300115,  0.19708085, -0.05852567],\n","       [ 0.0081009 , -0.16452275, -0.14735062],\n","       [-0.11307003,  0.13295342,  0.02637333],\n","       [ 0.05119918, -0.12205672, -0.1393659 ],\n","       [-0.1850778 ,  0.01673073,  0.04149875],\n","       [-0.03131472,  0.04130309, -0.15172887],\n","       [-0.06710181,  0.00477003,  0.00070241],\n","       [-0.07432178,  0.09352695,  0.17387809],\n","       [-0.02190592,  0.08528083,  0.16425216],\n","       [-0.1055304 , -0.13082796, -0.04653072],\n","       [-0.17826486, -0.02819398,  0.06164234],\n","       [-0.21134514,  0.19615823,  0.06378543],\n","       [-0.00246889, -0.16843113,  0.03835037],\n","       [-0.01226195, -0.10429173,  0.15445812],\n","       [-0.00899018,  0.03081247,  0.10136221],\n","       [-0.07522023,  0.09485407, -0.07371601],\n","       [-0.04436092, -0.12915386,  0.09379709],\n","       [ 0.15497781,  0.16584651,  0.12747636],\n","       [-0.13070945, -0.00966904,  0.1673473 ],\n","       [-0.148461  ,  0.06330262,  0.11688409],\n","       [-0.14754745,  0.06154979,  0.051447  ],\n","       [-0.01624683, -0.1996125 ,  0.03449176],\n","       [-0.09765878,  0.08098301,  0.06690023],\n","       [ 0.07599903, -0.18115784,  0.18859208],\n","       [ 0.02418706, -0.19672287,  0.06476865],\n","       [ 0.11248892,  0.0741623 ,  0.13165537],\n","       [ 0.146945  , -0.13534571, -0.0332397 ],\n","       [-0.03480676,  0.14467743, -0.07037748],\n","       [ 0.17717932, -0.14999254, -0.0735002 ],\n","       [-0.00638662,  0.10675383, -0.15207662],\n","       [ 0.0293676 ,  0.15724832, -0.0269517 ],\n","       [ 0.06809361, -0.02028014, -0.06913843],\n","       [ 0.15250471, -0.01322651, -0.04139084],\n","       [-0.20295401,  0.19997047,  0.05431615],\n","       [-0.08506301,  0.11915254, -0.06009953],\n","       [-0.12574665, -0.07381695, -0.11196271],\n","       [-0.12356204, -0.0428177 ,  0.15773028],\n","       [ 0.13643312, -0.16421904, -0.01733479],\n","       [ 0.15544645, -0.05487134, -0.0714099 ],\n","       [ 0.08326377,  0.10505628, -0.06023994],\n","       [ 0.15856281,  0.00080378, -0.17375687],\n","       [-0.07319082,  0.01601836, -0.04493979],\n","       [ 0.14282091,  0.09844106,  0.14095783],\n","       [ 0.00311547,  0.09753758,  0.04041353],\n","       [-0.19532582, -0.11161833, -0.1953765 ],\n","       [ 0.03092827,  0.07085422, -0.12183218],\n","       [-0.10704155, -0.13116018, -0.1349472 ],\n","       [ 0.14855173, -0.11869327, -0.11427613],\n","       [-0.13985898,  0.19359855, -0.05266134],\n","       [ 0.09687617,  0.1166005 ,  0.12148438],\n","       [-0.02427248, -0.06158177,  0.07839098],\n","       [ 0.16627647, -0.01434179,  0.05628324],\n","       [-0.12405894,  0.05634732,  0.05922383],\n","       [-0.14155623,  0.12405796, -0.0605303 ],\n","       [ 0.20743027, -0.0963484 ,  0.18553138],\n","       [-0.03728152,  0.00819675,  0.09078767],\n","       [-0.00634591,  0.03511527, -0.12417816],\n","       [ 0.12073428, -0.09375086, -0.12571174],\n","       [-0.09608697, -0.12528455,  0.00649611],\n","       [ 0.16546991,  0.1648097 , -0.00585364],\n","       [-0.18393338, -0.07531264, -0.04067252],\n","       [ 0.09376461,  0.17673853, -0.14459857],\n","       [-0.0980662 , -0.06682856, -0.2110788 ],\n","       [-0.00390841, -0.13637668, -0.08413567],\n","       [ 0.06864355,  0.04035426,  0.15873583],\n","       [ 0.06862523, -0.00461643,  0.17380133],\n","       [ 0.19300085, -0.10866123,  0.08079984],\n","       [ 0.00746024, -0.06498488, -0.18462034],\n","       [-0.12728529,  0.17552502,  0.03721866],\n","       [ 0.10274288, -0.15804043,  0.10166321],\n","       [-0.0210062 ,  0.08491688,  0.13606119],\n","       [-0.17505828, -0.12031839,  0.03096972],\n","       [ 0.01378576,  0.07478374,  0.19277038],\n","       [ 0.09635428, -0.18760003,  0.02448948]], dtype=float32)>, <tf.Variable 'dense_224/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[-0.00258342,  0.05486742,  0.00288201, ..., -0.06435577,\n","        -0.02337978,  0.00769655],\n","       [ 0.01353177, -0.01460615, -0.04049063, ..., -0.05990133,\n","         0.06366189, -0.03790674],\n","       [ 0.00923676, -0.00455665,  0.00766419, ..., -0.01158787,\n","        -0.00086735, -0.02780791],\n","       ...,\n","       [-0.03590259,  0.00172065, -0.04465123, ..., -0.01586409,\n","        -0.04678613,  0.0480087 ],\n","       [-0.05537404, -0.06075775, -0.05222946, ..., -0.01708882,\n","         0.03727218, -0.01158393],\n","       [ 0.03130388,  0.03295323, -0.0615468 , ...,  0.0213319 ,\n","         0.04070033,  0.0193569 ]], dtype=float32)>, <tf.Variable 'dense_225/kernel:0' shape=(1280, 3) dtype=float32, numpy=\n","array([[ 0.01003648,  0.02610929,  0.00082986],\n","       [-0.04110801,  0.0436352 , -0.00849191],\n","       [-0.04087521,  0.01545643,  0.04013965],\n","       ...,\n","       [ 0.05990741, -0.05156167, -0.05899484],\n","       [-0.02154053,  0.02122727, -0.03248093],\n","       [ 0.00669023, -0.06359323,  0.0352909 ]], dtype=float32)>]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dNmgWEtBSh_Z","executionInfo":{"status":"error","timestamp":1614740396576,"user_tz":300,"elapsed":6395,"user":{"displayName":"Spencer Hill","photoUrl":"","userId":"06492296408916193265"}},"outputId":"ca4dfe6c-ed3c-496a-97fb-cd8d932236a7"},"source":["D = Discriminator(1, [3, 64, 128, 256, 512, 1024])\r\n","args = real_args()\r\n","G = Generator(batch_size=20, features=args.G_FEAT, degrees=args.DEGREES, support=args.support)\r\n","G([tf.random.uniform((20,1,  1, 96))])\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["layer num : 0\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_5 (Dense)              (None, 960)               92160     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               245760    \n","=================================================================\n","Total params: 337,920\n","Trainable params: 337,920\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  0 None\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-80ccb2f3bade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_FEAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEGREES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-d67730337afc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, features, degrees, support, debug_print)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertex_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertex_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LAYER \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0mvertex_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertex_num\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-4-4968f30516c8>:87 call  *\n        temp = tf.reshape(temp, (self.batch, -1, self.out_feature,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:195 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py:8378 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension size must be evenly divisible by 5120 but is 256 for '{{node tree_gcn/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](tree_gcn/Tile, tree_gcn/Reshape/shape)' with input shapes: [1,1,256], [3] and with input tensors computed as partial shapes: input[1] = [20,?,256].\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"rVwGzLYWL-WX","executionInfo":{"status":"error","timestamp":1615918014100,"user_tz":240,"elapsed":253,"user":{"displayName":"Spencer Hill","photoUrl":"","userId":"06492296408916193265"}},"outputId":"94006266-acd5-4567-a1e2-8b5654761116"},"source":["D = Discriminator(1, [3, 64, 128, 256, 512, 1024])\r\n","latent = [tf.random.uniform((1,1,  1, 96))]\r\n","D(latent)\r\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7497246c001e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Discriminator' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"9oaIHZYgh7Qz"},"source":["_____________________________________________________________________________________\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"NUYmMzxkYYfq"},"source":["ONLY TESTING GRADIENT TAPE\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xHksWE8ZzykU","executionInfo":{"status":"error","timestamp":1614720752735,"user_tz":300,"elapsed":3579,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"2fb294dc-7e36-4361-f90b-4801f829af88"},"source":["import os\r\n","args = real_args()\r\n","G = Generator(batch_size=args.batch_size, features=args.G_FEAT, degrees=args.DEGREES, support=args.support)\r\n","D = Discriminator(1, [3, 64, 128, 256, 512, 1024])\r\n","GP = GradientPenalty(10)\r\n","real, fake = male_30_train[0], male_30_train[1]\r\n","\r\n","real_point = real\r\n","\r\n","D_optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\r\n","G_optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=args.lr)\r\n","\r\n","latent = [tf.random.uniform((1,1,  1, 96))]\r\n","with tf.GradientTape() as tape:\r\n","  fake_point = G(latent)\r\n","\r\n","  loss_f = D(fake_point)\r\n","  loss_f_mean = np.mean(loss_f)\r\n","\r\n","  # Calculate loss on real points (mean over a batch)\r\n","  loss_r = D(real_point)\r\n","  loss_r_mean = np.mean(loss_r)\r\n","\r\n","  # Get total loss and apply gradient penalty to it\r\n","\r\n","  d_loss = -loss_r_mean + loss_f_mean\r\n","\r\n","  d_loss = d_loss + GP(D, real_point, fake_point)\r\n","\r\n","  watched_vars = tape.watched_variables()\r\n","\r\n","\r\n","# Calculate gradients and backpropogate through discriminator network\r\n","print(\"DISC LOSS\", d_loss)\r\n","\r\n","print(len(D.trainable_weights))\r\n","\r\n","# FIX THIS ALSO G WEIGHTS\r\n","\r\n","# d_gradients = tf.GradientTape.gradient(d_loss, self.D.trainable_weights)\r\n","d_gradients = tape.gradient(d_loss, D.trainable_weights)\r\n","# d_gradients = tf.GradientTape.gradient(self.D.trainable_weights)\r\n","print(\"GRADIENTS\", len(d_gradients))\r\n","D_optimizer.apply_gradients(zip(d_gradients, D.trainable_weights))\r\n","\r\n","\r\n","latent = [tf.random.uniform((1,1,  1, 96))]\r\n","\r\n","with tf.GradientTape() as tape2:\r\n","  tape2.watch(latent)\r\n","  fake_point = G(latent)\r\n","  G_fake = D(fake_point)\r\n","  G_fake_mean = np.mean(G_fake)\r\n","  g_loss = -G_fake_mean\r\n","  # tape2.watch(G.trainable_weights)\r\n","\r\n","\r\n","# Apply gradients and backpropograte to train\r\n","\r\n","  #   HERE\r\n","  print(\"G LOSS\")\r\n","  g_loss = tf.constant(g_loss, dtype=tf.float32)\r\n","g_gradients = tape2.gradient(g_loss, G.trainable_weights)\r\n","\r\n"," \r\n","  \r\n","print(\"Disc watched variables: \")\r\n","for var in watched_vars:\r\n","  print(var.shape)\r\n","print(\"Gen Watched Variables: \", tape2.watched_variables())\r\n","\r\n","# print(\"G TRAINABLE WEIGHTS\", G.trainable_weights)\r\n","print(g_gradients)\r\n","\r\n","G_optimizer.apply_gradients(zip(g_gradients, G.trainable_weights)) \r\n","\r\n","# dense_648/bias:0', 'dense_649/bias:0', 'dense_650/bias:0', 'dense_651/bias:0'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","          0.02539125,  0.04911175, -0.01893251,  0.05613184,\n","          0.04762813, -0.05672146, -0.03678724,  0.02670658,\n","          0.02358745, -0.03708184,  0.0067867 , -0.0445763 ,\n","          0.02255167, -0.04448166, -0.03807048,  0.04630618,\n","          0.02439651, -0.00070834, -0.00638677, -0.04234329,\n","          0.06101246, -0.02044445, -0.01020592,  0.0147634 ,\n","          0.0426161 ,  0.01831096, -0.00222845, -0.01802361,\n","         -0.00511263, -0.01071766,  0.05635443, -0.01347119,\n","          0.03197457,  0.05183364, -0.04624279,  0.02294531,\n","          0.00229581, -0.03205052,  0.01759273,  0.02113579,\n","          0.02838187, -0.00290824, -0.05588759,  0.00297743,\n","         -0.05605109,  0.05916469,  0.02985954,  0.01715083,\n","          0.02502297,  0.00469366,  0.00466445,  0.04421282,\n","          0.02403848, -0.02295196, -0.0053599 , -0.02944115,\n","          0.02655229, -0.06216158,  0.04047871,  0.0258382 ,\n","         -0.0486927 , -0.03602338,  0.03981169, -0.05083433,\n","          0.0356437 , -0.00614469, -0.04743664, -0.05581538,\n","          0.00907828, -0.00254735,  0.03773499, -0.04407202,\n","          0.05163626, -0.04798801, -0.01405931, -0.0577085 ,\n","          0.02726737,  0.04019061, -0.04622604,  0.01838449,\n","         -0.01011017,  0.02773792,  0.02478534,  0.05268902,\n","         -0.02371776, -0.00530945, -0.01848936,  0.04301822,\n","          0.03335686,  0.02668281,  0.00674361, -0.05232513,\n","          0.02472757, -0.0325298 , -0.05650854, -0.04885098,\n","          0.00807676,  0.03138526,  0.05533913,  0.05886781,\n","         -0.0227668 , -0.01915231, -0.03560536,  0.04604062,\n","          0.01749852,  0.04628645, -0.05047858, -0.01554036,\n","          0.03638245,  0.01051241,  0.0420464 ,  0.01382534,\n","          0.01503465, -0.00714265,  0.0527641 , -0.05347595,\n","         -0.04368752,  0.04720043, -0.05453026,  0.04271959,\n","         -0.01677449, -0.0261551 , -0.02225064,  0.0583289 ,\n","          0.01246367, -0.01473333, -0.01064149,  0.01724042,\n","          0.03553914, -0.02181616, -0.05403313,  0.05779767,\n","         -0.01460694, -0.0097581 , -0.05020061,  0.01410168,\n","          0.00952786, -0.00039943,  0.05091234,  0.04771501,\n","         -0.01346932, -0.05324408,  0.02096647,  0.05874637,\n","         -0.01319873, -0.04639255, -0.06139907,  0.04038902,\n","         -0.0389417 ,  0.04017271,  0.0295895 , -0.03709707,\n","         -0.03958893, -0.0249998 ,  0.04580972, -0.03960899,\n","          0.03106429, -0.06226023, -0.03173952,  0.00593847,\n","          0.00315365,  0.01453014, -0.05835755,  0.04694124,\n","          0.05849898, -0.0450262 , -0.03416237, -0.02576338,\n","         -0.01440087,  0.04070994,  0.0003656 , -0.04889646,\n","         -0.02494404, -0.03617738,  0.02972677,  0.0369315 ,\n","          0.03828402,  0.02986906, -0.02982193, -0.02335334,\n","         -0.01917453,  0.0306827 , -0.00672187, -0.0371709 ,\n","          0.01859619, -0.00425518,  0.00337301, -0.03470324,\n","         -0.04502465,  0.01858422, -0.01390937, -0.03941552]]],\n","      dtype=float32)>\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1372_input'), name='dense_1372_input', description=\"created by layer 'dense_1372_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1373_input'), name='dense_1373_input', description=\"created by layer 'dense_1373_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","LAYER  0 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_210')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_210')>]\n","layer num : 1\n","Model: \"sequential_1080\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1375 (Dense)           (None, 256)               24576     \n","=================================================================\n","Total params: 24,576\n","Trainable params: 24,576\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  1 None\n","Model: \"sequential_1081\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1376 (Dense)           (None, 256)               65536     \n","=================================================================\n","Total params: 65,536\n","Trainable params: 65,536\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  1 None\n","Model: \"sequential_1082\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1377 (Dense)           (None, 2560)              655360    \n","_________________________________________________________________\n","dense_1378 (Dense)           (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  1 None\n","W_BRANCH AT DEPTH  1 <tf.Variable 'branch:0' shape=(1, 256, 512) dtype=float32, numpy=\n","array([[[ 0.04437334, -0.07606724, -0.00577089, ...,  0.00524475,\n","          0.08505122,  0.06575928],\n","        [-0.06767882, -0.0775647 , -0.01666851, ...,  0.03400357,\n","          0.04394238,  0.0478775 ],\n","        [-0.02119995, -0.00111004, -0.0118966 , ...,  0.0806391 ,\n","          0.00312949, -0.03546596],\n","        ...,\n","        [ 0.03563181, -0.05578565, -0.03269702, ...,  0.02770915,\n","          0.02313381, -0.00442199],\n","        [-0.07466196, -0.01057981,  0.03958447, ..., -0.08556396,\n","         -0.02154698,  0.01132081],\n","        [-0.04897099, -0.04766979, -0.03990053, ..., -0.01830326,\n","          0.05650412,  0.07931039]]], dtype=float32)>\n","bias  <tf.Variable 'bias:0' shape=(1, 2, 256) dtype=float32, numpy=\n","array([[[ 0.00335877,  0.02044865, -0.02667929, -0.03465956,\n","         -0.04332471,  0.05464886,  0.00120112,  0.05943242,\n","          0.04349217, -0.01674326, -0.06032263,  0.01172806,\n","          0.00589612,  0.04218629,  0.05566762, -0.03956845,\n","         -0.00740141, -0.00646402,  0.03317025,  0.02102841,\n","         -0.04707029, -0.05314328,  0.06179781, -0.06209563,\n","          0.04370813,  0.01825839, -0.02362922, -0.02291971,\n","         -0.01887731, -0.05223297, -0.04201031, -0.01176211,\n","         -0.05311674,  0.00118794, -0.03567895,  0.03888357,\n","         -0.05903883, -0.02443136, -0.02621226,  0.05269031,\n","         -0.01423484,  0.05984002,  0.00868987,  0.06160387,\n","          0.02132542,  0.03922674,  0.03068356, -0.02784257,\n","          0.01103033, -0.01412806, -0.05021644, -0.02205609,\n","          0.02003579, -0.05082528,  0.01237875, -0.05451171,\n","          0.05317459,  0.05793244, -0.05965576,  0.01181792,\n","          0.02803621, -0.04466318, -0.06245002, -0.00888228,\n","         -0.05345169,  0.04496062,  0.01391737,  0.01122104,\n","          0.05697578, -0.04051226,  0.02145508, -0.05769734,\n","          0.01733442, -0.0442162 , -0.00697812, -0.03847617,\n","         -0.01311629,  0.01085204, -0.04388954,  0.01841906,\n","          0.00875986, -0.01709276, -0.01880383,  0.01705189,\n","         -0.02398479,  0.04012112,  0.04899749, -0.03167874,\n","         -0.06065486,  0.06041652,  0.04666294, -0.02296169,\n","          0.01077078,  0.01015292, -0.02289999, -0.03098634,\n","         -0.04989196, -0.01239969,  0.02563487,  0.04681359,\n","          0.04774423,  0.04034258,  0.02421808,  0.02043773,\n","          0.04323001,  0.02030399,  0.0616502 , -0.01713011,\n","          0.00147316, -0.03315732, -0.03558551,  0.04625098,\n","          0.01415914, -0.03944099,  0.024749  ,  0.01113282,\n","         -0.03997937,  0.02639095,  0.01614067, -0.04313794,\n","         -0.00440063,  0.06176218, -0.04960863, -0.02570552,\n","          0.04194964, -0.03572114, -0.01107754,  0.05383042,\n","          0.02001716, -0.03367653,  0.0226364 ,  0.00038251,\n","          0.05500855, -0.05061764, -0.01047681, -0.01741774,\n","         -0.05094343,  0.0036837 ,  0.06237154, -0.03521861,\n","          0.03823596, -0.05990215, -0.00049637,  0.04609306,\n","         -0.01719125,  0.00238624,  0.03872873,  0.03805919,\n","         -0.01836221, -0.00752316, -0.04351355,  0.05662358,\n","         -0.04528861,  0.02639468, -0.02088286, -0.02373584,\n","          0.0056856 ,  0.03456119,  0.01355389, -0.05705705,\n","          0.03265749,  0.04450625,  0.05633369,  0.01100726,\n","         -0.01812989, -0.02134784, -0.0226997 , -0.0464633 ,\n","         -0.00028209, -0.02404539,  0.01230136,  0.01918896,\n","         -0.04433288,  0.06029667, -0.04435393, -0.03138739,\n","         -0.00785767,  0.03541234, -0.02963828,  0.03521152,\n","         -0.04090543, -0.04918981,  0.03147376,  0.02871275,\n","         -0.05027364,  0.00049852,  0.04894231, -0.02377617,\n","         -0.04075821, -0.05584374, -0.05312838, -0.05389075,\n","         -0.01401386,  0.01584257,  0.05794384, -0.02947065,\n","          0.03734806,  0.00562012, -0.0267424 ,  0.0346089 ,\n","          0.03052334,  0.01729378,  0.03489688, -0.00574906,\n","          0.02827337, -0.02470315, -0.01836173, -0.00987537,\n","          0.00566098,  0.01400369,  0.01646909,  0.0278929 ,\n","          0.01179242, -0.01085404,  0.02441946,  0.02798179,\n","          0.06103025,  0.04614724,  0.04546101,  0.03440946,\n","          0.0358889 ,  0.0176973 , -0.00375727, -0.02391201,\n","         -0.06031588,  0.04694647,  0.04981053, -0.02933985,\n","          0.03043805,  0.00895576, -0.03268392,  0.05683488,\n","          0.03233169,  0.02712584, -0.05567525,  0.02583218,\n","          0.02285062, -0.00784269, -0.00238839,  0.01111035,\n","         -0.01688412,  0.02950911, -0.01615877,  0.01768504,\n","         -0.00577997, -0.01690952,  0.00229317, -0.05045228,\n","         -0.00178127, -0.02278277,  0.01135767, -0.02178583,\n","          0.04105635, -0.06007344, -0.05388585,  0.01196201],\n","        [-0.00385073, -0.00272723, -0.00353575,  0.05869621,\n","         -0.00873722, -0.05477239, -0.02303527, -0.0179338 ,\n","          0.04796995,  0.04002908, -0.03188221, -0.03252748,\n","          0.05411986,  0.05032186, -0.02464323, -0.00293234,\n","          0.05352879,  0.01226942, -0.03307907,  0.04976884,\n","          0.04964258,  0.03481013,  0.02538593, -0.02237287,\n","         -0.06162754,  0.03560323,  0.00458109,  0.03379957,\n","          0.04932788, -0.03645019,  0.03206544,  0.05320059,\n","          0.01134944, -0.04577635,  0.05459259, -0.04100363,\n","          0.00974295, -0.04558675, -0.01864697,  0.02254875,\n","         -0.03395693,  0.02006373, -0.05722226, -0.02558458,\n","         -0.05473229,  0.01595271,  0.05340299,  0.04472582,\n","          0.05476978, -0.06166218, -0.00805911,  0.01364584,\n","          0.02509803, -0.01549089, -0.02653976, -0.03424598,\n","         -0.03002711,  0.04732975,  0.0471486 ,  0.02094501,\n","         -0.02642292, -0.00283699, -0.00524767, -0.039674  ,\n","         -0.02218813, -0.0187545 , -0.04961073,  0.04947166,\n","          0.05737537,  0.03851101,  0.04916382, -0.01172471,\n","          0.03556682, -0.00756347, -0.00909343,  0.04416573,\n","          0.05099167, -0.01125509,  0.03109956,  0.05256177,\n","          0.05724849, -0.0443438 ,  0.0316305 ,  0.05137518,\n","          0.05171815,  0.01137018, -0.05262788,  0.00718553,\n","         -0.04543626, -0.0358675 , -0.033884  , -0.00792591,\n","          0.01232256, -0.03789115,  0.03600205, -0.02790245,\n","          0.03440428, -0.02179246, -0.00547831, -0.01829875,\n","          0.05633454,  0.03955719,  0.05026026, -0.03115796,\n","         -0.05388743, -0.04116184, -0.03021421,  0.06212513,\n","         -0.02639259,  0.01193832, -0.04226261, -0.03085829,\n","          0.04898265, -0.01103827,  0.01916826,  0.03537537,\n","         -0.02246717, -0.05031675, -0.01226448, -0.01772632,\n","         -0.0541911 , -0.05536301,  0.0203573 , -0.02218188,\n","         -0.03865743, -0.03402407,  0.04039441, -0.05259956,\n","          0.04397734, -0.00037196,  0.05198215, -0.04887167,\n","          0.03184602, -0.00021777, -0.01003106,  0.01866154,\n","         -0.05321051, -0.04585584, -0.00337665,  0.02941269,\n","          0.02769715,  0.06194636, -0.02994724, -0.02843542,\n","         -0.00411782, -0.0112171 , -0.03374127,  0.028762  ,\n","         -0.02091232,  0.02040301,  0.05831106,  0.03159337,\n","          0.05372413,  0.01384884, -0.06120485,  0.02054019,\n","         -0.04310395, -0.01634592,  0.05882317,  0.05619888,\n","          0.00854927, -0.04759291, -0.03913364,  0.01342461,\n","          0.04963049,  0.00640255, -0.03854008, -0.04210928,\n","          0.05264418, -0.02966191,  0.03577811,  0.05738293,\n","         -0.03311874, -0.02943371,  0.04448736, -0.0239401 ,\n","         -0.04770091, -0.04025644, -0.02956879,  0.0430432 ,\n","          0.01523806, -0.00903167, -0.04363081,  0.03593203,\n","         -0.00506331, -0.06117959, -0.03355888, -0.05679084,\n","          0.01148131, -0.03452492, -0.04702711,  0.04248074,\n","         -0.0098547 ,  0.02204837,  0.04137467, -0.0350204 ,\n","          0.05149437,  0.04242963,  0.01540209,  0.00082937,\n","          0.03516513, -0.02178183, -0.06080946, -0.01881635,\n","          0.02397718, -0.003682  , -0.06190795, -0.01420093,\n","         -0.02300681,  0.02694342,  0.03352511, -0.04057691,\n","         -0.02302277,  0.01073135,  0.01725608,  0.00932647,\n","          0.04346143, -0.05568148, -0.04505096,  0.00380303,\n","         -0.02742867,  0.05305079,  0.00478074, -0.05017239,\n","          0.00375514,  0.03215021, -0.00218715,  0.00744908,\n","         -0.01043378,  0.00452197, -0.00311914,  0.06136414,\n","         -0.02943161,  0.0284507 ,  0.04253037,  0.0278717 ,\n","         -0.03354031, -0.03248772,  0.05040641, -0.04521844,\n","          0.00461288,  0.05099146, -0.04283951, -0.00958106,\n","          0.05962537,  0.02148265, -0.03357564,  0.00975057,\n","          0.04450698,  0.02136078, -0.04368974,  0.03356199,\n","          0.04014085,  0.02529989, -0.05163455,  0.01997435]]],\n","      dtype=float32)>\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1375_input'), name='dense_1375_input', description=\"created by layer 'dense_1375_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1376_input'), name='dense_1376_input', description=\"created by layer 'dense_1376_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1377_input'), name='dense_1377_input', description=\"created by layer 'dense_1377_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","LAYER  1 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_211')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_211')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_211')>]\n","layer num : 2\n","Model: \"sequential_1083\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1379 (Dense)           (None, 256)               24576     \n","=================================================================\n","Total params: 24,576\n","Trainable params: 24,576\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  2 None\n","Model: \"sequential_1084\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1380 (Dense)           (None, 256)               65536     \n","=================================================================\n","Total params: 65,536\n","Trainable params: 65,536\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  2 None\n","Model: \"sequential_1085\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1381 (Dense)           (None, 256)               65536     \n","=================================================================\n","Total params: 65,536\n","Trainable params: 65,536\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  2 None\n","Model: \"sequential_1086\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1382 (Dense)           (None, 2560)              655360    \n","_________________________________________________________________\n","dense_1383 (Dense)           (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  2 None\n","W_BRANCH AT DEPTH  2 <tf.Variable 'branch:0' shape=(2, 256, 512) dtype=float32, numpy=\n","array([[[-0.03765549, -0.01261361,  0.04859726, ...,  0.02290747,\n","         -0.0493204 ,  0.00076152],\n","        [-0.02877125,  0.05077147, -0.00427386, ..., -0.02840781,\n","         -0.05749133, -0.06212492],\n","        [ 0.01191399,  0.0066693 ,  0.04013118, ..., -0.05853888,\n","         -0.01650493, -0.02391323],\n","        ...,\n","        [ 0.05860625, -0.03668334,  0.01786701, ...,  0.02778535,\n","         -0.05339046, -0.01945044],\n","        [ 0.00488439,  0.00778641, -0.01847874, ..., -0.05609296,\n","         -0.0533229 ,  0.02127486],\n","        [ 0.01777123,  0.05512722,  0.02697659, ..., -0.05558696,\n","          0.01322722,  0.00474504]],\n","\n","       [[-0.0351104 ,  0.00819179,  0.0294321 , ..., -0.05671814,\n","          0.03617004, -0.02681181],\n","        [-0.04082397, -0.05123737,  0.05546995, ...,  0.02428767,\n","          0.02369563,  0.01208578],\n","        [-0.04711993, -0.03341037, -0.01273687, ..., -0.01415768,\n","         -0.03848776, -0.01538044],\n","        ...,\n","        [-0.02461413, -0.01655065, -0.01401594, ..., -0.00528273,\n","         -0.04481082,  0.0530629 ],\n","        [ 0.00431161,  0.05034786,  0.04336332, ..., -0.03901803,\n","         -0.04406814, -0.02372912],\n","        [-0.00797586, -0.047782  ,  0.04016289, ...,  0.00978985,\n","          0.03715822, -0.0022357 ]]], dtype=float32)>\n","bias  <tf.Variable 'bias:0' shape=(1, 2, 256) dtype=float32, numpy=\n","array([[[ 0.04673077,  0.01830259, -0.00881352,  0.05521491,\n","         -0.0435351 , -0.02566333,  0.04625879,  0.00966439,\n","         -0.03410581,  0.06003103,  0.03697988, -0.02309555,\n","          0.04024412, -0.01392645,  0.04935786, -0.00204538,\n","         -0.00335376, -0.00397061,  0.01780187,  0.0515997 ,\n","         -0.00892547,  0.0106663 ,  0.04073927,  0.04036885,\n","         -0.02937014,  0.04042025, -0.05794191, -0.03086759,\n","         -0.03521737, -0.00181021,  0.00370349, -0.03147557,\n","         -0.00208525,  0.03390497, -0.01728834, -0.01631115,\n","          0.01237036,  0.01994205, -0.01784192, -0.00106984,\n","          0.05868569,  0.0509329 ,  0.02423638,  0.00946522,\n","          0.04124907,  0.04537687, -0.0332104 ,  0.05614869,\n","         -0.03898342, -0.01615119,  0.05067271,  0.03257839,\n","          0.00571515, -0.0470306 ,  0.04645018, -0.02999453,\n","         -0.00653388, -0.0467608 ,  0.02243513,  0.00598107,\n","          0.0281519 ,  0.04023954, -0.04379407, -0.04590079,\n","         -0.03522509,  0.02137393,  0.05067471,  0.01727414,\n","          0.02429052, -0.05153526,  0.02848019, -0.03897016,\n","          0.0375165 ,  0.05282834,  0.05371672,  0.06160364,\n","          0.01931417, -0.03548132,  0.04597309, -0.05750455,\n","         -0.04309629,  0.04877381,  0.02307309,  0.02221642,\n","          0.04864202,  0.00583307, -0.03196086, -0.02722785,\n","         -0.00825956,  0.05127206, -0.05957825,  0.05175069,\n","         -0.02506781, -0.02353403,  0.03369984, -0.06060621,\n","          0.04285775,  0.03627704, -0.02455184, -0.03179568,\n","          0.03538565,  0.01706769,  0.02492043,  0.06185263,\n","          0.00797485,  0.01961024, -0.0224885 , -0.03031737,\n","          0.04745486, -0.04624951,  0.01880369,  0.02628143,\n","         -0.00775783, -0.05346718,  0.05220656,  0.02005267,\n","         -0.02377538, -0.03881881, -0.06200811,  0.05232179,\n","          0.04590361,  0.0363791 , -0.02318819, -0.0018646 ,\n","         -0.02054688,  0.01174375,  0.01531652,  0.05315816,\n","         -0.05921294,  0.03596994, -0.05383557,  0.01154535,\n","          0.0428291 , -0.01079883, -0.01413894,  0.00830956,\n","         -0.03610957, -0.01789279,  0.01171686,  0.02969278,\n","          0.03178506, -0.04829207,  0.00445412,  0.01595117,\n","          0.02770562,  0.03426173, -0.05020025, -0.02334543,\n","          0.01936589,  0.03174949, -0.04076767,  0.06111625,\n","         -0.0515673 ,  0.05539878, -0.03987703,  0.02947532,\n","          0.00976518,  0.03832014,  0.00864288,  0.03945774,\n","         -0.03827699, -0.00443923,  0.02426222,  0.05900757,\n","          0.00469935, -0.00028653, -0.01677799,  0.02442165,\n","          0.01924212, -0.04082014, -0.04937708,  0.03235514,\n","          0.04846355,  0.04872572,  0.0099505 , -0.00121948,\n","         -0.00794171,  0.03512774, -0.06028634,  0.01713373,\n","         -0.00260262,  0.05715024,  0.02072176,  0.01120423,\n","          0.03276685, -0.00737667, -0.05363409, -0.04105945,\n","         -0.05759315,  0.00580908,  0.00309208,  0.0234185 ,\n","          0.00457622,  0.0586243 ,  0.0002992 , -0.00798528,\n","          0.00440532,  0.00390588,  0.05709545, -0.00056252,\n","          0.05590422,  0.00805268,  0.03907175, -0.05249099,\n","          0.05038467, -0.02173507,  0.05014917,  0.0533828 ,\n","          0.03592496,  0.03342956, -0.01150234, -0.0362305 ,\n","          0.00395544, -0.02311212,  0.04198153, -0.02121802,\n","          0.04238196, -0.02287911, -0.00605504, -0.04115638,\n","          0.0458087 , -0.05667068, -0.04299328, -0.04300039,\n","          0.0254596 ,  0.01927958, -0.0504185 ,  0.01741271,\n","         -0.0455959 ,  0.04600383,  0.0380398 ,  0.05356804,\n","         -0.02280287, -0.03141466, -0.05592516,  0.021376  ,\n","          0.05337778,  0.02659105, -0.05299859, -0.02135111,\n","         -0.05432199, -0.05452277, -0.04782899,  0.04822089,\n","         -0.02115637,  0.01532693, -0.02131447, -0.02713083,\n","         -0.02936974, -0.04433829, -0.01758906, -0.01349676,\n","          0.0245589 ,  0.00525121, -0.01924039,  0.03815906],\n","        [ 0.04885046, -0.01566489, -0.02584469, -0.02252579,\n","         -0.00237682, -0.02808774, -0.01429525, -0.0397481 ,\n","          0.01757286,  0.00964923,  0.048925  , -0.05204873,\n","         -0.0187967 , -0.04454063,  0.00440934,  0.06223254,\n","          0.01702811, -0.01665112,  0.05869272, -0.02217838,\n","          0.06194654,  0.01803638, -0.0509892 , -0.06074183,\n","         -0.00651971, -0.02371526, -0.01357329,  0.0034027 ,\n","         -0.05937077,  0.01930581, -0.02747861, -0.00244854,\n","         -0.01788725, -0.05506755,  0.00423169,  0.05215071,\n","         -0.05866426,  0.03557287, -0.05273734,  0.05714758,\n","          0.03263326, -0.01193178,  0.01551123,  0.02539715,\n","         -0.02788013,  0.06235558,  0.05351281, -0.00449055,\n","         -0.02090888, -0.01432879,  0.03614339,  0.06213708,\n","          0.0225746 , -0.02312206,  0.0229405 , -0.03828414,\n","          0.01256302,  0.03724061,  0.05534473,  0.05969851,\n","          0.00751434, -0.04955603,  0.04717356,  0.02289915,\n","         -0.055931  , -0.0103375 , -0.02880664,  0.04146911,\n","         -0.02168261, -0.0120638 ,  0.02041225,  0.01799528,\n","         -0.02324735,  0.04569019,  0.01351312, -0.04071885,\n","          0.00010967, -0.05364364,  0.04242936,  0.02407087,\n","         -0.01291443,  0.00667863,  0.04513153,  0.06041631,\n","          0.03914547,  0.01079281,  0.05256766,  0.04966161,\n","         -0.03234205,  0.00840245,  0.04126604, -0.00550999,\n","          0.02783765, -0.02807806,  0.00924648,  0.05740228,\n","         -0.02769276, -0.00564286,  0.05245447,  0.04628259,\n","          0.00249828,  0.02343327, -0.01411141,  0.04485351,\n","         -0.03242441, -0.02404121, -0.0537976 ,  0.03604344,\n","          0.05386271, -0.03988691,  0.05569044, -0.05235597,\n","         -0.0287265 ,  0.04417576,  0.0115997 ,  0.03011124,\n","         -0.04677503, -0.01620707,  0.02262054, -0.03050847,\n","          0.04315685,  0.02337132,  0.02698272,  0.03641668,\n","         -0.00271198, -0.00605351, -0.00787586, -0.02221736,\n","         -0.01035318, -0.01951624, -0.02555464,  0.0080605 ,\n","          0.06078596,  0.01566523, -0.0418788 , -0.05995634,\n","          0.03140575, -0.01351552,  0.02976444, -0.05408564,\n","         -0.01275361, -0.05599268, -0.03902708,  0.00118007,\n","          0.01293433,  0.03256761,  0.00136682, -0.05518906,\n","         -0.03642584,  0.04236253,  0.01748843,  0.03704411,\n","         -0.01622039, -0.01508041,  0.03329472, -0.01073471,\n","          0.0506206 , -0.00883757,  0.05515802, -0.05861446,\n","          0.06222951,  0.01315518, -0.01269835,  0.05036309,\n","          0.03159153,  0.00887421,  0.0159674 ,  0.04957208,\n","         -0.04666404,  0.06190285,  0.02160206,  0.0609514 ,\n","         -0.0552642 ,  0.04982114,  0.04524359, -0.00388795,\n","         -0.01447444, -0.05341668,  0.00910246,  0.0371335 ,\n","         -0.01291214, -0.01035601, -0.04366265,  0.00909558,\n","         -0.03369859,  0.00156386,  0.03839912, -0.02876198,\n","          0.03082134, -0.03408153, -0.05666527, -0.01605313,\n","          0.01034835, -0.05086564,  0.03634763, -0.03357822,\n","          0.01419991, -0.01773283,  0.0459893 ,  0.04027636,\n","          0.05516407, -0.04605627,  0.01651415,  0.00344975,\n","         -0.0083686 , -0.04433866,  0.01529031,  0.04448351,\n","          0.03861021,  0.02138792,  0.00619182,  0.04990855,\n","          0.0142865 , -0.0134282 , -0.06083354,  0.05160959,\n","         -0.02152009,  0.01313545, -0.01295671, -0.04507886,\n","         -0.05727881, -0.01438825, -0.04068325, -0.01897988,\n","         -0.03258733,  0.061653  ,  0.06149657, -0.00411817,\n","          0.04427397, -0.01294442, -0.03287752, -0.01035781,\n","         -0.05239165, -0.02629481, -0.01447509, -0.0466861 ,\n","          0.01573917,  0.00382911,  0.00615099,  0.01496969,\n","          0.05125397,  0.05260479, -0.06039728,  0.05847274,\n","         -0.03149174,  0.03531472, -0.0622056 , -0.02548385,\n","          0.02922317, -0.01010619,  0.00701685, -0.02721252,\n","         -0.01187518,  0.01565976,  0.00759515,  0.05167934]]],\n","      dtype=float32)>\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1379_input'), name='dense_1379_input', description=\"created by layer 'dense_1379_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1380_input'), name='dense_1380_input', description=\"created by layer 'dense_1380_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1381_input'), name='dense_1381_input', description=\"created by layer 'dense_1381_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1382_input'), name='dense_1382_input', description=\"created by layer 'dense_1382_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","LAYER  2 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_212')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_212')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_212')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_212')>]\n","layer num : 3\n","Model: \"sequential_1087\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1384 (Dense)           (None, 128)               12288     \n","=================================================================\n","Total params: 12,288\n","Trainable params: 12,288\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  3 None\n","Model: \"sequential_1088\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1385 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  3 None\n","Model: \"sequential_1089\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1386 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  3 None\n","Model: \"sequential_1090\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1387 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  3 None\n","Model: \"sequential_1091\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1388 (Dense)           (None, 2560)              655360    \n","_________________________________________________________________\n","dense_1389 (Dense)           (None, 128)               327680    \n","=================================================================\n","Total params: 983,040\n","Trainable params: 983,040\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  3 None\n","W_BRANCH AT DEPTH  3 <tf.Variable 'branch:0' shape=(4, 256, 768) dtype=float32, numpy=\n","array([[[ 1.63015276e-02, -2.97076032e-02,  1.82117783e-02, ...,\n","         -1.82283949e-02,  3.63280736e-02,  3.24763544e-02],\n","        [-3.04495618e-02,  1.42456330e-02, -1.12130754e-02, ...,\n","         -2.23898795e-02,  4.28590551e-03,  2.96396054e-02],\n","        [ 3.42270993e-02,  2.82464549e-03,  1.42742395e-02, ...,\n","          1.41400024e-02,  5.81501797e-03, -3.31182592e-02],\n","        ...,\n","        [-3.39799188e-02, -2.63974071e-05, -9.64925066e-03, ...,\n","          2.35779583e-03,  4.38932702e-03,  3.62578891e-02],\n","        [ 2.59403847e-02, -2.73930319e-02,  7.54189864e-03, ...,\n","          2.63335072e-02, -2.22226437e-02,  5.61922789e-05],\n","        [-9.95216519e-03,  5.60035184e-03,  1.59155764e-02, ...,\n","          1.16862543e-02,  1.46001428e-02, -1.90303680e-02]],\n","\n","       [[-3.74608003e-02,  9.65129212e-03, -1.99637897e-02, ...,\n","         -2.14012153e-02,  4.55394387e-03,  6.82632253e-03],\n","        [-1.02594886e-02,  3.70034240e-02,  8.48836824e-03, ...,\n","          9.98685881e-03, -3.18553783e-02,  2.65575759e-02],\n","        [ 1.88101530e-02,  2.17210203e-02, -5.49867749e-04, ...,\n","          3.72584425e-02, -1.99478120e-02,  3.13213356e-02],\n","        ...,\n","        [-2.95017231e-02, -3.04587148e-02, -2.75678746e-02, ...,\n","         -1.38531104e-02,  2.81167962e-02,  2.13827193e-02],\n","        [-1.42778084e-02, -9.54905711e-03, -1.84917450e-03, ...,\n","         -3.46372351e-02,  3.03346254e-02,  1.57219134e-02],\n","        [ 1.85311809e-02, -1.40130892e-03,  1.55567676e-02, ...,\n","         -3.11981142e-03, -3.52303460e-02, -3.81956697e-02]],\n","\n","       [[-1.70625225e-02,  3.24341618e-02, -2.35826969e-02, ...,\n","          2.74206512e-02, -3.30770053e-02, -3.23245227e-02],\n","        [-4.06601653e-03, -9.91039909e-03,  7.49966875e-03, ...,\n","          3.80264483e-02,  2.27294303e-02, -3.65849510e-02],\n","        [ 2.96343155e-02,  3.24257575e-02, -2.97235809e-02, ...,\n","         -1.39769651e-02,  2.26207413e-02, -1.98238119e-02],\n","        ...,\n","        [-1.00595299e-02, -1.32552534e-03,  2.50614770e-02, ...,\n","         -1.57406200e-02,  1.19499713e-02, -3.49121355e-02],\n","        [-8.27059150e-04, -2.13790964e-02,  1.03818811e-02, ...,\n","          1.27284937e-02, -2.60101277e-02,  2.06619948e-02],\n","        [ 7.73996115e-04, -2.09942833e-03,  2.91202031e-02, ...,\n","         -1.05892494e-02, -9.29216854e-03,  1.35102905e-02]],\n","\n","       [[ 1.24063604e-02, -1.25244558e-02,  1.15926042e-02, ...,\n","          1.36834309e-02, -2.14363374e-02,  3.44819613e-02],\n","        [-3.39936465e-04, -7.71239214e-03, -2.80310996e-02, ...,\n","         -3.26634459e-02, -2.36104373e-02,  2.22913548e-02],\n","        [ 2.53069215e-02,  2.55186073e-02,  3.56966890e-02, ...,\n","          3.71155925e-02,  3.81610431e-02,  1.86884180e-02],\n","        ...,\n","        [ 2.96391286e-02,  1.23475939e-02, -1.70266423e-02, ...,\n","          1.31239370e-02, -7.87242688e-03,  2.82667764e-02],\n","        [-2.58216318e-02, -3.31740305e-02, -2.20403336e-02, ...,\n","         -2.44923644e-02,  1.87554844e-02, -3.35678048e-02],\n","        [-1.66827366e-02, -2.97844168e-02,  2.15578750e-02, ...,\n","          2.56927423e-02,  1.10970810e-03,  4.59996983e-03]]],\n","      dtype=float32)>\n","bias  <tf.Variable 'bias:0' shape=(1, 3, 128) dtype=float32, numpy=\n","array([[[ 6.76783994e-02, -4.27311510e-02, -5.00647426e-02,\n","          5.93817756e-02,  4.55171987e-02, -5.18696196e-02,\n","          8.28701928e-02, -7.30746686e-02, -6.49111420e-02,\n","          4.18927595e-02,  2.87028849e-02, -8.78169611e-02,\n","         -7.59393722e-02, -6.36989325e-02, -7.03697279e-02,\n","          8.06147382e-02,  8.00984576e-02, -6.57348782e-02,\n","         -1.93393156e-02,  6.01795092e-02,  6.72153905e-02,\n","          5.49639091e-02,  3.01740468e-02,  5.97245470e-02,\n","         -4.94144410e-02,  1.84801891e-02, -6.23925291e-02,\n","          3.59600261e-02, -7.22847879e-03, -1.98731050e-02,\n","          6.60079643e-02,  2.94153839e-02,  9.20113921e-03,\n","         -8.93574208e-03, -4.70889881e-02,  8.68489966e-02,\n","         -5.39384596e-02,  3.75172272e-02,  2.14264914e-02,\n","          7.77050927e-02, -2.84292288e-02, -5.81281520e-02,\n","          5.15453517e-04,  1.98273733e-02, -4.70109321e-02,\n","         -5.82508743e-04, -5.48736565e-02, -6.26055896e-03,\n","          6.17495999e-02,  8.76253843e-03,  7.37399831e-02,\n","         -6.42233267e-02, -2.14834511e-02, -5.08038513e-02,\n","          6.06935099e-02, -1.17191672e-03, -4.44473065e-02,\n","          6.80686161e-02,  3.18889171e-02, -1.59608424e-02,\n","          1.51805580e-02, -5.73325455e-02,  2.14489326e-02,\n","          7.42640272e-02, -5.51955104e-02,  6.77602217e-02,\n","         -5.07080518e-02, -4.83395047e-02, -6.04255982e-02,\n","          2.78017670e-02,  6.85834363e-02,  2.71723270e-02,\n","          7.39273354e-02,  4.97666001e-03,  1.96952224e-02,\n","         -4.08965200e-02, -3.69673371e-02,  8.01767483e-02,\n","          2.63030082e-02,  6.43168464e-02, -9.32738185e-05,\n","         -4.52079736e-02, -2.17178315e-02,  2.98347026e-02,\n","          7.78265372e-02, -6.09260499e-02, -1.43959299e-02,\n","         -4.17793468e-02, -4.30859625e-02, -8.27199221e-03,\n","          6.28405288e-02, -4.46688943e-02,  8.17532837e-03,\n","         -7.95759261e-02,  8.48233476e-02, -3.35623361e-02,\n","          1.93051323e-02,  5.76586947e-02, -7.22233206e-02,\n","          7.13413209e-03,  6.18747100e-02,  9.56328958e-03,\n","         -5.11107221e-02, -7.50961974e-02,  7.53334910e-03,\n","          6.70627728e-02, -7.85795525e-02, -3.49767618e-02,\n","          1.83304027e-02,  2.90857926e-02, -3.11608091e-02,\n","         -5.69014251e-02, -7.96742737e-04, -2.48395577e-02,\n","         -2.79286280e-02, -7.36221373e-02, -8.45213756e-02,\n","          5.19535169e-02, -1.33736432e-03, -2.20221952e-02,\n","          7.71401301e-02,  7.08429888e-02,  5.64445183e-02,\n","         -7.50704929e-02, -9.55496728e-03, -7.55946264e-02,\n","         -5.45226373e-02,  7.84263238e-02],\n","        [-3.78234647e-02, -3.49323452e-03,  3.14635932e-02,\n","         -2.11927816e-02,  3.80422100e-02,  3.82247195e-02,\n","          4.99281213e-02,  2.37478316e-02, -4.62660715e-02,\n","         -1.45257264e-03, -2.37421393e-02, -6.85347617e-03,\n","          8.40698555e-02,  9.10504907e-03, -6.51799515e-02,\n","         -4.38447334e-02,  7.88678154e-02,  8.37402269e-02,\n","         -4.20723967e-02,  5.07578999e-03,  2.09376067e-02,\n","          3.11668143e-02,  2.64563113e-02,  5.36653027e-02,\n","          8.47466215e-02,  7.30404183e-02,  3.47723812e-03,\n","          6.37042299e-02,  7.58783594e-02,  4.76536527e-02,\n","          8.39327350e-02,  7.46380165e-02,  6.48282468e-04,\n","         -1.31295472e-02,  7.22639486e-02,  4.36769649e-02,\n","          6.77319244e-02, -2.53332704e-02,  6.94710240e-02,\n","         -5.98402396e-02,  4.33011279e-02, -2.58177444e-02,\n","         -8.06959346e-02,  5.36603704e-02, -4.18640859e-02,\n","         -5.74992597e-03,  6.85151666e-03, -6.30213320e-03,\n","          9.60566849e-03, -1.48219615e-03, -2.47767419e-02,\n","         -5.95380701e-02, -4.65794951e-02,  6.37972876e-02,\n","          3.61847728e-02, -4.73092459e-02, -5.28368689e-02,\n","          1.61318555e-02, -2.83265188e-02, -4.08632457e-02,\n","         -2.35852078e-02,  8.25830176e-02, -1.52584687e-02,\n","          3.11741233e-03,  4.93438542e-03, -4.30136807e-02,\n","          1.00610852e-02, -6.09913543e-02, -6.90272227e-02,\n","         -5.75618036e-02, -6.45473078e-02, -4.78924736e-02,\n","         -4.86025438e-02,  5.15039340e-02,  3.90614197e-02,\n","          3.68591622e-02, -5.34904748e-03, -4.68034409e-02,\n","          7.91304931e-02, -7.87714124e-03, -2.99227461e-02,\n","         -5.10070436e-02, -5.68132848e-03, -4.37168591e-02,\n","         -7.04436004e-03,  3.51518616e-02, -5.01024015e-02,\n","         -8.73239487e-02,  1.36292577e-02,  3.70523408e-02,\n","          7.98977539e-02, -1.53702796e-02,  7.76571706e-02,\n","          1.97787806e-02, -7.59117305e-03, -2.97882743e-02,\n","          4.92404327e-02, -5.17480895e-02, -4.51694317e-02,\n","         -2.98650675e-02, -2.00419873e-02,  2.12238282e-02,\n","         -8.41334313e-02, -1.41190663e-02,  5.26558086e-02,\n","         -7.55584240e-02,  5.70144579e-02,  4.96482477e-02,\n","         -8.80986676e-02, -7.77774528e-02, -2.93425508e-02,\n","          6.77806512e-02,  5.48055097e-02, -3.76106054e-02,\n","         -1.47300512e-02, -4.17388231e-02,  2.79901028e-02,\n","         -5.16439453e-02, -7.79231340e-02, -1.55416131e-03,\n","          8.40835050e-02, -4.09344733e-02, -2.08035782e-02,\n","         -4.21997830e-02,  5.95862642e-02, -7.96429366e-02,\n","         -7.69653916e-02,  2.64270231e-02],\n","        [ 4.34949622e-02,  7.87385777e-02, -4.13883738e-02,\n","         -3.22808810e-02,  4.34930250e-02, -5.24717085e-02,\n","         -4.41032201e-02,  3.88012081e-03,  1.41647533e-02,\n","         -2.38364413e-02, -2.38481164e-02, -8.70026872e-02,\n","         -6.62759617e-02, -5.38344644e-02,  6.72254637e-02,\n","          6.38773814e-02, -3.58241461e-02, -3.13977376e-02,\n","         -5.28947376e-02,  5.32712713e-02,  1.46967769e-02,\n","         -8.45883638e-02,  1.29669607e-02,  8.77721384e-02,\n","          3.40926275e-02, -5.07498607e-02,  7.13396817e-03,\n","         -3.35385241e-02,  8.45145807e-02,  7.42155313e-03,\n","         -8.49072263e-02,  6.03333190e-02,  4.10054699e-02,\n","         -6.93720430e-02,  7.08442181e-03, -4.98348139e-02,\n","          7.40110502e-02,  4.83969375e-02, -6.37968630e-03,\n","         -6.68735802e-02,  4.48616073e-02, -5.60274050e-02,\n","          8.05264488e-02, -4.05395776e-03,  4.99455109e-02,\n","         -1.95694789e-02, -4.73998003e-02, -8.01881254e-02,\n","         -1.27186328e-02,  5.91069460e-03, -3.57398093e-02,\n","          8.59629586e-02,  6.80444613e-02,  2.54269615e-02,\n","         -6.11953065e-02,  7.45117292e-02, -5.10407798e-02,\n","          5.77174500e-02, -8.82869586e-02, -4.70520668e-02,\n","          4.46501449e-02, -6.17174432e-02,  4.35469225e-02,\n","         -8.18226859e-02,  1.59400403e-02, -3.93357389e-02,\n","          4.06725034e-02, -2.10259035e-02, -5.61172441e-02,\n","         -7.69571960e-03, -7.91087449e-02, -1.62265822e-02,\n","          6.05449826e-03,  4.63073477e-02, -1.26629993e-02,\n","         -7.11246431e-02, -8.18171352e-03,  2.10929364e-02,\n","         -5.19844294e-02,  5.13810292e-02,  6.78669587e-02,\n","          5.96747771e-02,  2.96127796e-03,  6.54668286e-02,\n","         -2.53832787e-02,  7.43288919e-02,  8.45135003e-03,\n","          5.11794910e-02, -6.08465001e-02,  4.25249711e-02,\n","         -1.27699077e-02, -4.96730953e-02,  2.21813172e-02,\n","         -6.53612912e-02, -7.52852261e-02,  5.33715263e-02,\n","          2.01623589e-02, -1.63859129e-02,  6.09175339e-02,\n","          5.57899475e-04, -3.71885449e-02, -1.02052465e-02,\n","         -1.47374272e-02,  1.76510140e-02,  1.44124329e-02,\n","          1.45763159e-04,  8.78149644e-02,  2.25822777e-02,\n","         -8.68616179e-02, -1.64318755e-02,  6.73156455e-02,\n","         -3.23609821e-02,  3.29420790e-02,  6.12545237e-02,\n","          8.56208727e-02,  2.79686600e-03, -4.72183377e-02,\n","         -7.77911991e-02,  2.07271278e-02,  6.39706925e-02,\n","         -5.70540614e-02,  8.77087489e-02, -2.52290219e-02,\n","         -4.11266834e-03, -3.25072519e-02, -8.07554498e-02,\n","         -3.84918600e-03, -5.21148294e-02]]], dtype=float32)>\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1384_input'), name='dense_1384_input', description=\"created by layer 'dense_1384_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1385_input'), name='dense_1385_input', description=\"created by layer 'dense_1385_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1386_input'), name='dense_1386_input', description=\"created by layer 'dense_1386_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1387_input'), name='dense_1387_input', description=\"created by layer 'dense_1387_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1388_input'), name='dense_1388_input', description=\"created by layer 'dense_1388_input'\"), but it was called on an input with incompatible shape (1, 12, 256).\n","LAYER  3 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_213')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_213')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_213')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_213')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_213')>]\n","layer num : 4\n","Model: \"sequential_1092\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1390 (Dense)           (None, 128)               12288     \n","=================================================================\n","Total params: 12,288\n","Trainable params: 12,288\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  4 None\n","Model: \"sequential_1093\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1391 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  4 None\n","Model: \"sequential_1094\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1392 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  4 None\n","Model: \"sequential_1095\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1393 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  4 None\n","Model: \"sequential_1096\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1394 (Dense)           (None, 128)               16384     \n","=================================================================\n","Total params: 16,384\n","Trainable params: 16,384\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  4 None\n","Model: \"sequential_1097\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1395 (Dense)           (None, 1280)              163840    \n","_________________________________________________________________\n","dense_1396 (Dense)           (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  4 None\n","W_BRANCH AT DEPTH  4 <tf.Variable 'branch:0' shape=(12, 128, 256) dtype=float32, numpy=\n","array([[[-2.28974912e-02,  1.54584609e-02,  4.12188470e-04, ...,\n","          2.57202573e-02, -3.61369178e-03,  5.57503104e-03],\n","        [ 3.22849676e-02, -2.85259485e-02, -1.15373749e-02, ...,\n","         -2.19906047e-02,  2.55984887e-02, -1.66039579e-02],\n","        [ 3.61953303e-03,  3.58210132e-03,  2.00165845e-02, ...,\n","         -1.78897735e-02,  3.04071754e-02,  2.77719051e-02],\n","        ...,\n","        [ 2.41844356e-02,  3.32634896e-04,  4.08442318e-03, ...,\n","          1.83030702e-02, -7.79001601e-03, -1.05645098e-02],\n","        [-1.05074104e-02, -2.51835957e-03,  7.24064931e-03, ...,\n","         -2.22520456e-02,  1.79946050e-03,  2.13704668e-02],\n","        [ 1.80927813e-02, -1.55704729e-02, -8.39344412e-03, ...,\n","         -2.67456882e-02, -1.54765174e-02,  3.20075378e-02]],\n","\n","       [[ 1.64858028e-02, -1.92899071e-02,  2.43468583e-03, ...,\n","          1.98515393e-02, -2.37383768e-02, -4.08389047e-03],\n","        [-3.42777818e-02,  5.05880266e-03, -2.78432332e-02, ...,\n","          2.36938372e-02, -3.43201943e-02, -2.42513418e-02],\n","        [-2.35047564e-03, -1.15715656e-02, -2.51819640e-02, ...,\n","         -3.24043334e-02,  2.65617445e-02,  1.06023476e-02],\n","        ...,\n","        [-8.91644508e-04,  1.12040974e-02,  1.54419616e-03, ...,\n","         -3.15247439e-02, -2.64437348e-02, -1.54807847e-02],\n","        [-3.69633362e-03,  1.22148693e-02, -2.64255740e-02, ...,\n","         -2.24285498e-02, -4.01535630e-03, -4.34495509e-03],\n","        [-2.27479674e-02,  2.82067209e-02, -8.74494389e-03, ...,\n","          5.87590039e-04,  7.73364678e-03, -2.75022276e-02]],\n","\n","       [[ 1.28522255e-02, -2.41186805e-02,  2.67579556e-02, ...,\n","         -4.94657643e-03,  2.87885070e-02, -2.37856843e-02],\n","        [ 1.44409426e-02,  1.22257359e-02, -4.15404141e-03, ...,\n","         -3.66970897e-03,  3.31883281e-02, -1.64286327e-02],\n","        [ 2.36634240e-02,  1.77393220e-02,  2.96211243e-03, ...,\n","          3.96796316e-03, -2.07968950e-02, -2.75497511e-02],\n","        ...,\n","        [-3.31224687e-02,  3.50992754e-03,  1.54596642e-02, ...,\n","          1.49345584e-02, -1.43040325e-02,  2.26310343e-02],\n","        [ 2.91606486e-02,  2.94694677e-03, -2.34679505e-02, ...,\n","          1.20138563e-02, -7.64051825e-03,  8.69430602e-04],\n","        [-3.33590657e-02, -2.90505011e-02,  3.45148966e-02, ...,\n","         -2.09655426e-02, -3.54728326e-02, -1.02499425e-02]],\n","\n","       ...,\n","\n","       [[ 1.17343627e-02,  8.49702582e-03,  1.31635778e-02, ...,\n","         -2.69647874e-02,  1.16406493e-02,  1.79372355e-03],\n","        [ 3.14736292e-02, -1.19778588e-02, -3.72098386e-03, ...,\n","          1.29734725e-02, -2.31681392e-03, -1.16672590e-02],\n","        [-3.34663615e-02,  1.35111548e-02, -3.45395096e-02, ...,\n","         -2.20084041e-02,  3.10318321e-02,  2.28013508e-02],\n","        ...,\n","        [-2.86765769e-03, -2.14279983e-02,  3.45591381e-02, ...,\n","         -1.92735270e-02, -3.09042893e-02,  1.50519833e-02],\n","        [ 2.30783299e-02, -2.54872330e-02,  3.59839574e-03, ...,\n","         -3.36159207e-02,  2.83299908e-02,  6.84656575e-03],\n","        [-5.88200986e-03, -2.37992778e-03,  3.33181024e-03, ...,\n","          1.03108175e-02, -2.50630435e-02,  1.63927302e-02]],\n","\n","       [[ 2.77591050e-02,  4.13391739e-03, -1.04419142e-02, ...,\n","          2.80764997e-02,  2.35572085e-02, -1.95977036e-02],\n","        [-1.38094686e-02,  1.56843811e-02, -1.93197690e-02, ...,\n","          2.87703127e-02, -3.48712653e-02,  1.15219243e-02],\n","        [-9.93395597e-03, -3.31369713e-02,  1.52401961e-02, ...,\n","          2.88162082e-02, -4.16544080e-03,  1.88986175e-02],\n","        ...,\n","        [-2.23715864e-02, -9.01606493e-03,  2.40780488e-02, ...,\n","          2.69684792e-02,  1.34242363e-02,  5.68027422e-03],\n","        [-1.77662130e-02, -2.07973570e-02, -9.03161056e-03, ...,\n","          5.34504652e-05,  3.34443077e-02,  2.37568021e-02],\n","        [-1.51509829e-02,  2.88993940e-02, -3.07435058e-02, ...,\n","          4.57391143e-03, -2.07428150e-02,  1.76463462e-02]],\n","\n","       [[-2.72454750e-02, -2.77158804e-02, -4.58708405e-03, ...,\n","         -9.47202556e-03, -3.42915803e-02,  8.78671184e-03],\n","        [ 2.81288698e-02,  2.60273479e-02, -2.10548602e-02, ...,\n","          2.73656100e-03,  2.82725543e-02,  2.92398632e-02],\n","        [-3.03911455e-02,  6.26933202e-03,  3.26655880e-02, ...,\n","          1.59657300e-02,  7.87425786e-04,  6.95667788e-03],\n","        ...,\n","        [ 1.57944672e-02, -3.33133042e-02,  1.15449280e-02, ...,\n","         -1.65165570e-02,  2.96764746e-02, -2.62314770e-02],\n","        [ 6.78060204e-03, -2.07359754e-02,  2.65041664e-02, ...,\n","         -1.05020329e-02, -7.86459632e-03,  2.59412639e-02],\n","        [ 3.55144590e-02,  2.99873576e-02, -2.61120312e-02, ...,\n","         -1.61711480e-02,  9.25172493e-03, -7.07774982e-03]]],\n","      dtype=float32)>\n","bias  <tf.Variable 'bias:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[ 0.08696642, -0.04716302, -0.07117306, -0.03789845,\n","         -0.0523841 , -0.06084825, -0.05807973, -0.05211441,\n","         -0.03626291,  0.04036898, -0.00219151,  0.08089095,\n","          0.04215302,  0.07698592,  0.07290315, -0.05354462,\n","          0.0270151 , -0.02523319,  0.03492673, -0.072225  ,\n","          0.08433659,  0.03010359,  0.03937563, -0.0612882 ,\n","          0.00542291,  0.071552  ,  0.02569556,  0.08203072,\n","         -0.05459648,  0.06628203, -0.08305888,  0.00790808,\n","          0.01045848, -0.06722869, -0.04430544,  0.00899982,\n","         -0.05452786, -0.0403422 , -0.05366817,  0.024895  ,\n","          0.06067205,  0.08490387, -0.07856727, -0.00372235,\n","         -0.01808753, -0.0062163 ,  0.05842391, -0.05199242,\n","          0.00476184, -0.0401596 ,  0.02541615, -0.08099828,\n","          0.01356632,  0.03680456, -0.00017171, -0.01416602,\n","          0.02984787, -0.0505091 ,  0.07778414, -0.00990984,\n","         -0.00460707,  0.04360677, -0.04787755,  0.05449783,\n","          0.08165088,  0.00999713, -0.02021953,  0.00681175,\n","          0.05711817, -0.05324683,  0.0343175 ,  0.07965014,\n","         -0.00043167,  0.00999036, -0.01707369, -0.00928826,\n","         -0.04063038,  0.03305653,  0.05216796,  0.01663515,\n","         -0.07308757, -0.01644119,  0.01868035,  0.03285524,\n","          0.00949746, -0.07562759, -0.00962575,  0.01374942,\n","         -0.07755876, -0.01677278,  0.01416768, -0.00746109,\n","         -0.00795311, -0.04190973, -0.01444577,  0.05687454,\n","         -0.05514256, -0.05325697,  0.06029197,  0.04545289,\n","          0.0190957 ,  0.06200521, -0.04204686, -0.02748044,\n","         -0.01002726,  0.02740611,  0.04922561,  0.0162093 ,\n","          0.0039311 , -0.0636445 ,  0.07513816,  0.00314639,\n","          0.05203106,  0.08071945,  0.01189504, -0.01431444,\n","         -0.08659146,  0.01544295,  0.02541021, -0.02312621,\n","         -0.06251214, -0.03217364,  0.02560242, -0.05282098,\n","         -0.03959861,  0.08312465, -0.00248407,  0.05420456],\n","        [ 0.05373152,  0.05305438, -0.07351984, -0.03193755,\n","         -0.01776586, -0.0720179 , -0.04011701, -0.05007391,\n","          0.08040196,  0.02886379, -0.07057475, -0.00189703,\n","         -0.0515505 , -0.00573787, -0.08292428,  0.04212327,\n","         -0.08327595, -0.07366163, -0.04028202, -0.07911798,\n","         -0.02692638, -0.02525602, -0.01612077,  0.08271668,\n","          0.05004091, -0.02316077, -0.02257448, -0.03393245,\n","         -0.05593938,  0.00839565,  0.07908795, -0.07090008,\n","         -0.00284026,  0.01758736, -0.01213165, -0.0593721 ,\n","         -0.07896629, -0.01507106,  0.05453014, -0.08288565,\n","         -0.07465446,  0.0406692 ,  0.02647147, -0.05574096,\n","         -0.07834024,  0.03848311, -0.06566742,  0.05546934,\n","         -0.06668847,  0.05059902, -0.04193472, -0.07353912,\n","         -0.07852689,  0.02183664,  0.02644036,  0.06695517,\n","         -0.00499552, -0.08715395,  0.05440532, -0.01878399,\n","          0.00521738,  0.05793203,  0.01186423,  0.00442605,\n","          0.01693578,  0.01892604, -0.03106396,  0.01990269,\n","         -0.03663516,  0.01116067, -0.04160372, -0.01222027,\n","          0.07756739, -0.0101143 , -0.00151653, -0.07234295,\n","          0.05561768, -0.05768508,  0.04872639,  0.02910352,\n","         -0.07101192,  0.00021923,  0.01289774,  0.05373657,\n","          0.01181264,  0.02605902, -0.01998667, -0.08456379,\n","         -0.02174067,  0.07178885, -0.0005174 , -0.01982225,\n","         -0.04966614, -0.04677232, -0.04281414, -0.02817386,\n","         -0.06133867, -0.06156736, -0.01774976, -0.00635453,\n","         -0.02408838, -0.03323926, -0.0500356 , -0.01093846,\n","         -0.05419248,  0.01878007,  0.00512052,  0.01279525,\n","          0.05179083, -0.0424565 , -0.06798999, -0.08114512,\n","         -0.04913922, -0.03016935, -0.06044463, -0.06823163,\n","          0.02960378,  0.0523937 ,  0.033796  ,  0.04634757,\n","          0.00284205, -0.05720893, -0.0233797 , -0.01688103,\n","          0.03529274, -0.07074072, -0.02326103,  0.03785305]]],\n","      dtype=float32)>\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1390_input'), name='dense_1390_input', description=\"created by layer 'dense_1390_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1391_input'), name='dense_1391_input', description=\"created by layer 'dense_1391_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1392_input'), name='dense_1392_input', description=\"created by layer 'dense_1392_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1393_input'), name='dense_1393_input', description=\"created by layer 'dense_1393_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1394_input'), name='dense_1394_input', description=\"created by layer 'dense_1394_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1395_input'), name='dense_1395_input', description=\"created by layer 'dense_1395_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","LAYER  4 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_214')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_214')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_214')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_214')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_214')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_214')>]\n","layer num : 5\n","Model: \"sequential_1098\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1397 (Dense)           (None, 128)               12288     \n","=================================================================\n","Total params: 12,288\n","Trainable params: 12,288\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  5 None\n","Model: \"sequential_1099\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1398 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  5 None\n","Model: \"sequential_1100\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1399 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  5 None\n","Model: \"sequential_1101\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1400 (Dense)           (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  5 None\n","Model: \"sequential_1102\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1401 (Dense)           (None, 128)               16384     \n","=================================================================\n","Total params: 16,384\n","Trainable params: 16,384\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  5 None\n","Model: \"sequential_1103\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1402 (Dense)           (None, 128)               16384     \n","=================================================================\n","Total params: 16,384\n","Trainable params: 16,384\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  5 None\n","Model: \"sequential_1104\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1403 (Dense)           (None, 1280)              163840    \n","_________________________________________________________________\n","dense_1404 (Dense)           (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  5 None\n","W_BRANCH AT DEPTH  5 <tf.Variable 'branch:0' shape=(24, 128, 256) dtype=float32, numpy=\n","array([[[-1.96473487e-03,  1.49192661e-02, -1.54882511e-02, ...,\n","         -9.61322710e-03,  2.46124491e-02, -1.96085386e-02],\n","        [ 2.49799192e-02, -2.28254627e-02, -1.20410044e-02, ...,\n","          1.48624294e-02,  1.92528069e-02,  1.88462250e-02],\n","        [ 2.45506242e-02,  6.92910329e-03, -2.75428966e-03, ...,\n","         -2.49175653e-02,  1.05179213e-02,  9.88471135e-03],\n","        ...,\n","        [-2.33352371e-02,  1.38743445e-02, -1.20703690e-02, ...,\n","         -1.96084175e-02, -1.56812035e-02,  5.81541285e-03],\n","        [ 1.06731690e-02, -1.57434735e-02,  1.43554360e-02, ...,\n","         -1.91227458e-02, -8.08941573e-03,  8.33330303e-03],\n","        [-4.63297591e-03,  1.23255588e-02,  9.87400860e-03, ...,\n","         -1.63740106e-03,  6.27973303e-03,  9.68821719e-03]],\n","\n","       [[-2.21533291e-02,  2.46119238e-02, -6.62712380e-03, ...,\n","          2.26036757e-02,  1.62926055e-02, -2.31408067e-02],\n","        [-1.96699388e-02,  2.38804743e-02, -1.92156862e-02, ...,\n","          1.60168707e-02, -1.75155234e-02, -2.00179443e-02],\n","        [ 7.75470957e-03,  1.43814199e-02, -1.90259032e-02, ...,\n","         -2.00935081e-03,  1.00126863e-02,  1.63618065e-02],\n","        ...,\n","        [-2.43605599e-02, -3.75081971e-03,  1.38067827e-02, ...,\n","         -1.14033325e-02,  2.36925483e-03,  6.52900711e-03],\n","        [ 1.91368870e-02, -1.63638406e-03,  9.85152647e-03, ...,\n","         -1.83884092e-02,  2.47083642e-02,  1.86678581e-03],\n","        [-1.98142361e-02,  1.56648643e-03,  7.21834973e-03, ...,\n","          1.76968277e-02, -1.07507817e-02, -2.19038986e-02]],\n","\n","       [[ 3.27929109e-03, -1.09490631e-02,  5.09502552e-03, ...,\n","         -1.90202147e-03,  9.47283581e-03,  1.40756816e-02],\n","        [ 2.27500461e-02, -2.47331709e-03, -7.48519041e-03, ...,\n","          6.19445741e-03,  3.44644487e-03,  6.00467995e-03],\n","        [-5.75950369e-04,  9.54882428e-03,  3.32084112e-03, ...,\n","         -2.34211478e-02,  2.07855552e-03, -1.67902820e-02],\n","        ...,\n","        [ 4.15764563e-03, -1.80252008e-02,  1.47314966e-02, ...,\n","          1.79085210e-02,  1.93369053e-02,  1.92209966e-02],\n","        [-5.26756048e-05, -1.25793582e-02,  6.21584058e-03, ...,\n","         -2.39442326e-02, -2.41643470e-02, -1.58524755e-02],\n","        [-1.57422088e-02, -6.11985661e-03, -4.58309799e-03, ...,\n","         -8.73458758e-03, -2.45942343e-02, -1.35554112e-02]],\n","\n","       ...,\n","\n","       [[-2.15372480e-02,  1.72085762e-02, -9.15480778e-03, ...,\n","          1.46283619e-02,  2.01752670e-02,  1.49444230e-02],\n","        [-1.84441749e-02,  6.08985126e-03,  1.26641728e-02, ...,\n","          7.22076371e-03,  8.06108490e-03,  2.36571394e-03],\n","        [ 2.11503133e-02,  2.11577117e-02, -1.71177089e-05, ...,\n","          2.17614435e-02, -1.10788392e-02, -1.50456801e-02],\n","        ...,\n","        [-5.02670929e-03, -2.06838232e-02,  1.33850574e-02, ...,\n","          1.30221508e-02, -6.68926537e-03, -1.90297738e-02],\n","        [ 6.25764951e-03, -1.71779767e-02, -2.42409669e-03, ...,\n","          2.08699815e-02,  1.96170248e-02, -1.74864195e-02],\n","        [-1.49447285e-03, -1.45490877e-02,  1.47738755e-02, ...,\n","          1.02667511e-02, -1.68027040e-02, -2.40254812e-02]],\n","\n","       [[-2.52487324e-03, -9.77876224e-03, -1.21427309e-02, ...,\n","          1.90101787e-02,  1.46135092e-02,  1.89080872e-02],\n","        [-1.50343953e-02, -2.93182209e-03, -2.10490022e-02, ...,\n","          1.16349086e-02,  2.54186578e-02,  3.03360820e-03],\n","        [-2.06290670e-02,  9.49520990e-03,  6.28136843e-03, ...,\n","          6.42719865e-03, -1.68706439e-02,  9.21199098e-04],\n","        ...,\n","        [-1.41041167e-03,  1.37037076e-02,  3.52588668e-03, ...,\n","          9.26401839e-03, -9.01018828e-03,  8.28129053e-03],\n","        [ 1.10194087e-04, -2.28772573e-02,  2.54789963e-02, ...,\n","          4.96534631e-03, -1.07833091e-02, -7.93899223e-03],\n","        [-1.14190280e-02, -8.01615976e-03, -1.24643706e-02, ...,\n","          1.75074674e-03, -8.33091885e-03, -6.08973764e-03]],\n","\n","       [[ 1.73872076e-02, -8.77088122e-03,  7.44159147e-03, ...,\n","         -7.50407577e-04,  1.20429508e-03,  6.55818731e-04],\n","        [ 1.36450380e-02, -3.50657851e-03, -1.42282937e-02, ...,\n","         -3.81793827e-03,  1.07610673e-02,  7.68061727e-03],\n","        [ 1.76253654e-02, -2.44312007e-02, -9.38063487e-03, ...,\n","          1.51775144e-02,  6.37619197e-03,  5.70016913e-03],\n","        ...,\n","        [-1.87115148e-02,  9.70872492e-03, -1.92594565e-02, ...,\n","         -2.52511725e-03,  2.43853070e-02, -1.24673760e-02],\n","        [ 2.24919915e-02, -9.62433591e-03,  7.76048005e-03, ...,\n","          1.30097866e-02, -2.51840483e-02, -6.53180294e-03],\n","        [ 8.53908435e-03, -1.15914615e-02, -1.21392328e-02, ...,\n","          8.86877999e-03,  1.53639689e-02,  2.27339640e-02]]],\n","      dtype=float32)>\n","bias  <tf.Variable 'bias:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[ 8.4807806e-02,  7.4791454e-02, -4.3238431e-02, -6.6195816e-02,\n","         -2.4921134e-02,  6.3492507e-03, -2.4664290e-02,  4.3919533e-03,\n","         -6.2203519e-02,  4.7347523e-02,  3.7124522e-02,  1.8070251e-02,\n","         -8.6087190e-02,  2.6071869e-02, -9.8671243e-03, -8.0745943e-02,\n","          6.2776335e-02, -5.2664235e-02,  2.0017475e-02,  5.4573633e-02,\n","         -3.6306158e-02, -3.5081539e-02, -7.5269192e-03,  7.8060351e-02,\n","         -2.1243840e-04,  2.2607356e-02,  2.1466441e-02,  1.8786073e-02,\n","          4.4695176e-02, -6.5647699e-02,  7.5205438e-02, -6.5135762e-02,\n","          6.8070240e-02, -5.0801050e-02,  5.3371690e-02,  7.4999742e-02,\n","          2.8927341e-02,  5.6029342e-02, -5.8208358e-02,  2.9562935e-02,\n","         -4.8432291e-02, -4.9193822e-02,  1.4813438e-02,  3.7465282e-02,\n","         -2.9565636e-02,  5.4953553e-02,  8.7083429e-03,  9.3743876e-03,\n","          7.5563140e-02,  3.4784913e-02, -1.0512076e-02, -6.1410867e-02,\n","         -1.5565418e-02, -7.0103548e-02, -4.7229022e-02, -2.9426515e-03,\n","         -3.6583360e-02,  1.3318300e-02, -5.6582965e-02,  2.8003439e-02,\n","          8.0156036e-02, -4.7528114e-02, -5.1935602e-02,  6.6674732e-02,\n","         -5.9230883e-02,  4.5082718e-04, -5.5602629e-02,  2.2831455e-02,\n","          2.3376182e-02, -8.3118998e-02,  6.5515630e-02, -2.7505245e-02,\n","         -7.6128587e-02,  8.2644470e-02, -8.2240805e-02,  6.2572561e-02,\n","         -6.7169093e-02,  6.1674289e-02, -2.6268661e-03, -4.2112201e-02,\n","         -4.3900114e-02,  3.1233005e-02, -8.0730073e-02,  5.5666186e-02,\n","         -7.6541096e-02, -2.5171191e-02,  4.0243514e-02,  8.3597451e-03,\n","          6.3706569e-02, -1.6504176e-02, -5.5191804e-02, -3.9677970e-02,\n","         -1.5628681e-02,  7.2362788e-02, -7.2780922e-02, -5.9600048e-02,\n","          4.3815084e-02, -3.9625391e-03,  6.9210492e-02,  7.0439734e-02,\n","         -6.6919394e-02, -1.0579407e-02,  4.8486896e-02, -3.9054196e-02,\n","          8.6446978e-02, -6.4832345e-02, -1.5467346e-02,  8.6614527e-02,\n","          7.3095933e-03,  4.6630077e-02,  2.3878887e-02, -7.5997613e-02,\n","         -6.2862799e-02,  1.0752544e-02,  6.9539182e-02, -7.1593940e-02,\n","         -7.2766237e-02,  5.9891663e-02, -7.1243942e-03,  6.9609560e-02,\n","          7.0447929e-02, -6.3879281e-02, -3.3343635e-02, -1.8045254e-02,\n","          1.7950065e-02, -7.2506741e-02,  8.0276914e-02, -1.7091013e-02],\n","        [-3.0771140e-02,  6.5371193e-02, -5.5296421e-03, -3.5825811e-02,\n","         -7.3504254e-02,  3.3486515e-02, -8.3798237e-02, -6.8285540e-02,\n","         -5.9215054e-03,  7.9174481e-02, -5.8004662e-02,  7.9683505e-02,\n","          4.8156001e-02, -2.6060279e-02, -2.0042874e-02, -2.0322472e-02,\n","         -5.6470286e-02, -4.7405109e-02, -7.0613332e-02,  5.8426462e-02,\n","         -2.0719878e-02,  7.7733524e-02,  7.8128017e-02,  4.3548815e-02,\n","          5.7601802e-02,  2.0261064e-02,  5.0255440e-02,  4.0578462e-02,\n","         -2.0288080e-02,  2.3281753e-02, -1.2590088e-02, -1.4602788e-02,\n","          5.5385895e-02,  8.6413570e-02, -1.6482875e-02,  4.5868076e-02,\n","         -8.0265217e-02,  5.6541689e-02, -6.0104840e-02,  5.1560998e-03,\n","         -6.2692612e-03,  7.6265164e-02, -2.6233252e-02, -2.7441032e-02,\n","         -7.1452476e-02,  8.1574619e-03,  6.6011049e-02,  3.4972318e-02,\n","         -6.0501993e-03, -1.7026946e-02,  8.4775351e-02,  5.2877821e-02,\n","          2.3926996e-02, -8.7862313e-02,  1.0611542e-02, -7.0682980e-02,\n","          3.6742538e-03, -3.5073657e-02,  2.9073209e-02, -6.2303409e-02,\n","          2.7371280e-02,  8.7438382e-02,  2.6296154e-02,  7.5141557e-02,\n","         -1.8660367e-02, -1.5175812e-02, -5.9322257e-02, -7.6234899e-02,\n","          5.8995329e-02,  4.0684901e-02, -5.4345433e-02,  1.5589446e-02,\n","          1.8425442e-02, -4.2885136e-02, -8.8352524e-02,  5.3184249e-02,\n","          2.7632907e-02, -8.6623870e-02, -8.8642389e-03,  3.4964390e-02,\n","         -4.9762972e-02, -4.4505764e-02,  2.7328163e-02, -2.6731260e-02,\n","         -4.2960368e-02, -6.1122265e-02, -2.0899318e-02, -2.2449158e-02,\n","          2.4900965e-02, -5.1945191e-02, -7.4229427e-02, -6.5024644e-02,\n","         -2.7518708e-02, -7.6092616e-02,  3.8283683e-02, -4.3011386e-02,\n","          1.0924108e-02, -3.5908673e-02, -1.4200620e-02,  1.5480518e-02,\n","         -8.4234372e-02,  9.8091960e-03,  4.8547052e-02, -2.5480986e-05,\n","          3.5183452e-02,  5.9319519e-02, -5.6577906e-02, -2.1810442e-02,\n","         -8.3899371e-02, -2.2333592e-02, -1.1028126e-03,  4.8340775e-02,\n","         -3.3906400e-02, -7.7829339e-02,  2.1947928e-02, -7.5863898e-03,\n","         -6.4917631e-02, -8.8290565e-02, -5.2446548e-02, -6.5967046e-02,\n","         -4.3002557e-02,  2.6442513e-02,  8.6981215e-02,  5.6335397e-02,\n","         -1.8607810e-02,  2.9825851e-02,  7.6461248e-02,  3.4446068e-02]]],\n","      dtype=float32)>\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1397_input'), name='dense_1397_input', description=\"created by layer 'dense_1397_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1398_input'), name='dense_1398_input', description=\"created by layer 'dense_1398_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1399_input'), name='dense_1399_input', description=\"created by layer 'dense_1399_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1400_input'), name='dense_1400_input', description=\"created by layer 'dense_1400_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1401_input'), name='dense_1401_input', description=\"created by layer 'dense_1401_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1402_input'), name='dense_1402_input', description=\"created by layer 'dense_1402_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1403_input'), name='dense_1403_input', description=\"created by layer 'dense_1403_input'\"), but it was called on an input with incompatible shape (1, 48, 128).\n","LAYER  5 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_215')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_215')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_215')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_215')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_215')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_215')>, <KerasTensor: shape=(1, 48, 128) dtype=float32 (created by layer 'tree_gcn_215')>]\n","layer num : 6\n","Model: \"sequential_1105\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1405 (Dense)           (None, 3)                 288       \n","=================================================================\n","Total params: 288\n","Trainable params: 288\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  6 None\n","Model: \"sequential_1106\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1406 (Dense)           (None, 3)                 768       \n","=================================================================\n","Total params: 768\n","Trainable params: 768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  6 None\n","Model: \"sequential_1107\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1407 (Dense)           (None, 3)                 768       \n","=================================================================\n","Total params: 768\n","Trainable params: 768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  6 None\n","Model: \"sequential_1108\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1408 (Dense)           (None, 3)                 768       \n","=================================================================\n","Total params: 768\n","Trainable params: 768\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  6 None\n","Model: \"sequential_1109\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1409 (Dense)           (None, 3)                 384       \n","=================================================================\n","Total params: 384\n","Trainable params: 384\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  6 None\n","Model: \"sequential_1110\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1410 (Dense)           (None, 3)                 384       \n","=================================================================\n","Total params: 384\n","Trainable params: 384\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  6 None\n","Model: \"sequential_1111\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1411 (Dense)           (None, 3)                 384       \n","=================================================================\n","Total params: 384\n","Trainable params: 384\n","Non-trainable params: 0\n","_________________________________________________________________\n","W ROOT AT DEPTH  6 None\n","Model: \"sequential_1112\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1412 (Dense)           (None, 1280)              163840    \n","_________________________________________________________________\n","dense_1413 (Dense)           (None, 3)                 3840      \n","=================================================================\n","Total params: 167,680\n","Trainable params: 167,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","W LOOP AT DEPTH  6 None\n","W_BRANCH AT DEPTH  6 <tf.Variable 'branch:0' shape=(48, 128, 8192) dtype=float32, numpy=\n","array([[[-2.0310362e-03, -3.2708158e-03,  3.3715903e-03, ...,\n","         -1.5683062e-03,  2.5160750e-04,  2.5779069e-03],\n","        [-1.5269523e-03,  3.8496451e-03,  3.4951679e-03, ...,\n","         -2.7270832e-03, -3.0203164e-03, -8.2941097e-04],\n","        [ 2.9943692e-03,  2.6793112e-03,  1.4718887e-03, ...,\n","         -1.9970909e-03,  2.9700426e-03,  2.2114487e-05],\n","        ...,\n","        [-3.0832109e-03, -3.0869877e-03,  1.8431898e-03, ...,\n","         -1.3255500e-03, -2.0862669e-03,  2.3756982e-03],\n","        [ 1.2319707e-03,  8.1875362e-05, -2.8986305e-03, ...,\n","          8.4389606e-04, -6.7472924e-04,  1.2525436e-03],\n","        [ 2.8871656e-03, -2.8459560e-03,  2.3464160e-03, ...,\n","          4.0609157e-04, -2.9424306e-03,  1.0975190e-03]],\n","\n","       [[ 1.3693236e-03, -3.1841102e-03,  2.4861540e-03, ...,\n","          3.5347096e-03,  3.7211105e-03,  2.2010412e-04],\n","        [ 2.6713968e-03,  2.8469134e-03,  2.9668859e-03, ...,\n","         -2.6120094e-03,  1.6623773e-03,  2.7128402e-03],\n","        [ 3.7430050e-03,  2.9319776e-03, -3.6110724e-03, ...,\n","          1.0778462e-03,  1.8938971e-03,  6.4860098e-04],\n","        ...,\n","        [ 1.2374092e-03, -3.3233471e-03, -2.3457599e-03, ...,\n","         -2.1736859e-03, -1.2093175e-03, -1.5988655e-03],\n","        [-2.6005707e-03, -2.4085231e-03,  3.2313424e-03, ...,\n","         -2.3593642e-03,  1.7890311e-03, -3.6885664e-03],\n","        [ 2.2698520e-03, -3.1021168e-03,  1.4662785e-03, ...,\n","         -1.5639164e-04,  3.6468962e-04,  1.0350812e-04]],\n","\n","       [[-1.8631751e-03, -3.0584661e-03,  5.1359413e-04, ...,\n","         -3.6969269e-03,  2.5853482e-03,  3.0133734e-03],\n","        [-1.6929817e-03, -2.7927896e-03,  6.8300357e-04, ...,\n","          2.8671212e-03,  3.1593130e-03,  6.7060953e-04],\n","        [-3.0507497e-04, -3.4233732e-03,  2.3078346e-03, ...,\n","         -2.1655988e-03, -3.8442179e-04,  3.1425585e-03],\n","        ...,\n","        [ 3.8292035e-03, -1.3713073e-04,  1.6484619e-03, ...,\n","         -3.1219050e-03,  1.1246698e-03, -3.8341880e-03],\n","        [ 7.8842603e-04,  2.0108963e-03, -3.3549468e-03, ...,\n","         -3.0735906e-03, -2.2205254e-03,  2.3542526e-03],\n","        [-1.6683056e-03,  1.6646720e-03,  1.7225901e-03, ...,\n","          5.6433957e-05, -1.1423135e-03, -1.1102434e-03]],\n","\n","       ...,\n","\n","       [[ 1.9614277e-03, -3.2966794e-04,  3.4941291e-03, ...,\n","          2.8376561e-03, -1.8187438e-03, -2.8076866e-03],\n","        [ 2.3685573e-03,  3.3791019e-03, -7.6333294e-04, ...,\n","          2.9514539e-03,  3.3504702e-03,  3.2444764e-04],\n","        [ 2.7520005e-03,  3.4800991e-03, -3.2048393e-04, ...,\n","         -3.5873537e-03, -1.4856695e-03, -2.7300874e-03],\n","        ...,\n","        [ 1.3716659e-03, -2.7483352e-03, -1.6447024e-03, ...,\n","         -3.7826598e-05,  3.6979867e-03,  2.0239553e-03],\n","        [ 1.4380640e-03, -2.2113849e-03,  2.5828946e-03, ...,\n","         -3.1851009e-03, -1.2065738e-03,  2.7123801e-03],\n","        [ 2.5843973e-03,  1.8738136e-03,  3.2277098e-03, ...,\n","         -3.0298126e-03, -7.6702307e-04,  1.4648628e-03]],\n","\n","       [[ 1.8163468e-03,  2.4361834e-03, -3.4856955e-03, ...,\n","         -2.2931825e-03,  1.0909215e-03, -3.0783508e-03],\n","        [-8.3910068e-05,  1.0721893e-03,  2.6192325e-03, ...,\n","         -3.7690285e-03,  1.1538612e-03, -1.1727433e-03],\n","        [ 1.8930431e-03,  2.0087222e-03, -1.2676497e-03, ...,\n","          5.6172907e-04, -3.3179391e-03, -3.1095799e-03],\n","        ...,\n","        [ 1.0530837e-04, -3.0785475e-03, -4.8775156e-04, ...,\n","         -1.3529218e-03, -4.2572198e-04,  3.1842776e-03],\n","        [ 2.3379521e-03, -3.4671391e-03,  2.4415362e-03, ...,\n","          2.4940553e-03,  9.9784695e-05, -3.7408648e-03],\n","        [ 1.5347311e-04, -3.8563192e-03,  2.0254324e-03, ...,\n","         -3.0624603e-03, -6.8643037e-04, -3.6159139e-03]],\n","\n","       [[-1.4686887e-03,  2.8790538e-03, -1.1711861e-03, ...,\n","         -1.3322048e-03,  3.3866474e-03, -1.3313582e-04],\n","        [-4.0451321e-04,  6.3541578e-04,  5.3125853e-04, ...,\n","          3.1311703e-03, -3.7781256e-03,  3.3680983e-03],\n","        [ 3.5720342e-03,  2.0810943e-03,  3.8318732e-03, ...,\n","         -3.3377691e-03, -3.3673090e-03,  2.8556935e-03],\n","        ...,\n","        [ 8.3389506e-04,  3.0904207e-03, -3.2910432e-03, ...,\n","          2.8294590e-03, -1.7554234e-03,  1.5675412e-03],\n","        [-7.0779352e-04, -1.0458962e-03, -2.3960131e-03, ...,\n","          3.5974332e-03,  1.1863946e-03, -3.5586946e-03],\n","        [ 2.4134028e-03,  1.5389393e-03,  1.8644552e-03, ...,\n","          5.5850018e-05, -1.2933542e-03,  1.9439352e-03]]], dtype=float32)>\n","bias  <tf.Variable 'bias:0' shape=(1, 64, 3) dtype=float32, numpy=\n","array([[[ 2.25272954e-01,  2.52955556e-02,  2.57146180e-01],\n","        [ 1.40371859e-01, -3.76862764e-01, -1.33772433e-01],\n","        [ 3.62236142e-01,  5.41509509e-01,  5.21865845e-01],\n","        [ 2.45712757e-01, -5.22139370e-01,  4.95366573e-01],\n","        [-4.86320376e-01,  1.28683329e-01,  1.43086612e-01],\n","        [ 2.46448040e-01,  7.01118708e-02, -1.42634273e-01],\n","        [-1.16003335e-01,  4.65966344e-01,  2.90030837e-02],\n","        [ 3.08999717e-01, -5.07305682e-01, -3.56226265e-01],\n","        [ 1.95448637e-01, -1.68457478e-01,  4.75471139e-01],\n","        [-1.06155872e-04, -3.53092551e-02,  5.13917327e-01],\n","        [-3.72434974e-01, -3.89380902e-01,  1.96391940e-02],\n","        [ 4.90534186e-01, -1.02949202e-01,  1.43587649e-01],\n","        [ 4.68803763e-01,  2.94514298e-01, -5.49432814e-01],\n","        [-1.01604760e-01, -5.66014409e-01,  4.10278440e-02],\n","        [-3.81151557e-01, -1.78261995e-02,  1.08972013e-01],\n","        [ 2.79252350e-01,  4.24340963e-02, -3.15533191e-01],\n","        [ 1.03041828e-01,  3.34510863e-01, -7.34388828e-04],\n","        [ 5.66253424e-01, -3.30478638e-01,  4.49364781e-01],\n","        [ 6.15294576e-02,  5.76412678e-01, -6.67641759e-02],\n","        [-3.47278267e-01, -2.88396806e-01, -3.47743630e-02],\n","        [ 4.05868888e-01,  2.78541148e-01, -2.74146348e-01],\n","        [ 1.26910269e-01,  2.86812425e-01, -5.10194600e-01],\n","        [-3.71698260e-01,  5.62261939e-02,  5.36104679e-01],\n","        [-8.15951824e-03, -1.73013568e-01,  4.16492105e-01],\n","        [ 2.63194799e-01,  5.37872553e-01,  3.53779137e-01],\n","        [ 2.48700738e-01, -3.59592527e-01, -1.98414743e-01],\n","        [ 1.62704229e-01, -3.87035877e-01, -1.89380974e-01],\n","        [ 1.97432756e-01,  1.05058730e-01,  3.55904281e-01],\n","        [-2.93852180e-01, -2.25585669e-01,  5.53234577e-01],\n","        [ 4.79493618e-01, -5.68653047e-01, -2.42476135e-01],\n","        [ 2.35631883e-01,  1.50077939e-02, -5.75621903e-01],\n","        [ 8.88321400e-02,  3.75025153e-01, -2.40465760e-01],\n","        [ 2.26105988e-01,  5.19351363e-01,  1.21544600e-02],\n","        [-8.60894322e-02,  1.29100144e-01, -1.66073352e-01],\n","        [-3.63412499e-02, -3.18646312e-01,  2.26973057e-01],\n","        [ 4.91674304e-01, -5.41935980e-01,  1.42429471e-01],\n","        [-2.73260146e-01,  9.47601795e-02, -1.22525930e-01],\n","        [-4.05438721e-01,  3.57024074e-01, -2.59109616e-01],\n","        [-5.12754738e-01, -1.76290870e-02,  2.95855820e-01],\n","        [ 1.59001946e-02,  4.42077994e-01,  5.53673625e-01],\n","        [-2.96947420e-01, -4.53442723e-01, -8.45285952e-02],\n","        [ 5.33664584e-01, -1.42619550e-01,  5.09890795e-01],\n","        [-1.93507463e-01, -2.26284534e-01,  2.08082497e-01],\n","        [-8.68254602e-02,  4.91828680e-01,  2.09392250e-01],\n","        [-3.93697083e-01,  4.01811898e-01, -4.51303780e-01],\n","        [ 3.14657748e-01,  1.05576575e-01,  1.97505951e-01],\n","        [ 1.18488789e-01,  1.92121208e-01,  1.40755177e-01],\n","        [ 1.99929833e-01, -3.60627532e-01, -1.94593549e-01],\n","        [-4.20647383e-01,  3.20972741e-01, -2.08802283e-01],\n","        [-3.80632758e-01,  8.52306485e-02, -3.38045716e-01],\n","        [ 2.51007617e-01, -1.99031830e-01, -3.29807997e-01],\n","        [-5.50819933e-01,  2.84758151e-01,  4.72962737e-01],\n","        [ 6.55528903e-02, -5.39303541e-01, -3.77127469e-01],\n","        [-3.09758455e-01, -3.60253930e-01, -5.37862837e-01],\n","        [-2.47093439e-02,  3.47134948e-01, -1.14009380e-02],\n","        [-5.67464292e-01, -4.85065281e-01, -4.68658537e-01],\n","        [ 3.72044742e-01, -1.96417153e-01,  5.56329966e-01],\n","        [-1.17754132e-01, -8.38490129e-02,  4.37882066e-01],\n","        [ 1.14271402e-01, -5.33915699e-01,  2.25619793e-01],\n","        [ 4.82594490e-01, -4.57191378e-01, -5.31029582e-01],\n","        [ 5.13915181e-01,  4.53695178e-01, -3.38440537e-01],\n","        [-2.23699838e-01, -4.26007211e-01,  5.50888538e-01],\n","        [ 2.95785606e-01,  1.04121983e-01,  4.31451678e-01],\n","        [-1.15470499e-01, -4.28873956e-01, -5.68438292e-01]]],\n","      dtype=float32)>\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_1405_input'), name='dense_1405_input', description=\"created by layer 'dense_1405_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1406_input'), name='dense_1406_input', description=\"created by layer 'dense_1406_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1407_input'), name='dense_1407_input', description=\"created by layer 'dense_1407_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_1408_input'), name='dense_1408_input', description=\"created by layer 'dense_1408_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1409_input'), name='dense_1409_input', description=\"created by layer 'dense_1409_input'\"), but it was called on an input with incompatible shape (1, 12, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1410_input'), name='dense_1410_input', description=\"created by layer 'dense_1410_input'\"), but it was called on an input with incompatible shape (1, 24, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1411_input'), name='dense_1411_input', description=\"created by layer 'dense_1411_input'\"), but it was called on an input with incompatible shape (1, 48, 128).\n","WARNING:tensorflow:Model was constructed with shape (None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='dense_1412_input'), name='dense_1412_input', description=\"created by layer 'dense_1412_input'\"), but it was called on an input with incompatible shape (1, 3072, 128).\n","LAYER  6 [<KerasTensor: shape=(1, 1, 96) dtype=float32 (created by layer 'tree_gcn_216')>, <KerasTensor: shape=(1, 1, 256) dtype=float32 (created by layer 'tree_gcn_216')>, <KerasTensor: shape=(1, 2, 256) dtype=float32 (created by layer 'tree_gcn_216')>, <KerasTensor: shape=(1, 4, 256) dtype=float32 (created by layer 'tree_gcn_216')>, <KerasTensor: shape=(1, 12, 128) dtype=float32 (created by layer 'tree_gcn_216')>, <KerasTensor: shape=(1, 24, 128) dtype=float32 (created by layer 'tree_gcn_216')>, <KerasTensor: shape=(1, 48, 128) dtype=float32 (created by layer 'tree_gcn_216')>, <KerasTensor: shape=(1, 3072, 3) dtype=float32 (created by layer 'tree_gcn_216')>]\n","Model: \"TreeGCN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_33 (InputLayer)           [(None, 1, 1, 96)]   0                                            \n","__________________________________________________________________________________________________\n","tree_gcn_210 (TreeGCN)          [(1, 1, 96), (1, 1,  371968      input_33[0][0]                   \n","__________________________________________________________________________________________________\n","tree_gcn_211 (TreeGCN)          [(1, 1, 96), (1, 1,  1532416     tree_gcn_210[0][0]               \n","                                                                 tree_gcn_210[0][1]               \n","__________________________________________________________________________________________________\n","tree_gcn_212 (TreeGCN)          [(1, 1, 96), (1, 1,  1729024     tree_gcn_211[0][0]               \n","                                                                 tree_gcn_211[0][1]               \n","                                                                 tree_gcn_211[0][2]               \n","__________________________________________________________________________________________________\n","tree_gcn_213 (TreeGCN)          [(1, 1, 96), (1, 1,  1880448     tree_gcn_212[0][0]               \n","                                                                 tree_gcn_212[0][1]               \n","                                                                 tree_gcn_212[0][2]               \n","                                                                 tree_gcn_212[0][3]               \n","__________________________________________________________________________________________________\n","tree_gcn_214 (TreeGCN)          [(1, 1, 96), (1, 1,  848128      tree_gcn_213[0][0]               \n","                                                                 tree_gcn_213[0][1]               \n","                                                                 tree_gcn_213[0][2]               \n","                                                                 tree_gcn_213[0][3]               \n","                                                                 tree_gcn_213[0][4]               \n","__________________________________________________________________________________________________\n","tree_gcn_215 (TreeGCN)          [(1, 1, 96), (1, 1,  1257728     tree_gcn_214[0][0]               \n","                                                                 tree_gcn_214[0][1]               \n","                                                                 tree_gcn_214[0][2]               \n","                                                                 tree_gcn_214[0][3]               \n","                                                                 tree_gcn_214[0][4]               \n","                                                                 tree_gcn_214[0][5]               \n","__________________________________________________________________________________________________\n","tree_gcn_216 (TreeGCN)          [(1, 1, 96), (1, 1,  50503264    tree_gcn_215[0][0]               \n","                                                                 tree_gcn_215[0][1]               \n","                                                                 tree_gcn_215[0][2]               \n","                                                                 tree_gcn_215[0][3]               \n","                                                                 tree_gcn_215[0][4]               \n","                                                                 tree_gcn_215[0][5]               \n","                                                                 tree_gcn_215[0][6]               \n","==================================================================================================\n","Total params: 58,122,976\n","Trainable params: 58,122,976\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","tf.Tensor(\n","[[[-0.08347082 -0.15840754  0.06171245]\n","  [-0.11608535 -0.11059438 -0.09764854]\n","  [-0.17287765 -0.03439172 -0.28450948]\n","  ...\n","  [-0.5106552  -0.14228697  0.01785591]\n","  [-0.47441602 -0.32808098  0.745367  ]\n","  [-0.34537953 -0.3123542  -0.29703137]]], shape=(1, 3072, 3), dtype=float32)\n","(1, 3072, 3)\n","tf.Tensor([[-0.00109215]], shape=(1, 1), dtype=float32)\n","[<tf.Tensor: shape=(1, 3072, 3), dtype=float32, numpy=\n","array([[[ 2.1469018e-03,  3.6834881e-03, -1.6383411e-04],\n","        [-5.3584469e-03, -4.4939201e-04,  1.0781693e-03],\n","        [-3.2706910e-03,  1.9997847e-03,  6.5758917e-04],\n","        ...,\n","        [ 3.9718789e-04, -2.0791939e-03, -5.8904989e-04],\n","        [-2.7546748e-05,  3.6037376e-04,  1.8474448e-03],\n","        [ 2.0294772e-03,  1.6934500e-03,  2.3994481e-03]]], dtype=float32)>]\n","tf.Tensor(\n","[[[ 2.1469018e-03  3.6834881e-03 -1.6383411e-04]\n","  [-5.3584469e-03 -4.4939201e-04  1.0781693e-03]\n","  [-3.2706910e-03  1.9997847e-03  6.5758917e-04]\n","  ...\n","  [ 3.9718789e-04 -2.0791939e-03 -5.8904989e-04]\n","  [-2.7546748e-05  3.6037376e-04  1.8474448e-03]\n","  [ 2.0294772e-03  1.6934500e-03  2.3994481e-03]]], shape=(1, 3072, 3), dtype=float32)\n","DISC LOSS tf.Tensor(5.502695, shape=(), dtype=float32)\n","18\n","GRADIENTS 18\n","WARNING:tensorflow:Gradients do not exist for variables ['dense_1414/bias:0', 'dense_1415/bias:0', 'dense_1416/bias:0', 'dense_1417/bias:0'] when minimizing the loss.\n","Model: \"TreeGCN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_33 (InputLayer)           [(None, 1, 1, 96)]   0                                            \n","__________________________________________________________________________________________________\n","tree_gcn_210 (TreeGCN)          [(1, 1, 96), (1, 1,  371968      input_33[0][0]                   \n","__________________________________________________________________________________________________\n","tree_gcn_211 (TreeGCN)          [(1, 1, 96), (1, 1,  1532416     tree_gcn_210[0][0]               \n","                                                                 tree_gcn_210[0][1]               \n","__________________________________________________________________________________________________\n","tree_gcn_212 (TreeGCN)          [(1, 1, 96), (1, 1,  1729024     tree_gcn_211[0][0]               \n","                                                                 tree_gcn_211[0][1]               \n","                                                                 tree_gcn_211[0][2]               \n","__________________________________________________________________________________________________\n","tree_gcn_213 (TreeGCN)          [(1, 1, 96), (1, 1,  1880448     tree_gcn_212[0][0]               \n","                                                                 tree_gcn_212[0][1]               \n","                                                                 tree_gcn_212[0][2]               \n","                                                                 tree_gcn_212[0][3]               \n","__________________________________________________________________________________________________\n","tree_gcn_214 (TreeGCN)          [(1, 1, 96), (1, 1,  848128      tree_gcn_213[0][0]               \n","                                                                 tree_gcn_213[0][1]               \n","                                                                 tree_gcn_213[0][2]               \n","                                                                 tree_gcn_213[0][3]               \n","                                                                 tree_gcn_213[0][4]               \n","__________________________________________________________________________________________________\n","tree_gcn_215 (TreeGCN)          [(1, 1, 96), (1, 1,  1257728     tree_gcn_214[0][0]               \n","                                                                 tree_gcn_214[0][1]               \n","                                                                 tree_gcn_214[0][2]               \n","                                                                 tree_gcn_214[0][3]               \n","                                                                 tree_gcn_214[0][4]               \n","                                                                 tree_gcn_214[0][5]               \n","__________________________________________________________________________________________________\n","tree_gcn_216 (TreeGCN)          [(1, 1, 96), (1, 1,  50503264    tree_gcn_215[0][0]               \n","                                                                 tree_gcn_215[0][1]               \n","                                                                 tree_gcn_215[0][2]               \n","                                                                 tree_gcn_215[0][3]               \n","                                                                 tree_gcn_215[0][4]               \n","                                                                 tree_gcn_215[0][5]               \n","                                                                 tree_gcn_215[0][6]               \n","==================================================================================================\n","Total params: 58,122,976\n","Trainable params: 58,122,976\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","G LOSS\n","Disc watched variables: \n","(96, 256)\n","(96, 960)\n","(960, 256)\n","(1, 96, 96)\n","(1, 1, 256)\n","(96, 256)\n","(256, 256)\n","(256, 2560)\n","(2560, 256)\n","(1, 256, 512)\n","(1, 2, 256)\n","(96, 256)\n","(256, 256)\n","(256, 256)\n","(256, 2560)\n","(2560, 256)\n","(2, 256, 512)\n","(1, 2, 256)\n","(96, 128)\n","(256, 128)\n","(256, 128)\n","(256, 128)\n","(256, 2560)\n","(2560, 128)\n","(4, 256, 768)\n","(1, 3, 128)\n","(96, 128)\n","(256, 128)\n","(256, 128)\n","(256, 128)\n","(128, 128)\n","(128, 1280)\n","(1280, 128)\n","(12, 128, 256)\n","(1, 2, 128)\n","(96, 128)\n","(256, 128)\n","(256, 128)\n","(256, 128)\n","(128, 128)\n","(128, 128)\n","(128, 1280)\n","(1280, 128)\n","(24, 128, 256)\n","(1, 2, 128)\n","(96, 3)\n","(256, 3)\n","(256, 3)\n","(256, 3)\n","(128, 3)\n","(128, 3)\n","(128, 3)\n","(128, 1280)\n","(1280, 3)\n","(48, 128, 8192)\n","(1, 3072, 64)\n","(64,)\n","(1, 64, 128)\n","(128,)\n","(1, 128, 256)\n","(256,)\n","(1, 256, 512)\n","(512,)\n","(1, 512, 1024)\n","(1024,)\n","(1024, 1024)\n","(1024,)\n","(1024, 512)\n","(512,)\n","(512, 512)\n","(512,)\n","(512, 1)\n","(1,)\n","Gen Watched Variables:  (<tf.Variable 'dense_1372/kernel:0' shape=(96, 256) dtype=float32, numpy=\n","array([[-0.00559081,  0.04599713,  0.12354334, ..., -0.08164085,\n","         0.02515924, -0.05557559],\n","       [-0.05987451,  0.0952123 , -0.10472975, ...,  0.11711589,\n","         0.07943878,  0.06375061],\n","       [ 0.03228813, -0.12397433, -0.00083263, ..., -0.00821523,\n","         0.02235802,  0.00951204],\n","       ...,\n","       [ 0.0416224 ,  0.07720606,  0.01097733, ...,  0.01274155,\n","        -0.053231  ,  0.02889003],\n","       [ 0.11662973,  0.01023142, -0.06183131, ...,  0.10861872,\n","        -0.05014723, -0.08453687],\n","       [ 0.00388847, -0.05173535, -0.00028096, ..., -0.05702703,\n","         0.11116745,  0.10139745]], dtype=float32)>, <tf.Variable 'dense_1373/kernel:0' shape=(96, 960) dtype=float32, numpy=\n","array([[ 0.04675553,  0.0093419 ,  0.05709726, ...,  0.06854948,\n","        -0.00037213,  0.03329579],\n","       [ 0.00239615, -0.01458763, -0.01695411, ..., -0.02473218,\n","         0.0621977 , -0.00163316],\n","       [-0.03491509, -0.07133053,  0.02632599, ..., -0.06138726,\n","         0.07154833,  0.06243086],\n","       ...,\n","       [-0.01483596,  0.063646  , -0.00875846, ..., -0.0644659 ,\n","        -0.07495072, -0.02612041],\n","       [-0.03797765,  0.04737484,  0.00110591, ...,  0.0532338 ,\n","         0.06646022, -0.01553981],\n","       [ 0.04284136, -0.01046454, -0.03744853, ...,  0.04975303,\n","        -0.05360694,  0.05408213]], dtype=float32)>, <tf.Variable 'dense_1374/kernel:0' shape=(960, 256) dtype=float32, numpy=\n","array([[ 0.04582024,  0.06062315,  0.05913826, ..., -0.00827114,\n","        -0.0192358 , -0.03106061],\n","       [-0.06879575,  0.02680275, -0.02831284, ..., -0.00791085,\n","         0.03324959, -0.02392964],\n","       [-0.04745041,  0.01619846,  0.02793402, ...,  0.02205426,\n","         0.04973694, -0.04108229],\n","       ...,\n","       [ 0.01966557,  0.01777411,  0.02370279, ...,  0.02155466,\n","         0.05646043,  0.03684384],\n","       [ 0.03983454,  0.05159888, -0.03310145, ..., -0.04166324,\n","         0.06915884, -0.06047568],\n","       [-0.03123897,  0.00408142,  0.04259626, ..., -0.05094076,\n","        -0.04930428,  0.06169639]], dtype=float32)>, <tf.Variable 'branch:0' shape=(1, 96, 96) dtype=float32, numpy=\n","array([[[-0.17124976, -0.00612853,  0.02693841, ...,  0.09423082,\n","         -0.06869898, -0.15583085],\n","        [ 0.14388566, -0.09416419,  0.08536948, ...,  0.04160286,\n","         -0.11115249, -0.02943265],\n","        [-0.07504942, -0.00312261, -0.04418468, ...,  0.08166297,\n","         -0.08313154,  0.12766092],\n","        ...,\n","        [ 0.10875945, -0.11524398, -0.15470771, ...,  0.15939306,\n","         -0.11113968, -0.07444145],\n","        [ 0.13815396, -0.1513868 , -0.04603797, ...,  0.05917324,\n","         -0.00923492, -0.1695537 ],\n","        [-0.01577602, -0.07664379,  0.04761051, ..., -0.11040017,\n","          0.00924799, -0.01771356]]], dtype=float32)>, <tf.Variable 'bias:0' shape=(1, 1, 256) dtype=float32, numpy=\n","array([[[ 0.03263606, -0.00214846, -0.05671573,  0.01378067,\n","         -0.04249822, -0.02675778, -0.02989553, -0.03916933,\n","          0.03719559, -0.03398331, -0.05893196, -0.04862845,\n","          0.04835238,  0.02797213,  0.03563647,  0.04875752,\n","         -0.04508324, -0.02515644, -0.02662644,  0.05858535,\n","         -0.0383469 , -0.00185013, -0.02176498, -0.05635557,\n","          0.00182272,  0.05645181,  0.0178787 ,  0.00890538,\n","          0.01916757,  0.01242439,  0.03768034, -0.05461287,\n","         -0.03943121, -0.06099597, -0.02087736,  0.00737137,\n","         -0.00596675, -0.05783455, -0.0351005 ,  0.03694668,\n","          0.03656863,  0.02963138, -0.04431383,  0.02342314,\n","          0.04488145,  0.04387851,  0.03667709, -0.05890337,\n","         -0.05114605, -0.02193549, -0.04818885, -0.01169196,\n","          0.03559126, -0.02306083,  0.02984597,  0.00221831,\n","         -0.02464631,  0.03984806, -0.01895666,  0.02826132,\n","          0.03877613,  0.06222379, -0.04614915,  0.03569299,\n","          0.02539125,  0.04911175, -0.01893251,  0.05613184,\n","          0.04762813, -0.05672146, -0.03678724,  0.02670658,\n","          0.02358745, -0.03708184,  0.0067867 , -0.0445763 ,\n","          0.02255167, -0.04448166, -0.03807048,  0.04630618,\n","          0.02439651, -0.00070834, -0.00638677, -0.04234329,\n","          0.06101246, -0.02044445, -0.01020592,  0.0147634 ,\n","          0.0426161 ,  0.01831096, -0.00222845, -0.01802361,\n","         -0.00511263, -0.01071766,  0.05635443, -0.01347119,\n","          0.03197457,  0.05183364, -0.04624279,  0.02294531,\n","          0.00229581, -0.03205052,  0.01759273,  0.02113579,\n","          0.02838187, -0.00290824, -0.05588759,  0.00297743,\n","         -0.05605109,  0.05916469,  0.02985954,  0.01715083,\n","          0.02502297,  0.00469366,  0.00466445,  0.04421282,\n","          0.02403848, -0.02295196, -0.0053599 , -0.02944115,\n","          0.02655229, -0.06216158,  0.04047871,  0.0258382 ,\n","         -0.0486927 , -0.03602338,  0.03981169, -0.05083433,\n","          0.0356437 , -0.00614469, -0.04743664, -0.05581538,\n","          0.00907828, -0.00254735,  0.03773499, -0.04407202,\n","          0.05163626, -0.04798801, -0.01405931, -0.0577085 ,\n","          0.02726737,  0.04019061, -0.04622604,  0.01838449,\n","         -0.01011017,  0.02773792,  0.02478534,  0.05268902,\n","         -0.02371776, -0.00530945, -0.01848936,  0.04301822,\n","          0.03335686,  0.02668281,  0.00674361, -0.05232513,\n","          0.02472757, -0.0325298 , -0.05650854, -0.04885098,\n","          0.00807676,  0.03138526,  0.05533913,  0.05886781,\n","         -0.0227668 , -0.01915231, -0.03560536,  0.04604062,\n","          0.01749852,  0.04628645, -0.05047858, -0.01554036,\n","          0.03638245,  0.01051241,  0.0420464 ,  0.01382534,\n","          0.01503465, -0.00714265,  0.0527641 , -0.05347595,\n","         -0.04368752,  0.04720043, -0.05453026,  0.04271959,\n","         -0.01677449, -0.0261551 , -0.02225064,  0.0583289 ,\n","          0.01246367, -0.01473333, -0.01064149,  0.01724042,\n","          0.03553914, -0.02181616, -0.05403313,  0.05779767,\n","         -0.01460694, -0.0097581 , -0.05020061,  0.01410168,\n","          0.00952786, -0.00039943,  0.05091234,  0.04771501,\n","         -0.01346932, -0.05324408,  0.02096647,  0.05874637,\n","         -0.01319873, -0.04639255, -0.06139907,  0.04038902,\n","         -0.0389417 ,  0.04017271,  0.0295895 , -0.03709707,\n","         -0.03958893, -0.0249998 ,  0.04580972, -0.03960899,\n","          0.03106429, -0.06226023, -0.03173952,  0.00593847,\n","          0.00315365,  0.01453014, -0.05835755,  0.04694124,\n","          0.05849898, -0.0450262 , -0.03416237, -0.02576338,\n","         -0.01440087,  0.04070994,  0.0003656 , -0.04889646,\n","         -0.02494404, -0.03617738,  0.02972677,  0.0369315 ,\n","          0.03828402,  0.02986906, -0.02982193, -0.02335334,\n","         -0.01917453,  0.0306827 , -0.00672187, -0.0371709 ,\n","          0.01859619, -0.00425518,  0.00337301, -0.03470324,\n","         -0.04502465,  0.01858422, -0.01390937, -0.03941552]]],\n","      dtype=float32)>, <tf.Variable 'dense_1375/kernel:0' shape=(96, 256) dtype=float32, numpy=\n","array([[-0.06782924,  0.02149911, -0.08223268, ...,  0.04304996,\n","        -0.01262009,  0.11902092],\n","       [ 0.06414412,  0.06608681,  0.04604338, ..., -0.01008534,\n","        -0.09302194,  0.07323712],\n","       [-0.05349963,  0.12365581,  0.11029781, ..., -0.0081019 ,\n","         0.03049506,  0.06687051],\n","       ...,\n","       [ 0.06565529,  0.04330222, -0.00930946, ...,  0.10261522,\n","        -0.06766405, -0.0590778 ],\n","       [ 0.03053889, -0.00865301, -0.09846316, ...,  0.0276182 ,\n","         0.01708664, -0.08079836],\n","       [ 0.08087397, -0.10594727, -0.06170823, ..., -0.04126549,\n","        -0.1071976 ,  0.0054175 ]], dtype=float32)>, <tf.Variable 'dense_1376/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[-0.0930241 ,  0.02011401, -0.07966085, ..., -0.01499259,\n","         0.06348941,  0.06969509],\n","       [ 0.0822965 , -0.06922555,  0.08518367, ...,  0.06998711,\n","        -0.06213687, -0.0380988 ],\n","       [ 0.0959577 , -0.06780829, -0.03397169, ..., -0.02756839,\n","         0.08100086,  0.0059289 ],\n","       ...,\n","       [-0.06007647,  0.07693904, -0.03304148, ..., -0.01953539,\n","         0.04864535, -0.08657037],\n","       [-0.0258036 , -0.06473579,  0.05300862, ..., -0.02869546,\n","        -0.09932169, -0.06035585],\n","       [ 0.03511115,  0.09355924, -0.020229  , ...,  0.10407936,\n","        -0.00123031,  0.09405255]], dtype=float32)>, <tf.Variable 'dense_1377/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[-0.04286288, -0.03200065, -0.02449778, ..., -0.00020371,\n","        -0.00420917,  0.02031642],\n","       [ 0.02400146, -0.02693485, -0.02079038, ..., -0.02839547,\n","         0.02019683,  0.00162745],\n","       [ 0.02993368, -0.00586265, -0.01604105, ...,  0.0225644 ,\n","        -0.00440944,  0.03556721],\n","       ...,\n","       [ 0.01325142, -0.02471765,  0.02220472, ...,  0.00587777,\n","        -0.00012414, -0.02932644],\n","       [ 0.00545698,  0.01591964, -0.00433405, ...,  0.00305106,\n","         0.0136451 , -0.02529109],\n","       [ 0.00903769,  0.0244923 , -0.04325855, ..., -0.01823871,\n","        -0.00720818,  0.02753675]], dtype=float32)>, <tf.Variable 'dense_1378/kernel:0' shape=(2560, 256) dtype=float32, numpy=\n","array([[ 0.03917885,  0.00520464, -0.03996341, ..., -0.02490274,\n","         0.03330066, -0.036205  ],\n","       [ 0.04189961,  0.00586543,  0.03747992, ...,  0.01254707,\n","         0.02392641, -0.03277343],\n","       [-0.0161333 , -0.01921239, -0.01126965, ...,  0.01672408,\n","         0.02788129,  0.0247062 ],\n","       ...,\n","       [ 0.02807225,  0.00382875, -0.03344857, ..., -0.00461568,\n","         0.04301615, -0.0401451 ],\n","       [-0.02303858,  0.02948604,  0.0025906 , ...,  0.02254009,\n","         0.03008839, -0.00603532],\n","       [-0.03724082,  0.02105381,  0.02284705, ...,  0.019288  ,\n","        -0.0302988 , -0.02569166]], dtype=float32)>, <tf.Variable 'branch:0' shape=(1, 256, 512) dtype=float32, numpy=\n","array([[[ 0.04437334, -0.07606724, -0.00577089, ...,  0.00524475,\n","          0.08505122,  0.06575928],\n","        [-0.06767882, -0.0775647 , -0.01666851, ...,  0.03400357,\n","          0.04394238,  0.0478775 ],\n","        [-0.02119995, -0.00111004, -0.0118966 , ...,  0.0806391 ,\n","          0.00312949, -0.03546596],\n","        ...,\n","        [ 0.03563181, -0.05578565, -0.03269702, ...,  0.02770915,\n","          0.02313381, -0.00442199],\n","        [-0.07466196, -0.01057981,  0.03958447, ..., -0.08556396,\n","         -0.02154698,  0.01132081],\n","        [-0.04897099, -0.04766979, -0.03990053, ..., -0.01830326,\n","          0.05650412,  0.07931039]]], dtype=float32)>, <tf.Variable 'bias:0' shape=(1, 2, 256) dtype=float32, numpy=\n","array([[[ 0.00335877,  0.02044865, -0.02667929, -0.03465956,\n","         -0.04332471,  0.05464886,  0.00120112,  0.05943242,\n","          0.04349217, -0.01674326, -0.06032263,  0.01172806,\n","          0.00589612,  0.04218629,  0.05566762, -0.03956845,\n","         -0.00740141, -0.00646402,  0.03317025,  0.02102841,\n","         -0.04707029, -0.05314328,  0.06179781, -0.06209563,\n","          0.04370813,  0.01825839, -0.02362922, -0.02291971,\n","         -0.01887731, -0.05223297, -0.04201031, -0.01176211,\n","         -0.05311674,  0.00118794, -0.03567895,  0.03888357,\n","         -0.05903883, -0.02443136, -0.02621226,  0.05269031,\n","         -0.01423484,  0.05984002,  0.00868987,  0.06160387,\n","          0.02132542,  0.03922674,  0.03068356, -0.02784257,\n","          0.01103033, -0.01412806, -0.05021644, -0.02205609,\n","          0.02003579, -0.05082528,  0.01237875, -0.05451171,\n","          0.05317459,  0.05793244, -0.05965576,  0.01181792,\n","          0.02803621, -0.04466318, -0.06245002, -0.00888228,\n","         -0.05345169,  0.04496062,  0.01391737,  0.01122104,\n","          0.05697578, -0.04051226,  0.02145508, -0.05769734,\n","          0.01733442, -0.0442162 , -0.00697812, -0.03847617,\n","         -0.01311629,  0.01085204, -0.04388954,  0.01841906,\n","          0.00875986, -0.01709276, -0.01880383,  0.01705189,\n","         -0.02398479,  0.04012112,  0.04899749, -0.03167874,\n","         -0.06065486,  0.06041652,  0.04666294, -0.02296169,\n","          0.01077078,  0.01015292, -0.02289999, -0.03098634,\n","         -0.04989196, -0.01239969,  0.02563487,  0.04681359,\n","          0.04774423,  0.04034258,  0.02421808,  0.02043773,\n","          0.04323001,  0.02030399,  0.0616502 , -0.01713011,\n","          0.00147316, -0.03315732, -0.03558551,  0.04625098,\n","          0.01415914, -0.03944099,  0.024749  ,  0.01113282,\n","         -0.03997937,  0.02639095,  0.01614067, -0.04313794,\n","         -0.00440063,  0.06176218, -0.04960863, -0.02570552,\n","          0.04194964, -0.03572114, -0.01107754,  0.05383042,\n","          0.02001716, -0.03367653,  0.0226364 ,  0.00038251,\n","          0.05500855, -0.05061764, -0.01047681, -0.01741774,\n","         -0.05094343,  0.0036837 ,  0.06237154, -0.03521861,\n","          0.03823596, -0.05990215, -0.00049637,  0.04609306,\n","         -0.01719125,  0.00238624,  0.03872873,  0.03805919,\n","         -0.01836221, -0.00752316, -0.04351355,  0.05662358,\n","         -0.04528861,  0.02639468, -0.02088286, -0.02373584,\n","          0.0056856 ,  0.03456119,  0.01355389, -0.05705705,\n","          0.03265749,  0.04450625,  0.05633369,  0.01100726,\n","         -0.01812989, -0.02134784, -0.0226997 , -0.0464633 ,\n","         -0.00028209, -0.02404539,  0.01230136,  0.01918896,\n","         -0.04433288,  0.06029667, -0.04435393, -0.03138739,\n","         -0.00785767,  0.03541234, -0.02963828,  0.03521152,\n","         -0.04090543, -0.04918981,  0.03147376,  0.02871275,\n","         -0.05027364,  0.00049852,  0.04894231, -0.02377617,\n","         -0.04075821, -0.05584374, -0.05312838, -0.05389075,\n","         -0.01401386,  0.01584257,  0.05794384, -0.02947065,\n","          0.03734806,  0.00562012, -0.0267424 ,  0.0346089 ,\n","          0.03052334,  0.01729378,  0.03489688, -0.00574906,\n","          0.02827337, -0.02470315, -0.01836173, -0.00987537,\n","          0.00566098,  0.01400369,  0.01646909,  0.0278929 ,\n","          0.01179242, -0.01085404,  0.02441946,  0.02798179,\n","          0.06103025,  0.04614724,  0.04546101,  0.03440946,\n","          0.0358889 ,  0.0176973 , -0.00375727, -0.02391201,\n","         -0.06031588,  0.04694647,  0.04981053, -0.02933985,\n","          0.03043805,  0.00895576, -0.03268392,  0.05683488,\n","          0.03233169,  0.02712584, -0.05567525,  0.02583218,\n","          0.02285062, -0.00784269, -0.00238839,  0.01111035,\n","         -0.01688412,  0.02950911, -0.01615877,  0.01768504,\n","         -0.00577997, -0.01690952,  0.00229317, -0.05045228,\n","         -0.00178127, -0.02278277,  0.01135767, -0.02178583,\n","          0.04105635, -0.06007344, -0.05388585,  0.01196201],\n","        [-0.00385073, -0.00272723, -0.00353575,  0.05869621,\n","         -0.00873722, -0.05477239, -0.02303527, -0.0179338 ,\n","          0.04796995,  0.04002908, -0.03188221, -0.03252748,\n","          0.05411986,  0.05032186, -0.02464323, -0.00293234,\n","          0.05352879,  0.01226942, -0.03307907,  0.04976884,\n","          0.04964258,  0.03481013,  0.02538593, -0.02237287,\n","         -0.06162754,  0.03560323,  0.00458109,  0.03379957,\n","          0.04932788, -0.03645019,  0.03206544,  0.05320059,\n","          0.01134944, -0.04577635,  0.05459259, -0.04100363,\n","          0.00974295, -0.04558675, -0.01864697,  0.02254875,\n","         -0.03395693,  0.02006373, -0.05722226, -0.02558458,\n","         -0.05473229,  0.01595271,  0.05340299,  0.04472582,\n","          0.05476978, -0.06166218, -0.00805911,  0.01364584,\n","          0.02509803, -0.01549089, -0.02653976, -0.03424598,\n","         -0.03002711,  0.04732975,  0.0471486 ,  0.02094501,\n","         -0.02642292, -0.00283699, -0.00524767, -0.039674  ,\n","         -0.02218813, -0.0187545 , -0.04961073,  0.04947166,\n","          0.05737537,  0.03851101,  0.04916382, -0.01172471,\n","          0.03556682, -0.00756347, -0.00909343,  0.04416573,\n","          0.05099167, -0.01125509,  0.03109956,  0.05256177,\n","          0.05724849, -0.0443438 ,  0.0316305 ,  0.05137518,\n","          0.05171815,  0.01137018, -0.05262788,  0.00718553,\n","         -0.04543626, -0.0358675 , -0.033884  , -0.00792591,\n","          0.01232256, -0.03789115,  0.03600205, -0.02790245,\n","          0.03440428, -0.02179246, -0.00547831, -0.01829875,\n","          0.05633454,  0.03955719,  0.05026026, -0.03115796,\n","         -0.05388743, -0.04116184, -0.03021421,  0.06212513,\n","         -0.02639259,  0.01193832, -0.04226261, -0.03085829,\n","          0.04898265, -0.01103827,  0.01916826,  0.03537537,\n","         -0.02246717, -0.05031675, -0.01226448, -0.01772632,\n","         -0.0541911 , -0.05536301,  0.0203573 , -0.02218188,\n","         -0.03865743, -0.03402407,  0.04039441, -0.05259956,\n","          0.04397734, -0.00037196,  0.05198215, -0.04887167,\n","          0.03184602, -0.00021777, -0.01003106,  0.01866154,\n","         -0.05321051, -0.04585584, -0.00337665,  0.02941269,\n","          0.02769715,  0.06194636, -0.02994724, -0.02843542,\n","         -0.00411782, -0.0112171 , -0.03374127,  0.028762  ,\n","         -0.02091232,  0.02040301,  0.05831106,  0.03159337,\n","          0.05372413,  0.01384884, -0.06120485,  0.02054019,\n","         -0.04310395, -0.01634592,  0.05882317,  0.05619888,\n","          0.00854927, -0.04759291, -0.03913364,  0.01342461,\n","          0.04963049,  0.00640255, -0.03854008, -0.04210928,\n","          0.05264418, -0.02966191,  0.03577811,  0.05738293,\n","         -0.03311874, -0.02943371,  0.04448736, -0.0239401 ,\n","         -0.04770091, -0.04025644, -0.02956879,  0.0430432 ,\n","          0.01523806, -0.00903167, -0.04363081,  0.03593203,\n","         -0.00506331, -0.06117959, -0.03355888, -0.05679084,\n","          0.01148131, -0.03452492, -0.04702711,  0.04248074,\n","         -0.0098547 ,  0.02204837,  0.04137467, -0.0350204 ,\n","          0.05149437,  0.04242963,  0.01540209,  0.00082937,\n","          0.03516513, -0.02178183, -0.06080946, -0.01881635,\n","          0.02397718, -0.003682  , -0.06190795, -0.01420093,\n","         -0.02300681,  0.02694342,  0.03352511, -0.04057691,\n","         -0.02302277,  0.01073135,  0.01725608,  0.00932647,\n","          0.04346143, -0.05568148, -0.04505096,  0.00380303,\n","         -0.02742867,  0.05305079,  0.00478074, -0.05017239,\n","          0.00375514,  0.03215021, -0.00218715,  0.00744908,\n","         -0.01043378,  0.00452197, -0.00311914,  0.06136414,\n","         -0.02943161,  0.0284507 ,  0.04253037,  0.0278717 ,\n","         -0.03354031, -0.03248772,  0.05040641, -0.04521844,\n","          0.00461288,  0.05099146, -0.04283951, -0.00958106,\n","          0.05962537,  0.02148265, -0.03357564,  0.00975057,\n","          0.04450698,  0.02136078, -0.04368974,  0.03356199,\n","          0.04014085,  0.02529989, -0.05163455,  0.01997435]]],\n","      dtype=float32)>, <tf.Variable 'dense_1379/kernel:0' shape=(96, 256) dtype=float32, numpy=\n","array([[ 0.02105449, -0.00496665, -0.1270842 , ..., -0.04545385,\n","         0.10528441,  0.03525122],\n","       [ 0.0233728 , -0.08294301,  0.1033759 , ..., -0.07492158,\n","         0.11618017,  0.03582577],\n","       [ 0.02349934,  0.01943885,  0.03867303, ..., -0.03236885,\n","        -0.12175276, -0.04630578],\n","       ...,\n","       [ 0.07486643,  0.05097991,  0.05428541, ..., -0.02039048,\n","        -0.0894247 , -0.02827583],\n","       [-0.01622394, -0.02130594,  0.03044429, ...,  0.07428049,\n","        -0.02869287,  0.00325914],\n","       [ 0.02978875, -0.04268052, -0.03599666, ...,  0.10006981,\n","         0.08636066, -0.00099145]], dtype=float32)>, <tf.Variable 'dense_1380/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[-0.04833224,  0.08261939, -0.00700203, ..., -0.0872933 ,\n","        -0.10174813, -0.07524834],\n","       [ 0.10495157,  0.02307788, -0.08430932, ..., -0.08604972,\n","         0.02290826,  0.00383522],\n","       [-0.05114166,  0.0916435 ,  0.02284399, ..., -0.09341314,\n","        -0.03451173, -0.02239963],\n","       ...,\n","       [-0.00374518,  0.10689972,  0.10504853, ..., -0.10493016,\n","         0.01039395,  0.10572729],\n","       [ 0.05428287,  0.00132744,  0.03996516, ..., -0.0620923 ,\n","         0.10091982,  0.01368997],\n","       [ 0.02753734, -0.06301403,  0.03854027, ...,  0.08631963,\n","         0.04333093, -0.06775241]], dtype=float32)>, <tf.Variable 'dense_1381/kernel:0' shape=(256, 256) dtype=float32, numpy=\n","array([[-0.07528251, -0.09802414,  0.02956102, ..., -0.06092095,\n","         0.04804505, -0.07779938],\n","       [ 0.09081555, -0.051968  ,  0.08864977, ..., -0.05084991,\n","        -0.10099281,  0.09262303],\n","       [-0.07252525, -0.00267906, -0.07730453, ...,  0.02707011,\n","         0.00937491,  0.01450043],\n","       ...,\n","       [-0.07971099, -0.06592427, -0.05155618, ...,  0.05360291,\n","        -0.07850086, -0.05430178],\n","       [-0.09684904,  0.03106684, -0.04528828, ...,  0.09373524,\n","         0.043749  ,  0.08524301],\n","       [-0.02829521, -0.08468463,  0.0667732 , ...,  0.08378718,\n","         0.07895289, -0.03763564]], dtype=float32)>, <tf.Variable 'dense_1382/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[-0.01860718,  0.02219532,  0.01395784, ..., -0.0189106 ,\n","        -0.03401274,  0.03853771],\n","       [-0.03115401,  0.0095011 , -0.015172  , ...,  0.03984307,\n","        -0.03220798,  0.01057301],\n","       [-0.0157822 ,  0.02855727, -0.02098959, ..., -0.01231305,\n","        -0.02974698, -0.03528887],\n","       ...,\n","       [ 0.01168297,  0.03149315, -0.01221156, ..., -0.03575506,\n","        -0.00140092, -0.03083301],\n","       [-0.03592657, -0.04022378, -0.03240101, ..., -0.04244067,\n","        -0.02033417,  0.04282451],\n","       [ 0.0051135 , -0.0307626 , -0.02230136, ...,  0.04128395,\n","         0.01465864, -0.01887926]], dtype=float32)>, <tf.Variable 'dense_1383/kernel:0' shape=(2560, 256) dtype=float32, numpy=\n","array([[ 0.0037915 ,  0.02923315, -0.04075504, ..., -0.01563276,\n","        -0.02893789, -0.01490976],\n","       [-0.04407048, -0.01488686,  0.03653542, ...,  0.02195365,\n","         0.01424397,  0.00981001],\n","       [ 0.01497712, -0.01793138,  0.02695733, ...,  0.03674359,\n","        -0.02120425, -0.00861659],\n","       ...,\n","       [ 0.01588316,  0.00808521,  0.00187533, ...,  0.02625741,\n","        -0.03888442, -0.00028652],\n","       [ 0.0206365 ,  0.03342224,  0.04025057, ..., -0.04075725,\n","        -0.02290979, -0.01866801],\n","       [ 0.04445396,  0.03267943,  0.01663257, ...,  0.0246223 ,\n","         0.04441059, -0.03797632]], dtype=float32)>, <tf.Variable 'branch:0' shape=(2, 256, 512) dtype=float32, numpy=\n","array([[[-0.03765549, -0.01261361,  0.04859726, ...,  0.02290747,\n","         -0.0493204 ,  0.00076152],\n","        [-0.02877125,  0.05077147, -0.00427386, ..., -0.02840781,\n","         -0.05749133, -0.06212492],\n","        [ 0.01191399,  0.0066693 ,  0.04013118, ..., -0.05853888,\n","         -0.01650493, -0.02391323],\n","        ...,\n","        [ 0.05860625, -0.03668334,  0.01786701, ...,  0.02778535,\n","         -0.05339046, -0.01945044],\n","        [ 0.00488439,  0.00778641, -0.01847874, ..., -0.05609296,\n","         -0.0533229 ,  0.02127486],\n","        [ 0.01777123,  0.05512722,  0.02697659, ..., -0.05558696,\n","          0.01322722,  0.00474504]],\n","\n","       [[-0.0351104 ,  0.00819179,  0.0294321 , ..., -0.05671814,\n","          0.03617004, -0.02681181],\n","        [-0.04082397, -0.05123737,  0.05546995, ...,  0.02428767,\n","          0.02369563,  0.01208578],\n","        [-0.04711993, -0.03341037, -0.01273687, ..., -0.01415768,\n","         -0.03848776, -0.01538044],\n","        ...,\n","        [-0.02461413, -0.01655065, -0.01401594, ..., -0.00528273,\n","         -0.04481082,  0.0530629 ],\n","        [ 0.00431161,  0.05034786,  0.04336332, ..., -0.03901803,\n","         -0.04406814, -0.02372912],\n","        [-0.00797586, -0.047782  ,  0.04016289, ...,  0.00978985,\n","          0.03715822, -0.0022357 ]]], dtype=float32)>, <tf.Variable 'bias:0' shape=(1, 2, 256) dtype=float32, numpy=\n","array([[[ 0.04673077,  0.01830259, -0.00881352,  0.05521491,\n","         -0.0435351 , -0.02566333,  0.04625879,  0.00966439,\n","         -0.03410581,  0.06003103,  0.03697988, -0.02309555,\n","          0.04024412, -0.01392645,  0.04935786, -0.00204538,\n","         -0.00335376, -0.00397061,  0.01780187,  0.0515997 ,\n","         -0.00892547,  0.0106663 ,  0.04073927,  0.04036885,\n","         -0.02937014,  0.04042025, -0.05794191, -0.03086759,\n","         -0.03521737, -0.00181021,  0.00370349, -0.03147557,\n","         -0.00208525,  0.03390497, -0.01728834, -0.01631115,\n","          0.01237036,  0.01994205, -0.01784192, -0.00106984,\n","          0.05868569,  0.0509329 ,  0.02423638,  0.00946522,\n","          0.04124907,  0.04537687, -0.0332104 ,  0.05614869,\n","         -0.03898342, -0.01615119,  0.05067271,  0.03257839,\n","          0.00571515, -0.0470306 ,  0.04645018, -0.02999453,\n","         -0.00653388, -0.0467608 ,  0.02243513,  0.00598107,\n","          0.0281519 ,  0.04023954, -0.04379407, -0.04590079,\n","         -0.03522509,  0.02137393,  0.05067471,  0.01727414,\n","          0.02429052, -0.05153526,  0.02848019, -0.03897016,\n","          0.0375165 ,  0.05282834,  0.05371672,  0.06160364,\n","          0.01931417, -0.03548132,  0.04597309, -0.05750455,\n","         -0.04309629,  0.04877381,  0.02307309,  0.02221642,\n","          0.04864202,  0.00583307, -0.03196086, -0.02722785,\n","         -0.00825956,  0.05127206, -0.05957825,  0.05175069,\n","         -0.02506781, -0.02353403,  0.03369984, -0.06060621,\n","          0.04285775,  0.03627704, -0.02455184, -0.03179568,\n","          0.03538565,  0.01706769,  0.02492043,  0.06185263,\n","          0.00797485,  0.01961024, -0.0224885 , -0.03031737,\n","          0.04745486, -0.04624951,  0.01880369,  0.02628143,\n","         -0.00775783, -0.05346718,  0.05220656,  0.02005267,\n","         -0.02377538, -0.03881881, -0.06200811,  0.05232179,\n","          0.04590361,  0.0363791 , -0.02318819, -0.0018646 ,\n","         -0.02054688,  0.01174375,  0.01531652,  0.05315816,\n","         -0.05921294,  0.03596994, -0.05383557,  0.01154535,\n","          0.0428291 , -0.01079883, -0.01413894,  0.00830956,\n","         -0.03610957, -0.01789279,  0.01171686,  0.02969278,\n","          0.03178506, -0.04829207,  0.00445412,  0.01595117,\n","          0.02770562,  0.03426173, -0.05020025, -0.02334543,\n","          0.01936589,  0.03174949, -0.04076767,  0.06111625,\n","         -0.0515673 ,  0.05539878, -0.03987703,  0.02947532,\n","          0.00976518,  0.03832014,  0.00864288,  0.03945774,\n","         -0.03827699, -0.00443923,  0.02426222,  0.05900757,\n","          0.00469935, -0.00028653, -0.01677799,  0.02442165,\n","          0.01924212, -0.04082014, -0.04937708,  0.03235514,\n","          0.04846355,  0.04872572,  0.0099505 , -0.00121948,\n","         -0.00794171,  0.03512774, -0.06028634,  0.01713373,\n","         -0.00260262,  0.05715024,  0.02072176,  0.01120423,\n","          0.03276685, -0.00737667, -0.05363409, -0.04105945,\n","         -0.05759315,  0.00580908,  0.00309208,  0.0234185 ,\n","          0.00457622,  0.0586243 ,  0.0002992 , -0.00798528,\n","          0.00440532,  0.00390588,  0.05709545, -0.00056252,\n","          0.05590422,  0.00805268,  0.03907175, -0.05249099,\n","          0.05038467, -0.02173507,  0.05014917,  0.0533828 ,\n","          0.03592496,  0.03342956, -0.01150234, -0.0362305 ,\n","          0.00395544, -0.02311212,  0.04198153, -0.02121802,\n","          0.04238196, -0.02287911, -0.00605504, -0.04115638,\n","          0.0458087 , -0.05667068, -0.04299328, -0.04300039,\n","          0.0254596 ,  0.01927958, -0.0504185 ,  0.01741271,\n","         -0.0455959 ,  0.04600383,  0.0380398 ,  0.05356804,\n","         -0.02280287, -0.03141466, -0.05592516,  0.021376  ,\n","          0.05337778,  0.02659105, -0.05299859, -0.02135111,\n","         -0.05432199, -0.05452277, -0.04782899,  0.04822089,\n","         -0.02115637,  0.01532693, -0.02131447, -0.02713083,\n","         -0.02936974, -0.04433829, -0.01758906, -0.01349676,\n","          0.0245589 ,  0.00525121, -0.01924039,  0.03815906],\n","        [ 0.04885046, -0.01566489, -0.02584469, -0.02252579,\n","         -0.00237682, -0.02808774, -0.01429525, -0.0397481 ,\n","          0.01757286,  0.00964923,  0.048925  , -0.05204873,\n","         -0.0187967 , -0.04454063,  0.00440934,  0.06223254,\n","          0.01702811, -0.01665112,  0.05869272, -0.02217838,\n","          0.06194654,  0.01803638, -0.0509892 , -0.06074183,\n","         -0.00651971, -0.02371526, -0.01357329,  0.0034027 ,\n","         -0.05937077,  0.01930581, -0.02747861, -0.00244854,\n","         -0.01788725, -0.05506755,  0.00423169,  0.05215071,\n","         -0.05866426,  0.03557287, -0.05273734,  0.05714758,\n","          0.03263326, -0.01193178,  0.01551123,  0.02539715,\n","         -0.02788013,  0.06235558,  0.05351281, -0.00449055,\n","         -0.02090888, -0.01432879,  0.03614339,  0.06213708,\n","          0.0225746 , -0.02312206,  0.0229405 , -0.03828414,\n","          0.01256302,  0.03724061,  0.05534473,  0.05969851,\n","          0.00751434, -0.04955603,  0.04717356,  0.02289915,\n","         -0.055931  , -0.0103375 , -0.02880664,  0.04146911,\n","         -0.02168261, -0.0120638 ,  0.02041225,  0.01799528,\n","         -0.02324735,  0.04569019,  0.01351312, -0.04071885,\n","          0.00010967, -0.05364364,  0.04242936,  0.02407087,\n","         -0.01291443,  0.00667863,  0.04513153,  0.06041631,\n","          0.03914547,  0.01079281,  0.05256766,  0.04966161,\n","         -0.03234205,  0.00840245,  0.04126604, -0.00550999,\n","          0.02783765, -0.02807806,  0.00924648,  0.05740228,\n","         -0.02769276, -0.00564286,  0.05245447,  0.04628259,\n","          0.00249828,  0.02343327, -0.01411141,  0.04485351,\n","         -0.03242441, -0.02404121, -0.0537976 ,  0.03604344,\n","          0.05386271, -0.03988691,  0.05569044, -0.05235597,\n","         -0.0287265 ,  0.04417576,  0.0115997 ,  0.03011124,\n","         -0.04677503, -0.01620707,  0.02262054, -0.03050847,\n","          0.04315685,  0.02337132,  0.02698272,  0.03641668,\n","         -0.00271198, -0.00605351, -0.00787586, -0.02221736,\n","         -0.01035318, -0.01951624, -0.02555464,  0.0080605 ,\n","          0.06078596,  0.01566523, -0.0418788 , -0.05995634,\n","          0.03140575, -0.01351552,  0.02976444, -0.05408564,\n","         -0.01275361, -0.05599268, -0.03902708,  0.00118007,\n","          0.01293433,  0.03256761,  0.00136682, -0.05518906,\n","         -0.03642584,  0.04236253,  0.01748843,  0.03704411,\n","         -0.01622039, -0.01508041,  0.03329472, -0.01073471,\n","          0.0506206 , -0.00883757,  0.05515802, -0.05861446,\n","          0.06222951,  0.01315518, -0.01269835,  0.05036309,\n","          0.03159153,  0.00887421,  0.0159674 ,  0.04957208,\n","         -0.04666404,  0.06190285,  0.02160206,  0.0609514 ,\n","         -0.0552642 ,  0.04982114,  0.04524359, -0.00388795,\n","         -0.01447444, -0.05341668,  0.00910246,  0.0371335 ,\n","         -0.01291214, -0.01035601, -0.04366265,  0.00909558,\n","         -0.03369859,  0.00156386,  0.03839912, -0.02876198,\n","          0.03082134, -0.03408153, -0.05666527, -0.01605313,\n","          0.01034835, -0.05086564,  0.03634763, -0.03357822,\n","          0.01419991, -0.01773283,  0.0459893 ,  0.04027636,\n","          0.05516407, -0.04605627,  0.01651415,  0.00344975,\n","         -0.0083686 , -0.04433866,  0.01529031,  0.04448351,\n","          0.03861021,  0.02138792,  0.00619182,  0.04990855,\n","          0.0142865 , -0.0134282 , -0.06083354,  0.05160959,\n","         -0.02152009,  0.01313545, -0.01295671, -0.04507886,\n","         -0.05727881, -0.01438825, -0.04068325, -0.01897988,\n","         -0.03258733,  0.061653  ,  0.06149657, -0.00411817,\n","          0.04427397, -0.01294442, -0.03287752, -0.01035781,\n","         -0.05239165, -0.02629481, -0.01447509, -0.0466861 ,\n","          0.01573917,  0.00382911,  0.00615099,  0.01496969,\n","          0.05125397,  0.05260479, -0.06039728,  0.05847274,\n","         -0.03149174,  0.03531472, -0.0622056 , -0.02548385,\n","          0.02922317, -0.01010619,  0.00701685, -0.02721252,\n","         -0.01187518,  0.01565976,  0.00759515,  0.05167934]]],\n","      dtype=float32)>, <tf.Variable 'dense_1384/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[-0.00737564, -0.1504309 ,  0.02156645, ...,  0.0895769 ,\n","         0.0126832 ,  0.12583902],\n","       [-0.01136769,  0.05473801,  0.09925532, ...,  0.15163463,\n","         0.0837329 , -0.06045606],\n","       [ 0.13272572, -0.10846192,  0.12533763, ..., -0.0948735 ,\n","         0.00307137,  0.1169067 ],\n","       ...,\n","       [-0.15166944, -0.0593766 , -0.03235009, ...,  0.12339669,\n","         0.08265601,  0.14352128],\n","       [ 0.05889653, -0.09613784, -0.05691718, ..., -0.05210198,\n","         0.02136652,  0.02130257],\n","       [-0.07633299, -0.03143951,  0.05474503, ..., -0.0565296 ,\n","        -0.05244748,  0.01715434]], dtype=float32)>, <tf.Variable 'dense_1385/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.0046697 , -0.02952978,  0.045863  , ...,  0.03560781,\n","         0.0322237 , -0.07338676],\n","       [ 0.000319  ,  0.08567956,  0.11132032, ..., -0.09168422,\n","         0.02474791,  0.04920775],\n","       [ 0.01842409, -0.03614637,  0.01943976, ...,  0.10033974,\n","        -0.09431657, -0.0237211 ],\n","       ...,\n","       [-0.05822524, -0.10806552,  0.02267006, ...,  0.00341988,\n","         0.12181959,  0.01479331],\n","       [-0.02168986, -0.1158801 , -0.0670085 , ..., -0.1056951 ,\n","        -0.02888593,  0.01702568],\n","       [ 0.07689369,  0.10210571, -0.0718106 , ..., -0.06549832,\n","         0.0939438 ,  0.03097048]], dtype=float32)>, <tf.Variable 'dense_1386/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 7.36264586e-02,  8.00691545e-02, -7.98973441e-02, ...,\n","         8.36332440e-02, -2.98265815e-02,  9.90711749e-02],\n","       [ 2.25594640e-02,  5.03441393e-02,  2.11480260e-03, ...,\n","        -6.01297617e-02,  9.36388969e-05,  6.13394976e-02],\n","       [ 5.35306334e-03, -1.05502844e-01,  6.15787506e-03, ...,\n","        -3.52788270e-02, -7.61242509e-02,  7.63950348e-02],\n","       ...,\n","       [-8.24578106e-02,  5.69841266e-02,  1.17595673e-01, ...,\n","        -1.99335814e-02, -8.03829730e-02, -1.21840626e-01],\n","       [ 1.14586890e-01, -3.93930078e-03,  8.95825028e-02, ...,\n","         7.58738220e-02,  6.79403245e-02,  8.32141042e-02],\n","       [ 1.05048954e-01,  5.65225482e-02,  8.62496495e-02, ...,\n","         6.31469190e-02, -1.08719051e-01,  7.17257857e-02]], dtype=float32)>, <tf.Variable 'dense_1387/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.04560122, -0.03323781,  0.11853784, ...,  0.00401664,\n","        -0.09244367, -0.0264402 ],\n","       [ 0.07549807,  0.08942369,  0.01287419, ..., -0.01914167,\n","         0.05425325,  0.05091643],\n","       [ 0.08636898, -0.00360006,  0.04073003, ...,  0.02762476,\n","        -0.02052507, -0.01297146],\n","       ...,\n","       [-0.10922024,  0.0783048 , -0.04996982, ..., -0.1074805 ,\n","        -0.06050181, -0.01298887],\n","       [-0.02083081, -0.02877536,  0.0517371 , ..., -0.01008856,\n","        -0.09683269,  0.01534489],\n","       [ 0.00373384,  0.11255869, -0.09688818, ..., -0.08216879,\n","         0.07453606, -0.0222553 ]], dtype=float32)>, <tf.Variable 'dense_1388/kernel:0' shape=(256, 2560) dtype=float32, numpy=\n","array([[-0.00179567,  0.02071491, -0.02332212, ..., -0.02458172,\n","         0.01239515,  0.04609929],\n","       [-0.04367072, -0.01940242,  0.04565495, ..., -0.00884275,\n","        -0.00066993, -0.01892773],\n","       [ 0.01531636,  0.02442053,  0.01222774, ...,  0.01333787,\n","        -0.03366734, -0.03918942],\n","       ...,\n","       [-0.01493124, -0.02360099, -0.01408856, ...,  0.02463751,\n","         0.02116291, -0.03449287],\n","       [ 0.03381608, -0.00983067,  0.02875908, ...,  0.00309257,\n","        -0.03706169,  0.0116363 ],\n","       [ 0.03081834,  0.03702829,  0.01042338, ..., -0.03831641,\n","        -0.01660351,  0.02502036]], dtype=float32)>, <tf.Variable 'dense_1389/kernel:0' shape=(2560, 128) dtype=float32, numpy=\n","array([[ 0.04144816, -0.02864556, -0.03892449, ..., -0.03237813,\n","        -0.03450605, -0.00466738],\n","       [-0.03484903,  0.03737606, -0.04198652, ...,  0.03884929,\n","        -0.03666776, -0.04352903],\n","       [-0.04232004,  0.01202693, -0.04326687, ..., -0.03225359,\n","        -0.03548157,  0.02455921],\n","       ...,\n","       [-0.03560662,  0.04488585, -0.0214236 , ...,  0.00442442,\n","        -0.00478297, -0.045598  ],\n","       [-0.02860661,  0.01091532,  0.04719367, ...,  0.03519962,\n","        -0.01926936, -0.01927604],\n","       [-0.00948011,  0.03794989, -0.01580762, ...,  0.01396916,\n","         0.02451219, -0.03063265]], dtype=float32)>, <tf.Variable 'branch:0' shape=(4, 256, 768) dtype=float32, numpy=\n","array([[[ 1.63015276e-02, -2.97076032e-02,  1.82117783e-02, ...,\n","         -1.82283949e-02,  3.63280736e-02,  3.24763544e-02],\n","        [-3.04495618e-02,  1.42456330e-02, -1.12130754e-02, ...,\n","         -2.23898795e-02,  4.28590551e-03,  2.96396054e-02],\n","        [ 3.42270993e-02,  2.82464549e-03,  1.42742395e-02, ...,\n","          1.41400024e-02,  5.81501797e-03, -3.31182592e-02],\n","        ...,\n","        [-3.39799188e-02, -2.63974071e-05, -9.64925066e-03, ...,\n","          2.35779583e-03,  4.38932702e-03,  3.62578891e-02],\n","        [ 2.59403847e-02, -2.73930319e-02,  7.54189864e-03, ...,\n","          2.63335072e-02, -2.22226437e-02,  5.61922789e-05],\n","        [-9.95216519e-03,  5.60035184e-03,  1.59155764e-02, ...,\n","          1.16862543e-02,  1.46001428e-02, -1.90303680e-02]],\n","\n","       [[-3.74608003e-02,  9.65129212e-03, -1.99637897e-02, ...,\n","         -2.14012153e-02,  4.55394387e-03,  6.82632253e-03],\n","        [-1.02594886e-02,  3.70034240e-02,  8.48836824e-03, ...,\n","          9.98685881e-03, -3.18553783e-02,  2.65575759e-02],\n","        [ 1.88101530e-02,  2.17210203e-02, -5.49867749e-04, ...,\n","          3.72584425e-02, -1.99478120e-02,  3.13213356e-02],\n","        ...,\n","        [-2.95017231e-02, -3.04587148e-02, -2.75678746e-02, ...,\n","         -1.38531104e-02,  2.81167962e-02,  2.13827193e-02],\n","        [-1.42778084e-02, -9.54905711e-03, -1.84917450e-03, ...,\n","         -3.46372351e-02,  3.03346254e-02,  1.57219134e-02],\n","        [ 1.85311809e-02, -1.40130892e-03,  1.55567676e-02, ...,\n","         -3.11981142e-03, -3.52303460e-02, -3.81956697e-02]],\n","\n","       [[-1.70625225e-02,  3.24341618e-02, -2.35826969e-02, ...,\n","          2.74206512e-02, -3.30770053e-02, -3.23245227e-02],\n","        [-4.06601653e-03, -9.91039909e-03,  7.49966875e-03, ...,\n","          3.80264483e-02,  2.27294303e-02, -3.65849510e-02],\n","        [ 2.96343155e-02,  3.24257575e-02, -2.97235809e-02, ...,\n","         -1.39769651e-02,  2.26207413e-02, -1.98238119e-02],\n","        ...,\n","        [-1.00595299e-02, -1.32552534e-03,  2.50614770e-02, ...,\n","         -1.57406200e-02,  1.19499713e-02, -3.49121355e-02],\n","        [-8.27059150e-04, -2.13790964e-02,  1.03818811e-02, ...,\n","          1.27284937e-02, -2.60101277e-02,  2.06619948e-02],\n","        [ 7.73996115e-04, -2.09942833e-03,  2.91202031e-02, ...,\n","         -1.05892494e-02, -9.29216854e-03,  1.35102905e-02]],\n","\n","       [[ 1.24063604e-02, -1.25244558e-02,  1.15926042e-02, ...,\n","          1.36834309e-02, -2.14363374e-02,  3.44819613e-02],\n","        [-3.39936465e-04, -7.71239214e-03, -2.80310996e-02, ...,\n","         -3.26634459e-02, -2.36104373e-02,  2.22913548e-02],\n","        [ 2.53069215e-02,  2.55186073e-02,  3.56966890e-02, ...,\n","          3.71155925e-02,  3.81610431e-02,  1.86884180e-02],\n","        ...,\n","        [ 2.96391286e-02,  1.23475939e-02, -1.70266423e-02, ...,\n","          1.31239370e-02, -7.87242688e-03,  2.82667764e-02],\n","        [-2.58216318e-02, -3.31740305e-02, -2.20403336e-02, ...,\n","         -2.44923644e-02,  1.87554844e-02, -3.35678048e-02],\n","        [-1.66827366e-02, -2.97844168e-02,  2.15578750e-02, ...,\n","          2.56927423e-02,  1.10970810e-03,  4.59996983e-03]]],\n","      dtype=float32)>, <tf.Variable 'bias:0' shape=(1, 3, 128) dtype=float32, numpy=\n","array([[[ 6.76783994e-02, -4.27311510e-02, -5.00647426e-02,\n","          5.93817756e-02,  4.55171987e-02, -5.18696196e-02,\n","          8.28701928e-02, -7.30746686e-02, -6.49111420e-02,\n","          4.18927595e-02,  2.87028849e-02, -8.78169611e-02,\n","         -7.59393722e-02, -6.36989325e-02, -7.03697279e-02,\n","          8.06147382e-02,  8.00984576e-02, -6.57348782e-02,\n","         -1.93393156e-02,  6.01795092e-02,  6.72153905e-02,\n","          5.49639091e-02,  3.01740468e-02,  5.97245470e-02,\n","         -4.94144410e-02,  1.84801891e-02, -6.23925291e-02,\n","          3.59600261e-02, -7.22847879e-03, -1.98731050e-02,\n","          6.60079643e-02,  2.94153839e-02,  9.20113921e-03,\n","         -8.93574208e-03, -4.70889881e-02,  8.68489966e-02,\n","         -5.39384596e-02,  3.75172272e-02,  2.14264914e-02,\n","          7.77050927e-02, -2.84292288e-02, -5.81281520e-02,\n","          5.15453517e-04,  1.98273733e-02, -4.70109321e-02,\n","         -5.82508743e-04, -5.48736565e-02, -6.26055896e-03,\n","          6.17495999e-02,  8.76253843e-03,  7.37399831e-02,\n","         -6.42233267e-02, -2.14834511e-02, -5.08038513e-02,\n","          6.06935099e-02, -1.17191672e-03, -4.44473065e-02,\n","          6.80686161e-02,  3.18889171e-02, -1.59608424e-02,\n","          1.51805580e-02, -5.73325455e-02,  2.14489326e-02,\n","          7.42640272e-02, -5.51955104e-02,  6.77602217e-02,\n","         -5.07080518e-02, -4.83395047e-02, -6.04255982e-02,\n","          2.78017670e-02,  6.85834363e-02,  2.71723270e-02,\n","          7.39273354e-02,  4.97666001e-03,  1.96952224e-02,\n","         -4.08965200e-02, -3.69673371e-02,  8.01767483e-02,\n","          2.63030082e-02,  6.43168464e-02, -9.32738185e-05,\n","         -4.52079736e-02, -2.17178315e-02,  2.98347026e-02,\n","          7.78265372e-02, -6.09260499e-02, -1.43959299e-02,\n","         -4.17793468e-02, -4.30859625e-02, -8.27199221e-03,\n","          6.28405288e-02, -4.46688943e-02,  8.17532837e-03,\n","         -7.95759261e-02,  8.48233476e-02, -3.35623361e-02,\n","          1.93051323e-02,  5.76586947e-02, -7.22233206e-02,\n","          7.13413209e-03,  6.18747100e-02,  9.56328958e-03,\n","         -5.11107221e-02, -7.50961974e-02,  7.53334910e-03,\n","          6.70627728e-02, -7.85795525e-02, -3.49767618e-02,\n","          1.83304027e-02,  2.90857926e-02, -3.11608091e-02,\n","         -5.69014251e-02, -7.96742737e-04, -2.48395577e-02,\n","         -2.79286280e-02, -7.36221373e-02, -8.45213756e-02,\n","          5.19535169e-02, -1.33736432e-03, -2.20221952e-02,\n","          7.71401301e-02,  7.08429888e-02,  5.64445183e-02,\n","         -7.50704929e-02, -9.55496728e-03, -7.55946264e-02,\n","         -5.45226373e-02,  7.84263238e-02],\n","        [-3.78234647e-02, -3.49323452e-03,  3.14635932e-02,\n","         -2.11927816e-02,  3.80422100e-02,  3.82247195e-02,\n","          4.99281213e-02,  2.37478316e-02, -4.62660715e-02,\n","         -1.45257264e-03, -2.37421393e-02, -6.85347617e-03,\n","          8.40698555e-02,  9.10504907e-03, -6.51799515e-02,\n","         -4.38447334e-02,  7.88678154e-02,  8.37402269e-02,\n","         -4.20723967e-02,  5.07578999e-03,  2.09376067e-02,\n","          3.11668143e-02,  2.64563113e-02,  5.36653027e-02,\n","          8.47466215e-02,  7.30404183e-02,  3.47723812e-03,\n","          6.37042299e-02,  7.58783594e-02,  4.76536527e-02,\n","          8.39327350e-02,  7.46380165e-02,  6.48282468e-04,\n","         -1.31295472e-02,  7.22639486e-02,  4.36769649e-02,\n","          6.77319244e-02, -2.53332704e-02,  6.94710240e-02,\n","         -5.98402396e-02,  4.33011279e-02, -2.58177444e-02,\n","         -8.06959346e-02,  5.36603704e-02, -4.18640859e-02,\n","         -5.74992597e-03,  6.85151666e-03, -6.30213320e-03,\n","          9.60566849e-03, -1.48219615e-03, -2.47767419e-02,\n","         -5.95380701e-02, -4.65794951e-02,  6.37972876e-02,\n","          3.61847728e-02, -4.73092459e-02, -5.28368689e-02,\n","          1.61318555e-02, -2.83265188e-02, -4.08632457e-02,\n","         -2.35852078e-02,  8.25830176e-02, -1.52584687e-02,\n","          3.11741233e-03,  4.93438542e-03, -4.30136807e-02,\n","          1.00610852e-02, -6.09913543e-02, -6.90272227e-02,\n","         -5.75618036e-02, -6.45473078e-02, -4.78924736e-02,\n","         -4.86025438e-02,  5.15039340e-02,  3.90614197e-02,\n","          3.68591622e-02, -5.34904748e-03, -4.68034409e-02,\n","          7.91304931e-02, -7.87714124e-03, -2.99227461e-02,\n","         -5.10070436e-02, -5.68132848e-03, -4.37168591e-02,\n","         -7.04436004e-03,  3.51518616e-02, -5.01024015e-02,\n","         -8.73239487e-02,  1.36292577e-02,  3.70523408e-02,\n","          7.98977539e-02, -1.53702796e-02,  7.76571706e-02,\n","          1.97787806e-02, -7.59117305e-03, -2.97882743e-02,\n","          4.92404327e-02, -5.17480895e-02, -4.51694317e-02,\n","         -2.98650675e-02, -2.00419873e-02,  2.12238282e-02,\n","         -8.41334313e-02, -1.41190663e-02,  5.26558086e-02,\n","         -7.55584240e-02,  5.70144579e-02,  4.96482477e-02,\n","         -8.80986676e-02, -7.77774528e-02, -2.93425508e-02,\n","          6.77806512e-02,  5.48055097e-02, -3.76106054e-02,\n","         -1.47300512e-02, -4.17388231e-02,  2.79901028e-02,\n","         -5.16439453e-02, -7.79231340e-02, -1.55416131e-03,\n","          8.40835050e-02, -4.09344733e-02, -2.08035782e-02,\n","         -4.21997830e-02,  5.95862642e-02, -7.96429366e-02,\n","         -7.69653916e-02,  2.64270231e-02],\n","        [ 4.34949622e-02,  7.87385777e-02, -4.13883738e-02,\n","         -3.22808810e-02,  4.34930250e-02, -5.24717085e-02,\n","         -4.41032201e-02,  3.88012081e-03,  1.41647533e-02,\n","         -2.38364413e-02, -2.38481164e-02, -8.70026872e-02,\n","         -6.62759617e-02, -5.38344644e-02,  6.72254637e-02,\n","          6.38773814e-02, -3.58241461e-02, -3.13977376e-02,\n","         -5.28947376e-02,  5.32712713e-02,  1.46967769e-02,\n","         -8.45883638e-02,  1.29669607e-02,  8.77721384e-02,\n","          3.40926275e-02, -5.07498607e-02,  7.13396817e-03,\n","         -3.35385241e-02,  8.45145807e-02,  7.42155313e-03,\n","         -8.49072263e-02,  6.03333190e-02,  4.10054699e-02,\n","         -6.93720430e-02,  7.08442181e-03, -4.98348139e-02,\n","          7.40110502e-02,  4.83969375e-02, -6.37968630e-03,\n","         -6.68735802e-02,  4.48616073e-02, -5.60274050e-02,\n","          8.05264488e-02, -4.05395776e-03,  4.99455109e-02,\n","         -1.95694789e-02, -4.73998003e-02, -8.01881254e-02,\n","         -1.27186328e-02,  5.91069460e-03, -3.57398093e-02,\n","          8.59629586e-02,  6.80444613e-02,  2.54269615e-02,\n","         -6.11953065e-02,  7.45117292e-02, -5.10407798e-02,\n","          5.77174500e-02, -8.82869586e-02, -4.70520668e-02,\n","          4.46501449e-02, -6.17174432e-02,  4.35469225e-02,\n","         -8.18226859e-02,  1.59400403e-02, -3.93357389e-02,\n","          4.06725034e-02, -2.10259035e-02, -5.61172441e-02,\n","         -7.69571960e-03, -7.91087449e-02, -1.62265822e-02,\n","          6.05449826e-03,  4.63073477e-02, -1.26629993e-02,\n","         -7.11246431e-02, -8.18171352e-03,  2.10929364e-02,\n","         -5.19844294e-02,  5.13810292e-02,  6.78669587e-02,\n","          5.96747771e-02,  2.96127796e-03,  6.54668286e-02,\n","         -2.53832787e-02,  7.43288919e-02,  8.45135003e-03,\n","          5.11794910e-02, -6.08465001e-02,  4.25249711e-02,\n","         -1.27699077e-02, -4.96730953e-02,  2.21813172e-02,\n","         -6.53612912e-02, -7.52852261e-02,  5.33715263e-02,\n","          2.01623589e-02, -1.63859129e-02,  6.09175339e-02,\n","          5.57899475e-04, -3.71885449e-02, -1.02052465e-02,\n","         -1.47374272e-02,  1.76510140e-02,  1.44124329e-02,\n","          1.45763159e-04,  8.78149644e-02,  2.25822777e-02,\n","         -8.68616179e-02, -1.64318755e-02,  6.73156455e-02,\n","         -3.23609821e-02,  3.29420790e-02,  6.12545237e-02,\n","          8.56208727e-02,  2.79686600e-03, -4.72183377e-02,\n","         -7.77911991e-02,  2.07271278e-02,  6.39706925e-02,\n","         -5.70540614e-02,  8.77087489e-02, -2.52290219e-02,\n","         -4.11266834e-03, -3.25072519e-02, -8.07554498e-02,\n","         -3.84918600e-03, -5.21148294e-02]]], dtype=float32)>, <tf.Variable 'dense_1390/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[ 0.15530762, -0.00779195, -0.00265662, ..., -0.14884019,\n","         0.05627334, -0.09144985],\n","       [-0.0569303 ,  0.03804497,  0.15129447, ...,  0.00647606,\n","        -0.13472995, -0.01966344],\n","       [-0.14957131,  0.14737895,  0.0939697 , ...,  0.1322478 ,\n","        -0.1287094 , -0.01079707],\n","       ...,\n","       [-0.14206988, -0.06253678,  0.06351295, ..., -0.12028588,\n","         0.04474454, -0.10098374],\n","       [-0.00689857, -0.1425769 , -0.03788927, ..., -0.11791527,\n","         0.13354698, -0.11333865],\n","       [-0.09021068,  0.15139419, -0.01435958, ..., -0.10238414,\n","        -0.06718532, -0.01900497]], dtype=float32)>, <tf.Variable 'dense_1391/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.12390849,  0.07559246,  0.04374564, ..., -0.09081352,\n","        -0.05998054,  0.01866004],\n","       [-0.01911366,  0.10913357, -0.12008107, ...,  0.04555476,\n","         0.0325821 , -0.00367647],\n","       [ 0.11540747, -0.04880497,  0.06781384, ...,  0.029172  ,\n","         0.03073132,  0.02219173],\n","       ...,\n","       [ 0.00249714,  0.04865688, -0.04658082, ..., -0.11903656,\n","        -0.04368886,  0.10856634],\n","       [ 0.07550591,  0.07296193, -0.06180644, ...,  0.11835775,\n","        -0.05610549,  0.11788914],\n","       [-0.11130211, -0.12136942, -0.01426357, ...,  0.04724565,\n","        -0.07301855,  0.02167651]], dtype=float32)>, <tf.Variable 'dense_1392/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.0465548 , -0.00658467,  0.03754288, ..., -0.05324531,\n","         0.08075243, -0.02284989],\n","       [ 0.08079293, -0.0964821 ,  0.12159127, ..., -0.04699582,\n","        -0.11096892,  0.11929116],\n","       [ 0.0595392 ,  0.0698567 ,  0.02570912, ...,  0.10721168,\n","         0.062933  , -0.03074995],\n","       ...,\n","       [-0.06484067,  0.02692881, -0.00582796, ..., -0.10037348,\n","        -0.0248192 ,  0.05002949],\n","       [-0.01092306, -0.07034096,  0.0701417 , ..., -0.12176859,\n","        -0.06519908, -0.01189494],\n","       [ 0.07850891,  0.05932212,  0.04120165, ..., -0.11398807,\n","        -0.10293746, -0.11427924]], dtype=float32)>, <tf.Variable 'dense_1393/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.04392231, -0.00502142,  0.07195497, ..., -0.08075848,\n","         0.11550838, -0.00760531],\n","       [ 0.06684551, -0.04138362, -0.03373685, ..., -0.09574538,\n","         0.0077059 ,  0.11800846],\n","       [ 0.01284787, -0.1148034 , -0.04641289, ...,  0.1007289 ,\n","        -0.10331887,  0.03651601],\n","       ...,\n","       [ 0.08101162,  0.11529881,  0.03633067, ...,  0.04911971,\n","        -0.00563994,  0.01658559],\n","       [ 0.0543294 , -0.05164328, -0.03917566, ...,  0.09816858,\n","        -0.06793824,  0.11712235],\n","       [ 0.10411838, -0.09347653,  0.02600443, ...,  0.10441986,\n","        -0.10876524, -0.10494497]], dtype=float32)>, <tf.Variable 'dense_1394/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[ 0.01068504,  0.07064782,  0.10361002, ..., -0.0200789 ,\n","        -0.08334962,  0.13499509],\n","       [ 0.14677398,  0.13289107,  0.06376056, ...,  0.10899369,\n","        -0.1357547 ,  0.1414539 ],\n","       [ 0.04781112, -0.09187436,  0.12441353, ...,  0.06256321,\n","        -0.07577524, -0.04967745],\n","       ...,\n","       [-0.09382829,  0.05276665, -0.1263888 , ..., -0.08191242,\n","         0.037958  ,  0.1276337 ],\n","       [ 0.1304347 , -0.03578604, -0.12446886, ...,  0.02852082,\n","         0.0166335 , -0.13136365],\n","       [-0.05917612,  0.11694951, -0.1446336 , ..., -0.00552131,\n","         0.03070229, -0.07231504]], dtype=float32)>, <tf.Variable 'dense_1395/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[ 0.06462017,  0.05336832,  0.03916253, ..., -0.02895981,\n","         0.00050839, -0.03765048],\n","       [-0.0214859 , -0.0323302 , -0.01601979, ...,  0.05509149,\n","         0.05058409,  0.02301971],\n","       [-0.01476831, -0.04928227,  0.05029143, ...,  0.05294112,\n","        -0.0515124 ,  0.01246826],\n","       ...,\n","       [ 0.05516989, -0.04258007, -0.00585786, ..., -0.03862748,\n","         0.01086512,  0.00724193],\n","       [-0.04792777, -0.04261177, -0.05956747, ...,  0.03202361,\n","        -0.06264695,  0.01948141],\n","       [-0.03287295, -0.03758345, -0.0268467 , ..., -0.00662011,\n","        -0.0189106 , -0.03607601]], dtype=float32)>, <tf.Variable 'dense_1396/kernel:0' shape=(1280, 128) dtype=float32, numpy=\n","array([[ 0.06041127,  0.05254151,  0.04532602, ...,  0.00523467,\n","        -0.06194063, -0.04941367],\n","       [ 0.05134075, -0.00220805,  0.01168631, ...,  0.04977175,\n","         0.045459  ,  0.0319207 ],\n","       [-0.01812978, -0.06339759,  0.00073712, ..., -0.02549748,\n","        -0.00718657,  0.02016453],\n","       ...,\n","       [-0.01652231,  0.04013754,  0.00122856, ..., -0.04089406,\n","         0.02756881,  0.05823144],\n","       [-0.03272939, -0.0527858 ,  0.01272317, ...,  0.01522409,\n","         0.01335848, -0.04958793],\n","       [ 0.00465579, -0.02342438,  0.02243798, ...,  0.01008796,\n","        -0.00517128,  0.00182346]], dtype=float32)>, <tf.Variable 'branch:0' shape=(12, 128, 256) dtype=float32, numpy=\n","array([[[-2.28974912e-02,  1.54584609e-02,  4.12188470e-04, ...,\n","          2.57202573e-02, -3.61369178e-03,  5.57503104e-03],\n","        [ 3.22849676e-02, -2.85259485e-02, -1.15373749e-02, ...,\n","         -2.19906047e-02,  2.55984887e-02, -1.66039579e-02],\n","        [ 3.61953303e-03,  3.58210132e-03,  2.00165845e-02, ...,\n","         -1.78897735e-02,  3.04071754e-02,  2.77719051e-02],\n","        ...,\n","        [ 2.41844356e-02,  3.32634896e-04,  4.08442318e-03, ...,\n","          1.83030702e-02, -7.79001601e-03, -1.05645098e-02],\n","        [-1.05074104e-02, -2.51835957e-03,  7.24064931e-03, ...,\n","         -2.22520456e-02,  1.79946050e-03,  2.13704668e-02],\n","        [ 1.80927813e-02, -1.55704729e-02, -8.39344412e-03, ...,\n","         -2.67456882e-02, -1.54765174e-02,  3.20075378e-02]],\n","\n","       [[ 1.64858028e-02, -1.92899071e-02,  2.43468583e-03, ...,\n","          1.98515393e-02, -2.37383768e-02, -4.08389047e-03],\n","        [-3.42777818e-02,  5.05880266e-03, -2.78432332e-02, ...,\n","          2.36938372e-02, -3.43201943e-02, -2.42513418e-02],\n","        [-2.35047564e-03, -1.15715656e-02, -2.51819640e-02, ...,\n","         -3.24043334e-02,  2.65617445e-02,  1.06023476e-02],\n","        ...,\n","        [-8.91644508e-04,  1.12040974e-02,  1.54419616e-03, ...,\n","         -3.15247439e-02, -2.64437348e-02, -1.54807847e-02],\n","        [-3.69633362e-03,  1.22148693e-02, -2.64255740e-02, ...,\n","         -2.24285498e-02, -4.01535630e-03, -4.34495509e-03],\n","        [-2.27479674e-02,  2.82067209e-02, -8.74494389e-03, ...,\n","          5.87590039e-04,  7.73364678e-03, -2.75022276e-02]],\n","\n","       [[ 1.28522255e-02, -2.41186805e-02,  2.67579556e-02, ...,\n","         -4.94657643e-03,  2.87885070e-02, -2.37856843e-02],\n","        [ 1.44409426e-02,  1.22257359e-02, -4.15404141e-03, ...,\n","         -3.66970897e-03,  3.31883281e-02, -1.64286327e-02],\n","        [ 2.36634240e-02,  1.77393220e-02,  2.96211243e-03, ...,\n","          3.96796316e-03, -2.07968950e-02, -2.75497511e-02],\n","        ...,\n","        [-3.31224687e-02,  3.50992754e-03,  1.54596642e-02, ...,\n","          1.49345584e-02, -1.43040325e-02,  2.26310343e-02],\n","        [ 2.91606486e-02,  2.94694677e-03, -2.34679505e-02, ...,\n","          1.20138563e-02, -7.64051825e-03,  8.69430602e-04],\n","        [-3.33590657e-02, -2.90505011e-02,  3.45148966e-02, ...,\n","         -2.09655426e-02, -3.54728326e-02, -1.02499425e-02]],\n","\n","       ...,\n","\n","       [[ 1.17343627e-02,  8.49702582e-03,  1.31635778e-02, ...,\n","         -2.69647874e-02,  1.16406493e-02,  1.79372355e-03],\n","        [ 3.14736292e-02, -1.19778588e-02, -3.72098386e-03, ...,\n","          1.29734725e-02, -2.31681392e-03, -1.16672590e-02],\n","        [-3.34663615e-02,  1.35111548e-02, -3.45395096e-02, ...,\n","         -2.20084041e-02,  3.10318321e-02,  2.28013508e-02],\n","        ...,\n","        [-2.86765769e-03, -2.14279983e-02,  3.45591381e-02, ...,\n","         -1.92735270e-02, -3.09042893e-02,  1.50519833e-02],\n","        [ 2.30783299e-02, -2.54872330e-02,  3.59839574e-03, ...,\n","         -3.36159207e-02,  2.83299908e-02,  6.84656575e-03],\n","        [-5.88200986e-03, -2.37992778e-03,  3.33181024e-03, ...,\n","          1.03108175e-02, -2.50630435e-02,  1.63927302e-02]],\n","\n","       [[ 2.77591050e-02,  4.13391739e-03, -1.04419142e-02, ...,\n","          2.80764997e-02,  2.35572085e-02, -1.95977036e-02],\n","        [-1.38094686e-02,  1.56843811e-02, -1.93197690e-02, ...,\n","          2.87703127e-02, -3.48712653e-02,  1.15219243e-02],\n","        [-9.93395597e-03, -3.31369713e-02,  1.52401961e-02, ...,\n","          2.88162082e-02, -4.16544080e-03,  1.88986175e-02],\n","        ...,\n","        [-2.23715864e-02, -9.01606493e-03,  2.40780488e-02, ...,\n","          2.69684792e-02,  1.34242363e-02,  5.68027422e-03],\n","        [-1.77662130e-02, -2.07973570e-02, -9.03161056e-03, ...,\n","          5.34504652e-05,  3.34443077e-02,  2.37568021e-02],\n","        [-1.51509829e-02,  2.88993940e-02, -3.07435058e-02, ...,\n","          4.57391143e-03, -2.07428150e-02,  1.76463462e-02]],\n","\n","       [[-2.72454750e-02, -2.77158804e-02, -4.58708405e-03, ...,\n","         -9.47202556e-03, -3.42915803e-02,  8.78671184e-03],\n","        [ 2.81288698e-02,  2.60273479e-02, -2.10548602e-02, ...,\n","          2.73656100e-03,  2.82725543e-02,  2.92398632e-02],\n","        [-3.03911455e-02,  6.26933202e-03,  3.26655880e-02, ...,\n","          1.59657300e-02,  7.87425786e-04,  6.95667788e-03],\n","        ...,\n","        [ 1.57944672e-02, -3.33133042e-02,  1.15449280e-02, ...,\n","         -1.65165570e-02,  2.96764746e-02, -2.62314770e-02],\n","        [ 6.78060204e-03, -2.07359754e-02,  2.65041664e-02, ...,\n","         -1.05020329e-02, -7.86459632e-03,  2.59412639e-02],\n","        [ 3.55144590e-02,  2.99873576e-02, -2.61120312e-02, ...,\n","         -1.61711480e-02,  9.25172493e-03, -7.07774982e-03]]],\n","      dtype=float32)>, <tf.Variable 'bias:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[ 0.08696642, -0.04716302, -0.07117306, -0.03789845,\n","         -0.0523841 , -0.06084825, -0.05807973, -0.05211441,\n","         -0.03626291,  0.04036898, -0.00219151,  0.08089095,\n","          0.04215302,  0.07698592,  0.07290315, -0.05354462,\n","          0.0270151 , -0.02523319,  0.03492673, -0.072225  ,\n","          0.08433659,  0.03010359,  0.03937563, -0.0612882 ,\n","          0.00542291,  0.071552  ,  0.02569556,  0.08203072,\n","         -0.05459648,  0.06628203, -0.08305888,  0.00790808,\n","          0.01045848, -0.06722869, -0.04430544,  0.00899982,\n","         -0.05452786, -0.0403422 , -0.05366817,  0.024895  ,\n","          0.06067205,  0.08490387, -0.07856727, -0.00372235,\n","         -0.01808753, -0.0062163 ,  0.05842391, -0.05199242,\n","          0.00476184, -0.0401596 ,  0.02541615, -0.08099828,\n","          0.01356632,  0.03680456, -0.00017171, -0.01416602,\n","          0.02984787, -0.0505091 ,  0.07778414, -0.00990984,\n","         -0.00460707,  0.04360677, -0.04787755,  0.05449783,\n","          0.08165088,  0.00999713, -0.02021953,  0.00681175,\n","          0.05711817, -0.05324683,  0.0343175 ,  0.07965014,\n","         -0.00043167,  0.00999036, -0.01707369, -0.00928826,\n","         -0.04063038,  0.03305653,  0.05216796,  0.01663515,\n","         -0.07308757, -0.01644119,  0.01868035,  0.03285524,\n","          0.00949746, -0.07562759, -0.00962575,  0.01374942,\n","         -0.07755876, -0.01677278,  0.01416768, -0.00746109,\n","         -0.00795311, -0.04190973, -0.01444577,  0.05687454,\n","         -0.05514256, -0.05325697,  0.06029197,  0.04545289,\n","          0.0190957 ,  0.06200521, -0.04204686, -0.02748044,\n","         -0.01002726,  0.02740611,  0.04922561,  0.0162093 ,\n","          0.0039311 , -0.0636445 ,  0.07513816,  0.00314639,\n","          0.05203106,  0.08071945,  0.01189504, -0.01431444,\n","         -0.08659146,  0.01544295,  0.02541021, -0.02312621,\n","         -0.06251214, -0.03217364,  0.02560242, -0.05282098,\n","         -0.03959861,  0.08312465, -0.00248407,  0.05420456],\n","        [ 0.05373152,  0.05305438, -0.07351984, -0.03193755,\n","         -0.01776586, -0.0720179 , -0.04011701, -0.05007391,\n","          0.08040196,  0.02886379, -0.07057475, -0.00189703,\n","         -0.0515505 , -0.00573787, -0.08292428,  0.04212327,\n","         -0.08327595, -0.07366163, -0.04028202, -0.07911798,\n","         -0.02692638, -0.02525602, -0.01612077,  0.08271668,\n","          0.05004091, -0.02316077, -0.02257448, -0.03393245,\n","         -0.05593938,  0.00839565,  0.07908795, -0.07090008,\n","         -0.00284026,  0.01758736, -0.01213165, -0.0593721 ,\n","         -0.07896629, -0.01507106,  0.05453014, -0.08288565,\n","         -0.07465446,  0.0406692 ,  0.02647147, -0.05574096,\n","         -0.07834024,  0.03848311, -0.06566742,  0.05546934,\n","         -0.06668847,  0.05059902, -0.04193472, -0.07353912,\n","         -0.07852689,  0.02183664,  0.02644036,  0.06695517,\n","         -0.00499552, -0.08715395,  0.05440532, -0.01878399,\n","          0.00521738,  0.05793203,  0.01186423,  0.00442605,\n","          0.01693578,  0.01892604, -0.03106396,  0.01990269,\n","         -0.03663516,  0.01116067, -0.04160372, -0.01222027,\n","          0.07756739, -0.0101143 , -0.00151653, -0.07234295,\n","          0.05561768, -0.05768508,  0.04872639,  0.02910352,\n","         -0.07101192,  0.00021923,  0.01289774,  0.05373657,\n","          0.01181264,  0.02605902, -0.01998667, -0.08456379,\n","         -0.02174067,  0.07178885, -0.0005174 , -0.01982225,\n","         -0.04966614, -0.04677232, -0.04281414, -0.02817386,\n","         -0.06133867, -0.06156736, -0.01774976, -0.00635453,\n","         -0.02408838, -0.03323926, -0.0500356 , -0.01093846,\n","         -0.05419248,  0.01878007,  0.00512052,  0.01279525,\n","          0.05179083, -0.0424565 , -0.06798999, -0.08114512,\n","         -0.04913922, -0.03016935, -0.06044463, -0.06823163,\n","          0.02960378,  0.0523937 ,  0.033796  ,  0.04634757,\n","          0.00284205, -0.05720893, -0.0233797 , -0.01688103,\n","          0.03529274, -0.07074072, -0.02326103,  0.03785305]]],\n","      dtype=float32)>, <tf.Variable 'dense_1397/kernel:0' shape=(96, 128) dtype=float32, numpy=\n","array([[ 8.5648015e-02,  1.5381321e-01, -5.4515898e-04, ...,\n","        -1.0375142e-01, -4.4524670e-05,  2.1484241e-02],\n","       [ 3.6332086e-02, -1.7652124e-02,  7.8084260e-02, ...,\n","         1.1004299e-02, -1.4594972e-01, -1.2001540e-01],\n","       [-3.8812339e-02,  2.9227719e-02, -9.0262145e-02, ...,\n","        -1.4975409e-01,  1.5791795e-01,  1.2625894e-01],\n","       ...,\n","       [ 7.8600273e-02,  1.5674263e-01, -1.5054652e-01, ...,\n","         1.2365261e-01,  1.1622515e-01, -8.1994504e-02],\n","       [ 1.3212606e-01, -1.5601389e-01, -9.6249938e-02, ...,\n","         1.2246868e-01,  1.4599487e-02, -1.4013650e-01],\n","       [ 3.2366991e-02, -1.4110330e-01,  5.7997927e-02, ...,\n","        -9.5951438e-02, -8.2213014e-02, -4.0450655e-02]], dtype=float32)>, <tf.Variable 'dense_1398/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[ 0.01011044, -0.01719618,  0.04563013, ...,  0.03586677,\n","         0.0169155 , -0.08932328],\n","       [-0.01449955, -0.0445866 , -0.10941467, ...,  0.06798348,\n","         0.07456931,  0.01598513],\n","       [-0.10887718,  0.05642232,  0.01102075, ..., -0.00805736,\n","        -0.06754005,  0.05768293],\n","       ...,\n","       [ 0.00810874,  0.00320745, -0.08582249, ..., -0.10666728,\n","         0.03503707, -0.0282506 ],\n","       [-0.07048652, -0.08149847,  0.04821238, ...,  0.02955946,\n","        -0.10857528,  0.07004401],\n","       [ 0.08792725,  0.01817399, -0.00950018, ...,  0.12441078,\n","        -0.06647009,  0.08622301]], dtype=float32)>, <tf.Variable 'dense_1399/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.10554913, -0.0584726 ,  0.00055054, ...,  0.09086075,\n","         0.080865  ,  0.08254299],\n","       [-0.02126151,  0.08706495, -0.05583724, ...,  0.01909029,\n","         0.12201813,  0.12412417],\n","       [-0.09535274,  0.06753978,  0.1171577 , ...,  0.0134142 ,\n","         0.11088639,  0.09742886],\n","       ...,\n","       [ 0.10970911,  0.02749056, -0.00374463, ..., -0.02435327,\n","        -0.12387747, -0.09520769],\n","       [ 0.0192661 , -0.06156912, -0.12411422, ..., -0.01874587,\n","         0.11333108,  0.05982032],\n","       [-0.01026073,  0.06088534,  0.05817565, ...,  0.04618981,\n","        -0.06843904, -0.0119068 ]], dtype=float32)>, <tf.Variable 'dense_1400/kernel:0' shape=(256, 128) dtype=float32, numpy=\n","array([[-0.03919905,  0.10499135, -0.02815476, ...,  0.01825675,\n","         0.09025112,  0.10862729],\n","       [-0.06503913,  0.07987294, -0.05129188, ..., -0.11674896,\n","        -0.04213813, -0.12370887],\n","       [-0.11238188,  0.01157671,  0.03085858, ...,  0.01246271,\n","         0.04844898, -0.01249707],\n","       ...,\n","       [ 0.05013159,  0.1180371 ,  0.00481558, ...,  0.07407594,\n","         0.11297873,  0.08182761],\n","       [ 0.05547929, -0.01081359, -0.09932169, ...,  0.09078601,\n","         0.03872064,  0.0695796 ],\n","       [ 0.00348476,  0.01537025, -0.0027661 , ...,  0.02413613,\n","        -0.02598241, -0.08539385]], dtype=float32)>, <tf.Variable 'dense_1401/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[-0.02185674, -0.0725439 , -0.09166985, ...,  0.08947735,\n","         0.13428892, -0.11242871],\n","       [-0.05371773, -0.0015648 ,  0.00223589, ..., -0.02027497,\n","        -0.11875996, -0.01847731],\n","       [ 0.0302653 ,  0.12735413,  0.03649649, ...,  0.00801323,\n","        -0.14031507,  0.03565851],\n","       ...,\n","       [-0.03047562, -0.1197442 ,  0.14116861, ...,  0.00100678,\n","        -0.14432813, -0.05765337],\n","       [-0.03533311, -0.1365653 , -0.08531311, ...,  0.13292687,\n","         0.03363651,  0.12473644],\n","       [-0.09337416, -0.0404422 , -0.10148436, ...,  0.13273935,\n","        -0.01704043,  0.09188546]], dtype=float32)>, <tf.Variable 'dense_1402/kernel:0' shape=(128, 128) dtype=float32, numpy=\n","array([[ 0.12122194, -0.11458102, -0.08515149, ...,  0.1306703 ,\n","         0.00856705, -0.04782762],\n","       [ 0.06788403, -0.1239441 ,  0.13096671, ...,  0.05460837,\n","        -0.11625846, -0.05640776],\n","       [ 0.07279152,  0.14576404,  0.08215669, ...,  0.03196786,\n","         0.11170997,  0.01539059],\n","       ...,\n","       [-0.1267126 ,  0.0815364 ,  0.10495187, ..., -0.06298854,\n","         0.14104249,  0.05159393],\n","       [-0.0627948 , -0.11555827, -0.05275591, ...,  0.14036642,\n","         0.02204093, -0.15169464],\n","       [ 0.01420954, -0.0192153 , -0.12270629, ..., -0.1081761 ,\n","         0.07066841, -0.08644655]], dtype=float32)>, <tf.Variable 'dense_1403/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[-0.06182451,  0.03570568, -0.05605532, ...,  0.05405113,\n","         0.01818492,  0.06341576],\n","       [ 0.03090204,  0.00169834, -0.04249261, ...,  0.0549963 ,\n","        -0.03510027, -0.01308644],\n","       [-0.00620821,  0.04980862, -0.0081555 , ...,  0.01368767,\n","         0.03760647, -0.0570556 ],\n","       ...,\n","       [ 0.04504821, -0.05641698,  0.03944273, ..., -0.02320761,\n","        -0.01580906,  0.04677543],\n","       [-0.01435648,  0.05194792, -0.03997473, ...,  0.04685582,\n","        -0.01013493, -0.01420789],\n","       [ 0.01596787, -0.00261305, -0.0327871 , ..., -0.00324691,\n","        -0.05571343,  0.02923036]], dtype=float32)>, <tf.Variable 'dense_1404/kernel:0' shape=(1280, 128) dtype=float32, numpy=\n","array([[-0.00106518,  0.0263984 , -0.0261512 , ...,  0.04956612,\n","         0.05796104,  0.02107298],\n","       [ 0.02934112,  0.02493015, -0.05683422, ..., -0.03960003,\n","         0.013023  , -0.05109072],\n","       [ 0.01102328,  0.01334698, -0.05919617, ..., -0.00534366,\n","        -0.03922977, -0.00286949],\n","       ...,\n","       [ 0.02086327, -0.01257041,  0.06468158, ...,  0.00419283,\n","         0.01139877,  0.01422172],\n","       [-0.03841875, -0.01601297, -0.0342875 , ...,  0.00637312,\n","         0.00016577,  0.00593183],\n","       [ 0.00380243, -0.02368948, -0.01091376, ...,  0.01048901,\n","         0.06072889, -0.05590403]], dtype=float32)>, <tf.Variable 'branch:0' shape=(24, 128, 256) dtype=float32, numpy=\n","array([[[-1.96473487e-03,  1.49192661e-02, -1.54882511e-02, ...,\n","         -9.61322710e-03,  2.46124491e-02, -1.96085386e-02],\n","        [ 2.49799192e-02, -2.28254627e-02, -1.20410044e-02, ...,\n","          1.48624294e-02,  1.92528069e-02,  1.88462250e-02],\n","        [ 2.45506242e-02,  6.92910329e-03, -2.75428966e-03, ...,\n","         -2.49175653e-02,  1.05179213e-02,  9.88471135e-03],\n","        ...,\n","        [-2.33352371e-02,  1.38743445e-02, -1.20703690e-02, ...,\n","         -1.96084175e-02, -1.56812035e-02,  5.81541285e-03],\n","        [ 1.06731690e-02, -1.57434735e-02,  1.43554360e-02, ...,\n","         -1.91227458e-02, -8.08941573e-03,  8.33330303e-03],\n","        [-4.63297591e-03,  1.23255588e-02,  9.87400860e-03, ...,\n","         -1.63740106e-03,  6.27973303e-03,  9.68821719e-03]],\n","\n","       [[-2.21533291e-02,  2.46119238e-02, -6.62712380e-03, ...,\n","          2.26036757e-02,  1.62926055e-02, -2.31408067e-02],\n","        [-1.96699388e-02,  2.38804743e-02, -1.92156862e-02, ...,\n","          1.60168707e-02, -1.75155234e-02, -2.00179443e-02],\n","        [ 7.75470957e-03,  1.43814199e-02, -1.90259032e-02, ...,\n","         -2.00935081e-03,  1.00126863e-02,  1.63618065e-02],\n","        ...,\n","        [-2.43605599e-02, -3.75081971e-03,  1.38067827e-02, ...,\n","         -1.14033325e-02,  2.36925483e-03,  6.52900711e-03],\n","        [ 1.91368870e-02, -1.63638406e-03,  9.85152647e-03, ...,\n","         -1.83884092e-02,  2.47083642e-02,  1.86678581e-03],\n","        [-1.98142361e-02,  1.56648643e-03,  7.21834973e-03, ...,\n","          1.76968277e-02, -1.07507817e-02, -2.19038986e-02]],\n","\n","       [[ 3.27929109e-03, -1.09490631e-02,  5.09502552e-03, ...,\n","         -1.90202147e-03,  9.47283581e-03,  1.40756816e-02],\n","        [ 2.27500461e-02, -2.47331709e-03, -7.48519041e-03, ...,\n","          6.19445741e-03,  3.44644487e-03,  6.00467995e-03],\n","        [-5.75950369e-04,  9.54882428e-03,  3.32084112e-03, ...,\n","         -2.34211478e-02,  2.07855552e-03, -1.67902820e-02],\n","        ...,\n","        [ 4.15764563e-03, -1.80252008e-02,  1.47314966e-02, ...,\n","          1.79085210e-02,  1.93369053e-02,  1.92209966e-02],\n","        [-5.26756048e-05, -1.25793582e-02,  6.21584058e-03, ...,\n","         -2.39442326e-02, -2.41643470e-02, -1.58524755e-02],\n","        [-1.57422088e-02, -6.11985661e-03, -4.58309799e-03, ...,\n","         -8.73458758e-03, -2.45942343e-02, -1.35554112e-02]],\n","\n","       ...,\n","\n","       [[-2.15372480e-02,  1.72085762e-02, -9.15480778e-03, ...,\n","          1.46283619e-02,  2.01752670e-02,  1.49444230e-02],\n","        [-1.84441749e-02,  6.08985126e-03,  1.26641728e-02, ...,\n","          7.22076371e-03,  8.06108490e-03,  2.36571394e-03],\n","        [ 2.11503133e-02,  2.11577117e-02, -1.71177089e-05, ...,\n","          2.17614435e-02, -1.10788392e-02, -1.50456801e-02],\n","        ...,\n","        [-5.02670929e-03, -2.06838232e-02,  1.33850574e-02, ...,\n","          1.30221508e-02, -6.68926537e-03, -1.90297738e-02],\n","        [ 6.25764951e-03, -1.71779767e-02, -2.42409669e-03, ...,\n","          2.08699815e-02,  1.96170248e-02, -1.74864195e-02],\n","        [-1.49447285e-03, -1.45490877e-02,  1.47738755e-02, ...,\n","          1.02667511e-02, -1.68027040e-02, -2.40254812e-02]],\n","\n","       [[-2.52487324e-03, -9.77876224e-03, -1.21427309e-02, ...,\n","          1.90101787e-02,  1.46135092e-02,  1.89080872e-02],\n","        [-1.50343953e-02, -2.93182209e-03, -2.10490022e-02, ...,\n","          1.16349086e-02,  2.54186578e-02,  3.03360820e-03],\n","        [-2.06290670e-02,  9.49520990e-03,  6.28136843e-03, ...,\n","          6.42719865e-03, -1.68706439e-02,  9.21199098e-04],\n","        ...,\n","        [-1.41041167e-03,  1.37037076e-02,  3.52588668e-03, ...,\n","          9.26401839e-03, -9.01018828e-03,  8.28129053e-03],\n","        [ 1.10194087e-04, -2.28772573e-02,  2.54789963e-02, ...,\n","          4.96534631e-03, -1.07833091e-02, -7.93899223e-03],\n","        [-1.14190280e-02, -8.01615976e-03, -1.24643706e-02, ...,\n","          1.75074674e-03, -8.33091885e-03, -6.08973764e-03]],\n","\n","       [[ 1.73872076e-02, -8.77088122e-03,  7.44159147e-03, ...,\n","         -7.50407577e-04,  1.20429508e-03,  6.55818731e-04],\n","        [ 1.36450380e-02, -3.50657851e-03, -1.42282937e-02, ...,\n","         -3.81793827e-03,  1.07610673e-02,  7.68061727e-03],\n","        [ 1.76253654e-02, -2.44312007e-02, -9.38063487e-03, ...,\n","          1.51775144e-02,  6.37619197e-03,  5.70016913e-03],\n","        ...,\n","        [-1.87115148e-02,  9.70872492e-03, -1.92594565e-02, ...,\n","         -2.52511725e-03,  2.43853070e-02, -1.24673760e-02],\n","        [ 2.24919915e-02, -9.62433591e-03,  7.76048005e-03, ...,\n","          1.30097866e-02, -2.51840483e-02, -6.53180294e-03],\n","        [ 8.53908435e-03, -1.15914615e-02, -1.21392328e-02, ...,\n","          8.86877999e-03,  1.53639689e-02,  2.27339640e-02]]],\n","      dtype=float32)>, <tf.Variable 'bias:0' shape=(1, 2, 128) dtype=float32, numpy=\n","array([[[ 8.4807806e-02,  7.4791454e-02, -4.3238431e-02, -6.6195816e-02,\n","         -2.4921134e-02,  6.3492507e-03, -2.4664290e-02,  4.3919533e-03,\n","         -6.2203519e-02,  4.7347523e-02,  3.7124522e-02,  1.8070251e-02,\n","         -8.6087190e-02,  2.6071869e-02, -9.8671243e-03, -8.0745943e-02,\n","          6.2776335e-02, -5.2664235e-02,  2.0017475e-02,  5.4573633e-02,\n","         -3.6306158e-02, -3.5081539e-02, -7.5269192e-03,  7.8060351e-02,\n","         -2.1243840e-04,  2.2607356e-02,  2.1466441e-02,  1.8786073e-02,\n","          4.4695176e-02, -6.5647699e-02,  7.5205438e-02, -6.5135762e-02,\n","          6.8070240e-02, -5.0801050e-02,  5.3371690e-02,  7.4999742e-02,\n","          2.8927341e-02,  5.6029342e-02, -5.8208358e-02,  2.9562935e-02,\n","         -4.8432291e-02, -4.9193822e-02,  1.4813438e-02,  3.7465282e-02,\n","         -2.9565636e-02,  5.4953553e-02,  8.7083429e-03,  9.3743876e-03,\n","          7.5563140e-02,  3.4784913e-02, -1.0512076e-02, -6.1410867e-02,\n","         -1.5565418e-02, -7.0103548e-02, -4.7229022e-02, -2.9426515e-03,\n","         -3.6583360e-02,  1.3318300e-02, -5.6582965e-02,  2.8003439e-02,\n","          8.0156036e-02, -4.7528114e-02, -5.1935602e-02,  6.6674732e-02,\n","         -5.9230883e-02,  4.5082718e-04, -5.5602629e-02,  2.2831455e-02,\n","          2.3376182e-02, -8.3118998e-02,  6.5515630e-02, -2.7505245e-02,\n","         -7.6128587e-02,  8.2644470e-02, -8.2240805e-02,  6.2572561e-02,\n","         -6.7169093e-02,  6.1674289e-02, -2.6268661e-03, -4.2112201e-02,\n","         -4.3900114e-02,  3.1233005e-02, -8.0730073e-02,  5.5666186e-02,\n","         -7.6541096e-02, -2.5171191e-02,  4.0243514e-02,  8.3597451e-03,\n","          6.3706569e-02, -1.6504176e-02, -5.5191804e-02, -3.9677970e-02,\n","         -1.5628681e-02,  7.2362788e-02, -7.2780922e-02, -5.9600048e-02,\n","          4.3815084e-02, -3.9625391e-03,  6.9210492e-02,  7.0439734e-02,\n","         -6.6919394e-02, -1.0579407e-02,  4.8486896e-02, -3.9054196e-02,\n","          8.6446978e-02, -6.4832345e-02, -1.5467346e-02,  8.6614527e-02,\n","          7.3095933e-03,  4.6630077e-02,  2.3878887e-02, -7.5997613e-02,\n","         -6.2862799e-02,  1.0752544e-02,  6.9539182e-02, -7.1593940e-02,\n","         -7.2766237e-02,  5.9891663e-02, -7.1243942e-03,  6.9609560e-02,\n","          7.0447929e-02, -6.3879281e-02, -3.3343635e-02, -1.8045254e-02,\n","          1.7950065e-02, -7.2506741e-02,  8.0276914e-02, -1.7091013e-02],\n","        [-3.0771140e-02,  6.5371193e-02, -5.5296421e-03, -3.5825811e-02,\n","         -7.3504254e-02,  3.3486515e-02, -8.3798237e-02, -6.8285540e-02,\n","         -5.9215054e-03,  7.9174481e-02, -5.8004662e-02,  7.9683505e-02,\n","          4.8156001e-02, -2.6060279e-02, -2.0042874e-02, -2.0322472e-02,\n","         -5.6470286e-02, -4.7405109e-02, -7.0613332e-02,  5.8426462e-02,\n","         -2.0719878e-02,  7.7733524e-02,  7.8128017e-02,  4.3548815e-02,\n","          5.7601802e-02,  2.0261064e-02,  5.0255440e-02,  4.0578462e-02,\n","         -2.0288080e-02,  2.3281753e-02, -1.2590088e-02, -1.4602788e-02,\n","          5.5385895e-02,  8.6413570e-02, -1.6482875e-02,  4.5868076e-02,\n","         -8.0265217e-02,  5.6541689e-02, -6.0104840e-02,  5.1560998e-03,\n","         -6.2692612e-03,  7.6265164e-02, -2.6233252e-02, -2.7441032e-02,\n","         -7.1452476e-02,  8.1574619e-03,  6.6011049e-02,  3.4972318e-02,\n","         -6.0501993e-03, -1.7026946e-02,  8.4775351e-02,  5.2877821e-02,\n","          2.3926996e-02, -8.7862313e-02,  1.0611542e-02, -7.0682980e-02,\n","          3.6742538e-03, -3.5073657e-02,  2.9073209e-02, -6.2303409e-02,\n","          2.7371280e-02,  8.7438382e-02,  2.6296154e-02,  7.5141557e-02,\n","         -1.8660367e-02, -1.5175812e-02, -5.9322257e-02, -7.6234899e-02,\n","          5.8995329e-02,  4.0684901e-02, -5.4345433e-02,  1.5589446e-02,\n","          1.8425442e-02, -4.2885136e-02, -8.8352524e-02,  5.3184249e-02,\n","          2.7632907e-02, -8.6623870e-02, -8.8642389e-03,  3.4964390e-02,\n","         -4.9762972e-02, -4.4505764e-02,  2.7328163e-02, -2.6731260e-02,\n","         -4.2960368e-02, -6.1122265e-02, -2.0899318e-02, -2.2449158e-02,\n","          2.4900965e-02, -5.1945191e-02, -7.4229427e-02, -6.5024644e-02,\n","         -2.7518708e-02, -7.6092616e-02,  3.8283683e-02, -4.3011386e-02,\n","          1.0924108e-02, -3.5908673e-02, -1.4200620e-02,  1.5480518e-02,\n","         -8.4234372e-02,  9.8091960e-03,  4.8547052e-02, -2.5480986e-05,\n","          3.5183452e-02,  5.9319519e-02, -5.6577906e-02, -2.1810442e-02,\n","         -8.3899371e-02, -2.2333592e-02, -1.1028126e-03,  4.8340775e-02,\n","         -3.3906400e-02, -7.7829339e-02,  2.1947928e-02, -7.5863898e-03,\n","         -6.4917631e-02, -8.8290565e-02, -5.2446548e-02, -6.5967046e-02,\n","         -4.3002557e-02,  2.6442513e-02,  8.6981215e-02,  5.6335397e-02,\n","         -1.8607810e-02,  2.9825851e-02,  7.6461248e-02,  3.4446068e-02]]],\n","      dtype=float32)>, <tf.Variable 'dense_1405/kernel:0' shape=(96, 3) dtype=float32, numpy=\n","array([[-0.23045617, -0.03990734,  0.10585323],\n","       [-0.14872025,  0.131401  , -0.1011977 ],\n","       [-0.17868337, -0.18931442, -0.12730047],\n","       [ 0.16463563,  0.2249121 ,  0.08685234],\n","       [-0.10208088,  0.16713667,  0.22408512],\n","       [ 0.15572473,  0.0411101 , -0.00163512],\n","       [-0.12349548,  0.00363542, -0.04473731],\n","       [-0.03700371,  0.16400984,  0.14513665],\n","       [ 0.13679111, -0.10609818,  0.02286062],\n","       [ 0.08447912, -0.1656496 ,  0.01620275],\n","       [ 0.20145997, -0.20404947,  0.05503294],\n","       [-0.00678703, -0.0852778 ,  0.12982017],\n","       [ 0.03635907, -0.03262679,  0.17479861],\n","       [ 0.05305734,  0.14331728,  0.1392022 ],\n","       [ 0.05020133,  0.22311643,  0.22539875],\n","       [ 0.00339842, -0.20510098,  0.16875413],\n","       [ 0.23948228, -0.12731357, -0.00718638],\n","       [-0.18948188,  0.13664249, -0.24131702],\n","       [-0.13352728,  0.21253443,  0.21090055],\n","       [-0.2267739 ,  0.0893316 ,  0.04547235],\n","       [-0.23916076, -0.03136903, -0.11444923],\n","       [-0.22129765,  0.13909987,  0.21785474],\n","       [ 0.18714127, -0.19498204, -0.01770312],\n","       [-0.01493983, -0.12283253,  0.23670727],\n","       [-0.21483138, -0.04948166,  0.10156918],\n","       [-0.14148144,  0.21304876, -0.10082223],\n","       [-0.22294492, -0.14123651, -0.07070714],\n","       [-0.08609922, -0.07208183,  0.15730175],\n","       [ 0.1437406 ,  0.2310561 ,  0.15631527],\n","       [ 0.05683461, -0.08411235, -0.18090415],\n","       [-0.09479065,  0.10162318, -0.03869002],\n","       [ 0.15024444,  0.07291818, -0.07708567],\n","       [-0.19436657, -0.01581661, -0.19463685],\n","       [-0.07333314,  0.16304338,  0.09329858],\n","       [-0.17787474,  0.1835573 ,  0.15783575],\n","       [-0.00531562,  0.18122444,  0.13434443],\n","       [ 0.21065128,  0.03530779, -0.09330116],\n","       [-0.12105672,  0.2061212 , -0.22311783],\n","       [ 0.05572623,  0.19218713, -0.19071183],\n","       [ 0.22470826,  0.02549031, -0.00415176],\n","       [ 0.23897898, -0.04714103, -0.18301338],\n","       [ 0.0711385 ,  0.21493074, -0.10474679],\n","       [ 0.18154666,  0.19277132, -0.0225392 ],\n","       [-0.177618  , -0.01321785, -0.217602  ],\n","       [ 0.16535506,  0.16125295,  0.15224949],\n","       [ 0.00993946,  0.09254289,  0.19571725],\n","       [ 0.07436728,  0.19132367,  0.08166662],\n","       [-0.08900337, -0.04054716, -0.01186752],\n","       [ 0.14631054,  0.08709326,  0.00910154],\n","       [ 0.23404223,  0.10536137,  0.14316809],\n","       [ 0.00692502,  0.11930734,  0.23554254],\n","       [-0.2218684 ,  0.02416649,  0.24589613],\n","       [ 0.22051924, -0.24165809, -0.07322133],\n","       [ 0.16566315,  0.14582297,  0.22968897],\n","       [-0.12237007, -0.06077491,  0.01626581],\n","       [-0.16463153, -0.07591347, -0.03214797],\n","       [ 0.21108782,  0.05767184, -0.07760999],\n","       [ 0.11847681,  0.20722878,  0.04115283],\n","       [ 0.1424084 ,  0.20468432, -0.1221856 ],\n","       [ 0.23341021,  0.02791449, -0.20008911],\n","       [-0.09492648, -0.09847023, -0.24340707],\n","       [-0.21055119, -0.2287991 ,  0.2298097 ],\n","       [ 0.03989461,  0.02728036,  0.06996742],\n","       [-0.17521581, -0.05737697,  0.01281783],\n","       [-0.0224987 ,  0.00514376,  0.02231294],\n","       [ 0.17204502,  0.00904113, -0.24552342],\n","       [ 0.03695753, -0.06208743, -0.09606099],\n","       [ 0.13742411, -0.02139388,  0.03516769],\n","       [-0.20785834,  0.09727362,  0.21358418],\n","       [-0.04301257, -0.11696348, -0.19766456],\n","       [ 0.03304058, -0.05544773,  0.04239258],\n","       [-0.23506334, -0.04311576,  0.22681111],\n","       [ 0.07831642,  0.09595662,  0.11494246],\n","       [ 0.11308423, -0.22125462, -0.07268915],\n","       [ 0.05007529, -0.23242714,  0.07192332],\n","       [ 0.01032308,  0.00717208, -0.04157215],\n","       [-0.21049532, -0.09555709,  0.01474503],\n","       [ 0.14231902,  0.0173057 , -0.1560137 ],\n","       [ 0.05099174,  0.17171708, -0.2204282 ],\n","       [-0.01851068, -0.1931156 ,  0.18065587],\n","       [ 0.1525824 , -0.07144994, -0.15217355],\n","       [ 0.03476152,  0.07427156,  0.09861806],\n","       [-0.03785485, -0.08125763,  0.17428234],\n","       [-0.1817258 , -0.2157527 ,  0.24100804],\n","       [ 0.00092033,  0.14553401, -0.15347692],\n","       [ 0.14769837, -0.18035823, -0.20973751],\n","       [ 0.24206966, -0.17500973, -0.11890005],\n","       [-0.10359749,  0.13553035, -0.07921745],\n","       [ 0.07862905,  0.14331308, -0.16519494],\n","       [ 0.03472355,  0.1024425 , -0.05823672],\n","       [ 0.17494929,  0.12374172, -0.23428436],\n","       [-0.23923612, -0.06963074,  0.17809936],\n","       [ 0.2400316 , -0.09312332, -0.1480098 ],\n","       [-0.07511535, -0.19493496, -0.10465716],\n","       [ 0.01495174, -0.0964347 ,  0.16326278],\n","       [ 0.11760905,  0.0793609 ,  0.0683724 ]], dtype=float32)>, <tf.Variable 'dense_1406/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[ 1.40599102e-01,  9.53044742e-02,  2.30191201e-02],\n","       [-9.29785147e-02,  9.82043445e-02, -1.28849655e-01],\n","       [ 1.18159354e-01,  3.21440399e-02, -3.11045349e-02],\n","       [-5.45308366e-02, -1.12149552e-01,  2.46548057e-02],\n","       [ 1.51928604e-01, -2.85629407e-02, -9.41489935e-02],\n","       [ 8.57204199e-03,  1.35754317e-01, -1.63475573e-02],\n","       [-5.03799021e-02, -7.34022781e-02,  1.35379493e-01],\n","       [-1.27952069e-01,  9.15600359e-02,  1.67225599e-02],\n","       [-6.06913865e-03, -3.53102386e-03, -8.76105055e-02],\n","       [ 6.02685511e-02,  5.99435866e-02,  1.40351027e-01],\n","       [-5.89981675e-03,  2.90782005e-02,  8.90310109e-02],\n","       [-9.92292017e-02,  1.22421563e-01, -2.48357803e-02],\n","       [ 3.03057134e-02,  5.86482137e-02,  1.05122685e-01],\n","       [-9.90605354e-02, -4.07473296e-02, -9.94210169e-02],\n","       [-7.46245384e-02,  6.31371737e-02, -1.51460782e-01],\n","       [ 4.60569561e-02, -1.19001240e-01,  1.22698903e-01],\n","       [-1.31303176e-01,  1.23721540e-01, -1.49729505e-01],\n","       [-8.45273435e-02, -1.49520442e-01,  2.51476020e-02],\n","       [-4.67752442e-02,  5.92205524e-02, -8.64640102e-02],\n","       [ 6.75779879e-02, -6.98923767e-02,  1.40081346e-01],\n","       [ 1.79395229e-02, -7.94937313e-02,  1.02934092e-02],\n","       [ 1.44319028e-01,  3.99838388e-03,  1.26994729e-01],\n","       [-1.23568155e-01, -7.59195611e-02,  7.58672357e-02],\n","       [-2.84647420e-02, -5.09948730e-02, -8.04860368e-02],\n","       [-8.35862458e-02,  5.58088422e-02, -1.26519978e-01],\n","       [ 1.04633898e-01,  5.37621379e-02,  4.28967923e-02],\n","       [ 1.06554121e-01,  1.26753747e-01,  8.76237452e-02],\n","       [-1.35534674e-01,  1.49273723e-01,  1.01415753e-01],\n","       [ 6.62059933e-02, -1.50016248e-01,  1.36328846e-01],\n","       [-4.90128100e-02,  3.08318287e-02,  4.76714224e-02],\n","       [ 3.61222178e-02,  3.44004184e-02, -7.05427304e-02],\n","       [ 6.57882839e-02,  1.02915406e-01,  1.04114711e-01],\n","       [ 1.07593030e-01, -2.35376805e-02, -7.43844584e-02],\n","       [ 1.00312948e-01, -5.51431999e-02,  4.00034636e-02],\n","       [ 1.51918262e-01, -1.13135211e-01, -3.46555561e-02],\n","       [ 6.99596554e-02, -2.46253461e-02, -1.14104360e-01],\n","       [ 4.12403047e-02, -3.54664847e-02,  1.86265260e-02],\n","       [-1.41967192e-01,  6.11642599e-02, -3.66550386e-02],\n","       [-6.38835877e-02, -7.81360790e-02,  1.88936144e-02],\n","       [-7.23445490e-02, -1.05946586e-01, -1.00635804e-01],\n","       [ 1.05552346e-01,  1.26469314e-01,  1.07717663e-01],\n","       [-1.24033988e-01, -4.31325585e-02,  5.32922149e-02],\n","       [ 5.93117774e-02,  1.50137842e-02, -5.85557520e-03],\n","       [-1.00423224e-01, -1.21103711e-01,  9.93862152e-02],\n","       [-2.30080783e-02,  7.97438622e-02,  9.70274806e-02],\n","       [ 1.10581249e-01,  1.53266937e-02, -9.58119035e-02],\n","       [-8.47667009e-02,  1.47602499e-01,  1.40321702e-01],\n","       [ 1.52011484e-01,  9.75754708e-02,  5.12617826e-02],\n","       [-1.38943478e-01, -9.81087983e-02,  1.87379718e-02],\n","       [ 1.38811171e-02, -1.20271549e-01,  1.18205994e-02],\n","       [-3.51018980e-02,  6.60689324e-02,  9.46886986e-02],\n","       [-1.30121052e-01,  2.66942382e-02, -2.98357531e-02],\n","       [-3.31851169e-02, -1.42625362e-01,  1.23768896e-01],\n","       [ 1.48430973e-01,  1.21067524e-01,  3.33064795e-03],\n","       [ 4.30907905e-02, -5.33268303e-02,  7.59569705e-02],\n","       [-1.02541514e-01,  4.78363484e-02,  5.93455285e-02],\n","       [ 3.40281278e-02,  4.49004471e-02,  1.50478423e-01],\n","       [ 6.61729425e-02, -4.23259065e-02,  1.02651894e-01],\n","       [-9.89124030e-02, -1.27202749e-01, -4.82656732e-02],\n","       [-7.47126117e-02, -5.05284965e-02,  1.22859329e-01],\n","       [-1.35110468e-01, -9.61144343e-02, -4.59832549e-02],\n","       [ 8.99241269e-02,  1.20564938e-01,  2.89499164e-02],\n","       [ 5.59790581e-02, -2.70390213e-02,  2.24347711e-02],\n","       [-1.65700465e-02,  7.93144107e-03, -3.17291617e-02],\n","       [ 1.58681124e-02,  5.07311672e-02, -1.48867220e-01],\n","       [-6.07272387e-02, -2.44316310e-02,  1.18970007e-01],\n","       [ 4.01179790e-02,  1.25691950e-01, -1.11072153e-01],\n","       [ 7.36884475e-02, -9.18495134e-02, -1.20218992e-02],\n","       [ 1.34931058e-01,  1.37709200e-01,  1.57161504e-02],\n","       [ 4.57543880e-02,  1.32344663e-02, -1.47987127e-01],\n","       [ 8.59930217e-02, -2.96304673e-02, -4.99631986e-02],\n","       [-1.17558599e-01, -4.09828126e-03, -1.36592224e-01],\n","       [ 9.66153145e-02, -7.56809637e-02,  1.06816739e-01],\n","       [-5.71490675e-02, -1.08030543e-01, -1.09197244e-01],\n","       [-2.57472992e-02, -7.03480840e-02, -1.49669111e-01],\n","       [-3.94906104e-03,  1.24416798e-01, -1.46954536e-01],\n","       [ 5.97075671e-02,  9.28355008e-02,  1.37792885e-01],\n","       [-1.51507735e-01,  8.69348198e-02,  2.65259743e-02],\n","       [-3.40860486e-02, -1.37546510e-02,  4.66243923e-02],\n","       [-4.54730764e-02,  8.89433026e-02,  7.89659619e-02],\n","       [-6.93780631e-02,  5.64549118e-02,  6.68248534e-03],\n","       [ 1.74761564e-02, -1.34344518e-01, -1.07217804e-01],\n","       [-7.07897842e-02,  3.58206630e-02,  1.36005729e-02],\n","       [ 3.44683826e-02,  7.34780431e-02, -2.28375345e-02],\n","       [-5.47716022e-03,  3.45135182e-02, -1.23970121e-01],\n","       [ 5.00583202e-02, -1.49606451e-01,  1.21858537e-01],\n","       [-9.24184024e-02,  6.34012371e-02,  1.12267882e-02],\n","       [-8.06431994e-02, -1.46294534e-01,  7.05704540e-02],\n","       [ 1.24272615e-01, -1.10139877e-01,  4.99297082e-02],\n","       [-1.18095085e-01,  6.70061857e-02, -7.38353059e-02],\n","       [ 1.40921772e-02,  1.12942964e-01, -6.69616461e-03],\n","       [ 2.26841718e-02,  9.10424292e-02, -3.16056386e-02],\n","       [ 9.21567976e-02,  4.32120711e-02,  1.29452497e-02],\n","       [ 4.30746377e-02,  9.68435407e-03, -1.45939738e-01],\n","       [ 2.58846581e-02, -5.90075031e-02,  5.12596667e-02],\n","       [ 1.13944173e-01,  4.56810743e-02,  1.09610200e-01],\n","       [-4.04518768e-02,  2.01807916e-02,  1.20993912e-01],\n","       [ 1.07299417e-01, -7.90259019e-02, -5.58304638e-02],\n","       [-7.72672296e-02, -7.20383152e-02,  1.40246749e-02],\n","       [-8.83974880e-02,  3.57052237e-02,  1.91763788e-02],\n","       [ 4.98256087e-03, -8.78206119e-02,  1.32271349e-02],\n","       [-1.50849611e-01, -5.76834530e-02, -1.23505443e-01],\n","       [-1.08927950e-01, -1.51264489e-01, -2.71982551e-02],\n","       [ 4.92357016e-02,  1.27181411e-01, -1.04667716e-01],\n","       [-8.91678482e-02,  1.43497497e-01,  3.44185233e-02],\n","       [ 5.32907248e-02, -1.05254568e-01, -1.07272416e-01],\n","       [-9.62489918e-02, -1.14090860e-01, -1.04163349e-01],\n","       [ 7.97142237e-02,  5.52822202e-02, -3.11879963e-02],\n","       [ 2.99795270e-02, -2.13577002e-02, -5.62659949e-02],\n","       [ 6.45981431e-02,  1.48350447e-01, -5.63969985e-02],\n","       [ 7.20652342e-02, -4.90604267e-02, -1.29718974e-01],\n","       [ 1.30754501e-01, -1.23567060e-01, -8.88000652e-02],\n","       [ 5.47698736e-02,  2.94006616e-02,  9.87173021e-02],\n","       [-3.43563557e-02, -1.23357028e-01, -4.04270142e-02],\n","       [ 7.03062415e-02,  1.40424520e-01, -8.59260038e-02],\n","       [-7.85688534e-02, -1.41050845e-01,  1.49840951e-01],\n","       [-3.30114439e-02,  8.00101161e-02, -1.02403618e-01],\n","       [ 1.18501455e-01,  1.22237623e-01, -9.56859440e-02],\n","       [ 1.13016158e-01, -1.26238823e-01,  1.16100878e-01],\n","       [ 1.00205243e-02,  3.33323777e-02, -7.29745179e-02],\n","       [ 2.01281458e-02,  4.20652926e-02, -4.59421352e-02],\n","       [-6.65736347e-02,  1.02261364e-01, -1.33299127e-01],\n","       [-1.31729811e-01,  2.44306922e-02, -4.56792340e-02],\n","       [ 1.12933844e-01,  1.98036581e-02, -6.19994253e-02],\n","       [ 1.35341138e-01,  5.52096963e-03, -4.34166938e-02],\n","       [ 9.50269401e-03,  8.01346153e-02, -5.80750033e-02],\n","       [ 4.38359380e-02, -2.69520283e-03, -1.22194901e-01],\n","       [ 9.01066959e-02, -1.44205302e-01, -5.16999587e-02],\n","       [ 1.35302216e-01,  6.56735450e-02,  1.49941146e-02],\n","       [ 1.21688485e-01, -6.97091892e-02,  3.01937759e-02],\n","       [ 1.25061452e-01, -2.97274664e-02, -9.20711607e-02],\n","       [ 1.28754973e-02,  1.26559347e-01, -6.20645285e-02],\n","       [-5.83320707e-02, -1.30092204e-01,  6.20466024e-02],\n","       [ 7.80947804e-02,  8.13686848e-03,  8.59649032e-02],\n","       [-1.22739546e-01, -8.80884230e-02,  1.04221702e-01],\n","       [-1.47500932e-01, -1.34204745e-01, -8.99754092e-02],\n","       [ 2.19613314e-03, -1.07709691e-01,  4.92724180e-02],\n","       [-1.10591948e-03, -1.01323828e-01,  1.49337292e-01],\n","       [ 1.42292798e-01, -5.85573465e-02, -7.15509281e-02],\n","       [-4.11334783e-02, -1.05589800e-01,  1.06315047e-01],\n","       [ 1.28707737e-01, -6.81106597e-02, -5.92590868e-02],\n","       [ 1.23650938e-01,  1.42704129e-01, -5.43627143e-02],\n","       [-1.14377826e-01, -1.01391032e-01, -1.43688783e-01],\n","       [-7.75720552e-02, -1.44620016e-01,  2.25292295e-02],\n","       [-4.13048267e-02,  1.70379728e-02,  8.27549249e-02],\n","       [ 1.07360303e-01, -1.12926699e-01,  4.65840101e-02],\n","       [ 9.13872421e-02, -1.24800533e-01,  4.15744185e-02],\n","       [-3.61416265e-02,  7.49268979e-02, -9.15519893e-02],\n","       [-5.30287623e-02, -1.03746027e-01,  3.36235166e-02],\n","       [ 3.03675979e-02, -1.15286887e-01,  3.33799571e-02],\n","       [ 9.68717635e-02, -1.07798442e-01, -1.51702926e-01],\n","       [-3.55258882e-02,  3.56798321e-02,  1.51806831e-01],\n","       [-7.79251382e-02,  5.84565699e-02,  1.07874155e-01],\n","       [ 8.96923989e-02,  7.71920383e-02,  7.41923898e-02],\n","       [ 2.61341035e-03, -1.96603090e-02, -1.25181749e-01],\n","       [ 5.67572713e-02, -7.82888904e-02,  9.27475691e-02],\n","       [-6.62087202e-02,  1.00057572e-02,  8.09675753e-02],\n","       [ 5.16054630e-02,  1.82410479e-02, -1.39909253e-01],\n","       [-9.60520953e-02, -1.29392117e-01, -4.29194719e-02],\n","       [ 1.19332612e-01,  9.64574963e-02,  9.20367241e-02],\n","       [ 1.43192708e-03, -5.04809618e-03,  1.08549505e-01],\n","       [ 5.04619777e-02, -9.96180251e-02,  1.19883180e-01],\n","       [ 7.60168135e-02,  5.22363335e-02,  1.35932475e-01],\n","       [ 4.61119264e-02, -2.69650221e-02,  1.12655312e-01],\n","       [ 1.11567229e-01, -1.21302240e-01,  9.05155540e-02],\n","       [ 6.39963299e-02,  5.85116893e-02,  1.43049419e-01],\n","       [ 1.05771810e-01, -1.08983874e-01, -4.94367704e-02],\n","       [ 5.33715338e-02, -1.01685077e-01, -1.21491551e-02],\n","       [-6.50572553e-02,  1.85495317e-02,  7.56001920e-02],\n","       [ 1.27615124e-01, -1.49493665e-01, -1.19693659e-01],\n","       [-1.33452669e-01,  2.74230987e-02,  9.33129489e-02],\n","       [ 1.33970827e-01, -8.77030417e-02, -6.00212514e-02],\n","       [ 3.93597037e-02, -7.16383830e-02, -9.17828530e-02],\n","       [ 1.32940739e-01, -1.13528468e-01, -1.31874278e-01],\n","       [ 1.30821526e-01, -6.10339642e-03, -3.80752459e-02],\n","       [-3.61605361e-02, -5.96019775e-02,  1.14378035e-01],\n","       [-9.05811787e-03, -8.75673220e-02,  5.34729213e-02],\n","       [ 1.19730055e-01,  8.87511671e-03,  5.28521836e-02],\n","       [-8.26722533e-02,  4.10703272e-02,  1.12062901e-01],\n","       [ 6.65798038e-02,  6.78451657e-02,  4.28722948e-02],\n","       [-1.20612442e-01,  6.82560354e-02, -6.39312342e-02],\n","       [-1.82204694e-02,  5.11593372e-02,  9.51006860e-02],\n","       [-2.79361010e-03,  1.01706147e-01,  8.19513947e-02],\n","       [ 1.74324661e-02, -4.42758948e-02,  4.39177603e-02],\n","       [-4.99953553e-02,  1.50012463e-01,  1.51797384e-02],\n","       [ 8.43766332e-03,  1.05879307e-01, -1.00806355e-04],\n","       [ 1.15918130e-01, -1.29128054e-01,  1.08566642e-01],\n","       [-9.85877290e-02, -9.32668597e-02, -1.35183141e-01],\n","       [ 1.02085382e-01, -1.31381080e-01, -5.56989536e-02],\n","       [-1.43239528e-01,  2.78490782e-02,  1.49088353e-01],\n","       [ 9.07475799e-02, -1.61929280e-02,  2.42278725e-02],\n","       [ 4.73361909e-02,  4.01699841e-02,  2.25279480e-02],\n","       [-1.26924813e-01, -3.42847258e-02, -1.45412683e-01],\n","       [ 2.99285054e-02,  4.30905074e-02,  9.35053825e-02],\n","       [-2.15261430e-02,  4.16693836e-02,  1.30307108e-01],\n","       [-1.24060109e-01,  6.52849972e-02,  1.38795227e-01],\n","       [ 1.13759637e-01,  9.39149261e-02, -8.61319005e-02],\n","       [ 1.41589046e-01, -5.64489588e-02,  1.17597818e-01],\n","       [-1.19755864e-02, -4.04920429e-02, -1.04863018e-01],\n","       [-1.46461740e-01,  1.35529876e-01,  7.62540251e-02],\n","       [-1.04197927e-01,  1.22368366e-01, -1.13331601e-01],\n","       [ 1.36902660e-01,  1.42285973e-01, -6.92832395e-02],\n","       [ 4.01791632e-02, -1.16615616e-01,  6.68799430e-02],\n","       [ 7.97735900e-02,  9.48750526e-02,  4.33915854e-02],\n","       [-1.22311130e-01, -7.52391219e-02, -1.98186338e-02],\n","       [ 4.74505723e-02,  8.76165330e-02,  2.59136111e-02],\n","       [ 2.32139081e-02,  1.44232959e-02, -6.65989593e-02],\n","       [-1.16748795e-01, -6.56691864e-02,  1.07968360e-01],\n","       [ 9.61008668e-02, -7.09077939e-02, -1.12436742e-01],\n","       [-9.06805992e-02, -3.57718766e-03,  7.31387585e-02],\n","       [ 1.58316791e-02, -1.28853783e-01, -9.06071514e-02],\n","       [-8.74954313e-02, -2.72908807e-03, -5.84619418e-02],\n","       [ 8.66089165e-02,  2.56647468e-02, -1.33189365e-01],\n","       [ 1.32512540e-01, -1.43482238e-02,  8.36424530e-02],\n","       [-1.01984635e-01,  4.12658155e-02,  5.26908040e-02],\n","       [-8.26507360e-02, -7.17626661e-02, -1.15937591e-02],\n","       [ 6.49643242e-02,  1.21362656e-01,  5.27963638e-02],\n","       [-6.58540726e-02,  1.37680560e-01,  7.96839893e-02],\n","       [ 4.10619378e-03,  1.52727813e-02,  5.32642007e-03],\n","       [-8.04882869e-02,  1.35039747e-01, -8.55993405e-02],\n","       [ 2.42399573e-02,  1.01340473e-01, -4.53606918e-02],\n","       [-1.25571340e-01, -1.08713672e-01,  1.31069064e-01],\n","       [ 1.34283334e-01,  7.08833039e-02, -3.08337510e-02],\n","       [-1.27421767e-02, -8.53817537e-02, -9.43938643e-02],\n","       [ 5.31241596e-02, -8.04473907e-02, -9.17514265e-02],\n","       [ 3.99687737e-02,  1.11397207e-02,  1.04956359e-01],\n","       [ 1.04918152e-01, -8.83951783e-04, -3.59981805e-02],\n","       [ 9.16627795e-02, -8.15016329e-02, -4.21761796e-02],\n","       [ 5.35533726e-02,  4.72235084e-02, -6.52913898e-02],\n","       [ 7.37248808e-02, -5.24876267e-02,  4.45659012e-02],\n","       [ 1.40130252e-01, -1.24169052e-01, -1.37407437e-01],\n","       [-4.98530641e-02,  8.96510631e-02,  1.82598829e-03],\n","       [ 6.81201220e-02,  2.11903304e-02, -9.88671854e-02],\n","       [-1.09743424e-01,  6.21984303e-02,  6.21804297e-02],\n","       [ 5.73861599e-03, -1.45461857e-01,  6.94090128e-02],\n","       [ 9.81337428e-02,  1.01086766e-01,  1.20130122e-01],\n","       [-1.44809619e-01, -1.01808757e-02, -1.47896841e-01],\n","       [-7.53388032e-02,  4.51425612e-02, -5.75920418e-02],\n","       [ 1.25756860e-02, -2.51747072e-02,  9.19928551e-02],\n","       [-1.35442212e-01, -1.21843733e-01, -1.10306293e-01],\n","       [-9.27394778e-02, -8.00602660e-02, -1.06000185e-01],\n","       [-1.47207439e-01, -1.40944526e-01,  5.95863760e-02],\n","       [ 5.82288653e-02,  3.40438783e-02,  2.67439634e-02],\n","       [-1.28376558e-01, -8.33728388e-02, -5.22676855e-02],\n","       [ 1.18965983e-01,  6.07805848e-02,  2.19333321e-02],\n","       [-1.67121142e-02,  8.15282017e-02, -6.20126724e-03],\n","       [ 1.54350549e-02,  2.85065919e-02, -4.87589017e-02],\n","       [ 5.62140346e-02, -1.43292725e-01, -4.19414341e-02],\n","       [ 1.31128043e-01, -9.02187526e-02, -4.21362296e-02],\n","       [ 1.26635224e-01, -3.32877785e-02, -1.46460980e-01],\n","       [ 8.90291929e-02,  6.75637275e-02,  1.05764270e-02],\n","       [-1.10963032e-01,  2.89265811e-02, -1.41303554e-01],\n","       [-1.17478475e-01, -8.28391835e-02, -2.52095461e-02],\n","       [ 1.47303909e-01, -1.07196063e-01, -4.65627015e-02],\n","       [ 1.62528902e-02, -6.32358044e-02,  9.41740721e-02],\n","       [-1.36558935e-01, -1.27798200e-01, -6.03884161e-02]], dtype=float32)>, <tf.Variable 'dense_1407/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[-0.11998349,  0.02030984, -0.03605686],\n","       [ 0.14839944, -0.07154512, -0.01479152],\n","       [-0.10451959,  0.1258415 , -0.08049913],\n","       [ 0.12219235,  0.00830965,  0.01907836],\n","       [ 0.11791405, -0.08872288, -0.04309566],\n","       [ 0.11769682,  0.10283864, -0.14307101],\n","       [ 0.12398195,  0.04496813,  0.03800866],\n","       [-0.08692974,  0.14681694, -0.07841408],\n","       [ 0.13622314,  0.05765089,  0.13640398],\n","       [ 0.02039148, -0.09526779,  0.00061479],\n","       [-0.09281148, -0.05510521,  0.14492646],\n","       [-0.02680978, -0.05484016, -0.08372777],\n","       [-0.14482613,  0.02435097, -0.11974943],\n","       [ 0.07235968, -0.14978379,  0.02193518],\n","       [ 0.02259897, -0.06838514, -0.06724003],\n","       [-0.0776541 ,  0.14815837, -0.13321668],\n","       [-0.01109506, -0.01131377,  0.02679302],\n","       [ 0.10076636, -0.1314513 , -0.02543558],\n","       [-0.10545604,  0.08960214,  0.10332528],\n","       [ 0.0950841 ,  0.08351077,  0.11258918],\n","       [-0.02030498, -0.02571769, -0.09535162],\n","       [-0.02019209,  0.12567213,  0.00125016],\n","       [ 0.14431262,  0.11699632, -0.01135877],\n","       [ 0.00213927,  0.06430802,  0.01943311],\n","       [-0.08312985, -0.10034695,  0.05882657],\n","       [-0.13003418,  0.03444166,  0.04784763],\n","       [-0.0519063 ,  0.04369974, -0.13641396],\n","       [-0.04716124, -0.14305152, -0.04251965],\n","       [ 0.12077588,  0.14796448,  0.0408337 ],\n","       [ 0.10645404, -0.105869  ,  0.14810616],\n","       [ 0.03272833, -0.04499055,  0.13609883],\n","       [ 0.06715414,  0.13357297,  0.0578305 ],\n","       [ 0.12973875, -0.03654055,  0.08474424],\n","       [-0.00628135,  0.10560852, -0.1358561 ],\n","       [-0.15094382, -0.00095823,  0.14935365],\n","       [ 0.06743653, -0.03972346, -0.12431648],\n","       [ 0.1311861 ,  0.02489257, -0.01871385],\n","       [-0.06020563,  0.07287933, -0.1342808 ],\n","       [-0.00840428, -0.08342753, -0.01314273],\n","       [-0.05494543,  0.0703515 ,  0.12742648],\n","       [ 0.11267266,  0.03543924,  0.08084217],\n","       [ 0.14775774, -0.06522683,  0.0499595 ],\n","       [-0.14553995, -0.13395159, -0.15185116],\n","       [-0.1059406 , -0.02704109, -0.07787146],\n","       [-0.00294159, -0.10979623, -0.10981959],\n","       [-0.10893437,  0.01501466, -0.10932459],\n","       [-0.11213094, -0.08746437, -0.12192629],\n","       [-0.03240931, -0.00535575,  0.09015982],\n","       [-0.02229404, -0.09338512, -0.1422599 ],\n","       [ 0.09135585,  0.11396185, -0.11261128],\n","       [-0.01693921, -0.13935956,  0.09729674],\n","       [-0.11252818, -0.03716546, -0.14701068],\n","       [ 0.02783957,  0.00853296, -0.05156841],\n","       [ 0.06393504, -0.05631248, -0.07774311],\n","       [-0.12216209,  0.03048861,  0.0295576 ],\n","       [ 0.12954584,  0.07338403,  0.00866008],\n","       [-0.0690847 ,  0.09772135, -0.09080724],\n","       [ 0.14558819, -0.08662807, -0.15074433],\n","       [-0.1073131 ,  0.12056047,  0.09021382],\n","       [-0.01449007, -0.12373497,  0.12816873],\n","       [-0.01760659,  0.01610152, -0.1331342 ],\n","       [ 0.03613059, -0.08231957, -0.09593441],\n","       [-0.10240209, -0.0634584 ,  0.12269512],\n","       [-0.00699659, -0.09267341, -0.05257675],\n","       [ 0.0484117 , -0.09595749, -0.09676559],\n","       [ 0.03171316, -0.02004094,  0.08501691],\n","       [ 0.04815307, -0.053959  ,  0.15092847],\n","       [-0.04374434, -0.07708423, -0.13952743],\n","       [ 0.02320582,  0.04499058,  0.06015033],\n","       [ 0.13251984,  0.03582107, -0.14125443],\n","       [ 0.06295316, -0.02923267,  0.1107724 ],\n","       [ 0.02384946,  0.06467025,  0.15109971],\n","       [ 0.09879827, -0.06917659,  0.0837941 ],\n","       [ 0.08802408,  0.01133437,  0.03008084],\n","       [-0.08454154,  0.05850726,  0.07932873],\n","       [ 0.04325996,  0.08329068,  0.05422841],\n","       [-0.08625078,  0.13619468, -0.09961574],\n","       [-0.13347267,  0.1175732 , -0.13958132],\n","       [ 0.04199021, -0.10370883, -0.13409863],\n","       [-0.05697928,  0.10098377, -0.00301602],\n","       [-0.10748503, -0.03935749, -0.02391899],\n","       [ 0.07439052,  0.09446931, -0.10871807],\n","       [ 0.07508914, -0.01244168,  0.00276706],\n","       [-0.11557955,  0.0654106 , -0.06833576],\n","       [-0.00212957, -0.05871668,  0.05201596],\n","       [ 0.07146913, -0.14552681,  0.14635068],\n","       [ 0.07544237,  0.10699251,  0.03972735],\n","       [-0.09525538,  0.07952683,  0.14570764],\n","       [ 0.02063157,  0.10724407, -0.04414645],\n","       [-0.1132026 , -0.04608206, -0.03962069],\n","       [-0.12123097,  0.05608006, -0.0175627 ],\n","       [-0.05473906,  0.14164591,  0.01484489],\n","       [-0.03446406, -0.15081765, -0.11023702],\n","       [-0.11174022, -0.00941345, -0.11746328],\n","       [-0.06015523,  0.13347611, -0.07731339],\n","       [ 0.03723656, -0.01214539,  0.05435872],\n","       [ 0.07602958,  0.10549948,  0.00400607],\n","       [ 0.08634458, -0.0629578 , -0.01248178],\n","       [ 0.0993273 , -0.08603755, -0.00260477],\n","       [ 0.072382  ,  0.0736689 , -0.1123369 ],\n","       [ 0.10056326,  0.1119394 ,  0.09041138],\n","       [ 0.01945572, -0.1252889 ,  0.09001079],\n","       [-0.03416856, -0.12616803, -0.12933487],\n","       [-0.07448614,  0.10553682,  0.11382604],\n","       [-0.07526365, -0.12030664,  0.00981942],\n","       [ 0.11918968, -0.12811735, -0.11784118],\n","       [ 0.0275775 , -0.0327632 ,  0.03227215],\n","       [ 0.08425051,  0.1362989 , -0.11336854],\n","       [ 0.04424432,  0.04685389,  0.0543641 ],\n","       [ 0.0822659 , -0.05379542,  0.10210365],\n","       [ 0.12262636,  0.10452172, -0.00558251],\n","       [ 0.08780943,  0.03170645,  0.03690509],\n","       [ 0.09007923,  0.12610981,  0.06867769],\n","       [-0.10079855,  0.11753955, -0.00452332],\n","       [-0.05407172,  0.0553806 , -0.0721769 ],\n","       [ 0.11608747, -0.09104638,  0.11617383],\n","       [-0.06568529, -0.04754525, -0.12986071],\n","       [-0.03104197,  0.01848769, -0.13505527],\n","       [-0.07019898, -0.02681312,  0.12182784],\n","       [ 0.04854633,  0.06870466, -0.01650371],\n","       [ 0.13468969,  0.11889815, -0.01456563],\n","       [-0.02995732,  0.03137553,  0.10251072],\n","       [ 0.088936  ,  0.08425522, -0.00300586],\n","       [-0.08967683, -0.06215503,  0.08850148],\n","       [-0.07507045, -0.10432552, -0.05642657],\n","       [ 0.10895741, -0.12648772, -0.00784019],\n","       [-0.00993931,  0.14272907, -0.08658446],\n","       [ 0.10829857, -0.01721121,  0.06236891],\n","       [-0.03603636,  0.00296533, -0.0931052 ],\n","       [ 0.03406115, -0.01109448,  0.02671939],\n","       [ 0.09329811, -0.00429572,  0.03162712],\n","       [ 0.06348899, -0.10698763,  0.02901371],\n","       [ 0.10346001,  0.12996098, -0.08296873],\n","       [ 0.0280086 ,  0.14170635,  0.12586305],\n","       [-0.04954683, -0.06762102, -0.05715746],\n","       [-0.01225297,  0.08747374, -0.10167295],\n","       [ 0.08125421,  0.06826586,  0.11993152],\n","       [-0.04459421, -0.11604223, -0.07983408],\n","       [-0.04985438, -0.02608539,  0.03803344],\n","       [-0.07332031,  0.12794238,  0.09829158],\n","       [ 0.10841513, -0.06998172, -0.10554361],\n","       [-0.05933682, -0.10369933,  0.04208735],\n","       [-0.0950939 , -0.08549588,  0.14059237],\n","       [-0.01374696, -0.14049578, -0.06063946],\n","       [-0.01257765,  0.14142248, -0.01923876],\n","       [-0.13870089, -0.13888586,  0.09560418],\n","       [-0.08092941, -0.05808686,  0.05077374],\n","       [-0.05472284,  0.05200689,  0.1450508 ],\n","       [ 0.1417352 ,  0.07238853,  0.07038967],\n","       [-0.1237538 , -0.09050038, -0.0503075 ],\n","       [-0.09733967,  0.13311177, -0.1272701 ],\n","       [ 0.01753382, -0.14825453, -0.14727108],\n","       [ 0.05486777,  0.02773775,  0.14729583],\n","       [-0.13532369, -0.00685123, -0.0087913 ],\n","       [ 0.04698046,  0.13364583,  0.08462253],\n","       [-0.03280326, -0.07798523,  0.08131453],\n","       [ 0.08562692,  0.1480459 , -0.01217598],\n","       [ 0.04687808,  0.03244713,  0.05833498],\n","       [-0.14089085,  0.0511404 , -0.11920972],\n","       [-0.10709732, -0.1265873 , -0.13961197],\n","       [-0.09621622,  0.0854122 ,  0.13020763],\n","       [ 0.04689191,  0.07546584, -0.12722847],\n","       [-0.10894845,  0.0503197 ,  0.05476722],\n","       [ 0.1427173 ,  0.14841017, -0.1327842 ],\n","       [ 0.0393506 , -0.13621417,  0.13244194],\n","       [-0.00878905, -0.02137776,  0.11272392],\n","       [ 0.00032155, -0.11135985, -0.11699537],\n","       [-0.01244636, -0.12473994,  0.02968758],\n","       [-0.05861544,  0.0334633 ,  0.01557222],\n","       [-0.10773327, -0.01048625,  0.02565585],\n","       [-0.08939251,  0.01114444,  0.04162954],\n","       [-0.00285462, -0.07300674,  0.12824067],\n","       [-0.12935646, -0.01789138, -0.09097903],\n","       [ 0.14518258, -0.06397877,  0.14576367],\n","       [ 0.04637767, -0.03235437,  0.04529861],\n","       [ 0.06874922,  0.10532475,  0.07583544],\n","       [-0.12249406, -0.00632083,  0.10765064],\n","       [ 0.02603118, -0.12155717, -0.03461187],\n","       [-0.12585047,  0.04787627, -0.07502901],\n","       [ 0.11368945,  0.07568666,  0.04494368],\n","       [ 0.10328326,  0.09938017,  0.1141142 ],\n","       [ 0.11699855,  0.11269078, -0.01032397],\n","       [ 0.08950715,  0.1514506 , -0.11245695],\n","       [-0.07105951, -0.09944808,  0.0899711 ],\n","       [-0.08828967, -0.06268913,  0.11309528],\n","       [ 0.08196212, -0.03569899,  0.01083875],\n","       [ 0.07168919, -0.09554254,  0.05494241],\n","       [-0.06881839,  0.14956257, -0.10318614],\n","       [ 0.14743873, -0.11528667, -0.03980514],\n","       [ 0.01576993,  0.06293672, -0.06381369],\n","       [-0.03214405,  0.00280127,  0.05509798],\n","       [ 0.08620887, -0.09063981,  0.07804765],\n","       [-0.03730673,  0.03739387,  0.09728956],\n","       [ 0.0974513 ,  0.10273707, -0.00272924],\n","       [ 0.12336639, -0.0445605 ,  0.08583945],\n","       [ 0.15082607,  0.05673978,  0.02420004],\n","       [ 0.09284642,  0.14273727,  0.02666344],\n","       [-0.07291134,  0.02552837,  0.00178723],\n","       [-0.10711329, -0.03409762, -0.08225643],\n","       [-0.06926778, -0.14660327, -0.03638686],\n","       [-0.0782202 , -0.00020462,  0.15218282],\n","       [-0.10280032, -0.11900636, -0.08404475],\n","       [-0.07588298, -0.12329566,  0.09585987],\n","       [-0.01381606, -0.12511759, -0.14789176],\n","       [-0.02083823, -0.00852878, -0.0344428 ],\n","       [-0.13396858,  0.1110521 , -0.00073534],\n","       [ 0.0469532 ,  0.01577221, -0.13594513],\n","       [-0.08567333,  0.12983781, -0.13666153],\n","       [ 0.02052601, -0.03007337,  0.07182284],\n","       [ 0.01941392, -0.14389962,  0.14429969],\n","       [-0.06584057, -0.03464594,  0.13857445],\n","       [-0.15127882,  0.14352936, -0.03274229],\n","       [-0.00804086, -0.10645894, -0.096347  ],\n","       [ 0.03236726, -0.03376715, -0.12294389],\n","       [ 0.09950912,  0.06756169, -0.10143182],\n","       [ 0.10039237,  0.05678372, -0.0421339 ],\n","       [-0.02269223,  0.1220479 , -0.14068165],\n","       [-0.0033624 , -0.07441033,  0.0624796 ],\n","       [ 0.02949522,  0.1347599 ,  0.03266297],\n","       [-0.07080651,  0.02368355, -0.01408981],\n","       [-0.09260435,  0.00764184,  0.12589052],\n","       [ 0.00300217, -0.08314738, -0.14981739],\n","       [-0.07295503,  0.13760799,  0.04946057],\n","       [ 0.07293028, -0.14542176, -0.09973346],\n","       [ 0.01712145, -0.07085238, -0.03622941],\n","       [ 0.07432055, -0.08267462,  0.09169783],\n","       [ 0.04622686, -0.1162495 ,  0.01069981],\n","       [-0.14671844, -0.00880411, -0.1375111 ],\n","       [-0.09730537,  0.00828758,  0.09371959],\n","       [ 0.06866485,  0.0031344 ,  0.02384035],\n","       [ 0.08669814,  0.03630696,  0.01799494],\n","       [ 0.01534975,  0.09582268, -0.08898833],\n","       [ 0.00286205,  0.00618051, -0.02146526],\n","       [ 0.10373735,  0.02490117, -0.14751291],\n","       [ 0.1238451 , -0.01897389, -0.05123942],\n","       [-0.11471723,  0.09186563, -0.13075326],\n","       [ 0.1458849 , -0.02968878,  0.03044136],\n","       [-0.12333899,  0.05641805, -0.08226859],\n","       [-0.07681802,  0.14330837,  0.12874165],\n","       [ 0.0897257 ,  0.10386196,  0.14029649],\n","       [ 0.1253955 ,  0.10279685, -0.06145765],\n","       [-0.10488069, -0.13252895, -0.04345371],\n","       [-0.07357389, -0.06195661, -0.06054453],\n","       [ 0.08288302,  0.10617593, -0.05922904],\n","       [ 0.01955526, -0.08451947,  0.04806094],\n","       [-0.14415236, -0.03989565,  0.1419557 ],\n","       [-0.03401633, -0.0781244 , -0.08437769],\n","       [ 0.02419776,  0.13590121,  0.04057805],\n","       [-0.11283783, -0.04180282,  0.06290075],\n","       [-0.10873283,  0.0374545 , -0.02849817],\n","       [ 0.08863224,  0.08061482, -0.13286988],\n","       [ 0.0645382 ,  0.09253202,  0.02331628],\n","       [ 0.06111893, -0.0917986 ,  0.07423563],\n","       [ 0.00071223,  0.1398493 ,  0.05824836],\n","       [ 0.00538604, -0.13417274, -0.05017171],\n","       [ 0.10638201, -0.12662645, -0.15218277]], dtype=float32)>, <tf.Variable 'dense_1408/kernel:0' shape=(256, 3) dtype=float32, numpy=\n","array([[ 0.00873403, -0.09078391, -0.01012535],\n","       [ 0.1312801 ,  0.04135506, -0.13774371],\n","       [-0.09470344,  0.13539124,  0.0771395 ],\n","       [ 0.08289801,  0.1061306 ,  0.0423574 ],\n","       [ 0.09425738,  0.04881105,  0.13095465],\n","       [ 0.12781754, -0.10541551,  0.11858767],\n","       [ 0.02980985,  0.14005885,  0.04439215],\n","       [-0.14859629, -0.07165468, -0.03891267],\n","       [-0.11491112, -0.14926861,  0.01762991],\n","       [ 0.03502522, -0.0973986 ,  0.07108223],\n","       [ 0.06752427,  0.02601786, -0.14169833],\n","       [-0.03597441, -0.07137028,  0.12735164],\n","       [-0.06430265, -0.08680545,  0.13997924],\n","       [ 0.03054591, -0.02107087, -0.1332799 ],\n","       [ 0.11535642, -0.10753061,  0.02646625],\n","       [ 0.12317842,  0.08640718, -0.072538  ],\n","       [-0.13311653,  0.04293646,  0.0039908 ],\n","       [-0.14992839,  0.06990968, -0.07519532],\n","       [-0.05337209,  0.00161809,  0.03611605],\n","       [-0.07076264,  0.11674961, -0.13405022],\n","       [ 0.08303612,  0.06544235, -0.07103244],\n","       [ 0.06923403, -0.01750465, -0.14836949],\n","       [ 0.1147477 , -0.07270519, -0.05796635],\n","       [-0.04316845, -0.12076794,  0.12969667],\n","       [ 0.14502376,  0.06352313, -0.14659572],\n","       [-0.12550227,  0.15134022,  0.14418507],\n","       [-0.0445772 ,  0.03363249, -0.11540228],\n","       [ 0.02528448, -0.10864255, -0.10885999],\n","       [-0.1288965 ,  0.03964922, -0.00201233],\n","       [ 0.04035303, -0.01040663,  0.06835364],\n","       [ 0.1344319 ,  0.02351652,  0.12329605],\n","       [ 0.02766848,  0.13598254,  0.07044262],\n","       [ 0.03256121,  0.12350404, -0.0900785 ],\n","       [ 0.08971754, -0.12164321,  0.14203733],\n","       [-0.027135  , -0.06427662,  0.1222882 ],\n","       [ 0.02791876,  0.04604045, -0.05471486],\n","       [-0.12235794,  0.09595142,  0.10624674],\n","       [-0.07822931,  0.11295113,  0.13253537],\n","       [-0.13182758,  0.06518343,  0.09943944],\n","       [ 0.06542559,  0.1080876 ,  0.04368363],\n","       [-0.07311665, -0.01538828,  0.08488867],\n","       [-0.13658942, -0.13769506,  0.02589063],\n","       [-0.05764549, -0.059886  , -0.11074352],\n","       [ 0.01512882, -0.06363922,  0.03421125],\n","       [ 0.0370291 , -0.11571084,  0.01991193],\n","       [ 0.04830457, -0.09187154, -0.11008714],\n","       [-0.11578229,  0.06697516,  0.0657827 ],\n","       [ 0.03747033, -0.10273461,  0.01796584],\n","       [-0.03085077, -0.0949727 , -0.03752341],\n","       [-0.14441907,  0.07027714,  0.08517019],\n","       [-0.00626147,  0.03593497, -0.11333959],\n","       [-0.00301555, -0.0099425 ,  0.0204764 ],\n","       [-0.06465344, -0.1005298 , -0.05357087],\n","       [-0.0071563 ,  0.13704526,  0.12416857],\n","       [ 0.08203188, -0.00668582, -0.0420421 ],\n","       [ 0.06145431,  0.0414229 , -0.08548623],\n","       [-0.01737049, -0.00947921, -0.08103155],\n","       [-0.00029488,  0.12647071,  0.03801849],\n","       [-0.09481731,  0.15095103,  0.05620943],\n","       [-0.07673898, -0.05016133, -0.11850221],\n","       [ 0.15218902, -0.10848495, -0.00243719],\n","       [-0.13468516,  0.08642605, -0.08990435],\n","       [-0.01269776,  0.0999133 ,  0.12990692],\n","       [ 0.09060051,  0.09705836,  0.07273842],\n","       [ 0.11478522, -0.08983798,  0.01386327],\n","       [ 0.01959012,  0.05038898,  0.05694844],\n","       [-0.03743567, -0.06525412,  0.14492983],\n","       [-0.00930235, -0.03037169,  0.0548656 ],\n","       [-0.08203848,  0.1275697 , -0.03551638],\n","       [-0.10939632,  0.11377758,  0.07943527],\n","       [-0.07033629, -0.0452773 , -0.02621216],\n","       [ 0.06251454,  0.05133195, -0.01372261],\n","       [-0.07448959, -0.09809522,  0.01472899],\n","       [-0.1157987 ,  0.04739462,  0.11234635],\n","       [-0.10210867, -0.01368099, -0.04299369],\n","       [ 0.09181751,  0.12969068,  0.08175075],\n","       [ 0.09923086,  0.03190632, -0.12347663],\n","       [ 0.08758268,  0.03073312,  0.14235514],\n","       [ 0.02095664, -0.0953403 ,  0.11339071],\n","       [-0.01178007, -0.08557397,  0.05292439],\n","       [-0.06508269,  0.07259138,  0.02993758],\n","       [-0.12432621, -0.09145427, -0.15083934],\n","       [-0.10847196, -0.0039265 , -0.07881997],\n","       [ 0.01459585,  0.03097542,  0.01094054],\n","       [ 0.03265455, -0.15028435,  0.14107901],\n","       [ 0.1102384 ,  0.09390324, -0.00576162],\n","       [-0.01102448,  0.0856861 ,  0.12588894],\n","       [-0.06688092, -0.11414011, -0.14431326],\n","       [ 0.03864484,  0.02952258, -0.00888336],\n","       [-0.05720303,  0.04569831,  0.03017932],\n","       [ 0.08872195,  0.08028638,  0.12615424],\n","       [ 0.10396329,  0.0542987 ,  0.04808554],\n","       [-0.09215336,  0.0909992 ,  0.05234849],\n","       [ 0.1017946 ,  0.06334136,  0.11904377],\n","       [-0.10862978,  0.02439782,  0.01040263],\n","       [-0.02147211,  0.09472068, -0.114443  ],\n","       [ 0.02781083, -0.10267045,  0.08332752],\n","       [ 0.10216936,  0.10865358, -0.01760662],\n","       [-0.05046441, -0.14474219,  0.00526361],\n","       [-0.11981341, -0.12530941,  0.10073897],\n","       [-0.10987392, -0.02289908, -0.00517333],\n","       [-0.13090883, -0.02712519,  0.13116172],\n","       [-0.14443418,  0.12073371, -0.02008289],\n","       [ 0.07343116, -0.02079636, -0.06274853],\n","       [ 0.10154554, -0.10027452,  0.05834757],\n","       [-0.04394073,  0.03557059, -0.09802276],\n","       [ 0.06237584, -0.13495035,  0.03971511],\n","       [ 0.12557998, -0.12051758,  0.1423156 ],\n","       [ 0.00747798,  0.14757279,  0.03818861],\n","       [ 0.00744842, -0.05793046,  0.10399574],\n","       [ 0.1077964 , -0.00355512, -0.10707349],\n","       [-0.03313754,  0.07512239,  0.01076388],\n","       [ 0.12950262,  0.11909306,  0.04701518],\n","       [ 0.04607445,  0.11200267,  0.05089632],\n","       [-0.04578726,  0.09927931,  0.0177108 ],\n","       [ 0.0965979 ,  0.01221244,  0.06973064],\n","       [ 0.07473373,  0.12752911,  0.05295719],\n","       [ 0.13406238, -0.13407367,  0.08337353],\n","       [-0.00823355,  0.11875996,  0.04503559],\n","       [ 0.02449173,  0.01679166, -0.05359548],\n","       [ 0.06599516,  0.09573396, -0.15175119],\n","       [ 0.14288041,  0.03132713, -0.01988976],\n","       [ 0.14415163,  0.0512666 ,  0.03547494],\n","       [ 0.02075252,  0.00344677, -0.09418988],\n","       [-0.1480557 , -0.04576033,  0.03979248],\n","       [-0.09152324, -0.03787602,  0.08095343],\n","       [-0.14354421,  0.11386904, -0.11588456],\n","       [ 0.11740732, -0.03534126, -0.11540863],\n","       [ 0.04897514, -0.06325699,  0.14311427],\n","       [-0.08237756, -0.12086156,  0.0778648 ],\n","       [ 0.04414268, -0.12992814,  0.09620094],\n","       [-0.1219461 ,  0.13541713,  0.02675489],\n","       [ 0.02865329, -0.03793993, -0.07979224],\n","       [-0.02957375,  0.06485775,  0.07401729],\n","       [-0.09180935,  0.02939986,  0.14410695],\n","       [ 0.04724684,  0.05173729, -0.09296045],\n","       [ 0.12031761,  0.13168406, -0.05496695],\n","       [ 0.07106115,  0.00535984, -0.00852092],\n","       [ 0.01359633, -0.12859099, -0.11746229],\n","       [-0.12894116, -0.12582281, -0.09952596],\n","       [-0.01170981,  0.01191346,  0.00982708],\n","       [-0.13311043,  0.1320017 , -0.0265145 ],\n","       [-0.09264161,  0.05039214, -0.07530668],\n","       [-0.06199119, -0.0120571 ,  0.02679029],\n","       [-0.07518469,  0.15036595,  0.00857368],\n","       [-0.00644454,  0.04472801,  0.07478043],\n","       [ 0.12817788,  0.05169828,  0.01309526],\n","       [-0.00624999,  0.06440789,  0.13824844],\n","       [ 0.02708431,  0.09604502, -0.08109792],\n","       [-0.05811289,  0.01543005,  0.085135  ],\n","       [ 0.1208317 , -0.12923253, -0.04514159],\n","       [ 0.06635898,  0.06438248,  0.1441603 ],\n","       [ 0.09519942,  0.10100979, -0.13510448],\n","       [ 0.00564936, -0.03616319,  0.13065234],\n","       [ 0.04309224,  0.10101905, -0.0142567 ],\n","       [-0.07574527,  0.11076552, -0.08515307],\n","       [ 0.08538273,  0.08030745,  0.10811651],\n","       [-0.11053933, -0.14154506,  0.03307335],\n","       [ 0.10810804, -0.03356498, -0.11120258],\n","       [ 0.00212641, -0.10147174, -0.10457155],\n","       [ 0.03652589, -0.01950115,  0.06904352],\n","       [-0.11258319, -0.04042049,  0.00083056],\n","       [-0.00018778,  0.13915402, -0.01824664],\n","       [ 0.06956436, -0.04638493,  0.10550132],\n","       [ 0.13858443, -0.1483574 ,  0.06394371],\n","       [-0.09913866, -0.13386759, -0.11798811],\n","       [-0.03817424,  0.0201207 ,  0.1248039 ],\n","       [-0.11714321, -0.04479242, -0.07192688],\n","       [-0.01353137, -0.0960457 ,  0.02920288],\n","       [ 0.04769033, -0.14873329, -0.04655886],\n","       [ 0.0426303 , -0.13202588, -0.04303367],\n","       [ 0.14322996, -0.0530706 , -0.13788858],\n","       [ 0.13632184, -0.08693434, -0.04965824],\n","       [-0.09161662, -0.11102836, -0.10245907],\n","       [-0.13473484, -0.04181029, -0.09046464],\n","       [ 0.07254359,  0.06906275,  0.00467233],\n","       [ 0.06476757,  0.0388242 ,  0.07150303],\n","       [-0.12255509, -0.0253567 , -0.03403811],\n","       [ 0.05058703, -0.0928064 ,  0.10250485],\n","       [ 0.081468  , -0.00034223, -0.06860033],\n","       [ 0.10545263,  0.11615738, -0.01163608],\n","       [ 0.04300672, -0.15024918,  0.01590049],\n","       [ 0.10726106, -0.09644073, -0.10936338],\n","       [-0.01268332, -0.10541344, -0.15143509],\n","       [-0.07687989,  0.04715246, -0.01770452],\n","       [-0.07555896, -0.10453519,  0.12731636],\n","       [-0.11937991,  0.04588971, -0.12879845],\n","       [ 0.10477674,  0.03856714, -0.03455587],\n","       [-0.12711097,  0.09714712,  0.15150344],\n","       [ 0.11359745,  0.00457497, -0.14024688],\n","       [-0.08978838, -0.07581312,  0.13274828],\n","       [-0.02559815,  0.06325692,  0.14038274],\n","       [-0.04278441,  0.04022975,  0.15166941],\n","       [ 0.08641224,  0.01779948, -0.05574171],\n","       [-0.13549791,  0.10533756,  0.14429605],\n","       [ 0.01391748,  0.12707248, -0.08980557],\n","       [ 0.02591081, -0.02622169, -0.0180424 ],\n","       [ 0.10786274, -0.09016676,  0.02210364],\n","       [-0.07835962,  0.0305483 , -0.12606409],\n","       [-0.01421678,  0.13137525,  0.10793012],\n","       [-0.01304211,  0.10887629, -0.04745413],\n","       [ 0.14186043, -0.00572011, -0.06920054],\n","       [ 0.08836551,  0.12504056, -0.02106841],\n","       [ 0.05068733,  0.12885478,  0.0406491 ],\n","       [ 0.00556901, -0.10277982,  0.04307547],\n","       [ 0.04622276, -0.04908597,  0.08724032],\n","       [ 0.02465782,  0.11831111,  0.06390303],\n","       [-0.06699345, -0.09028545, -0.06733674],\n","       [-0.10481893,  0.03988458,  0.02070425],\n","       [ 0.05261399,  0.03868957,  0.04611316],\n","       [ 0.0541243 , -0.03767361,  0.09521118],\n","       [-0.14025915,  0.10813722,  0.01164682],\n","       [ 0.13453087,  0.02964887,  0.04760736],\n","       [-0.07701126,  0.12532121, -0.07995114],\n","       [-0.11472184,  0.06546104,  0.14728668],\n","       [-0.1344459 , -0.0880923 ,  0.04304674],\n","       [-0.08256764, -0.01418576, -0.04438809],\n","       [ 0.06970367, -0.08278595,  0.02240661],\n","       [ 0.10667622,  0.02663389,  0.07655917],\n","       [ 0.09073329, -0.10036258,  0.14154786],\n","       [ 0.07137595,  0.03983817, -0.08717228],\n","       [-0.05755641, -0.09273796,  0.12217104],\n","       [ 0.12896445,  0.10677582,  0.03824675],\n","       [-0.13805924, -0.10375351,  0.00640309],\n","       [ 0.09699249, -0.13346969, -0.07778122],\n","       [ 0.13952094, -0.02159585,  0.13079059],\n","       [-0.031543  ,  0.12199137,  0.07218742],\n","       [ 0.11692715,  0.12418768, -0.05574442],\n","       [-0.01491146, -0.06963027,  0.02961947],\n","       [ 0.06438164, -0.00301646, -0.00033033],\n","       [ 0.00889033, -0.13275227,  0.03233035],\n","       [-0.09998846, -0.06817231,  0.03892943],\n","       [ 0.01599136,  0.14816493,  0.10152766],\n","       [-0.03605617,  0.14339918,  0.06082177],\n","       [-0.04905745, -0.05631673,  0.11867219],\n","       [-0.11939624,  0.11462954, -0.03271613],\n","       [ 0.0241753 ,  0.1252496 ,  0.09163857],\n","       [ 0.10600254, -0.07240123,  0.05615035],\n","       [-0.06413934, -0.12519285,  0.0397239 ],\n","       [ 0.09689459,  0.08601041,  0.10163683],\n","       [-0.05371718,  0.08544326,  0.04257767],\n","       [ 0.14460886,  0.10299888,  0.0968328 ],\n","       [ 0.06814201,  0.0575894 ,  0.1331703 ],\n","       [ 0.07193613, -0.04042143,  0.07849428],\n","       [-0.14555962, -0.07577753, -0.07254508],\n","       [ 0.11934328, -0.12556197, -0.02642828],\n","       [ 0.09840849, -0.08163615, -0.08799077],\n","       [-0.08443311, -0.04308353,  0.0835247 ],\n","       [-0.132822  , -0.11724104,  0.11293039],\n","       [-0.13633166, -0.09122321,  0.09001362],\n","       [-0.07342765,  0.09604433, -0.03766266],\n","       [ 0.1361421 , -0.02763911,  0.00486901],\n","       [-0.07253517,  0.00590551,  0.06731141],\n","       [-0.10405934,  0.00801444,  0.09080775],\n","       [-0.04922521, -0.13724   ,  0.07866462],\n","       [-0.02790351, -0.15168265,  0.0645559 ]], dtype=float32)>, <tf.Variable 'dense_1409/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[ 0.10417478,  0.16186215,  0.15887694],\n","       [ 0.00682098, -0.13654691,  0.13454323],\n","       [ 0.19834246, -0.19011924,  0.08908512],\n","       [-0.20291422, -0.03863633, -0.2035356 ],\n","       [ 0.1014788 , -0.01311247,  0.12708454],\n","       [ 0.09471585,  0.18049951,  0.08474414],\n","       [-0.01923977,  0.07524882,  0.00155278],\n","       [-0.19910927,  0.09075586, -0.04873691],\n","       [ 0.06641878,  0.04995458,  0.05285211],\n","       [ 0.20516856, -0.19736683,  0.04612006],\n","       [ 0.1094671 , -0.05011141,  0.03379276],\n","       [ 0.20465805,  0.13973077,  0.17891203],\n","       [-0.10599999, -0.20421372,  0.07861648],\n","       [-0.14683202,  0.1521249 , -0.07503073],\n","       [-0.03938955,  0.06313337,  0.16032384],\n","       [ 0.17499416, -0.04442538,  0.13222794],\n","       [ 0.08435993,  0.11269321,  0.19265439],\n","       [-0.17190604, -0.08790262,  0.15090357],\n","       [ 0.1535971 ,  0.01494579,  0.15066703],\n","       [ 0.13460521, -0.03298606,  0.10619016],\n","       [ 0.20810436, -0.10960534, -0.06657605],\n","       [ 0.02690953,  0.16389476,  0.1834894 ],\n","       [-0.06367444, -0.118995  ,  0.04342546],\n","       [ 0.11185052,  0.08266039, -0.17771488],\n","       [ 0.07676537, -0.18691136,  0.1809019 ],\n","       [-0.03918183,  0.00548245, -0.13305143],\n","       [-0.0205486 , -0.02844338,  0.12756817],\n","       [ 0.02512771,  0.10315357,  0.09644078],\n","       [ 0.05500941, -0.10318206, -0.05757214],\n","       [ 0.2101333 , -0.05193095, -0.2082208 ],\n","       [ 0.14699192, -0.20429735,  0.19074123],\n","       [ 0.0541818 , -0.05607639, -0.11449458],\n","       [ 0.12214403, -0.13710722,  0.1117792 ],\n","       [-0.02455169,  0.1464235 , -0.00907075],\n","       [ 0.07676823,  0.19498856, -0.10797709],\n","       [ 0.1539572 ,  0.01676747, -0.08184537],\n","       [ 0.09004749, -0.16887584, -0.07829233],\n","       [-0.17879829,  0.09737642,  0.158695  ],\n","       [ 0.20652728,  0.20921032, -0.0123574 ],\n","       [-0.11705576,  0.03201863, -0.07922542],\n","       [-0.08913818,  0.14978822, -0.03457727],\n","       [-0.1985256 , -0.04655199, -0.01323141],\n","       [-0.0900829 , -0.1261336 ,  0.02671349],\n","       [ 0.20320536, -0.14762539,  0.08594729],\n","       [ 0.03253576, -0.12127264, -0.1186886 ],\n","       [ 0.14800031, -0.16519247, -0.08795124],\n","       [-0.02333015,  0.20343114,  0.17816998],\n","       [-0.11764443, -0.15975635,  0.11819877],\n","       [-0.09343828, -0.00892319,  0.15376784],\n","       [-0.10148717, -0.01275493, -0.19476381],\n","       [-0.04244266, -0.1463137 ,  0.20155941],\n","       [ 0.0095062 ,  0.03418703,  0.17026095],\n","       [ 0.08403377, -0.06033349,  0.12567072],\n","       [ 0.01530913, -0.1274634 , -0.06067352],\n","       [ 0.0168615 , -0.03645594,  0.08754666],\n","       [-0.00714289,  0.04496364,  0.17445089],\n","       [ 0.03500296, -0.12279731,  0.12387754],\n","       [ 0.00503802,  0.09585665,  0.12909503],\n","       [ 0.12641026, -0.0387843 , -0.07539107],\n","       [-0.19206996,  0.04561584,  0.15162696],\n","       [ 0.09746484, -0.1094884 , -0.12414977],\n","       [ 0.11473818,  0.18033607,  0.18678619],\n","       [ 0.00128755,  0.13530476, -0.1684486 ],\n","       [-0.0152104 , -0.1225008 ,  0.16656463],\n","       [ 0.09027334, -0.17110755, -0.0501212 ],\n","       [-0.00772595,  0.01940902, -0.15021846],\n","       [-0.15254554,  0.10112797,  0.03183061],\n","       [ 0.08657096, -0.0267086 ,  0.0364594 ],\n","       [-0.07774626, -0.19361274,  0.03233744],\n","       [-0.1731319 ,  0.07313119,  0.1211289 ],\n","       [-0.16945416,  0.13727908, -0.03914127],\n","       [ 0.20151754, -0.07081155,  0.11215995],\n","       [ 0.19165818, -0.18696785,  0.16590609],\n","       [-0.06610718, -0.16679591, -0.11341571],\n","       [-0.21289027,  0.1713071 , -0.16900697],\n","       [-0.11090948, -0.18278955,  0.13500093],\n","       [-0.17187685,  0.08069937, -0.10204834],\n","       [-0.14519994,  0.11314534, -0.06455639],\n","       [ 0.10419424, -0.16110243, -0.17272508],\n","       [ 0.09314121, -0.14674272,  0.15897222],\n","       [-0.1466798 ,  0.02283134,  0.11278857],\n","       [-0.00651079, -0.16764033,  0.16781135],\n","       [-0.04921384,  0.13876842,  0.1306891 ],\n","       [ 0.0462435 ,  0.1741948 ,  0.0149243 ],\n","       [ 0.0651425 , -0.00343922, -0.08064105],\n","       [ 0.04065613,  0.1888525 , -0.2096755 ],\n","       [ 0.01957913, -0.08832832,  0.07077093],\n","       [-0.04807976,  0.00918806, -0.01774484],\n","       [ 0.16706772, -0.03023431, -0.08913624],\n","       [-0.1788661 ,  0.03792097,  0.18122427],\n","       [-0.12241662,  0.03712814, -0.1590242 ],\n","       [ 0.04593177, -0.18269046,  0.20746763],\n","       [ 0.10786535,  0.03602503, -0.10278574],\n","       [-0.10292576,  0.05150531, -0.02021781],\n","       [-0.12780416,  0.19522701,  0.20702963],\n","       [-0.04934762,  0.17482884,  0.10116638],\n","       [ 0.18716778,  0.19885857,  0.01820208],\n","       [ 0.02074468, -0.17341708,  0.12755118],\n","       [ 0.03939848, -0.19519582,  0.12971894],\n","       [-0.06843896, -0.21284679, -0.14255595],\n","       [ 0.00243765,  0.18458869,  0.05058487],\n","       [ 0.16221981, -0.17553379, -0.16668709],\n","       [ 0.06103636,  0.14115168,  0.05345257],\n","       [-0.14611338, -0.1927318 , -0.10065088],\n","       [-0.07652499, -0.01813906, -0.03523196],\n","       [-0.1204095 ,  0.17843695,  0.05768113],\n","       [-0.05544579,  0.10956438,  0.05906342],\n","       [-0.17422174,  0.04458462, -0.11466592],\n","       [-0.05307227,  0.01933707,  0.10402365],\n","       [-0.07120629, -0.15880582, -0.17151596],\n","       [-0.14792573, -0.13963997,  0.00898688],\n","       [ 0.07745348,  0.00405601,  0.1984242 ],\n","       [ 0.06347932,  0.21269454,  0.15558691],\n","       [ 0.12242477, -0.13318327, -0.1079175 ],\n","       [ 0.16042115,  0.12450658,  0.14990513],\n","       [-0.21231863,  0.00909816, -0.01005319],\n","       [-0.01736715, -0.19668417, -0.13802016],\n","       [-0.00573109,  0.13717492,  0.10456644],\n","       [ 0.09951006, -0.16226584,  0.17246456],\n","       [ 0.16521256, -0.18443125,  0.02680846],\n","       [ 0.02675106,  0.08944289, -0.16189857],\n","       [-0.1861509 ,  0.11980368, -0.06522685],\n","       [-0.15807208, -0.06802928, -0.13693216],\n","       [ 0.12250845, -0.17293996,  0.19197787],\n","       [-0.06149997,  0.09936021, -0.09352589],\n","       [-0.1761692 ,  0.20176382, -0.15961379],\n","       [ 0.07278173,  0.07270019,  0.1458836 ],\n","       [-0.20268267,  0.05440427, -0.17304894]], dtype=float32)>, <tf.Variable 'dense_1410/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[ 0.01506202, -0.08245967, -0.12270327],\n","       [ 0.01191697, -0.15755464,  0.02285863],\n","       [-0.06437622,  0.0284414 ,  0.09796371],\n","       [ 0.05987959, -0.1784206 , -0.18861906],\n","       [-0.2047503 , -0.03242759,  0.18913098],\n","       [ 0.12060262, -0.13635425,  0.19543917],\n","       [-0.00998904,  0.06222217,  0.00138772],\n","       [ 0.02829796,  0.03182887,  0.04018952],\n","       [ 0.0349829 , -0.05832408, -0.08929763],\n","       [ 0.0911081 , -0.02099109, -0.09393618],\n","       [-0.01004395, -0.09065749,  0.03892131],\n","       [ 0.05012189,  0.20674138,  0.19093944],\n","       [-0.16481632,  0.03169622, -0.21060778],\n","       [ 0.12981538, -0.00916663, -0.11157653],\n","       [ 0.19047157, -0.00366797,  0.1973633 ],\n","       [-0.18251279,  0.05912031, -0.05720456],\n","       [ 0.15911002, -0.04712881, -0.10469448],\n","       [ 0.1560934 , -0.10349208, -0.125508  ],\n","       [ 0.02118528,  0.06341843,  0.13655095],\n","       [ 0.04600893, -0.15227455,  0.13082476],\n","       [-0.20642014, -0.17413102, -0.1915935 ],\n","       [-0.14493318, -0.17262498, -0.05686626],\n","       [ 0.2035905 , -0.07718913,  0.09009637],\n","       [-0.08625621,  0.0367917 ,  0.12158911],\n","       [-0.07451625, -0.04524621,  0.1377727 ],\n","       [-0.18664931,  0.003695  ,  0.16062562],\n","       [-0.06173657,  0.02304339,  0.18701907],\n","       [-0.03641124,  0.13571455, -0.07610939],\n","       [-0.13060015,  0.1872444 , -0.0229218 ],\n","       [ 0.05925201,  0.05063866, -0.10821737],\n","       [-0.141394  ,  0.0140104 ,  0.21235283],\n","       [ 0.08150776,  0.03799887,  0.02884255],\n","       [ 0.13570572,  0.07952167, -0.11290506],\n","       [-0.1829343 , -0.12217093,  0.18504722],\n","       [-0.07237582, -0.1633643 ,  0.10307486],\n","       [-0.11296573, -0.17141497, -0.063031  ],\n","       [ 0.00781152,  0.0922821 , -0.13230304],\n","       [-0.11902225, -0.1741551 ,  0.08164425],\n","       [-0.04002257,  0.13411738,  0.15061994],\n","       [-0.01158679, -0.05518204,  0.148046  ],\n","       [ 0.12957607, -0.09692501, -0.10021686],\n","       [ 0.09464125, -0.2028833 ,  0.05954994],\n","       [ 0.11912785, -0.0126783 , -0.0255785 ],\n","       [ 0.08445911, -0.09466318,  0.17996593],\n","       [-0.0464581 , -0.091761  , -0.12742382],\n","       [-0.05760923,  0.10732035,  0.12339543],\n","       [ 0.00266089, -0.18845308, -0.01196738],\n","       [-0.05024479, -0.00278865,  0.18873079],\n","       [-0.13078986,  0.02017362,  0.1698776 ],\n","       [ 0.07395564, -0.0111573 , -0.19362263],\n","       [ 0.14207913,  0.16736434,  0.0465229 ],\n","       [ 0.05368637, -0.0986352 ,  0.17799695],\n","       [ 0.08935247,  0.04846801, -0.01100311],\n","       [ 0.00161958,  0.16849075,  0.09660457],\n","       [ 0.06264   ,  0.08719347, -0.14498451],\n","       [-0.08346061,  0.08410938,  0.00215763],\n","       [-0.06818685, -0.02979758, -0.05313805],\n","       [-0.04429032, -0.12030327, -0.19961748],\n","       [-0.03953773,  0.15715344, -0.07331492],\n","       [-0.01848853,  0.06549229, -0.01821095],\n","       [-0.15244375, -0.19367178,  0.04592074],\n","       [ 0.0886264 , -0.1483101 ,  0.11696754],\n","       [-0.19933388,  0.1343648 , -0.18536618],\n","       [-0.19192939,  0.16595845,  0.09715717],\n","       [ 0.08530109,  0.03530563, -0.20244765],\n","       [-0.03260756, -0.1261283 , -0.20106398],\n","       [-0.02250233,  0.20432566, -0.05292839],\n","       [ 0.0550534 ,  0.02308896, -0.17135915],\n","       [-0.15864106, -0.09123759, -0.05579357],\n","       [ 0.0096858 ,  0.0404651 , -0.08967359],\n","       [ 0.16698681, -0.04695672, -0.09744168],\n","       [ 0.11694892,  0.05718069, -0.07106973],\n","       [-0.06384572,  0.11275576, -0.18191099],\n","       [ 0.09753321,  0.1058784 ,  0.13469104],\n","       [ 0.1079921 , -0.0346092 ,  0.06558006],\n","       [ 0.15884791,  0.00852959, -0.16843152],\n","       [ 0.10210069, -0.09261765, -0.21305951],\n","       [-0.05716859,  0.08727063,  0.04007058],\n","       [-0.03471492, -0.11589515,  0.17611434],\n","       [ 0.10956262, -0.03498459, -0.17031957],\n","       [-0.04140896,  0.05032517,  0.12629046],\n","       [-0.11566585, -0.19753475,  0.21177717],\n","       [-0.21326663, -0.12033634, -0.19013388],\n","       [ 0.04252823,  0.19515438,  0.14832355],\n","       [ 0.19718389,  0.08738615, -0.16912156],\n","       [-0.08950326, -0.06464957, -0.01628186],\n","       [-0.19994526, -0.171436  , -0.0441727 ],\n","       [-0.209013  ,  0.1490496 ,  0.06210767],\n","       [-0.06320317, -0.20296   , -0.05181201],\n","       [-0.11864962,  0.00818482, -0.1225978 ],\n","       [-0.04058827, -0.17525753, -0.0375766 ],\n","       [-0.08585648, -0.2075909 , -0.04172516],\n","       [ 0.14836933, -0.19581358, -0.16562633],\n","       [ 0.13036461,  0.13639493, -0.16896558],\n","       [ 0.18459494, -0.14886361,  0.20574473],\n","       [ 0.19805188,  0.1456268 ,  0.1082982 ],\n","       [ 0.18500702,  0.0727333 , -0.06196541],\n","       [ 0.20602046, -0.05984339, -0.17905065],\n","       [-0.10385032, -0.15643674, -0.06250402],\n","       [ 0.14253832,  0.0051516 , -0.13446823],\n","       [-0.11007313, -0.0200261 , -0.09769955],\n","       [-0.18330377, -0.05159567,  0.11902915],\n","       [-0.17972448,  0.03826053, -0.18672344],\n","       [-0.20590253,  0.01051654, -0.07611261],\n","       [-0.14890999, -0.11742615,  0.13862877],\n","       [ 0.1660407 , -0.02052788,  0.00059511],\n","       [ 0.20053847,  0.17603542, -0.04928288],\n","       [ 0.05394147,  0.18065716, -0.11194212],\n","       [-0.13949886, -0.00909744, -0.16898774],\n","       [ 0.08647622, -0.07274555, -0.20588525],\n","       [ 0.00165351,  0.14296226,  0.18389516],\n","       [-0.06286559,  0.20711131, -0.07114066],\n","       [-0.06078582, -0.20609602, -0.00717743],\n","       [-0.1339219 ,  0.00303847,  0.2122369 ],\n","       [ 0.10623424, -0.04229867, -0.11531995],\n","       [-0.05839226, -0.18494186,  0.05012064],\n","       [-0.06533773, -0.12510316, -0.0421012 ],\n","       [ 0.01060303, -0.12934081, -0.06702639],\n","       [ 0.10275711, -0.01727088,  0.13491891],\n","       [ 0.00361173, -0.01871462,  0.0012823 ],\n","       [ 0.04813676, -0.03566256, -0.167261  ],\n","       [ 0.0952176 ,  0.14692916, -0.19758704],\n","       [ 0.05438219, -0.00805159,  0.21025304],\n","       [ 0.02277379, -0.00879006,  0.11084865],\n","       [-0.17124425, -0.12263755,  0.10386916],\n","       [-0.03205241, -0.16830058, -0.04521213],\n","       [-0.14392886,  0.08769055,  0.13521527],\n","       [-0.20115352,  0.15593405,  0.17133252]], dtype=float32)>, <tf.Variable 'dense_1411/kernel:0' shape=(128, 3) dtype=float32, numpy=\n","array([[-2.00872272e-02, -2.07031414e-01, -1.58110350e-01],\n","       [ 1.44049242e-01,  9.32926983e-02, -9.76132229e-02],\n","       [ 2.41724700e-02, -1.13567665e-01, -6.15542084e-02],\n","       [ 4.10286039e-02,  9.27020460e-02, -1.61585942e-01],\n","       [-1.19747669e-01, -1.88944086e-01,  1.19852021e-01],\n","       [-7.84908086e-02, -1.25124693e-01,  1.81346461e-01],\n","       [ 4.33749408e-02,  1.63670704e-01,  6.23786002e-02],\n","       [-1.22145981e-01, -1.79537997e-01,  1.72309726e-02],\n","       [-1.96580127e-01,  4.63889092e-02,  1.78218290e-01],\n","       [-1.68359369e-01, -1.46411672e-01, -1.27435297e-01],\n","       [-6.67503476e-02, -4.26032394e-02, -6.54170811e-02],\n","       [ 5.82277626e-02,  1.99038282e-01, -3.03734839e-03],\n","       [-2.95023471e-02, -1.01958990e-01,  1.23803422e-01],\n","       [ 1.16083637e-01,  1.64271101e-01, -8.47503692e-02],\n","       [ 1.62657395e-01,  9.72497612e-02,  4.47046310e-02],\n","       [-1.40531436e-01, -7.48541355e-02,  1.23564258e-01],\n","       [-2.13283658e-01,  1.16588280e-01, -7.70231485e-02],\n","       [ 3.27720046e-02, -8.50107968e-02,  2.29990035e-02],\n","       [ 1.44776776e-01,  1.30980313e-02, -2.03859106e-01],\n","       [ 1.95106700e-01,  4.32437509e-02,  8.42351168e-02],\n","       [-2.64178663e-02, -2.27485746e-02, -2.11492345e-01],\n","       [ 9.01249498e-02,  1.44147053e-01,  9.64549184e-03],\n","       [-1.70581788e-01, -1.46419942e-01,  1.32100731e-02],\n","       [ 1.66919097e-01, -3.12478989e-02, -1.83321685e-01],\n","       [-1.85206175e-01,  1.42034069e-01, -1.63866132e-01],\n","       [ 3.68876010e-02,  1.75569668e-01, -2.13171259e-01],\n","       [-1.41524076e-02, -4.86215949e-02,  2.66805291e-02],\n","       [-4.83047813e-02, -6.57182932e-03,  8.33613127e-02],\n","       [ 1.22606754e-04, -1.38619244e-02, -2.13198960e-01],\n","       [-7.80237913e-02, -3.85243744e-02, -1.25125155e-01],\n","       [-1.36196166e-01,  1.39599994e-01,  1.56221613e-01],\n","       [-5.97102791e-02, -1.71217963e-01,  5.25995940e-02],\n","       [ 1.48148790e-01, -8.99310559e-02, -1.45942807e-01],\n","       [ 1.36756942e-01,  2.05716655e-01,  2.07360730e-01],\n","       [ 1.07040957e-01, -1.11855023e-01,  1.72392294e-01],\n","       [-1.47059172e-01, -2.21785754e-02,  2.06051633e-01],\n","       [-1.24025367e-01, -1.12290978e-02,  1.97979137e-01],\n","       [-7.36297518e-02, -7.19177127e-02,  2.16196626e-02],\n","       [ 1.21314064e-01,  1.75458923e-01,  1.20904043e-01],\n","       [-1.07046150e-01, -8.84261280e-02, -1.68258384e-01],\n","       [-7.26484954e-02,  1.05933264e-01, -3.46959978e-02],\n","       [ 3.73821408e-02, -9.24150348e-02, -8.01169127e-02],\n","       [-1.81213588e-01, -2.71522999e-03, -1.87972531e-01],\n","       [-1.38350993e-01, -8.80960971e-02, -5.46333641e-02],\n","       [-4.89982069e-02,  4.28351015e-02,  2.78770626e-02],\n","       [ 4.20350879e-02, -5.95111251e-02, -2.11532399e-01],\n","       [-1.26627013e-01, -9.93572176e-03,  2.46764719e-03],\n","       [-8.51868838e-02,  1.19986013e-01, -1.63989007e-01],\n","       [ 1.56377658e-01, -1.63147300e-02,  2.13372305e-01],\n","       [ 1.94743916e-01, -3.10556889e-02,  1.18307754e-01],\n","       [ 2.22961456e-02, -5.82586229e-02, -1.24414176e-01],\n","       [-1.15271784e-01, -7.42275566e-02, -2.12874904e-01],\n","       [-5.00980020e-03,  1.10153869e-01, -3.31816822e-02],\n","       [ 7.33404905e-02, -1.72423884e-01,  1.32403657e-01],\n","       [ 2.79372782e-02, -1.21748343e-01,  1.49153575e-01],\n","       [-6.72520250e-02, -1.20289028e-02,  8.29196423e-02],\n","       [-1.07211523e-01, -1.55257195e-01,  9.30477828e-02],\n","       [ 5.60093671e-02,  1.23054877e-01, -1.33758008e-01],\n","       [ 1.40129313e-01, -1.52674466e-02, -6.94745481e-02],\n","       [ 2.04144225e-01, -9.78153795e-02,  2.05362096e-01],\n","       [-2.01695457e-01, -1.68105826e-01, -1.39171273e-01],\n","       [ 2.00072780e-01,  1.04104921e-01,  1.90775320e-01],\n","       [-1.97713688e-01,  1.50294289e-01,  9.56455618e-02],\n","       [ 1.18385419e-01, -7.97922462e-02,  1.41089991e-01],\n","       [-3.03480029e-03, -1.77203119e-03,  6.90972656e-02],\n","       [-2.48554796e-02,  1.55889556e-01,  9.12632495e-02],\n","       [-6.64868504e-02, -1.05965599e-01, -1.27553210e-01],\n","       [ 1.35694131e-01,  7.26068467e-02,  1.97211608e-01],\n","       [-6.08398616e-02, -2.85327286e-02, -1.53405920e-01],\n","       [-1.19582497e-01, -2.45518833e-02, -1.17738262e-01],\n","       [ 1.04666159e-01,  1.50471345e-01,  2.99742222e-02],\n","       [-5.17137349e-02,  2.67232955e-02,  1.22754768e-01],\n","       [-4.37684357e-03, -5.85190058e-02, -2.13644668e-01],\n","       [ 1.13506392e-01, -1.05896004e-01,  8.65773410e-02],\n","       [-8.96980762e-02, -6.99924082e-02,  8.58365148e-02],\n","       [ 1.74362019e-01,  7.70045668e-02, -3.38844955e-03],\n","       [-6.06201440e-02,  1.16916895e-02, -1.68594897e-01],\n","       [ 2.71229744e-02,  7.41483718e-02,  1.70300558e-01],\n","       [-2.11226150e-01, -2.11657345e-01,  1.33499160e-01],\n","       [-7.79518932e-02, -2.06195876e-01,  1.69654936e-02],\n","       [ 2.07957819e-01,  8.96278769e-02, -3.87079716e-02],\n","       [-1.19126134e-01,  8.46529156e-02,  1.75362185e-01],\n","       [ 1.49803534e-01, -1.82579115e-01, -5.39952517e-02],\n","       [-1.75103083e-01,  1.08191803e-01,  3.93585712e-02],\n","       [ 2.35259533e-03,  3.40395123e-02, -7.94805884e-02],\n","       [-1.16780229e-01, -1.97010621e-01,  6.26837462e-02],\n","       [ 2.13975459e-02,  1.50690660e-01,  1.18931517e-01],\n","       [-1.18398674e-01,  1.03204235e-01, -1.85349196e-01],\n","       [-2.05995962e-01, -5.39574921e-02, -2.12294191e-01],\n","       [-1.27141386e-01,  5.03367931e-02,  2.03754589e-01],\n","       [-1.14202611e-01, -1.46940187e-01, -6.79752529e-02],\n","       [ 1.58047482e-01,  9.22016054e-02,  6.24508709e-02],\n","       [-5.97570837e-03,  2.00447813e-01,  2.07907870e-01],\n","       [ 1.98453411e-01,  2.47003138e-02,  1.90471098e-01],\n","       [-1.93045810e-01, -7.85837322e-02,  1.75260708e-01],\n","       [ 1.24535725e-01, -4.86278236e-02,  2.11107627e-01],\n","       [ 1.77053258e-01,  7.90851563e-02,  7.50796646e-02],\n","       [ 1.04965672e-01, -8.19104910e-02,  1.29886866e-02],\n","       [-6.97942823e-02,  3.65730971e-02, -9.55565199e-02],\n","       [-8.09787214e-03,  1.88126221e-01, -1.32502809e-01],\n","       [-2.82460302e-02,  8.78771991e-02,  2.12850049e-01],\n","       [ 5.33458143e-02,  1.04652837e-01, -6.87991083e-03],\n","       [-2.03806490e-01,  1.37887582e-01, -2.86985636e-02],\n","       [-1.68671370e-01,  1.26310393e-01, -2.81204581e-02],\n","       [ 1.16776660e-01,  9.40680504e-03,  1.56456754e-01],\n","       [-1.96841776e-01,  7.80141354e-03,  5.17280847e-02],\n","       [ 9.85369235e-02,  3.90642732e-02,  6.98072761e-02],\n","       [-7.43210316e-02, -7.40193725e-02, -8.56982470e-02],\n","       [ 5.12606949e-02,  4.92867678e-02,  1.28502831e-01],\n","       [ 1.85294345e-01, -1.08183183e-01,  1.45305201e-01],\n","       [ 1.73941001e-01, -1.06841646e-01,  4.46675569e-02],\n","       [ 5.55793792e-02,  8.64313096e-02,  1.72346130e-01],\n","       [-5.16197532e-02, -1.50391594e-01, -1.87219247e-01],\n","       [ 4.21206504e-02,  1.00445613e-01,  2.04459623e-01],\n","       [ 2.20534205e-02,  8.01189095e-02,  2.01255307e-01],\n","       [ 6.48876876e-02, -1.27902329e-01, -1.54061496e-01],\n","       [-1.13442041e-01,  4.82594222e-02, -7.75969177e-02],\n","       [ 6.99104369e-03,  1.59016848e-02,  4.76393849e-02],\n","       [ 9.34484452e-02, -1.01125248e-01, -1.83220342e-01],\n","       [ 1.04369536e-01, -6.08545989e-02,  1.52135044e-02],\n","       [-1.14120245e-02, -1.87182814e-01, -1.36639789e-01],\n","       [ 1.94824025e-01,  1.84087768e-01,  3.83220613e-03],\n","       [-2.64060795e-02, -1.38509423e-01,  4.05162424e-02],\n","       [-1.89350650e-01, -1.25370622e-02, -3.95920873e-03],\n","       [ 9.66285914e-02,  1.67672560e-01, -1.38590872e-01],\n","       [-4.16840315e-02, -2.19225436e-02,  1.31505892e-01],\n","       [-9.09577236e-02,  1.85809880e-02,  5.87301403e-02],\n","       [-1.50090605e-01, -1.24928303e-01, -1.30316660e-01]], dtype=float32)>, <tf.Variable 'dense_1412/kernel:0' shape=(128, 1280) dtype=float32, numpy=\n","array([[ 0.04692399,  0.05010592, -0.02553511, ..., -0.02269491,\n","        -0.0541708 , -0.05256725],\n","       [-0.02830287, -0.00915119, -0.02894644, ...,  0.04538503,\n","         0.03777251, -0.00052417],\n","       [ 0.02034486,  0.05448103,  0.0016967 , ...,  0.00351649,\n","        -0.03766883, -0.03722279],\n","       ...,\n","       [ 0.04783361,  0.00853562, -0.03588312, ...,  0.01550663,\n","        -0.04641952, -0.03328174],\n","       [ 0.02377386, -0.03956143, -0.04403327, ..., -0.05600591,\n","         0.00463928, -0.06180468],\n","       [-0.06248381, -0.02711469,  0.05144221, ...,  0.00830848,\n","         0.05860502, -0.05950934]], dtype=float32)>, <tf.Variable 'dense_1413/kernel:0' shape=(1280, 3) dtype=float32, numpy=\n","array([[ 0.01113199, -0.02892849, -0.03190093],\n","       [-0.00892193,  0.05486365,  0.05668968],\n","       [-0.06412636, -0.0181842 , -0.0209302 ],\n","       ...,\n","       [ 0.05335986,  0.02690009, -0.05828322],\n","       [ 0.0569763 ,  0.0614883 , -0.03553245],\n","       [-0.02799691,  0.00631493,  0.06434005]], dtype=float32)>, <tf.Variable 'branch:0' shape=(48, 128, 8192) dtype=float32, numpy=\n","array([[[-2.0310362e-03, -3.2708158e-03,  3.3715903e-03, ...,\n","         -1.5683062e-03,  2.5160750e-04,  2.5779069e-03],\n","        [-1.5269523e-03,  3.8496451e-03,  3.4951679e-03, ...,\n","         -2.7270832e-03, -3.0203164e-03, -8.2941097e-04],\n","        [ 2.9943692e-03,  2.6793112e-03,  1.4718887e-03, ...,\n","         -1.9970909e-03,  2.9700426e-03,  2.2114487e-05],\n","        ...,\n","        [-3.0832109e-03, -3.0869877e-03,  1.8431898e-03, ...,\n","         -1.3255500e-03, -2.0862669e-03,  2.3756982e-03],\n","        [ 1.2319707e-03,  8.1875362e-05, -2.8986305e-03, ...,\n","          8.4389606e-04, -6.7472924e-04,  1.2525436e-03],\n","        [ 2.8871656e-03, -2.8459560e-03,  2.3464160e-03, ...,\n","          4.0609157e-04, -2.9424306e-03,  1.0975190e-03]],\n","\n","       [[ 1.3693236e-03, -3.1841102e-03,  2.4861540e-03, ...,\n","          3.5347096e-03,  3.7211105e-03,  2.2010412e-04],\n","        [ 2.6713968e-03,  2.8469134e-03,  2.9668859e-03, ...,\n","         -2.6120094e-03,  1.6623773e-03,  2.7128402e-03],\n","        [ 3.7430050e-03,  2.9319776e-03, -3.6110724e-03, ...,\n","          1.0778462e-03,  1.8938971e-03,  6.4860098e-04],\n","        ...,\n","        [ 1.2374092e-03, -3.3233471e-03, -2.3457599e-03, ...,\n","         -2.1736859e-03, -1.2093175e-03, -1.5988655e-03],\n","        [-2.6005707e-03, -2.4085231e-03,  3.2313424e-03, ...,\n","         -2.3593642e-03,  1.7890311e-03, -3.6885664e-03],\n","        [ 2.2698520e-03, -3.1021168e-03,  1.4662785e-03, ...,\n","         -1.5639164e-04,  3.6468962e-04,  1.0350812e-04]],\n","\n","       [[-1.8631751e-03, -3.0584661e-03,  5.1359413e-04, ...,\n","         -3.6969269e-03,  2.5853482e-03,  3.0133734e-03],\n","        [-1.6929817e-03, -2.7927896e-03,  6.8300357e-04, ...,\n","          2.8671212e-03,  3.1593130e-03,  6.7060953e-04],\n","        [-3.0507497e-04, -3.4233732e-03,  2.3078346e-03, ...,\n","         -2.1655988e-03, -3.8442179e-04,  3.1425585e-03],\n","        ...,\n","        [ 3.8292035e-03, -1.3713073e-04,  1.6484619e-03, ...,\n","         -3.1219050e-03,  1.1246698e-03, -3.8341880e-03],\n","        [ 7.8842603e-04,  2.0108963e-03, -3.3549468e-03, ...,\n","         -3.0735906e-03, -2.2205254e-03,  2.3542526e-03],\n","        [-1.6683056e-03,  1.6646720e-03,  1.7225901e-03, ...,\n","          5.6433957e-05, -1.1423135e-03, -1.1102434e-03]],\n","\n","       ...,\n","\n","       [[ 1.9614277e-03, -3.2966794e-04,  3.4941291e-03, ...,\n","          2.8376561e-03, -1.8187438e-03, -2.8076866e-03],\n","        [ 2.3685573e-03,  3.3791019e-03, -7.6333294e-04, ...,\n","          2.9514539e-03,  3.3504702e-03,  3.2444764e-04],\n","        [ 2.7520005e-03,  3.4800991e-03, -3.2048393e-04, ...,\n","         -3.5873537e-03, -1.4856695e-03, -2.7300874e-03],\n","        ...,\n","        [ 1.3716659e-03, -2.7483352e-03, -1.6447024e-03, ...,\n","         -3.7826598e-05,  3.6979867e-03,  2.0239553e-03],\n","        [ 1.4380640e-03, -2.2113849e-03,  2.5828946e-03, ...,\n","         -3.1851009e-03, -1.2065738e-03,  2.7123801e-03],\n","        [ 2.5843973e-03,  1.8738136e-03,  3.2277098e-03, ...,\n","         -3.0298126e-03, -7.6702307e-04,  1.4648628e-03]],\n","\n","       [[ 1.8163468e-03,  2.4361834e-03, -3.4856955e-03, ...,\n","         -2.2931825e-03,  1.0909215e-03, -3.0783508e-03],\n","        [-8.3910068e-05,  1.0721893e-03,  2.6192325e-03, ...,\n","         -3.7690285e-03,  1.1538612e-03, -1.1727433e-03],\n","        [ 1.8930431e-03,  2.0087222e-03, -1.2676497e-03, ...,\n","          5.6172907e-04, -3.3179391e-03, -3.1095799e-03],\n","        ...,\n","        [ 1.0530837e-04, -3.0785475e-03, -4.8775156e-04, ...,\n","         -1.3529218e-03, -4.2572198e-04,  3.1842776e-03],\n","        [ 2.3379521e-03, -3.4671391e-03,  2.4415362e-03, ...,\n","          2.4940553e-03,  9.9784695e-05, -3.7408648e-03],\n","        [ 1.5347311e-04, -3.8563192e-03,  2.0254324e-03, ...,\n","         -3.0624603e-03, -6.8643037e-04, -3.6159139e-03]],\n","\n","       [[-1.4686887e-03,  2.8790538e-03, -1.1711861e-03, ...,\n","         -1.3322048e-03,  3.3866474e-03, -1.3313582e-04],\n","        [-4.0451321e-04,  6.3541578e-04,  5.3125853e-04, ...,\n","          3.1311703e-03, -3.7781256e-03,  3.3680983e-03],\n","        [ 3.5720342e-03,  2.0810943e-03,  3.8318732e-03, ...,\n","         -3.3377691e-03, -3.3673090e-03,  2.8556935e-03],\n","        ...,\n","        [ 8.3389506e-04,  3.0904207e-03, -3.2910432e-03, ...,\n","          2.8294590e-03, -1.7554234e-03,  1.5675412e-03],\n","        [-7.0779352e-04, -1.0458962e-03, -2.3960131e-03, ...,\n","          3.5974332e-03,  1.1863946e-03, -3.5586946e-03],\n","        [ 2.4134028e-03,  1.5389393e-03,  1.8644552e-03, ...,\n","          5.5850018e-05, -1.2933542e-03,  1.9439352e-03]]], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_140/kernel:0' shape=(1, 3072, 64) dtype=float32, numpy=\n","array([[[-0.01755077, -0.01669522,  0.00366702, ..., -0.02130936,\n","          0.02711051,  0.03004967],\n","        [-0.01658737, -0.04326435,  0.03300128, ...,  0.02523976,\n","         -0.01816934, -0.03386408],\n","        [ 0.00893116, -0.03906786, -0.04058287, ...,  0.01866076,\n","          0.03122273,  0.02737268],\n","        ...,\n","        [-0.03507484,  0.01827381,  0.03771046, ..., -0.04069404,\n","         -0.03537632, -0.01602929],\n","        [-0.0168488 ,  0.0219588 ,  0.02516796, ..., -0.02751748,\n","         -0.01118267,  0.02171791],\n","        [-0.0270312 ,  0.03270725, -0.01301024, ...,  0.03862549,\n","         -0.01744941, -0.01495841]]], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_140/bias:0' shape=(64,) dtype=float32, numpy=\n","array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_141/kernel:0' shape=(1, 64, 128) dtype=float32, numpy=\n","array([[[-0.07989758, -0.01961056, -0.11554704, ..., -0.09924257,\n","         -0.1268925 , -0.08860256],\n","        [-0.02041011,  0.02202056,  0.0545624 , ...,  0.13867243,\n","          0.17113179,  0.16352284],\n","        [-0.12716238, -0.0280869 , -0.12648782, ..., -0.16347627,\n","         -0.02052166, -0.10615076],\n","        ...,\n","        [ 0.03412487,  0.16617028, -0.10799217, ..., -0.02167879,\n","          0.03654914, -0.1080519 ],\n","        [-0.11239622, -0.11881354,  0.04613581, ..., -0.17108078,\n","         -0.04861196,  0.09007636],\n","        [ 0.09507587,  0.13022271, -0.09531242, ...,  0.15920761,\n","          0.04361904,  0.10635374]]], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_141/bias:0' shape=(128,) dtype=float32, numpy=\n","array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_142/kernel:0' shape=(1, 128, 256) dtype=float32, numpy=\n","array([[[-0.02589927, -0.10801403,  0.02377051, ..., -0.00339117,\n","          0.03748272,  0.0796179 ],\n","        [-0.11320315,  0.02618415,  0.00848128, ..., -0.10505609,\n","          0.05735301, -0.08515823],\n","        [-0.10576303, -0.01222905, -0.05691298, ..., -0.06944489,\n","         -0.00264255, -0.04665419],\n","        ...,\n","        [-0.07161561, -0.07147174,  0.07511781, ...,  0.08353426,\n","         -0.0237294 ,  0.00571041],\n","        [-0.06100768, -0.00541773, -0.0076714 , ...,  0.03345104,\n","          0.03555622,  0.00304429],\n","        [-0.08392071,  0.06822266,  0.05035398, ..., -0.09438046,\n","          0.00284984, -0.08739924]]], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_142/bias:0' shape=(256,) dtype=float32, numpy=\n","array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0.], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_143/kernel:0' shape=(1, 256, 512) dtype=float32, numpy=\n","array([[[ 0.05652298, -0.02159556, -0.00084697, ...,  0.00263941,\n","          0.00517673, -0.05643259],\n","        [-0.00757982,  0.07289889, -0.08703266, ..., -0.06997456,\n","          0.07354543, -0.05944891],\n","        [ 0.04469847,  0.06864578, -0.04969404, ..., -0.07019514,\n","         -0.04341274,  0.01425397],\n","        ...,\n","        [ 0.08054413, -0.04189213, -0.06696397, ..., -0.074025  ,\n","          0.0214275 ,  0.03372982],\n","        [ 0.08457346,  0.05761233,  0.01055768, ..., -0.03320878,\n","         -0.08671203, -0.06951833],\n","        [ 0.03552251,  0.00407858, -0.04569745, ...,  0.03304395,\n","         -0.03613803,  0.08275401]]], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_143/bias:0' shape=(512,) dtype=float32, numpy=\n","array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0.], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_144/kernel:0' shape=(1, 512, 1024) dtype=float32, numpy=\n","array([[[ 0.03136399, -0.02651722, -0.00890546, ..., -0.03500566,\n","         -0.04835139,  0.01630174],\n","        [-0.00558537,  0.04402857, -0.05614058, ..., -0.04969476,\n","         -0.04893221,  0.05476402],\n","        [ 0.0404024 , -0.06048791,  0.02856861, ..., -0.05617622,\n","          0.04560139,  0.04123646],\n","        ...,\n","        [-0.03544994,  0.05451256,  0.0258404 , ..., -0.05245887,\n","          0.00988871, -0.01552169],\n","        [-0.02194109,  0.02072258,  0.05376328, ..., -0.01762232,\n","         -0.05843345,  0.00237079],\n","        [ 0.00696788,  0.04903307,  0.04410953, ..., -0.00791816,\n","         -0.00790619, -0.05176924]]], dtype=float32)>, <tf.Variable 'discriminator_28/conv1d_144/bias:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_1414/kernel:0' shape=(1024, 1024) dtype=float32, numpy=\n","array([[-0.01399692,  0.02958853, -0.05389654, ...,  0.03930636,\n","         0.03904397, -0.01588148],\n","       [ 0.01383363,  0.01007129,  0.05367991, ..., -0.00084209,\n","        -0.02528354,  0.00666396],\n","       [-0.04165129, -0.03797748, -0.0229468 , ...,  0.0492494 ,\n","         0.02651438, -0.01748686],\n","       ...,\n","       [-0.04365582, -0.00403569,  0.02544411, ..., -0.0116098 ,\n","        -0.04248361,  0.01827115],\n","       [-0.03174883, -0.04217772,  0.01654417, ..., -0.03726494,\n","         0.04039263, -0.02059515],\n","       [-0.00060091,  0.00414558, -0.03644521, ...,  0.03825831,\n","        -0.03545305, -0.01018863]], dtype=float32)>, <tf.Variable 'dense_1414/bias:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_1415/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n","array([[-0.04910485, -0.02854619, -0.02932942, ...,  0.00508047,\n","        -0.03913249, -0.01691586],\n","       [ 0.04263115, -0.04222367,  0.00297774, ..., -0.00140273,\n","        -0.00104615, -0.04800136],\n","       [-0.0041542 ,  0.02796658, -0.02956317, ...,  0.02563637,\n","         0.04118902,  0.02706713],\n","       ...,\n","       [ 0.02612909, -0.04031264,  0.05194237, ...,  0.05176859,\n","        -0.04400747,  0.05244204],\n","       [-0.03416729,  0.04325929,  0.03099325, ...,  0.03879503,\n","         0.03052121,  0.03199056],\n","       [-0.02557958, -0.01396395,  0.05092417, ...,  0.01539587,\n","        -0.04771385, -0.02609928]], dtype=float32)>, <tf.Variable 'dense_1415/bias:0' shape=(512,) dtype=float32, numpy=\n","array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0.], dtype=float32)>, <tf.Variable 'dense_1416/kernel:0' shape=(512, 512) dtype=float32, numpy=\n","array([[-0.0355892 ,  0.07087264,  0.00585729, ...,  0.00694794,\n","         0.06577633, -0.03591048],\n","       [-0.00787851, -0.03172926,  0.01815276, ..., -0.04828071,\n","         0.05309728,  0.03485213],\n","       [ 0.04272549,  0.02844606,  0.04936126, ..., -0.03514784,\n","        -0.0119625 , -0.01724841],\n","       ...,\n","       [ 0.05607478, -0.02938945,  0.02215062, ..., -0.05557549,\n","        -0.05272137,  0.01984029],\n","       [-0.03428978, -0.02236556,  0.00322079, ...,  0.02165622,\n","         0.03411525, -0.0346544 ],\n","       [ 0.04874182,  0.03879813, -0.07662011, ...,  0.07458349,\n","         0.0710088 ,  0.06414565]], dtype=float32)>, <tf.Variable 'dense_1416/bias:0' shape=(512,) dtype=float32, numpy=\n","array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0.], dtype=float32)>, <tf.Variable 'dense_1417/kernel:0' shape=(512, 1) dtype=float32, numpy=\n","array([[-0.10688607],\n","       [ 0.10627263],\n","       [ 0.03841262],\n","       [-0.04501643],\n","       [ 0.03057397],\n","       [ 0.00155642],\n","       [ 0.02976326],\n","       [ 0.02697175],\n","       [-0.06548364],\n","       [-0.03302304],\n","       [-0.04710361],\n","       [-0.03371874],\n","       [ 0.10075433],\n","       [ 0.07784881],\n","       [-0.06278603],\n","       [ 0.03770046],\n","       [ 0.0031012 ],\n","       [-0.07760239],\n","       [ 0.08603548],\n","       [ 0.07333203],\n","       [ 0.10006662],\n","       [ 0.04083776],\n","       [ 0.004094  ],\n","       [-0.00436088],\n","       [ 0.10063746],\n","       [-0.04769943],\n","       [-0.01218044],\n","       [-0.06419082],\n","       [-0.0608424 ],\n","       [-0.02732041],\n","       [-0.08501928],\n","       [ 0.05960741],\n","       [ 0.05358673],\n","       [ 0.04973557],\n","       [-0.03344526],\n","       [-0.0788665 ],\n","       [ 0.10434809],\n","       [-0.01801008],\n","       [ 0.08096286],\n","       [-0.00036474],\n","       [ 0.06756037],\n","       [ 0.01278686],\n","       [ 0.00053465],\n","       [ 0.05466963],\n","       [ 0.0199775 ],\n","       [ 0.03283228],\n","       [-0.01868478],\n","       [ 0.0649499 ],\n","       [-0.01332364],\n","       [ 0.04255997],\n","       [-0.06140097],\n","       [ 0.02408447],\n","       [-0.0966074 ],\n","       [-0.0107205 ],\n","       [ 0.096813  ],\n","       [ 0.06315684],\n","       [-0.05805684],\n","       [-0.0143253 ],\n","       [-0.02251219],\n","       [-0.09275687],\n","       [-0.09193515],\n","       [-0.04630367],\n","       [ 0.017111  ],\n","       [-0.04872631],\n","       [-0.10710821],\n","       [ 0.10768343],\n","       [ 0.09642776],\n","       [-0.0238123 ],\n","       [-0.0593867 ],\n","       [-0.03540076],\n","       [ 0.01708493],\n","       [ 0.03925287],\n","       [ 0.06823144],\n","       [ 0.05036298],\n","       [ 0.06977072],\n","       [-0.05587579],\n","       [-0.05996377],\n","       [ 0.06962086],\n","       [-0.08832775],\n","       [-0.07187506],\n","       [-0.03433257],\n","       [ 0.08692162],\n","       [-0.05878749],\n","       [ 0.03855466],\n","       [ 0.00065218],\n","       [-0.04952184],\n","       [ 0.10364275],\n","       [-0.10401964],\n","       [ 0.03921352],\n","       [-0.10070068],\n","       [-0.08784632],\n","       [-0.07498477],\n","       [ 0.02129379],\n","       [-0.06462424],\n","       [-0.01145723],\n","       [-0.0241585 ],\n","       [ 0.05578265],\n","       [-0.01687511],\n","       [ 0.05987783],\n","       [ 0.06074538],\n","       [-0.05468297],\n","       [-0.08765442],\n","       [ 0.07861833],\n","       [ 0.07671822],\n","       [ 0.02648637],\n","       [-0.06269586],\n","       [-0.06927813],\n","       [-0.051282  ],\n","       [-0.08570556],\n","       [-0.09887691],\n","       [-0.01530448],\n","       [-0.0120858 ],\n","       [-0.06418909],\n","       [-0.05585926],\n","       [-0.00966813],\n","       [ 0.05492751],\n","       [ 0.06335329],\n","       [-0.05104799],\n","       [-0.03382623],\n","       [ 0.08116385],\n","       [ 0.00318796],\n","       [ 0.09190615],\n","       [-0.10574022],\n","       [-0.02202608],\n","       [-0.02823055],\n","       [-0.06510448],\n","       [ 0.08481026],\n","       [-0.02776078],\n","       [-0.00053489],\n","       [ 0.03505054],\n","       [-0.00026015],\n","       [ 0.05058223],\n","       [ 0.03802276],\n","       [-0.07287346],\n","       [-0.02694652],\n","       [-0.10765189],\n","       [-0.0857708 ],\n","       [-0.06894325],\n","       [ 0.04651419],\n","       [-0.05306062],\n","       [ 0.05824571],\n","       [ 0.06246975],\n","       [-0.03052203],\n","       [-0.0341382 ],\n","       [ 0.0699905 ],\n","       [ 0.02563099],\n","       [-0.03454035],\n","       [ 0.06369222],\n","       [-0.01825287],\n","       [-0.0048484 ],\n","       [-0.03839277],\n","       [ 0.04737856],\n","       [ 0.04313295],\n","       [-0.02002452],\n","       [-0.03065282],\n","       [-0.10499103],\n","       [ 0.04153154],\n","       [-0.01835667],\n","       [ 0.04318742],\n","       [ 0.02307528],\n","       [-0.02561975],\n","       [ 0.07299834],\n","       [-0.03458566],\n","       [-0.01158135],\n","       [-0.05407526],\n","       [-0.0552104 ],\n","       [ 0.0215096 ],\n","       [ 0.10127964],\n","       [-0.05139145],\n","       [-0.00369789],\n","       [ 0.08457264],\n","       [ 0.05131396],\n","       [ 0.07480427],\n","       [ 0.10814904],\n","       [ 0.06204409],\n","       [-0.06618435],\n","       [ 0.01352894],\n","       [-0.05972625],\n","       [ 0.05132973],\n","       [ 0.01874396],\n","       [ 0.08960483],\n","       [ 0.05441261],\n","       [-0.037395  ],\n","       [ 0.030701  ],\n","       [-0.02977089],\n","       [ 0.03834245],\n","       [ 0.01624622],\n","       [-0.0339716 ],\n","       [-0.00959356],\n","       [ 0.08205806],\n","       [-0.02770789],\n","       [-0.02502125],\n","       [ 0.05081897],\n","       [ 0.00367594],\n","       [-0.04647822],\n","       [-0.00027261],\n","       [ 0.06671258],\n","       [ 0.09707693],\n","       [-0.05879511],\n","       [-0.08626698],\n","       [ 0.09891076],\n","       [-0.00179858],\n","       [ 0.10069733],\n","       [-0.04531445],\n","       [ 0.02753624],\n","       [-0.10552412],\n","       [-0.01244107],\n","       [ 0.0628899 ],\n","       [ 0.02456712],\n","       [ 0.06875412],\n","       [-0.02635077],\n","       [-0.01603482],\n","       [ 0.10584294],\n","       [ 0.09960879],\n","       [ 0.08471459],\n","       [ 0.01260938],\n","       [ 0.02697926],\n","       [-0.07590003],\n","       [-0.03777356],\n","       [-0.04400415],\n","       [-0.02920351],\n","       [ 0.00165193],\n","       [ 0.0096146 ],\n","       [-0.07188218],\n","       [-0.02860283],\n","       [ 0.07115302],\n","       [ 0.03954452],\n","       [-0.00756297],\n","       [ 0.07262386],\n","       [-0.10181704],\n","       [-0.07726691],\n","       [-0.00147468],\n","       [ 0.04408018],\n","       [-0.09326675],\n","       [-0.00166401],\n","       [ 0.00301491],\n","       [ 0.03956771],\n","       [ 0.0910758 ],\n","       [-0.03532962],\n","       [-0.00361807],\n","       [-0.08258905],\n","       [ 0.03659458],\n","       [-0.05703309],\n","       [-0.00912946],\n","       [ 0.07891455],\n","       [-0.09647379],\n","       [-0.05125718],\n","       [ 0.04589181],\n","       [-0.10774115],\n","       [-0.03308532],\n","       [ 0.07470026],\n","       [ 0.01906123],\n","       [ 0.03789943],\n","       [-0.09342199],\n","       [-0.10715405],\n","       [ 0.09128488],\n","       [ 0.03709681],\n","       [ 0.05062626],\n","       [-0.06908599],\n","       [-0.08983766],\n","       [ 0.04010718],\n","       [ 0.02790869],\n","       [ 0.06916813],\n","       [ 0.07618911],\n","       [ 0.06063336],\n","       [-0.09343842],\n","       [-0.07701907],\n","       [-0.09293506],\n","       [ 0.01351826],\n","       [-0.03032574],\n","       [-0.01754052],\n","       [ 0.08269938],\n","       [-0.0783914 ],\n","       [ 0.06229959],\n","       [-0.07255559],\n","       [ 0.00971134],\n","       [ 0.03935469],\n","       [ 0.09577183],\n","       [ 0.00341257],\n","       [ 0.08189125],\n","       [-0.0393534 ],\n","       [ 0.02047182],\n","       [ 0.03703768],\n","       [-0.09583645],\n","       [ 0.09808061],\n","       [ 0.02378944],\n","       [-0.02271055],\n","       [-0.08144809],\n","       [ 0.01734144],\n","       [ 0.0067852 ],\n","       [ 0.09336411],\n","       [ 0.0691969 ],\n","       [ 0.03514246],\n","       [ 0.0107354 ],\n","       [-0.10504194],\n","       [-0.00986685],\n","       [ 0.05476422],\n","       [ 0.00994883],\n","       [ 0.02664097],\n","       [ 0.10568521],\n","       [-0.04381768],\n","       [ 0.00958281],\n","       [ 0.07035249],\n","       [-0.0851427 ],\n","       [ 0.07234382],\n","       [ 0.08014662],\n","       [ 0.02974526],\n","       [ 0.03693184],\n","       [ 0.02298076],\n","       [-0.08794658],\n","       [ 0.03924475],\n","       [-0.09810404],\n","       [ 0.09414335],\n","       [ 0.09690887],\n","       [ 0.10142053],\n","       [-0.09666646],\n","       [ 0.08346065],\n","       [ 0.092736  ],\n","       [ 0.07344308],\n","       [-0.08867127],\n","       [-0.02729125],\n","       [ 0.08227269],\n","       [-0.07480886],\n","       [ 0.05823693],\n","       [ 0.1042522 ],\n","       [-0.07179864],\n","       [ 0.04899818],\n","       [-0.05795491],\n","       [-0.06684978],\n","       [ 0.01605562],\n","       [ 0.06989703],\n","       [-0.02133835],\n","       [ 0.01510988],\n","       [-0.09380572],\n","       [-0.04665544],\n","       [ 0.07928223],\n","       [ 0.04127658],\n","       [ 0.03334556],\n","       [ 0.0772189 ],\n","       [-0.0077934 ],\n","       [-0.08867537],\n","       [-0.08648331],\n","       [-0.09098285],\n","       [ 0.0549956 ],\n","       [ 0.09933659],\n","       [ 0.07806046],\n","       [-0.01020471],\n","       [ 0.01401955],\n","       [ 0.07783832],\n","       [-0.03024027],\n","       [ 0.02960523],\n","       [-0.04413151],\n","       [-0.08225599],\n","       [-0.09351809],\n","       [-0.04427084],\n","       [-0.02605443],\n","       [ 0.01764955],\n","       [ 0.08542388],\n","       [-0.10440602],\n","       [ 0.05794136],\n","       [ 0.04693203],\n","       [-0.09786601],\n","       [ 0.01755484],\n","       [-0.04858756],\n","       [ 0.07365433],\n","       [-0.07308237],\n","       [ 0.08439187],\n","       [ 0.07468929],\n","       [-0.0244526 ],\n","       [-0.07027248],\n","       [-0.01634645],\n","       [-0.10074162],\n","       [-0.0684437 ],\n","       [ 0.03794142],\n","       [-0.09264078],\n","       [-0.07716511],\n","       [-0.02268691],\n","       [-0.05748852],\n","       [ 0.09683382],\n","       [-0.02469745],\n","       [-0.07563815],\n","       [ 0.09184542],\n","       [ 0.07732004],\n","       [ 0.06521686],\n","       [-0.1023722 ],\n","       [-0.03826064],\n","       [ 0.07825085],\n","       [ 0.02770118],\n","       [-0.08078295],\n","       [ 0.0179246 ],\n","       [-0.00641417],\n","       [-0.01956135],\n","       [ 0.03950802],\n","       [-0.09180593],\n","       [ 0.0242714 ],\n","       [-0.01758216],\n","       [ 0.02992598],\n","       [-0.10654007],\n","       [ 0.05854044],\n","       [-0.0463255 ],\n","       [-0.07673807],\n","       [ 0.01806428],\n","       [ 0.03194661],\n","       [ 0.09341689],\n","       [ 0.02842157],\n","       [-0.01932918],\n","       [-0.00789934],\n","       [-0.09094357],\n","       [ 0.09410664],\n","       [ 0.04538193],\n","       [-0.0931062 ],\n","       [-0.01769847],\n","       [-0.03177357],\n","       [-0.03606311],\n","       [ 0.04608593],\n","       [-0.04314622],\n","       [ 0.10498165],\n","       [-0.02762671],\n","       [ 0.01765399],\n","       [ 0.10354471],\n","       [ 0.07538151],\n","       [-0.01932304],\n","       [-0.07110258],\n","       [-0.042787  ],\n","       [ 0.07530879],\n","       [ 0.01614098],\n","       [ 0.04663765],\n","       [-0.10281827],\n","       [-0.00842999],\n","       [-0.02892591],\n","       [-0.08267526],\n","       [-0.08735236],\n","       [-0.07911994],\n","       [ 0.10607175],\n","       [-0.10181464],\n","       [-0.0652168 ],\n","       [-0.03229479],\n","       [-0.06289003],\n","       [-0.10761634],\n","       [-0.10615932],\n","       [ 0.06332808],\n","       [-0.01420283],\n","       [ 0.08458667],\n","       [ 0.054321  ],\n","       [ 0.04193338],\n","       [ 0.03848181],\n","       [ 0.1062327 ],\n","       [ 0.00392488],\n","       [ 0.0076532 ],\n","       [ 0.00467257],\n","       [ 0.10555946],\n","       [ 0.07418532],\n","       [-0.05589434],\n","       [-0.01913521],\n","       [ 0.06675167],\n","       [-0.03429125],\n","       [ 0.01156645],\n","       [ 0.02960246],\n","       [ 0.07177024],\n","       [ 0.02085964],\n","       [ 0.02198514],\n","       [ 0.09869411],\n","       [-0.02074049],\n","       [ 0.09066512],\n","       [-0.04025452],\n","       [ 0.04336932],\n","       [ 0.02612361],\n","       [ 0.02635244],\n","       [-0.01451524],\n","       [-0.07162227],\n","       [-0.04437146],\n","       [-0.09136688],\n","       [ 0.02554321],\n","       [ 0.0307057 ],\n","       [-0.04345931],\n","       [-0.02885769],\n","       [-0.02186264],\n","       [-0.05157046],\n","       [ 0.00795774],\n","       [-0.04780273],\n","       [-0.07149729],\n","       [ 0.06967371],\n","       [-0.02703214],\n","       [ 0.00524126],\n","       [ 0.10340082],\n","       [ 0.05010157],\n","       [-0.03487127],\n","       [ 0.00157546],\n","       [ 0.069327  ],\n","       [ 0.06530724],\n","       [-0.09844978],\n","       [-0.02803532],\n","       [-0.07974207],\n","       [ 0.07191434],\n","       [ 0.02668228],\n","       [-0.02187546],\n","       [-0.09318973],\n","       [-0.0987836 ],\n","       [ 0.00722668],\n","       [-0.08275004],\n","       [ 0.05605371],\n","       [-0.1024542 ],\n","       [ 0.00305518],\n","       [-0.00037564],\n","       [ 0.03140793],\n","       [ 0.05991798],\n","       [ 0.03441107],\n","       [ 0.06860361],\n","       [-0.07270859],\n","       [-0.02717411],\n","       [-0.03393612],\n","       [ 0.03513216]], dtype=float32)>, <tf.Variable 'dense_1417/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>)\n","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-e6358e746e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mG_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# dense_648/bias:0', 'dense_649/bias:0', 'dense_650/bias:0', 'dense_651/bias:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m       raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m--> 595\u001b[0;31m                        ([str(v) for _, v, _ in converted_grads_and_vars],))\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: [\"<tf.Variable 'branch:0' shape=(1, 96, 96) dtype=float32, numpy=\\narray([[[-0.17124976, -0.00612853,  0.02693841, ...,  0.09423082,\\n         -0.06869898, -0.15583085],\\n        [ 0.14388566, -0.09416419,  0.08536948, ...,  0.04160286,\\n         -0.11115249, -0.02943265],\\n        [-0.07504942, -0.00312261, -0.04418468, ...,  0.08166297,\\n         -0.08313154,  0.12766092],\\n        ...,\\n        [ 0.10875945, -0.11524398, -0.15470771, ...,  0.15939306,\\n         -0.11113968, -0.07444145],\\n        [ 0.13815396, -0.1513868 , -0.04603797, ...,  0.05917324,\\n         -0.00923492, -0.1695537 ],\\n        [-0.01577602, -0.07664379,  0.04761051, ..., -0.11040017,\\n          0.00924799, -0.01771356]]], dtype=float32)>\", \"<tf.Variable 'bias:0' shape=(1, 1, 256) dtype=float32, numpy=\\narray([[[ 0.03263606, -0.00214846, -0.05671573,  0.01378067,\\n         -0.04249822, -0.02675778, -0.02989553, -0.03916933,\\n          0.03719559, -0.03398331, -0.05893196, -0.04862845,\\n          0.04835238,  0.02797213,  0.03563647,  0.04875752,\\n         -0.04508324, -0.02515644, -0.02662644,  0.05858535,\\n         -0.0383469 , -0.00185013, -0.02176498, -0.05635557,\\n          0.00182272,  0.05645181,  0.0178787 ,  0.00890538,\\n          0.01916757,  0.01242439,  0.03768034, -0.05461287,\\n         -0.03943121, -0.06099597, -0.02087736,  0.00737137,\\n         -0.00596675, -0.05783455, -0.0351005 ,  0.03694668,\\n          0.03656863,  0.0..."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77},"id":"2vRRF3iYxdg0","executionInfo":{"status":"ok","timestamp":1614719472297,"user_tz":300,"elapsed":350,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"98806bc4-2a23-493a-b579-3de38b62541c"},"source":["\r\n","# keras.utils.plot_model(D, show_shapes=True)\r\n","keras.utils.plot_model(G, show_shapes=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"RZ_AlC7ezynL"},"source":["class TreeGAN():\r\n","  def __init__(self, args, data):\r\n","    self.args = args\r\n","    self.G = Generator(batch_size=args.batch_size, features=args.G_FEAT, degrees=args.DEGREES, support=args.support)\r\n","    self.D = Discriminator(batch_size=args.batch_size, features=args.D_FEAT)\r\n","\r\n","    self.GP = GradientPenalty(args.lambdaGP, gamma=1)\r\n","    self.data = data\r\n","    self.num_samples = self.data.shape[0]\r\n","\r\n","    self.D_optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\r\n","    self.G_optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\r\n","    print(\"Network Prepared\") \r\n","\r\n","    # self.visualize = visdom.Visdom(port=args.visdom_port)\r\n","    # assert self.visualize.check_connection()\r\n","    # print(\"Visdom Connected\")\r\n","\r\n","  def run(self, save_d_ckpt=None, save_g_ckpt=None, load_g_ckpt=None, load_d_ckpt=None): # Add arguments for whether to save/load data\r\n","    # #visdom visualizations\r\n","    # color_num = self.args.visdom_color\r\n","    # chunk_size = int(self.args.point_num / color_num)\r\n","    # #color list\r\n","    # colors = np.array([(227,0,27),(231,64,28),(237,120,15),(246,176,44),\r\n","    #                        (252,234,0),(224,221,128),(142,188,40),(18,126,68),\r\n","    #                        (63,174,0),(113,169,156),(164,194,184),(51,186,216),\r\n","    #                        (0,152,206),(16,68,151),(57,64,139),(96,72,132),\r\n","    #                        (172,113,161),(202,174,199),(145,35,132),(201,47,133),\r\n","    #                        (229,0,123),(225,106,112),(163,38,42),(128,128,128)])\r\n","    # #randomly choose color from list\r\n","    # colors = colors[np.random.choice(len(colors), color_num, replace=False)]\r\n","    # label = tf.stack([tf.ones(chunk_size) * inx for inx in range(1,int(color_num)+1)], axis=0).view(-1)\r\n","\r\n","    # Add option to load trained model parameters\r\n","    if not load_g_ckpt == None:\r\n","      self.G.load_weights(load_g_ckpt)\r\n","      print(\"Generator Checkpoint Loaded\")\r\n","    if not load_d_ckpt == None:\r\n","      self.D.load_weights(load_d_ckpt)\r\n","      print(\"Discriminator Checkpoint Loaded\")\r\n","\r\n","    #training loop (for one epoch)\r\n","    for epoch in range(1):\r\n","      # for batch in range(self.args.batch_size):\r\n","      # for i in range(batch * self.args.batch_size, (batch + 1) * self.args.batch_size):\r\n","      for  i in range(self.num_samples):\r\n","        start_time = time.time()\r\n","        half_batch = int (self.args.batch_size / 2)\r\n","\r\n","        # -------Discriminator------- #\r\n","        d_loss_sum = 0\r\n","        for iter in range(self.args.D_iter):\r\n","          # Generate latent vectors\r\n","          # latent = np.random.randn(self.args.latent_dim * self.args.batch_size)\r\n","          # latent = latent.reshape(self.args.batch_size, self.args.latent_dim)\r\n","          # BATCH_SIZE = 1 come back and fix\r\n","          latent = [tf.random.uniform((1,1,  1, 96))]\r\n","          # Generate fake points using Generator network\r\n","          fake_point = self.G(latent)\r\n","          if i == 1:\r\n","            print(\"GENERATED IMAGE \", fake_point.shape )\r\n","          # Need to get real points\r\n","          with tf.GradientTape() as tape:\r\n","            real_point = self.data[i]\r\n","\r\n","            # Calculate loss on fake points (mean over a batch)\r\n","            loss_f = self.D(fake_point)\r\n","            loss_f_mean = np.mean(loss_f)\r\n","            \r\n","            # Calculate loss on real points (mean over a batch)\r\n","            loss_r = self.D(real_point)\r\n","            loss_r_mean = np.mean(loss_r)\r\n","\r\n","            # Get total loss and apply gradient penalty to it\r\n","\r\n","            d_loss = -loss_r_mean + loss_f_mean\r\n","            \r\n","            d_loss = d_loss + self.GP(self.D, real_point, fake_point)\r\n","\r\n","            \r\n","\r\n","            # Calculate gradients and backpropogate through discriminator network\r\n","            print(\"WEIGHTS\")\r\n","            print(d_loss)\r\n","            # print(np.array(self.D.trainable_weights).shape)\r\n","\r\n","          # FIX THIS ALSO G WEIGHTS\r\n","\r\n","          # d_gradients = tf.GradientTape.gradient(d_loss, self.D.trainable_weights)\r\n","          d_gradients = tape.gradient(d_loss, self.D.trainable_weights)\r\n","          # d_gradients = tf.GradientTape.gradient(self.D.trainable_weights)\r\n","\r\n","          self.D_optimizer.apply_gradients(zip(d_gradients, self.D.trainable_weights))\r\n","          \r\n","        # -------Generator-------- #\r\n","        # Create latent vector\r\n","        # latent = np.random.randn(self.args.latent_dim * self.args.batch_size)\r\n","        # latent = latent.reshape(self.args.batch_size, self.args.latent_dim)\r\n","        # BATCH_SIZE = 1 come back and fix\r\n","        latent = [tf.random.uniform((1,1,  1, 96))]\r\n","\r\n","        # Use latent vector to generate examples\r\n","        \r\n","        \r\n","        # Calculate mean loss using discriminator\r\n","        with tf.GradientTape() as tape2:\r\n","          fake_point = self.G(latent)\r\n","          G_fake = self.D(fake_point)\r\n","          G_fake_mean = np.mean(G_fake)\r\n","          g_loss = -G_fake_mean\r\n","\r\n","\r\n","        # Apply gradients and backpropograte to train\r\n","\r\n","          #   HERE\r\n","          print(\"G LOSS\")\r\n","          g_loss = tf.Variable(g_loss, dtype=tf.float32)\r\n","          print(\"Disc watched variables: \", self.watched_variables)\r\n","          print(\"Gen Watched Variables: \", tape2.watched_variables)\r\n","        \r\n","        g_gradients = tape2.gradient(g_loss, self.G.trainable_weights)\r\n","\r\n","        print(g_gradients)\r\n","        self.G_optimizer.apply_gradients(zip(g_gradients, self.G.trainable_weights))\r\n","\r\n","model = TreeGAN(real_args(), male_30_train)\r\n","model.run()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22wEcWSIUvCS","executionInfo":{"status":"ok","timestamp":1614208269372,"user_tz":300,"elapsed":1723,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"0a69a203-dc1a-48b5-fd5a-6d4fc9e5eae8"},"source":["b_size = 1\n","# depth = 0\n","features = [96, 256, 256, 256, 128, 128, 128, 3]\n","degrees = [1, 2, 2, 2, 2, 3, 64]\n","support = 10\n","node = 1\n","\n","# model = Sequential()\n","# model.add(TreeGCN(b_size, depth, features, degrees, \n","#                                           support=support, node=node, upsample=True, activation=True))\n","# model.add(TreeGCN(b_size, 1, features, degrees, \n","#                                         support=support, node=96, upsample=True, activation=False))\n","\n","#Functional API Implementation of TreeGCN\n","model_inputs = keras.Input(shape=(1, 1, 96,))\n","outputs = TreeGCN(b_size, 0, features, degrees, support=support, node=node, upsample=True, activation=True)(model_inputs)\n","outputs = TreeGCN(b_size, 1, features, degrees, support=support, node=node, upsample=True, activation=True)(outputs)\n","outputs = TreeGCN(b_size, 2, features, degrees, support=support, node=2, upsample=True, activation=True)(outputs)\n","outputs = TreeGCN(b_size, 3, features, degrees, support=support, node=4, upsample=True, activation=False)(outputs)\n","model = keras.Model(model_inputs, outputs, name='TreeGCN')\n","\n","\n","print(model.summary())\n","\n","\n","# Make latent vector random Tensor, then put it into a list: [Tensor] so you can append to it. Input shape of the tensor should be (batch_size, 1, 96)\n","\n","\n","\n","z = tf.random.uniform((1,1,  1, 96))\n","tree = [z]\n","print(tree)\n","print(np.shape(tree))\n","print(\"FINAL OUTPUT\")\n","y = model([tree])\n","# print(y)\n","print([ele.shape for ele in y])\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","Tree INDEX:  0 0\n","Tensor(\"tree_gcn_22/strided_slice:0\", shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 1\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_104_input'), name='dense_104_input', description=\"created by layer 'dense_104_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","Root Node\n","Tensor(\"tree_gcn_22/sequential_81/dense_104/Tensordot:0\", shape=(1, 1, 256), dtype=float32)\n","Tensor(\"tree_gcn_22/Shape:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_22/Tile:0\", shape=(1, 1, 256), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_22/add:0\", shape=(1, 1, 256), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(1, 96, 96) dtype=float32>\n","branch shape after EXPAND DIMS Tensor(\"tree_gcn_22/matmul:0\", shape=(1, 1, 1, 96), dtype=float32)\n","BRANCH AFTER RESHAPE\n","Tensor(\"tree_gcn_22/Reshape_1:0\", shape=(1, 1, 96), dtype=float32)\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_105_input'), name='dense_105_input', description=\"created by layer 'dense_105_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","Branch W_loop call\n","Tensor(\"tree_gcn_22/sequential_82/dense_106/Tensordot:0\", shape=(1, 1, 256), dtype=float32)\n","BRANCH AFTER RE TILE\n","Tensor(\"tree_gcn_22/add_1:0\", shape=(1, 1, 256), dtype=float32)\n","0\n","Tree INDEX:  0 1\n","Tensor(\"Placeholder:0\", shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 1\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_107_input'), name='dense_107_input', description=\"created by layer 'dense_107_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","Root Node\n","Tensor(\"tree_gcn_23/sequential_83/dense_107/Tensordot:0\", shape=(1, 1, 256), dtype=float32)\n","Tensor(\"tree_gcn_23/Shape:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_23/Tile:0\", shape=(1, 1, 256), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_23/add:0\", shape=(1, 1, 256), dtype=float32)\n","1\n","Tree INDEX:  1 1\n","Tensor(\"Placeholder_1:0\", shape=(1, 1, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 1\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_108_input'), name='dense_108_input', description=\"created by layer 'dense_108_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","Root Node\n","Tensor(\"tree_gcn_23/sequential_84/dense_108/Tensordot:0\", shape=(1, 1, 256), dtype=float32)\n","Tensor(\"tree_gcn_23/Shape_1:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_23/Tile_1:0\", shape=(1, 1, 256), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_23/add_1:0\", shape=(1, 1, 256), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(1, 256, 512) dtype=float32>\n","branch shape after EXPAND DIMS Tensor(\"tree_gcn_23/matmul:0\", shape=(1, 1, 1, 512), dtype=float32)\n","BRANCH AFTER RESHAPE\n","Tensor(\"tree_gcn_23/Reshape_2:0\", shape=(1, 2, 256), dtype=float32)\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_109_input'), name='dense_109_input', description=\"created by layer 'dense_109_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","Branch W_loop call\n","Tensor(\"tree_gcn_23/sequential_85/dense_110/Tensordot:0\", shape=(1, 2, 256), dtype=float32)\n","BRANCH AFTER RE TILE\n","Tensor(\"tree_gcn_23/add_2:0\", shape=(1, 2, 256), dtype=float32)\n","0\n","Tree INDEX:  0 2\n","Tensor(\"Placeholder:0\", shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 2\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_111_input'), name='dense_111_input', description=\"created by layer 'dense_111_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","Root Node\n","Tensor(\"tree_gcn_24/sequential_86/dense_111/Tensordot:0\", shape=(1, 1, 256), dtype=float32)\n","Tensor(\"tree_gcn_24/Shape:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_24/Tile:0\", shape=(1, 1, 512), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_24/add:0\", shape=(1, 2, 256), dtype=float32)\n","1\n","Tree INDEX:  1 2\n","Tensor(\"Placeholder_1:0\", shape=(1, 1, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 2\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_112_input'), name='dense_112_input', description=\"created by layer 'dense_112_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","Root Node\n","Tensor(\"tree_gcn_24/sequential_87/dense_112/Tensordot:0\", shape=(1, 1, 256), dtype=float32)\n","Tensor(\"tree_gcn_24/Shape_1:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_24/Tile_1:0\", shape=(1, 1, 512), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_24/add_1:0\", shape=(1, 2, 256), dtype=float32)\n","2\n","Tree INDEX:  2 2\n","Tensor(\"Placeholder_2:0\", shape=(1, 2, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","2 1\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_113_input'), name='dense_113_input', description=\"created by layer 'dense_113_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","Root Node\n","Tensor(\"tree_gcn_24/sequential_88/dense_113/Tensordot:0\", shape=(1, 2, 256), dtype=float32)\n","Tensor(\"tree_gcn_24/Shape_2:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_24/Tile_2:0\", shape=(1, 2, 256), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_24/add_2:0\", shape=(1, 2, 256), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(2, 256, 512) dtype=float32>\n","branch shape after EXPAND DIMS Tensor(\"tree_gcn_24/matmul:0\", shape=(1, 2, 1, 512), dtype=float32)\n","BRANCH AFTER RESHAPE\n","Tensor(\"tree_gcn_24/Reshape_3:0\", shape=(1, 4, 256), dtype=float32)\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_114_input'), name='dense_114_input', description=\"created by layer 'dense_114_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","Branch W_loop call\n","Tensor(\"tree_gcn_24/sequential_89/dense_115/Tensordot:0\", shape=(1, 4, 256), dtype=float32)\n","BRANCH AFTER RE TILE\n","Tensor(\"tree_gcn_24/add_3:0\", shape=(1, 4, 256), dtype=float32)\n","0\n","Tree INDEX:  0 3\n","Tensor(\"Placeholder:0\", shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 4\n","WARNING:tensorflow:Model was constructed with shape (None, 96) for input KerasTensor(type_spec=TensorSpec(shape=(None, 96), dtype=tf.float32, name='dense_116_input'), name='dense_116_input', description=\"created by layer 'dense_116_input'\"), but it was called on an input with incompatible shape (1, 1, 96).\n","Root Node\n","Tensor(\"tree_gcn_25/sequential_90/dense_116/Tensordot:0\", shape=(1, 1, 128), dtype=float32)\n","Tensor(\"tree_gcn_25/Shape:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_25/Tile:0\", shape=(1, 1, 512), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_25/add:0\", shape=(1, 4, 128), dtype=float32)\n","1\n","Tree INDEX:  1 3\n","Tensor(\"Placeholder_1:0\", shape=(1, 1, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 4\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_117_input'), name='dense_117_input', description=\"created by layer 'dense_117_input'\"), but it was called on an input with incompatible shape (1, 1, 256).\n","Root Node\n","Tensor(\"tree_gcn_25/sequential_91/dense_117/Tensordot:0\", shape=(1, 1, 128), dtype=float32)\n","Tensor(\"tree_gcn_25/Shape_1:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_25/Tile_1:0\", shape=(1, 1, 512), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_25/add_1:0\", shape=(1, 4, 128), dtype=float32)\n","2\n","Tree INDEX:  2 3\n","Tensor(\"Placeholder_2:0\", shape=(1, 2, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","2 2\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_118_input'), name='dense_118_input', description=\"created by layer 'dense_118_input'\"), but it was called on an input with incompatible shape (1, 2, 256).\n","Root Node\n","Tensor(\"tree_gcn_25/sequential_92/dense_118/Tensordot:0\", shape=(1, 2, 128), dtype=float32)\n","Tensor(\"tree_gcn_25/Shape_2:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_25/Tile_2:0\", shape=(1, 2, 256), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_25/add_2:0\", shape=(1, 4, 128), dtype=float32)\n","3\n","Tree INDEX:  3 3\n","Tensor(\"Placeholder_3:0\", shape=(1, 4, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","4 1\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_119_input'), name='dense_119_input', description=\"created by layer 'dense_119_input'\"), but it was called on an input with incompatible shape (1, 4, 256).\n","Root Node\n","Tensor(\"tree_gcn_25/sequential_93/dense_119/Tensordot:0\", shape=(1, 4, 128), dtype=float32)\n","Tensor(\"tree_gcn_25/Shape_3:0\", shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","Tensor(\"tree_gcn_25/Tile_3:0\", shape=(1, 4, 128), dtype=float32)\n","ROOT\n","Tensor(\"tree_gcn_25/add_3:0\", shape=(1, 4, 128), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(4, 256, 512) dtype=float32>\n","branch shape after EXPAND DIMS Tensor(\"tree_gcn_25/matmul:0\", shape=(1, 4, 1, 512), dtype=float32)\n","BRANCH AFTER RESHAPE\n","Tensor(\"tree_gcn_25/Reshape_4:0\", shape=(1, 8, 256), dtype=float32)\n","WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='dense_120_input'), name='dense_120_input', description=\"created by layer 'dense_120_input'\"), but it was called on an input with incompatible shape (1, 8, 256).\n","Branch W_loop call\n","Tensor(\"tree_gcn_25/sequential_94/dense_121/Tensordot:0\", shape=(1, 8, 128), dtype=float32)\n","BRANCH AFTER RE TILE\n","Tensor(\"tree_gcn_25/add_4:0\", shape=(1, 8, 128), dtype=float32)\n","Model: \"TreeGCN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 1, 1, 96)]   0                                            \n","__________________________________________________________________________________________________\n","tree_gcn_22 (TreeGCN)           [(1, 1, 96), (1, 1,  371968      input_7[0][0]                    \n","__________________________________________________________________________________________________\n","tree_gcn_23 (TreeGCN)           [(1, 1, 96), (1, 1,  1532416     tree_gcn_22[0][0]                \n","                                                                 tree_gcn_22[0][1]                \n","__________________________________________________________________________________________________\n","tree_gcn_24 (TreeGCN)           [(1, 1, 96), (1, 1,  1729024     tree_gcn_23[0][0]                \n","                                                                 tree_gcn_23[0][1]                \n","                                                                 tree_gcn_23[0][2]                \n","__________________________________________________________________________________________________\n","tree_gcn_25 (TreeGCN)           [(1, 1, 96), (1, 1,  1618176     tree_gcn_24[0][0]                \n","                                                                 tree_gcn_24[0][1]                \n","                                                                 tree_gcn_24[0][2]                \n","                                                                 tree_gcn_24[0][3]                \n","==================================================================================================\n","Total params: 5,251,584\n","Trainable params: 5,251,584\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","[<tf.Tensor: shape=(1, 1, 1, 96), dtype=float32, numpy=\n","array([[[[0.01047182, 0.59066546, 0.39506686, 0.6289226 , 0.61416733,\n","          0.11192453, 0.30162597, 0.92322063, 0.06005347, 0.4205227 ,\n","          0.5107981 , 0.7969223 , 0.9080839 , 0.57025886, 0.2834581 ,\n","          0.90183246, 0.9557593 , 0.9391173 , 0.2427814 , 0.40333366,\n","          0.5925106 , 0.5375744 , 0.6049135 , 0.6379062 , 0.83508635,\n","          0.6918887 , 0.01023054, 0.8498752 , 0.24461305, 0.33344865,\n","          0.88443565, 0.50010383, 0.06586492, 0.14401078, 0.9661263 ,\n","          0.07820046, 0.8140285 , 0.32176793, 0.48425317, 0.39198327,\n","          0.75259864, 0.44515467, 0.00307918, 0.4255302 , 0.6385578 ,\n","          0.7718121 , 0.01598752, 0.8888041 , 0.7453935 , 0.9360999 ,\n","          0.469962  , 0.33280253, 0.62882626, 0.30295599, 0.8215525 ,\n","          0.13067889, 0.2499367 , 0.43057394, 0.4070083 , 0.10915458,\n","          0.66520846, 0.10049736, 0.3901155 , 0.69108176, 0.11987472,\n","          0.9388958 , 0.39744174, 0.48599482, 0.8281683 , 0.17230654,\n","          0.7776722 , 0.5991373 , 0.97225726, 0.25942183, 0.28829956,\n","          0.40875483, 0.95815384, 0.5111251 , 0.09509945, 0.65893793,\n","          0.51377916, 0.574008  , 0.17741227, 0.9151815 , 0.48197544,\n","          0.5930363 , 0.9448329 , 0.66817796, 0.83241916, 0.9848572 ,\n","          0.92965066, 0.6101297 , 0.10795307, 0.8371556 , 0.8690964 ,\n","          0.47578883]]]], dtype=float32)>]\n","(1, 1, 1, 1, 96)\n","FINAL OUTPUT\n","0\n","Tree INDEX:  0 0\n","tf.Tensor(\n","[[[0.01047182 0.59066546 0.39506686 0.6289226  0.61416733 0.11192453\n","   0.30162597 0.92322063 0.06005347 0.4205227  0.5107981  0.7969223\n","   0.9080839  0.57025886 0.2834581  0.90183246 0.9557593  0.9391173\n","   0.2427814  0.40333366 0.5925106  0.5375744  0.6049135  0.6379062\n","   0.83508635 0.6918887  0.01023054 0.8498752  0.24461305 0.33344865\n","   0.88443565 0.50010383 0.06586492 0.14401078 0.9661263  0.07820046\n","   0.8140285  0.32176793 0.48425317 0.39198327 0.75259864 0.44515467\n","   0.00307918 0.4255302  0.6385578  0.7718121  0.01598752 0.8888041\n","   0.7453935  0.9360999  0.469962   0.33280253 0.62882626 0.30295599\n","   0.8215525  0.13067889 0.2499367  0.43057394 0.4070083  0.10915458\n","   0.66520846 0.10049736 0.3901155  0.69108176 0.11987472 0.9388958\n","   0.39744174 0.48599482 0.8281683  0.17230654 0.7776722  0.5991373\n","   0.97225726 0.25942183 0.28829956 0.40875483 0.95815384 0.5111251\n","   0.09509945 0.65893793 0.51377916 0.574008   0.17741227 0.9151815\n","   0.48197544 0.5930363  0.9448329  0.66817796 0.83241916 0.9848572\n","   0.92965066 0.6101297  0.10795307 0.8371556  0.8690964  0.47578883]]], shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 1\n","Root Node\n","tf.Tensor(\n","[[[-0.49843028  0.45793402 -0.16099502 -0.39898732  0.3786369\n","   -0.11791149  0.48162946  0.18106616  0.38755205  0.27463087\n","   -0.30986732  0.19577435 -0.9086685  -0.654822   -0.5285517\n","    0.11366641  0.4037282  -0.5760555  -0.115002    0.05136856\n","    0.68085855  0.6248358   0.25758398 -0.1955764   0.16356704\n","    0.22683382 -0.5448642  -0.32136178 -0.37832412 -0.4802328\n","    0.05141962  0.5001621  -0.40545434 -0.18385573 -0.0251427\n","   -0.27787393  0.39930874 -0.34720808  0.42142218 -0.26454198\n","   -0.05613063 -0.26499343 -0.2778236  -0.27269888  0.08480242\n","   -0.37246692  0.95231664 -0.1941241  -0.26917037  0.09518296\n","   -0.22504023 -0.21332717  0.01925512  0.4533709   0.11824452\n","   -0.03795948  0.14410843  0.26247373 -0.0114429   0.39910346\n","   -0.01743707 -0.40045106 -0.62042624  0.04849593  0.16038445\n","    0.3626857  -0.2819208  -0.76865405  0.01722379 -0.658095\n","   -0.31208077  0.50535107 -0.33386508  0.16690801 -0.44402653\n","    0.58019745  0.04607891  1.0415134  -0.4219187   0.3153422\n","   -0.1862858  -0.13687901  0.4290585  -0.37038    -0.3188713\n","    0.16878185  0.41241413  0.7030036   0.24619454  0.00144289\n","    0.1798493  -0.00405058 -0.5190508  -0.05446572  0.18865116\n","   -0.3108497  -0.7724172   0.20972677 -0.11232775  0.62360024\n","   -0.5641455   0.5173346   0.3087312   0.13627435 -0.3544734\n","   -0.06765945  0.11233938 -0.2441862  -0.442015    0.42526504\n","   -0.36355773  0.10198657 -0.11844337  0.35935917 -0.50108755\n","   -0.10446005 -0.32879603 -0.1517911   0.25380152 -0.6973863\n","    0.16240564  0.14658234 -0.41227975 -0.5362046   0.03039384\n","   -0.08960249  0.51451814 -0.2099849   0.7244014  -0.09263824\n","   -0.4591897   0.34484193 -0.3963511   0.39510822 -0.5700536\n","   -0.5553004  -0.0823963   0.11509328 -0.6519867   0.21993908\n","   -0.6852629   0.30615103  0.14354971  0.2269372   0.35466406\n","    0.75825894  0.34421706 -0.22468805  0.31654823  0.7808417\n","   -0.42868024 -0.4148348  -0.09450413  0.6851285   0.69694215\n","   -0.43919817  0.4730789  -0.11401068 -0.10092831 -0.80277777\n","    0.0109844  -0.8403803  -0.19419023  0.18827666  0.25938016\n","    0.4056096  -0.38051757 -0.54675674 -0.45345205 -0.69126874\n","   -0.11838472  0.46339816 -1.1231165  -0.27315742  0.38797203\n","   -0.23100856  0.8964259   0.64130604  0.56117356 -0.14932245\n","   -0.15036249 -0.05641999 -0.09643743  0.14830866  0.16126947\n","    0.14725788  0.5393308  -0.27818483 -0.29178014 -0.82374734\n","    0.22305739 -0.51469964  0.71956146  0.28305018  0.22318207\n","    0.35056064 -0.6959506  -0.46344548 -0.6142471  -0.05741679\n","   -0.2813458  -0.8244682   0.22503224 -0.5960386  -0.4026037\n","   -0.45507258  0.07501081 -0.19959714  0.48336944 -0.5020873\n","   -0.966852    0.2212893  -0.41503063 -0.33351377 -0.4002179\n","    0.49026567  0.37026793  0.1305161  -0.12281334  0.83401877\n","    0.21978404  0.16769947  0.37582853 -0.34315953 -0.7694219\n","    0.29936412  0.93331164  0.15992703 -0.2344577  -0.776544\n","    0.4731467   0.05145236 -1.047768    0.13823423 -0.15069407\n","   -0.25377062 -0.35175022  0.29079002 -0.6126096  -0.4085325\n","    0.42134002  0.03745731 -0.5368936  -0.30318308 -0.12356469\n","    0.81101227 -0.39804786  0.23913568 -0.08049142  0.00488677\n","    0.8579061   0.2235747  -0.4281533   0.01115248 -0.15960917\n","   -0.26749447]]], shape=(1, 1, 256), dtype=float32)\n","tf.Tensor([  1   1 256], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[-0.49843028  0.45793402 -0.16099502 -0.39898732  0.3786369\n","   -0.11791149  0.48162946  0.18106616  0.38755205  0.27463087\n","   -0.30986732  0.19577435 -0.9086685  -0.654822   -0.5285517\n","    0.11366641  0.4037282  -0.5760555  -0.115002    0.05136856\n","    0.68085855  0.6248358   0.25758398 -0.1955764   0.16356704\n","    0.22683382 -0.5448642  -0.32136178 -0.37832412 -0.4802328\n","    0.05141962  0.5001621  -0.40545434 -0.18385573 -0.0251427\n","   -0.27787393  0.39930874 -0.34720808  0.42142218 -0.26454198\n","   -0.05613063 -0.26499343 -0.2778236  -0.27269888  0.08480242\n","   -0.37246692  0.95231664 -0.1941241  -0.26917037  0.09518296\n","   -0.22504023 -0.21332717  0.01925512  0.4533709   0.11824452\n","   -0.03795948  0.14410843  0.26247373 -0.0114429   0.39910346\n","   -0.01743707 -0.40045106 -0.62042624  0.04849593  0.16038445\n","    0.3626857  -0.2819208  -0.76865405  0.01722379 -0.658095\n","   -0.31208077  0.50535107 -0.33386508  0.16690801 -0.44402653\n","    0.58019745  0.04607891  1.0415134  -0.4219187   0.3153422\n","   -0.1862858  -0.13687901  0.4290585  -0.37038    -0.3188713\n","    0.16878185  0.41241413  0.7030036   0.24619454  0.00144289\n","    0.1798493  -0.00405058 -0.5190508  -0.05446572  0.18865116\n","   -0.3108497  -0.7724172   0.20972677 -0.11232775  0.62360024\n","   -0.5641455   0.5173346   0.3087312   0.13627435 -0.3544734\n","   -0.06765945  0.11233938 -0.2441862  -0.442015    0.42526504\n","   -0.36355773  0.10198657 -0.11844337  0.35935917 -0.50108755\n","   -0.10446005 -0.32879603 -0.1517911   0.25380152 -0.6973863\n","    0.16240564  0.14658234 -0.41227975 -0.5362046   0.03039384\n","   -0.08960249  0.51451814 -0.2099849   0.7244014  -0.09263824\n","   -0.4591897   0.34484193 -0.3963511   0.39510822 -0.5700536\n","   -0.5553004  -0.0823963   0.11509328 -0.6519867   0.21993908\n","   -0.6852629   0.30615103  0.14354971  0.2269372   0.35466406\n","    0.75825894  0.34421706 -0.22468805  0.31654823  0.7808417\n","   -0.42868024 -0.4148348  -0.09450413  0.6851285   0.69694215\n","   -0.43919817  0.4730789  -0.11401068 -0.10092831 -0.80277777\n","    0.0109844  -0.8403803  -0.19419023  0.18827666  0.25938016\n","    0.4056096  -0.38051757 -0.54675674 -0.45345205 -0.69126874\n","   -0.11838472  0.46339816 -1.1231165  -0.27315742  0.38797203\n","   -0.23100856  0.8964259   0.64130604  0.56117356 -0.14932245\n","   -0.15036249 -0.05641999 -0.09643743  0.14830866  0.16126947\n","    0.14725788  0.5393308  -0.27818483 -0.29178014 -0.82374734\n","    0.22305739 -0.51469964  0.71956146  0.28305018  0.22318207\n","    0.35056064 -0.6959506  -0.46344548 -0.6142471  -0.05741679\n","   -0.2813458  -0.8244682   0.22503224 -0.5960386  -0.4026037\n","   -0.45507258  0.07501081 -0.19959714  0.48336944 -0.5020873\n","   -0.966852    0.2212893  -0.41503063 -0.33351377 -0.4002179\n","    0.49026567  0.37026793  0.1305161  -0.12281334  0.83401877\n","    0.21978404  0.16769947  0.37582853 -0.34315953 -0.7694219\n","    0.29936412  0.93331164  0.15992703 -0.2344577  -0.776544\n","    0.4731467   0.05145236 -1.047768    0.13823423 -0.15069407\n","   -0.25377062 -0.35175022  0.29079002 -0.6126096  -0.4085325\n","    0.42134002  0.03745731 -0.5368936  -0.30318308 -0.12356469\n","    0.81101227 -0.39804786  0.23913568 -0.08049142  0.00488677\n","    0.8579061   0.2235747  -0.4281533   0.01115248 -0.15960917\n","   -0.26749447]]], shape=(1, 1, 256), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[-0.49843028  0.45793402 -0.16099502 -0.39898732  0.3786369\n","   -0.11791149  0.48162946  0.18106616  0.38755205  0.27463087\n","   -0.30986732  0.19577435 -0.9086685  -0.654822   -0.5285517\n","    0.11366641  0.4037282  -0.5760555  -0.115002    0.05136856\n","    0.68085855  0.6248358   0.25758398 -0.1955764   0.16356704\n","    0.22683382 -0.5448642  -0.32136178 -0.37832412 -0.4802328\n","    0.05141962  0.5001621  -0.40545434 -0.18385573 -0.0251427\n","   -0.27787393  0.39930874 -0.34720808  0.42142218 -0.26454198\n","   -0.05613063 -0.26499343 -0.2778236  -0.27269888  0.08480242\n","   -0.37246692  0.95231664 -0.1941241  -0.26917037  0.09518296\n","   -0.22504023 -0.21332717  0.01925512  0.4533709   0.11824452\n","   -0.03795948  0.14410843  0.26247373 -0.0114429   0.39910346\n","   -0.01743707 -0.40045106 -0.62042624  0.04849593  0.16038445\n","    0.3626857  -0.2819208  -0.76865405  0.01722379 -0.658095\n","   -0.31208077  0.50535107 -0.33386508  0.16690801 -0.44402653\n","    0.58019745  0.04607891  1.0415134  -0.4219187   0.3153422\n","   -0.1862858  -0.13687901  0.4290585  -0.37038    -0.3188713\n","    0.16878185  0.41241413  0.7030036   0.24619454  0.00144289\n","    0.1798493  -0.00405058 -0.5190508  -0.05446572  0.18865116\n","   -0.3108497  -0.7724172   0.20972677 -0.11232775  0.62360024\n","   -0.5641455   0.5173346   0.3087312   0.13627435 -0.3544734\n","   -0.06765945  0.11233938 -0.2441862  -0.442015    0.42526504\n","   -0.36355773  0.10198657 -0.11844337  0.35935917 -0.50108755\n","   -0.10446005 -0.32879603 -0.1517911   0.25380152 -0.6973863\n","    0.16240564  0.14658234 -0.41227975 -0.5362046   0.03039384\n","   -0.08960249  0.51451814 -0.2099849   0.7244014  -0.09263824\n","   -0.4591897   0.34484193 -0.3963511   0.39510822 -0.5700536\n","   -0.5553004  -0.0823963   0.11509328 -0.6519867   0.21993908\n","   -0.6852629   0.30615103  0.14354971  0.2269372   0.35466406\n","    0.75825894  0.34421706 -0.22468805  0.31654823  0.7808417\n","   -0.42868024 -0.4148348  -0.09450413  0.6851285   0.69694215\n","   -0.43919817  0.4730789  -0.11401068 -0.10092831 -0.80277777\n","    0.0109844  -0.8403803  -0.19419023  0.18827666  0.25938016\n","    0.4056096  -0.38051757 -0.54675674 -0.45345205 -0.69126874\n","   -0.11838472  0.46339816 -1.1231165  -0.27315742  0.38797203\n","   -0.23100856  0.8964259   0.64130604  0.56117356 -0.14932245\n","   -0.15036249 -0.05641999 -0.09643743  0.14830866  0.16126947\n","    0.14725788  0.5393308  -0.27818483 -0.29178014 -0.82374734\n","    0.22305739 -0.51469964  0.71956146  0.28305018  0.22318207\n","    0.35056064 -0.6959506  -0.46344548 -0.6142471  -0.05741679\n","   -0.2813458  -0.8244682   0.22503224 -0.5960386  -0.4026037\n","   -0.45507258  0.07501081 -0.19959714  0.48336944 -0.5020873\n","   -0.966852    0.2212893  -0.41503063 -0.33351377 -0.4002179\n","    0.49026567  0.37026793  0.1305161  -0.12281334  0.83401877\n","    0.21978404  0.16769947  0.37582853 -0.34315953 -0.7694219\n","    0.29936412  0.93331164  0.15992703 -0.2344577  -0.776544\n","    0.4731467   0.05145236 -1.047768    0.13823423 -0.15069407\n","   -0.25377062 -0.35175022  0.29079002 -0.6126096  -0.4085325\n","    0.42134002  0.03745731 -0.5368936  -0.30318308 -0.12356469\n","    0.81101227 -0.39804786  0.23913568 -0.08049142  0.00488677\n","    0.8579061   0.2235747  -0.4281533   0.01115248 -0.15960917\n","   -0.26749447]]], shape=(1, 1, 256), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(1, 96, 96) dtype=float32, numpy=\n","array([[[ 0.17068736, -0.13117583,  0.12907593, ..., -0.09014111,\n","          0.03416166,  0.13259305],\n","        [ 0.07713743,  0.05675933,  0.11062725, ...,  0.04912624,\n","         -0.17443375, -0.17440875],\n","        [-0.12228774, -0.02971786,  0.07118455, ...,  0.03616212,\n","          0.05871642, -0.15641463],\n","        ...,\n","        [ 0.04347052,  0.08276729, -0.10545331, ...,  0.1169564 ,\n","          0.08614986, -0.00968985],\n","        [ 0.04321046, -0.05320782,  0.15476225, ...,  0.12549986,\n","          0.07279705,  0.0944186 ],\n","        [-0.13057236, -0.07154731, -0.11032692, ...,  0.10610501,\n","          0.13029845, -0.06875015]]], dtype=float32)>\n","branch shape after EXPAND DIMS tf.Tensor(\n","[[[[ 0.45915315 -0.32473087 -0.5330301  -0.4272989   0.2017684\n","    -0.4495353  -1.0820074  -0.34432405 -0.6594976   0.34885395\n","     0.21554495  0.95980775 -0.4722346   0.10899773  0.5605454\n","    -1.2987347   0.5481159  -0.49100628  1.1005692   0.20266874\n","    -0.2717103   0.71766955  0.62113106 -0.02937031  0.6855118\n","    -0.00967251 -1.0315048  -0.12468128  0.3282629   0.64295185\n","     0.5120343   1.2122147   0.0086495  -0.7456998  -0.56376684\n","    -1.1313294   0.23243535 -0.22145507 -0.2265783   0.1675185\n","    -0.9578593  -0.28877345  0.43721262 -0.165142    0.12943912\n","     0.78931594 -0.43495286  0.4168179  -0.26211536 -0.31814593\n","    -0.12422243 -0.05742802  1.2770786  -0.283117    0.1651147\n","     0.8376511   0.08346018 -0.1586758  -0.5301306   0.8120755\n","     0.6707728  -0.17900479 -0.21561891 -0.86372423 -1.2575412\n","    -0.58982027 -0.09184682 -1.0359699  -0.12261665  0.32644108\n","    -0.38816452  0.01002897 -0.8807018  -0.38803566  0.8223034\n","     0.76342505  0.4266305  -0.39651233  1.262547   -0.1279515\n","     0.7052541   0.564502   -0.7707801  -0.30712074 -0.23935378\n","    -0.37341744 -0.7219252  -0.94719195 -0.05675882  0.08245037\n","    -0.18178394  0.9582623  -0.20568861 -0.6980232   0.51698846\n","     0.14900273]]]], shape=(1, 1, 1, 96), dtype=float32)\n","BRANCH AFTER RESHAPE\n","tf.Tensor(\n","[[[ 0.45915315 -0.06494617 -0.10660602 -0.08545978  0.2017684\n","   -0.08990707 -0.21640149 -0.06886481 -0.13189952  0.34885395\n","    0.21554495  0.95980775 -0.09444692  0.10899773  0.5605454\n","   -0.25974694  0.5481159  -0.09820126  1.1005692   0.20266874\n","   -0.05434206  0.71766955  0.62113106 -0.00587406  0.6855118\n","   -0.0019345  -0.20630096 -0.02493626  0.3282629   0.64295185\n","    0.5120343   1.2122147   0.0086495  -0.14913997 -0.11275337\n","   -0.22626589  0.23243535 -0.04429102 -0.04531566  0.1675185\n","   -0.19157186 -0.05775469  0.43721262 -0.0330284   0.12943912\n","    0.78931594 -0.08699057  0.4168179  -0.05242307 -0.06362919\n","   -0.02484449 -0.0114856   1.2770786  -0.0566234   0.1651147\n","    0.8376511   0.08346018 -0.03173516 -0.10602613  0.8120755\n","    0.6707728  -0.03580096 -0.04312378 -0.17274486 -0.25150824\n","   -0.11796405 -0.01836936 -0.20719397 -0.02452333  0.32644108\n","   -0.0776329   0.01002897 -0.17614035 -0.07760713  0.8223034\n","    0.76342505  0.4266305  -0.07930247  1.262547   -0.0255903\n","    0.7052541   0.564502   -0.15415601 -0.06142415 -0.04787076\n","   -0.07468349 -0.14438504 -0.18943839 -0.01135176  0.08245037\n","   -0.03635679  0.9582623  -0.04113772 -0.13960464  0.51698846\n","    0.14900273]]], shape=(1, 1, 96), dtype=float32)\n","Branch W_loop call\n","tf.Tensor(\n","[[[ 0.2606652   0.10997524  0.470294   -0.02525051 -0.01278828\n","   -0.08265522 -0.14947537 -0.03699239 -0.05579164 -0.1546226\n","   -0.5932709   0.0984904   0.10864254 -0.01546771  0.18126106\n","    0.25399786 -0.35375717 -0.44380218 -0.04020289  0.009233\n","   -0.01298486 -0.13366374 -0.25588617 -0.06476089 -0.39127806\n","    0.22948661 -0.02574877  0.39048395  0.18239018 -0.16818455\n","   -0.08479685  0.1248071   0.2220757   0.1865581   0.09774631\n","    0.14847606 -0.3348245  -0.20402096 -0.26292908 -0.33166242\n","    0.16682862 -0.07550471  0.04451516 -0.04741912  0.48579022\n","    0.03085195 -0.00728255 -0.02754501 -0.26176468  0.22942966\n","    0.01587284 -0.24679527 -0.34934896 -0.04371488 -0.22437845\n","   -0.1266199  -0.16977975 -0.10777196  0.64184225 -0.11874348\n","   -0.0338015  -0.46124554  0.1916194  -0.09905601 -0.00912175\n","    0.20348552  0.19011556 -0.07201543 -0.15653712 -0.22830817\n","   -0.14301853  0.11784574 -0.47321603 -0.11026759  0.00921436\n","   -0.29862037  0.16820556  0.14648539  0.15259351 -0.3609606\n","    0.04705991 -0.3571962   0.05861104 -0.39511997 -0.25982535\n","   -0.02851258 -0.06746456 -0.26024082  0.6335101   0.12694713\n","   -0.20458105  0.05135549  0.10363641  0.11411881  0.01036323\n","   -0.2753729   0.21377626 -0.1218919   0.09188539  0.13962053\n","    0.0049708   0.03741908  0.01641414  0.01610552 -0.31013545\n","   -0.45571467  0.15932322  0.04356816  0.47702175  0.28232774\n","   -0.2544811   0.12473819 -0.24707298 -0.25770503 -0.15336029\n","    0.16098799  0.12812246 -0.1643637   0.09173907 -0.21567437\n","    0.19902143 -0.275404   -0.0550289   0.50420916 -0.06204126\n","    0.18846229  0.14365551 -0.13514395 -0.01867775  0.08854478\n","   -0.19913793  0.30551332 -0.2084674  -0.22335978 -0.32563087\n","   -0.1835753   0.41640818  0.18843712 -0.452412    0.04915354\n","   -0.04391435  0.20751724  0.24148075  0.17594376 -0.21505016\n","    0.27508342  0.24278267  0.13377433 -0.65717727 -0.3055264\n","   -0.11876115 -0.08256    -0.02378456  0.11302595 -0.07731768\n","   -0.0143393  -0.0927631  -0.04253133  0.08098061 -0.46366915\n","   -0.15096766 -0.34024274  0.00795681  0.3185553  -0.41194218\n","    0.18775159 -0.11039788  0.10350066 -0.21918757  0.30007058\n","    0.28255293 -0.11825667 -0.19511811 -0.14310089 -0.10872747\n","   -0.20786645 -0.03537543  0.23882014  0.10880949 -0.3637976\n","    0.02275689  0.1780378  -0.22749116 -0.20071313  0.19272636\n","   -0.58100253 -0.06727114 -0.01430944 -0.15577212 -0.18380612\n","    0.3618109  -0.20505175  0.02802252  0.2924202   0.2742242\n","   -0.10788536  0.0533745   0.01846365 -0.0749229   0.0115327\n","    0.02244804 -0.00214099 -0.0145325   0.11885981  0.22400297\n","   -0.10897452 -0.08640519 -0.19901566 -0.36865646  0.06515352\n","    0.11388089  0.04778775  0.1817329   0.07435596 -0.05890588\n","    0.3555377   0.32999963 -0.34142986  0.1784917   0.12471316\n","   -0.27282357 -0.06561872 -0.19782947 -0.23455402  0.31981033\n","    0.09162948 -0.1787066  -0.20004714 -0.11450294  0.33036238\n","    0.03422296 -0.1728189   0.12949127 -0.5486625   0.21348925\n","   -0.0085806   0.21534188  0.04869978  0.36642283 -0.19926849\n","    0.18790436  0.24363571 -0.13272896  0.18414372 -0.2724068\n","   -0.2002415   0.4928373  -0.25057364 -0.19742617  0.0852781\n","    0.26021695  0.09031317  0.22413616  0.19383116 -0.21346518\n","    0.27921972]]], shape=(1, 1, 256), dtype=float32)\n","BRANCH AFTER RE TILE\n","tf.Tensor(\n","[[[-0.23776507  0.56790924  0.309299   -0.42423785  0.3658486\n","   -0.20056671  0.3321541   0.14407377  0.3317604   0.12000827\n","   -0.9031382   0.29426473 -0.800026   -0.6702897  -0.34729064\n","    0.36766428  0.04997101 -1.0198576  -0.15520489  0.06060156\n","    0.6678737   0.49117205  0.00169781 -0.2603373  -0.22771102\n","    0.45632043 -0.57061297  0.06912217 -0.19593394 -0.64841735\n","   -0.03337723  0.62496924 -0.18337864  0.00270237  0.07260361\n","   -0.12939787  0.06448424 -0.55122906  0.1584931  -0.5962044\n","    0.11069798 -0.34049815 -0.23330843 -0.320118    0.57059264\n","   -0.34161496  0.9450341  -0.22166911 -0.53093505  0.32461262\n","   -0.20916739 -0.46012244 -0.33009383  0.40965602 -0.10613393\n","   -0.16457939 -0.02567132  0.15470177  0.63039935  0.28035998\n","   -0.05123857 -0.8616966  -0.42880684 -0.05056008  0.1512627\n","    0.5661712  -0.09180523 -0.8406695  -0.13931333 -0.8864032\n","   -0.45509928  0.62319684 -0.8070811   0.05664042 -0.43481216\n","    0.28157708  0.21428448  1.1879988  -0.2693252  -0.04561841\n","   -0.13922589 -0.49407524  0.48766953 -0.76549995 -0.5786966\n","    0.14026926  0.34494957  0.44276276  0.87970465  0.12839003\n","   -0.02473176  0.04730491 -0.41541436  0.0596531   0.1990144\n","   -0.5862226  -0.55864096  0.08783486 -0.02044237  0.7632208\n","   -0.5591747   0.55475366  0.32514533  0.15237987 -0.66460884\n","   -0.52337414  0.2716626  -0.20061803  0.03500676  0.7075928\n","   -0.61803883  0.22672477 -0.36551636  0.10165414 -0.65444785\n","    0.05652794 -0.20067357 -0.31615478  0.34554058 -0.91306067\n","    0.36142707 -0.12882167 -0.46730864 -0.03199542 -0.03164742\n","    0.09885979  0.6581737  -0.34512883  0.70572364 -0.00409346\n","   -0.65832764  0.6503552  -0.60481846  0.17174844 -0.8956845\n","   -0.73887575  0.33401188  0.3035304  -1.1043987   0.26909262\n","   -0.7291773   0.5136683   0.38503045  0.40288097  0.1396139\n","    1.0333424   0.5869997  -0.09091373 -0.34062904  0.4753153\n","   -0.54744136 -0.4973948  -0.1182887   0.7981545   0.6196245\n","   -0.45353746  0.3803158  -0.156542   -0.01994769 -1.266447\n","   -0.13998325 -1.180623   -0.18623343  0.50683194 -0.15256202\n","    0.5933612  -0.49091545 -0.44325608 -0.6726396  -0.39119816\n","    0.16416821  0.3451415  -1.3182346  -0.4162583   0.27924454\n","   -0.43887502  0.8610505   0.8801262   0.669983   -0.51312006\n","   -0.1276056   0.12161782 -0.3239286  -0.05240446  0.35399583\n","   -0.43374467  0.47205964 -0.29249427 -0.44755226 -1.0075535\n","    0.5848683  -0.71975136  0.747584    0.5754704   0.49740624\n","    0.24267527 -0.6425761  -0.44498184 -0.68917    -0.04588409\n","   -0.25889778 -0.8266092   0.21049975 -0.47717875 -0.17860071\n","   -0.5640471  -0.01139438 -0.3986128   0.11471298 -0.43693376\n","   -0.85297114  0.26907706 -0.23329774 -0.2591578  -0.4591238\n","    0.8458034   0.70026755 -0.21091376  0.05567835  0.95873195\n","   -0.05303954  0.10208075  0.17799906 -0.57771355 -0.44961154\n","    0.3909936   0.75460505 -0.04012011 -0.34896064 -0.4461816\n","    0.5073697  -0.12136654 -0.9182767  -0.41042826  0.06279518\n","   -0.2623512  -0.13640834  0.33948982 -0.2461868  -0.60780096\n","    0.60924435  0.28109303 -0.66962254 -0.11903936 -0.39597148\n","    0.61077076  0.09478945 -0.01143795 -0.2779176   0.09016487\n","    1.118123    0.31388786 -0.20401715  0.20498364 -0.37307435\n","    0.01172525]]], shape=(1, 1, 256), dtype=float32)\n","0\n","Tree INDEX:  0 1\n","tf.Tensor(\n","[[[0.01047182 0.59066546 0.39506686 0.6289226  0.61416733 0.11192453\n","   0.30162597 0.92322063 0.06005347 0.4205227  0.5107981  0.7969223\n","   0.9080839  0.57025886 0.2834581  0.90183246 0.9557593  0.9391173\n","   0.2427814  0.40333366 0.5925106  0.5375744  0.6049135  0.6379062\n","   0.83508635 0.6918887  0.01023054 0.8498752  0.24461305 0.33344865\n","   0.88443565 0.50010383 0.06586492 0.14401078 0.9661263  0.07820046\n","   0.8140285  0.32176793 0.48425317 0.39198327 0.75259864 0.44515467\n","   0.00307918 0.4255302  0.6385578  0.7718121  0.01598752 0.8888041\n","   0.7453935  0.9360999  0.469962   0.33280253 0.62882626 0.30295599\n","   0.8215525  0.13067889 0.2499367  0.43057394 0.4070083  0.10915458\n","   0.66520846 0.10049736 0.3901155  0.69108176 0.11987472 0.9388958\n","   0.39744174 0.48599482 0.8281683  0.17230654 0.7776722  0.5991373\n","   0.97225726 0.25942183 0.28829956 0.40875483 0.95815384 0.5111251\n","   0.09509945 0.65893793 0.51377916 0.574008   0.17741227 0.9151815\n","   0.48197544 0.5930363  0.9448329  0.66817796 0.83241916 0.9848572\n","   0.92965066 0.6101297  0.10795307 0.8371556  0.8690964  0.47578883]]], shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 1\n","Root Node\n","tf.Tensor(\n","[[[ 0.09068746  0.49434787 -0.555719   -0.20136328 -0.27359873\n","    0.7650622   0.12648675  0.03491518  0.40000474  0.9912313\n","    0.54790413  0.20361158 -0.85425717 -0.11816581 -0.7935964\n","   -0.14031312 -0.07174295  0.4869513   0.5047679  -0.2829162\n","   -0.16544408  0.3327936  -0.4130413   0.44827726 -0.83576214\n","    0.13830939 -0.04259948  0.66145957  0.62738967 -0.05038752\n","    0.37784803  0.09574745 -0.0059586  -0.35579056  0.44919252\n","    0.06239514 -0.22936052 -0.4981288   0.05287731 -0.32425532\n","    0.17590842 -0.3314457   0.4486066  -0.19964126  0.2946331\n","   -0.34874624  0.10416965  0.07451902 -0.68444616 -0.22854207\n","   -0.5582396   0.25529042  0.15574029 -0.07050576 -0.9937561\n","    0.3134545  -0.1116931  -0.5845649  -0.9698435   0.67249775\n","    0.40639287  0.13989303  0.1164678   0.05436251 -0.10174832\n","    0.28813684  0.54207474  0.3549104  -0.2799307   0.17040913\n","   -0.72348756 -0.24345052 -0.12628236 -0.27312335  0.6352504\n","    1.0926586   0.73029345  0.65525854  0.4048328   0.16568749\n","    0.5631295  -0.7730398  -0.16187626 -0.5261851  -0.75529885\n","    0.5566754   0.07858692 -0.258903    0.174927    0.2998721\n","   -0.06211779 -0.9707007  -0.05877319 -0.04586209 -0.22094445\n","    0.5067736   0.22615229  0.21505886 -0.28178966  0.1585826\n","   -0.54668397 -0.20871435 -0.8180232  -0.11028307  0.46669143\n","    0.24214844 -0.8063762   0.57159114 -0.66535807 -0.5937772\n","    0.48514014 -0.0349476  -0.08719483 -0.30806503 -0.16230819\n","    0.01915208 -0.5973792   0.01602507 -0.55802727  0.4433945\n","   -0.26126474 -0.5470171  -0.16763064 -0.01997791  0.22143406\n","   -0.3191585   0.7675873   0.34271765  0.4774139  -0.5913496\n","    0.37227103  0.9177753   0.36054224  0.33231866  0.5458212\n","   -0.8970484  -0.1570127   0.05632257 -0.18565272 -0.43662784\n","    0.45750576 -1.0361471  -0.03175837  0.5834498  -0.05013904\n","    0.08632638  0.13291737  0.3844222   0.67831564 -0.38639688\n","    0.16399561 -0.5390808  -0.4601534   0.17553003 -0.08658278\n","    0.16909619 -0.5357009  -0.38889372 -0.51805353 -0.7687979\n","    0.3193909   0.11964318 -0.3101143  -0.20900883  0.34486032\n","    0.32165164 -0.5102571   0.63702697 -0.08241139 -0.04161792\n","   -0.04194189  0.7671621  -0.17919606  0.63844776  0.27102605\n","    0.30860367  0.03327549 -0.30891028  0.3148374   0.05578535\n","    0.2612523   0.11905146  0.6140153   0.85732377 -0.82315767\n","    0.00625874 -0.13874388  0.00315127  1.0521538  -0.03889635\n","    0.77251315 -0.31543303  0.14973438 -0.85735756 -0.29229066\n","    0.1811266  -0.68668437 -0.04131117  0.8678857  -0.1534488\n","   -0.12622535  0.2912552  -0.31632918  1.1597661   0.21566144\n","   -0.3655543   0.30560225 -0.977206   -0.15548228 -0.02582374\n","   -0.09173373  0.5992343  -0.0341695   0.01555797 -0.84513646\n","    0.46963254 -0.29123098  0.13477825  0.5491651   0.2925964\n","   -0.341156    0.06676507 -0.50145674 -0.7902126   0.20682748\n","   -0.34168023 -0.63673425 -0.12734546 -0.02987881  0.53367317\n","   -0.53594255 -0.59868747  0.23781586  0.09609168  0.59448075\n","    0.56603086 -0.19232064 -0.55044854 -0.40422374  0.00574132\n","   -0.5026869  -0.2913049   0.21578062 -0.5810364   0.5827535\n","    0.39171454  0.11569898  0.12199783 -0.18255705  0.45001233\n","    0.06837653 -0.14266904  0.5559732   0.5448747   1.131206\n","    0.03195935]]], shape=(1, 1, 256), dtype=float32)\n","tf.Tensor([  1   1 256], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[ 0.09068746  0.49434787 -0.555719   -0.20136328 -0.27359873\n","    0.7650622   0.12648675  0.03491518  0.40000474  0.9912313\n","    0.54790413  0.20361158 -0.85425717 -0.11816581 -0.7935964\n","   -0.14031312 -0.07174295  0.4869513   0.5047679  -0.2829162\n","   -0.16544408  0.3327936  -0.4130413   0.44827726 -0.83576214\n","    0.13830939 -0.04259948  0.66145957  0.62738967 -0.05038752\n","    0.37784803  0.09574745 -0.0059586  -0.35579056  0.44919252\n","    0.06239514 -0.22936052 -0.4981288   0.05287731 -0.32425532\n","    0.17590842 -0.3314457   0.4486066  -0.19964126  0.2946331\n","   -0.34874624  0.10416965  0.07451902 -0.68444616 -0.22854207\n","   -0.5582396   0.25529042  0.15574029 -0.07050576 -0.9937561\n","    0.3134545  -0.1116931  -0.5845649  -0.9698435   0.67249775\n","    0.40639287  0.13989303  0.1164678   0.05436251 -0.10174832\n","    0.28813684  0.54207474  0.3549104  -0.2799307   0.17040913\n","   -0.72348756 -0.24345052 -0.12628236 -0.27312335  0.6352504\n","    1.0926586   0.73029345  0.65525854  0.4048328   0.16568749\n","    0.5631295  -0.7730398  -0.16187626 -0.5261851  -0.75529885\n","    0.5566754   0.07858692 -0.258903    0.174927    0.2998721\n","   -0.06211779 -0.9707007  -0.05877319 -0.04586209 -0.22094445\n","    0.5067736   0.22615229  0.21505886 -0.28178966  0.1585826\n","   -0.54668397 -0.20871435 -0.8180232  -0.11028307  0.46669143\n","    0.24214844 -0.8063762   0.57159114 -0.66535807 -0.5937772\n","    0.48514014 -0.0349476  -0.08719483 -0.30806503 -0.16230819\n","    0.01915208 -0.5973792   0.01602507 -0.55802727  0.4433945\n","   -0.26126474 -0.5470171  -0.16763064 -0.01997791  0.22143406\n","   -0.3191585   0.7675873   0.34271765  0.4774139  -0.5913496\n","    0.37227103  0.9177753   0.36054224  0.33231866  0.5458212\n","   -0.8970484  -0.1570127   0.05632257 -0.18565272 -0.43662784\n","    0.45750576 -1.0361471  -0.03175837  0.5834498  -0.05013904\n","    0.08632638  0.13291737  0.3844222   0.67831564 -0.38639688\n","    0.16399561 -0.5390808  -0.4601534   0.17553003 -0.08658278\n","    0.16909619 -0.5357009  -0.38889372 -0.51805353 -0.7687979\n","    0.3193909   0.11964318 -0.3101143  -0.20900883  0.34486032\n","    0.32165164 -0.5102571   0.63702697 -0.08241139 -0.04161792\n","   -0.04194189  0.7671621  -0.17919606  0.63844776  0.27102605\n","    0.30860367  0.03327549 -0.30891028  0.3148374   0.05578535\n","    0.2612523   0.11905146  0.6140153   0.85732377 -0.82315767\n","    0.00625874 -0.13874388  0.00315127  1.0521538  -0.03889635\n","    0.77251315 -0.31543303  0.14973438 -0.85735756 -0.29229066\n","    0.1811266  -0.68668437 -0.04131117  0.8678857  -0.1534488\n","   -0.12622535  0.2912552  -0.31632918  1.1597661   0.21566144\n","   -0.3655543   0.30560225 -0.977206   -0.15548228 -0.02582374\n","   -0.09173373  0.5992343  -0.0341695   0.01555797 -0.84513646\n","    0.46963254 -0.29123098  0.13477825  0.5491651   0.2925964\n","   -0.341156    0.06676507 -0.50145674 -0.7902126   0.20682748\n","   -0.34168023 -0.63673425 -0.12734546 -0.02987881  0.53367317\n","   -0.53594255 -0.59868747  0.23781586  0.09609168  0.59448075\n","    0.56603086 -0.19232064 -0.55044854 -0.40422374  0.00574132\n","   -0.5026869  -0.2913049   0.21578062 -0.5810364   0.5827535\n","    0.39171454  0.11569898  0.12199783 -0.18255705  0.45001233\n","    0.06837653 -0.14266904  0.5559732   0.5448747   1.131206\n","    0.03195935]]], shape=(1, 1, 256), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 0.09068746  0.49434787 -0.555719   -0.20136328 -0.27359873\n","    0.7650622   0.12648675  0.03491518  0.40000474  0.9912313\n","    0.54790413  0.20361158 -0.85425717 -0.11816581 -0.7935964\n","   -0.14031312 -0.07174295  0.4869513   0.5047679  -0.2829162\n","   -0.16544408  0.3327936  -0.4130413   0.44827726 -0.83576214\n","    0.13830939 -0.04259948  0.66145957  0.62738967 -0.05038752\n","    0.37784803  0.09574745 -0.0059586  -0.35579056  0.44919252\n","    0.06239514 -0.22936052 -0.4981288   0.05287731 -0.32425532\n","    0.17590842 -0.3314457   0.4486066  -0.19964126  0.2946331\n","   -0.34874624  0.10416965  0.07451902 -0.68444616 -0.22854207\n","   -0.5582396   0.25529042  0.15574029 -0.07050576 -0.9937561\n","    0.3134545  -0.1116931  -0.5845649  -0.9698435   0.67249775\n","    0.40639287  0.13989303  0.1164678   0.05436251 -0.10174832\n","    0.28813684  0.54207474  0.3549104  -0.2799307   0.17040913\n","   -0.72348756 -0.24345052 -0.12628236 -0.27312335  0.6352504\n","    1.0926586   0.73029345  0.65525854  0.4048328   0.16568749\n","    0.5631295  -0.7730398  -0.16187626 -0.5261851  -0.75529885\n","    0.5566754   0.07858692 -0.258903    0.174927    0.2998721\n","   -0.06211779 -0.9707007  -0.05877319 -0.04586209 -0.22094445\n","    0.5067736   0.22615229  0.21505886 -0.28178966  0.1585826\n","   -0.54668397 -0.20871435 -0.8180232  -0.11028307  0.46669143\n","    0.24214844 -0.8063762   0.57159114 -0.66535807 -0.5937772\n","    0.48514014 -0.0349476  -0.08719483 -0.30806503 -0.16230819\n","    0.01915208 -0.5973792   0.01602507 -0.55802727  0.4433945\n","   -0.26126474 -0.5470171  -0.16763064 -0.01997791  0.22143406\n","   -0.3191585   0.7675873   0.34271765  0.4774139  -0.5913496\n","    0.37227103  0.9177753   0.36054224  0.33231866  0.5458212\n","   -0.8970484  -0.1570127   0.05632257 -0.18565272 -0.43662784\n","    0.45750576 -1.0361471  -0.03175837  0.5834498  -0.05013904\n","    0.08632638  0.13291737  0.3844222   0.67831564 -0.38639688\n","    0.16399561 -0.5390808  -0.4601534   0.17553003 -0.08658278\n","    0.16909619 -0.5357009  -0.38889372 -0.51805353 -0.7687979\n","    0.3193909   0.11964318 -0.3101143  -0.20900883  0.34486032\n","    0.32165164 -0.5102571   0.63702697 -0.08241139 -0.04161792\n","   -0.04194189  0.7671621  -0.17919606  0.63844776  0.27102605\n","    0.30860367  0.03327549 -0.30891028  0.3148374   0.05578535\n","    0.2612523   0.11905146  0.6140153   0.85732377 -0.82315767\n","    0.00625874 -0.13874388  0.00315127  1.0521538  -0.03889635\n","    0.77251315 -0.31543303  0.14973438 -0.85735756 -0.29229066\n","    0.1811266  -0.68668437 -0.04131117  0.8678857  -0.1534488\n","   -0.12622535  0.2912552  -0.31632918  1.1597661   0.21566144\n","   -0.3655543   0.30560225 -0.977206   -0.15548228 -0.02582374\n","   -0.09173373  0.5992343  -0.0341695   0.01555797 -0.84513646\n","    0.46963254 -0.29123098  0.13477825  0.5491651   0.2925964\n","   -0.341156    0.06676507 -0.50145674 -0.7902126   0.20682748\n","   -0.34168023 -0.63673425 -0.12734546 -0.02987881  0.53367317\n","   -0.53594255 -0.59868747  0.23781586  0.09609168  0.59448075\n","    0.56603086 -0.19232064 -0.55044854 -0.40422374  0.00574132\n","   -0.5026869  -0.2913049   0.21578062 -0.5810364   0.5827535\n","    0.39171454  0.11569898  0.12199783 -0.18255705  0.45001233\n","    0.06837653 -0.14266904  0.5559732   0.5448747   1.131206\n","    0.03195935]]], shape=(1, 1, 256), dtype=float32)\n","1\n","Tree INDEX:  1 1\n","tf.Tensor(\n","[[[-4.38085161e-02  5.14522731e-01  2.79901981e-01 -8.42245668e-02\n","    3.10131192e-01 -4.91717719e-02  2.82714933e-01  1.59668729e-01\n","    3.16451937e-01  1.06002778e-01 -1.75797984e-01  2.43300289e-01\n","   -1.64478689e-01 -1.36502862e-01 -6.29783124e-02  3.34693581e-01\n","    5.62972575e-02 -2.08755001e-01 -2.35163011e-02  4.75989431e-02\n","    6.91371381e-01  4.30168569e-01 -1.54355762e-03 -5.37517965e-02\n","   -5.20638600e-02  4.11936998e-01 -1.20539621e-01  1.11038074e-01\n","   -3.03011369e-02 -1.38722941e-01 -1.40641006e-02  6.65612340e-01\n","   -4.24496494e-02  3.96848619e-02  4.31291163e-02 -1.95318349e-02\n","    9.59906131e-02 -1.05199710e-01  1.95507586e-01 -1.26699820e-01\n","    1.28836364e-01 -6.88220784e-02 -3.85855585e-02 -5.60288690e-02\n","    5.18352509e-01 -6.01034872e-02  9.03500319e-01 -3.26057449e-02\n","   -9.54587013e-02  3.70612174e-01 -3.59645486e-02 -8.60777125e-02\n","   -6.46821409e-02  4.43804145e-01 -1.74348634e-02 -2.72681396e-02\n","   -1.01330522e-02  1.12554908e-01  6.42261267e-01  3.02520126e-01\n","   -6.61709928e-04 -1.60289556e-01 -7.79324695e-02 -1.38009591e-02\n","    9.41904336e-02  5.89249969e-01 -2.62701400e-02 -1.70951396e-01\n","   -3.97389568e-02 -1.82683662e-01 -1.02914207e-01  5.65070093e-01\n","   -1.69491798e-01  3.61192599e-02 -8.35777298e-02  3.07498991e-01\n","    1.70458123e-01  1.15783095e+00 -4.53899838e-02 -1.48425521e-02\n","   -2.28466671e-02 -9.98113677e-02  5.18225551e-01 -1.61068395e-01\n","   -1.15866914e-01  1.01097316e-01  3.80062699e-01  4.65870589e-01\n","    8.82818639e-01  1.05144113e-01 -4.04038420e-03  8.61021951e-02\n","   -7.97107145e-02  5.37506565e-02  1.61904633e-01 -1.22601725e-01\n","   -1.00071840e-01  8.22263807e-02 -2.52077286e-03  8.16332042e-01\n","   -1.21257246e-01  5.40857911e-01  3.20210099e-01  2.04921946e-01\n","   -1.39518946e-01 -1.00047044e-01  3.31661403e-01 -3.80643718e-02\n","    3.11563760e-02  7.30425954e-01 -1.22975193e-01  1.75942704e-01\n","   -8.55988488e-02  4.75723296e-02 -1.28500894e-01  5.40147871e-02\n","   -3.89585160e-02 -6.07193373e-02  3.22029412e-01 -1.83825597e-01\n","    3.60989213e-01 -3.17464583e-02 -9.42828655e-02 -1.57229009e-03\n","   -1.20822955e-02  5.33291325e-02  6.91701889e-01 -6.13104701e-02\n","    6.83839977e-01 -5.03671635e-03 -1.21477142e-01  6.75283194e-01\n","   -1.17253698e-01  2.13981539e-01 -1.75970748e-01 -1.57257378e-01\n","    3.83838773e-01  3.16658974e-01 -2.18769953e-01  3.01411927e-01\n","   -1.43378735e-01  5.75608850e-01  3.69392514e-01  4.21119153e-01\n","    1.99424356e-01  1.04867280e+00  5.83800554e-01 -2.83690728e-02\n","   -7.38091543e-02  4.98416334e-01 -1.14961743e-01 -1.04038253e-01\n","   -3.48988734e-02  8.40120792e-01  5.99176526e-01 -8.60372484e-02\n","    3.18731606e-01 -2.25727987e-02 -1.13547323e-02 -2.42312551e-01\n","   -1.66865084e-02 -2.36818776e-01 -3.06139886e-02  4.63447452e-01\n","   -2.03188490e-02  5.95955253e-01 -1.03045814e-01 -9.36243162e-02\n","   -1.38037264e-01 -8.49231109e-02  1.14787087e-01  2.94745386e-01\n","   -2.57693738e-01 -8.62302706e-02  2.48403400e-01 -8.06332752e-02\n","    8.42356443e-01  8.37407112e-01  7.04727113e-01 -1.05859868e-01\n","   -2.08054911e-02  5.99296167e-02 -5.57315908e-02 -1.19325612e-02\n","    3.27064395e-01 -9.52453166e-02  4.80743587e-01 -6.31099045e-02\n","   -7.79415295e-02 -1.89042166e-01  5.92057526e-01 -1.45959064e-01\n","    7.80217528e-01  5.93814313e-01  5.35137296e-01  2.92976677e-01\n","   -1.16906941e-01 -9.80610996e-02 -1.46089494e-01 -5.50946081e-03\n","   -5.49266301e-02 -1.54027566e-01  1.79697081e-01 -9.01245400e-02\n","   -2.96709426e-02 -1.16103508e-01  4.42664325e-03 -7.27676302e-02\n","    1.23814344e-01 -9.50086340e-02 -1.74927384e-01  3.07584763e-01\n","   -4.50636558e-02 -6.32648915e-02 -8.37559924e-02  8.36740255e-01\n","    7.35139966e-01 -4.36255559e-02  5.60533553e-02  9.75343883e-01\n","   -8.64997786e-03  9.29381847e-02  1.42363712e-01 -1.14082217e-01\n","   -8.13403651e-02  3.41797709e-01  7.97768474e-01 -1.34938331e-02\n","   -7.73214325e-02 -7.79429078e-02  5.68927169e-01 -3.44287418e-02\n","   -1.95526466e-01 -7.07361028e-02  2.91816294e-02 -4.70517054e-02\n","   -2.44555678e-02  3.53707671e-01 -5.52726388e-02 -1.31136447e-01\n","    5.78834474e-01  3.06794703e-01 -1.43088177e-01 -3.00416686e-02\n","   -7.45682567e-02  5.96050024e-01  1.32087752e-01 -9.65137500e-03\n","   -5.68172224e-02  4.14800346e-02  1.15839410e+00  3.20272565e-01\n","   -5.14090769e-02  2.63104320e-01 -7.59995803e-02 -1.75420044e-03]]], shape=(1, 1, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 1\n","Root Node\n","tf.Tensor(\n","[[[-0.2514758   0.2678001  -0.34962022  0.0951793   0.06861456\n","    0.61268187  0.39851454  0.38167554  0.01869597  0.30836013\n","   -0.07436389 -0.13982117 -0.01977346 -0.0274584   0.31997868\n","    0.08695804 -0.4966505  -0.20996599  0.30655518  0.5590454\n","    0.5790984  -0.08686021 -0.6690289   0.50966156 -0.09891939\n","    0.5772177  -0.8045981   0.02601148  0.19463584 -0.18533695\n","   -0.25941095  0.91814584  0.2625526  -0.06296778 -0.04062678\n","   -0.32480252  0.21374094 -0.21602081  0.39766553  0.01087093\n","    0.49130267 -0.5217833  -0.21967661 -0.13136892 -0.07674061\n","    0.02036889 -0.5060506  -0.15536493  0.00115696  0.10347664\n","    0.31122476 -0.07345939  0.28974378  0.0467421  -0.61018896\n","   -0.27193308  0.46553543  0.03534225 -0.11491138  0.0625044\n","    0.00973516 -0.07747216  0.39763397  0.47562397 -0.4864495\n","   -0.03882809  0.1523675  -0.09509312 -0.11220089 -0.094967\n","    0.30244634 -0.2917429  -0.35644448 -0.20918158  0.50078374\n","   -0.1953919  -0.0756878  -0.10158594  0.01295041  0.32926017\n","   -0.14313012  0.37002358 -0.08215585 -0.26613164  0.36032248\n","   -0.33663684 -0.3404701  -0.10742086  0.05681406 -0.53515553\n","   -0.03935647 -0.28785568  0.41089904 -0.10587551  0.54279995\n","    0.4630744   0.3901045   0.28941628  0.48913014  0.06320183\n","   -0.03402542 -0.02900378  0.0586351   0.45617637  0.0335348\n","    0.06156044  0.68917876  0.03394378 -0.03856777  0.66965413\n","   -0.04943417 -0.06319629 -0.6097138   0.21910077  0.2673418\n","   -0.0825849  -0.04025154 -0.34595406 -0.43631065  0.26526037\n","    0.00098575  0.13214494  0.16772628  0.278592   -0.13947923\n","   -0.34208143 -0.07965866 -0.24367243  0.5204816   0.07569536\n","    0.28574717 -0.10106406  0.03725487  0.00625485  0.42307305\n","   -0.43531144 -0.25322926 -0.22137737 -0.20261705  0.11006509\n","    0.59567505 -0.4174504   0.44620386  0.12985627 -0.3664637\n","    0.02214463  0.19878793  0.041124   -0.03184712 -0.03475352\n","    0.39997834  0.04080494  0.18095659  0.6740142  -0.20273204\n","   -0.2441751  -0.66312724  0.23895366  0.2165171  -0.12077926\n","   -0.08817416 -0.33210182  0.30947107  0.40765834  0.23380631\n","   -0.25964558  0.11778504  0.2972641   0.02307634 -0.3292613\n","   -0.28927374  0.10566354  0.1318593  -0.18535332  0.04028212\n","    0.10978593 -0.21844144 -0.07605281  0.3103839  -0.42630675\n","   -0.0496494   0.18748926  0.50637096 -0.4868864  -0.06291643\n","    0.04986026  0.1480451   0.48986658  0.59882003 -0.5810696\n","    0.8265717  -0.21155986 -0.37112463  0.06001419 -0.2795396\n","    0.7875915  -0.23120359 -0.18164006 -0.03016816 -0.09418024\n","   -0.29808348  0.3578166  -0.7612355  -0.29641262  0.07066186\n","   -0.52642596 -0.08113182 -0.6861265  -0.2367084   0.17118941\n","    0.29780692 -0.6433234   0.90687805  0.16622531  0.21336257\n","   -0.02121269 -0.02649663 -0.28680527  0.10415368  0.5659302\n","    0.47697052 -0.5265454  -0.07092044  0.2657732   0.14230809\n","    0.47443497 -0.07055171 -0.0902079  -0.48459566  0.35871863\n","    0.17482033  0.15088739  0.20881607  0.34072337  0.35716626\n","    0.15472552  0.2492113  -0.49078268  0.13452041 -0.07760916\n","    0.24128729 -0.14250389 -0.06303547  0.2880988  -0.44811252\n","    0.0129559   0.01715763  0.13581653 -0.75230616  0.08008914\n","   -0.11593772 -0.11428118 -0.03775832 -0.45702818 -0.04747228\n","    0.38635424]]], shape=(1, 1, 256), dtype=float32)\n","tf.Tensor([  1   1 256], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[-0.2514758   0.2678001  -0.34962022  0.0951793   0.06861456\n","    0.61268187  0.39851454  0.38167554  0.01869597  0.30836013\n","   -0.07436389 -0.13982117 -0.01977346 -0.0274584   0.31997868\n","    0.08695804 -0.4966505  -0.20996599  0.30655518  0.5590454\n","    0.5790984  -0.08686021 -0.6690289   0.50966156 -0.09891939\n","    0.5772177  -0.8045981   0.02601148  0.19463584 -0.18533695\n","   -0.25941095  0.91814584  0.2625526  -0.06296778 -0.04062678\n","   -0.32480252  0.21374094 -0.21602081  0.39766553  0.01087093\n","    0.49130267 -0.5217833  -0.21967661 -0.13136892 -0.07674061\n","    0.02036889 -0.5060506  -0.15536493  0.00115696  0.10347664\n","    0.31122476 -0.07345939  0.28974378  0.0467421  -0.61018896\n","   -0.27193308  0.46553543  0.03534225 -0.11491138  0.0625044\n","    0.00973516 -0.07747216  0.39763397  0.47562397 -0.4864495\n","   -0.03882809  0.1523675  -0.09509312 -0.11220089 -0.094967\n","    0.30244634 -0.2917429  -0.35644448 -0.20918158  0.50078374\n","   -0.1953919  -0.0756878  -0.10158594  0.01295041  0.32926017\n","   -0.14313012  0.37002358 -0.08215585 -0.26613164  0.36032248\n","   -0.33663684 -0.3404701  -0.10742086  0.05681406 -0.53515553\n","   -0.03935647 -0.28785568  0.41089904 -0.10587551  0.54279995\n","    0.4630744   0.3901045   0.28941628  0.48913014  0.06320183\n","   -0.03402542 -0.02900378  0.0586351   0.45617637  0.0335348\n","    0.06156044  0.68917876  0.03394378 -0.03856777  0.66965413\n","   -0.04943417 -0.06319629 -0.6097138   0.21910077  0.2673418\n","   -0.0825849  -0.04025154 -0.34595406 -0.43631065  0.26526037\n","    0.00098575  0.13214494  0.16772628  0.278592   -0.13947923\n","   -0.34208143 -0.07965866 -0.24367243  0.5204816   0.07569536\n","    0.28574717 -0.10106406  0.03725487  0.00625485  0.42307305\n","   -0.43531144 -0.25322926 -0.22137737 -0.20261705  0.11006509\n","    0.59567505 -0.4174504   0.44620386  0.12985627 -0.3664637\n","    0.02214463  0.19878793  0.041124   -0.03184712 -0.03475352\n","    0.39997834  0.04080494  0.18095659  0.6740142  -0.20273204\n","   -0.2441751  -0.66312724  0.23895366  0.2165171  -0.12077926\n","   -0.08817416 -0.33210182  0.30947107  0.40765834  0.23380631\n","   -0.25964558  0.11778504  0.2972641   0.02307634 -0.3292613\n","   -0.28927374  0.10566354  0.1318593  -0.18535332  0.04028212\n","    0.10978593 -0.21844144 -0.07605281  0.3103839  -0.42630675\n","   -0.0496494   0.18748926  0.50637096 -0.4868864  -0.06291643\n","    0.04986026  0.1480451   0.48986658  0.59882003 -0.5810696\n","    0.8265717  -0.21155986 -0.37112463  0.06001419 -0.2795396\n","    0.7875915  -0.23120359 -0.18164006 -0.03016816 -0.09418024\n","   -0.29808348  0.3578166  -0.7612355  -0.29641262  0.07066186\n","   -0.52642596 -0.08113182 -0.6861265  -0.2367084   0.17118941\n","    0.29780692 -0.6433234   0.90687805  0.16622531  0.21336257\n","   -0.02121269 -0.02649663 -0.28680527  0.10415368  0.5659302\n","    0.47697052 -0.5265454  -0.07092044  0.2657732   0.14230809\n","    0.47443497 -0.07055171 -0.0902079  -0.48459566  0.35871863\n","    0.17482033  0.15088739  0.20881607  0.34072337  0.35716626\n","    0.15472552  0.2492113  -0.49078268  0.13452041 -0.07760916\n","    0.24128729 -0.14250389 -0.06303547  0.2880988  -0.44811252\n","    0.0129559   0.01715763  0.13581653 -0.75230616  0.08008914\n","   -0.11593772 -0.11428118 -0.03775832 -0.45702818 -0.04747228\n","    0.38635424]]], shape=(1, 1, 256), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[-1.60788357e-01  7.62147963e-01 -9.05339241e-01 -1.06183976e-01\n","   -2.04984173e-01  1.37774408e+00  5.25001287e-01  4.16590720e-01\n","    4.18700695e-01  1.29959142e+00  4.73540246e-01  6.37904108e-02\n","   -8.74030650e-01 -1.45624205e-01 -4.73617703e-01 -5.33550754e-02\n","   -5.68393469e-01  2.76985288e-01  8.11323047e-01  2.76129186e-01\n","    4.13654327e-01  2.45933384e-01 -1.08207011e+00  9.57938790e-01\n","   -9.34681535e-01  7.15527058e-01 -8.47197592e-01  6.87471032e-01\n","    8.22025537e-01 -2.35724479e-01  1.18437082e-01  1.01389325e+00\n","    2.56594002e-01 -4.18758333e-01  4.08565760e-01 -2.62407362e-01\n","   -1.56195760e-02 -7.14149594e-01  4.50542837e-01 -3.13384384e-01\n","    6.67211056e-01 -8.53228986e-01  2.28929996e-01 -3.31010163e-01\n","    2.17892483e-01 -3.28377366e-01 -4.01880920e-01 -8.08459073e-02\n","   -6.83289170e-01 -1.25065431e-01 -2.47014821e-01  1.81831032e-01\n","    4.45484072e-01 -2.37636566e-02 -1.60394502e+00  4.15214300e-02\n","    3.53842318e-01 -5.49222648e-01 -1.08475494e+00  7.35002160e-01\n","    4.16128039e-01  6.24208674e-02  5.14101744e-01  5.29986501e-01\n","   -5.88197827e-01  2.49308750e-01  6.94442272e-01  2.59817302e-01\n","   -3.92131597e-01  7.54421279e-02 -4.21041220e-01 -5.35193443e-01\n","   -4.82726842e-01 -4.82304931e-01  1.13603413e+00  8.97266746e-01\n","    6.54605627e-01  5.53672612e-01  4.17783201e-01  4.94947672e-01\n","    4.19999361e-01 -4.03016239e-01 -2.44032115e-01 -7.92316735e-01\n","   -3.94976377e-01  2.20038533e-01 -2.61883199e-01 -3.66323858e-01\n","    2.31741056e-01 -2.35283434e-01 -1.01474255e-01 -1.25855637e+00\n","    3.52125853e-01 -1.51737601e-01  3.21855485e-01  9.69847977e-01\n","    6.16256773e-01  5.04475117e-01  2.07340479e-01  2.21784428e-01\n","   -5.80709398e-01 -2.37718135e-01 -7.59388089e-01  3.45893294e-01\n","    5.00226259e-01  3.03708881e-01 -1.17197454e-01  6.05534911e-01\n","   -7.03925848e-01  7.58769512e-02  4.35705960e-01 -9.81438905e-02\n","   -6.96908593e-01 -8.89642537e-02  1.05033606e-01 -6.34328201e-02\n","   -6.37630761e-01 -3.29928994e-01 -9.94337916e-01  7.08654881e-01\n","   -2.60279000e-01 -4.14872169e-01  9.56356525e-05  2.58614063e-01\n","    8.19548219e-02 -6.61239922e-01  6.87928677e-01  9.90452170e-02\n","    9.97895479e-01 -5.15654266e-01  6.58018231e-01  8.16711187e-01\n","    3.97797108e-01  3.38573515e-01  9.68894243e-01 -1.33235979e+00\n","   -4.10241961e-01 -1.65054798e-01 -3.88269782e-01 -3.26562762e-01\n","    1.05318081e+00 -1.45359755e+00  4.14445490e-01  7.13306069e-01\n","   -4.16602731e-01  1.08471021e-01  3.31705302e-01  4.25546229e-01\n","    6.46468520e-01 -4.21150386e-01  5.63973963e-01 -4.98275876e-01\n","   -2.79196799e-01  8.49544227e-01 -2.89314806e-01 -7.50789195e-02\n","   -1.19882822e+00 -1.49940059e-01 -3.01536441e-01 -8.89577150e-01\n","    2.31216729e-01 -2.12458640e-01 -6.43223524e-04  1.98649511e-01\n","    5.78666627e-01  6.20060563e-02 -3.92472088e-01  9.34291065e-01\n","   -5.93350567e-02 -3.70879233e-01 -3.31215620e-01  8.72825623e-01\n","   -4.73367572e-02  4.53094423e-01  3.11308146e-01  4.18389618e-01\n","   -1.85165942e-01 -3.84963095e-01  6.25221252e-01 -3.70521396e-01\n","    2.11602911e-01  3.06540728e-01  1.12038624e+00  3.70437354e-01\n","   -8.86074066e-01  5.61190024e-02  9.30121541e-03  4.93017852e-01\n","    1.65097380e+00 -6.19965911e-01  1.59908485e+00 -5.26992917e-01\n","   -2.21390247e-01 -7.97343373e-01 -5.71830273e-01  9.68718112e-01\n","   -9.17887926e-01 -2.22951233e-01  8.37717533e-01 -2.47629046e-01\n","   -4.24308836e-01  6.49071813e-01 -1.07756472e+00  8.63353491e-01\n","    2.86323309e-01 -8.91980290e-01  2.24470437e-01 -1.66333246e+00\n","   -3.92190695e-01  1.45365670e-01  2.06073195e-01 -4.40891385e-02\n","    8.72708559e-01  1.81783289e-01 -6.31773889e-01  4.48419839e-01\n","   -3.17727596e-01 -1.52027026e-01  6.53318822e-01  8.58526587e-01\n","    1.35814518e-01 -4.59780335e-01 -5.72377205e-01 -5.24439335e-01\n","    3.49135578e-01  1.32754743e-01 -7.07285941e-01 -2.17553347e-01\n","   -5.14474452e-01  8.92391801e-01 -3.61122221e-01 -4.47800100e-01\n","    4.46631908e-01  4.36815053e-01  9.51647043e-01  7.20756412e-01\n","    5.68906516e-02 -1.04123116e+00 -2.69703329e-01 -7.18678385e-02\n","   -2.61399627e-01 -4.33808774e-01  1.52745143e-01 -2.92937577e-01\n","    1.34640962e-01  4.04670447e-01  1.32856607e-01  2.57814348e-01\n","   -9.34863210e-01  5.30101478e-01 -4.75611910e-02 -2.56950200e-01\n","    5.18214822e-01  8.78465474e-02  1.08373380e+00  4.18313593e-01]]], shape=(1, 1, 256), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(1, 256, 512) dtype=float32, numpy=\n","array([[[ 0.03582853,  0.04669882,  0.07272639, ..., -0.03812619,\n","         -0.00859065, -0.02239153],\n","        [ 0.00587257, -0.05703094,  0.06879161, ..., -0.04088522,\n","         -0.02043816, -0.01200772],\n","        [-0.07202462, -0.03121014,  0.05631921, ..., -0.0059315 ,\n","          0.03588492,  0.03130687],\n","        ...,\n","        [ 0.06567176,  0.0196281 ,  0.01159473, ...,  0.04838084,\n","          0.03319821,  0.02379057],\n","        [ 0.00143746, -0.06649843,  0.02233115, ...,  0.04147906,\n","          0.01624487,  0.01057635],\n","        [-0.00259165,  0.06797966,  0.0210041 , ...,  0.02319499,\n","         -0.00671075,  0.06832843]]], dtype=float32)>\n","branch shape after EXPAND DIMS tf.Tensor(\n","[[[[ 3.34978074e-01 -8.70374218e-02  4.84363317e-01 -2.23696113e-01\n","     1.99014276e-01  4.74684358e-01 -2.17360348e-01 -3.14242840e-01\n","     6.73566312e-02 -4.96813841e-02  3.35785836e-01 -3.30952853e-02\n","     2.49824002e-01  9.56793502e-02 -2.37666070e-01 -3.40907097e-01\n","    -3.02252322e-01 -3.07268724e-02 -5.40450662e-02  3.83937418e-01\n","    -2.13585690e-01  3.97230804e-01  4.47136790e-01  2.65472233e-01\n","    -2.19262421e-01 -2.99017310e-01  3.82028192e-01  2.52583921e-01\n","    -4.91466187e-02  2.08281115e-01 -3.84858638e-01  6.16698563e-01\n","    -4.31696415e-01 -5.15292406e-01  2.00812414e-01 -2.69058108e-01\n","     9.33620036e-02 -8.91858786e-02  1.86207548e-01 -3.57870221e-01\n","     2.79453844e-02  4.06312615e-01  3.34959030e-01  3.29565704e-01\n","    -3.51908505e-01 -5.50307482e-02  1.13866255e-01  9.93724987e-02\n","     9.78282541e-02  1.36746362e-01 -7.44952355e-04  9.12522078e-02\n","    -2.32670277e-01  5.87081760e-02 -1.09120077e-02  1.30675659e-02\n","    -4.09567766e-02  3.64533603e-01  4.33521807e-01  1.21904366e-01\n","     1.84751511e-01  1.40301362e-02 -3.42019409e-01  1.85932666e-02\n","    -1.05451293e-01  3.11126947e-01  3.22749585e-01  1.96697652e-01\n","     1.06339790e-02  2.22899854e-01 -1.45646021e-01  3.69698942e-01\n","     1.23715475e-02 -1.55053362e-01 -8.15370753e-02  4.26198930e-01\n","     4.15589511e-02  6.78792968e-02 -2.36521974e-01 -1.27060652e-01\n","    -1.91861510e-01 -2.81353593e-01  2.29494721e-01  1.41725183e-01\n","     4.05534595e-01  4.94804472e-01  1.31679401e-01  2.25525483e-01\n","    -2.95015454e-01 -9.72463191e-02 -2.39683986e-02 -9.65156257e-02\n","     2.46336743e-01  2.33794466e-01 -4.70171839e-01 -2.47596473e-01\n","     4.35011052e-02 -1.80463523e-01 -9.25487280e-02  1.39576152e-01\n","     7.90892541e-02  9.22825262e-02  1.62057996e-01 -6.19495869e-01\n","     2.63793409e-01  8.79021436e-02 -4.15690362e-01  4.90584910e-01\n","    -2.13935748e-01  6.23749614e-01 -9.64052230e-02  1.89357758e-01\n","    -2.47632101e-01  3.20503592e-01  1.28532544e-01  1.72024757e-01\n","     2.62952983e-01 -2.52045821e-02 -1.16732582e-01  1.39450818e-01\n","     3.43433022e-01  1.87746584e-02 -3.39027792e-01 -3.73559773e-01\n","     1.67003900e-01 -1.19442776e-01  5.26356339e-01  2.67910153e-01\n","    -3.77651483e-01 -3.46953601e-01  3.63543630e-01  1.46169573e-01\n","    -2.54767299e-01 -2.61442006e-01  5.76477885e-01  3.57677825e-02\n","     4.57403183e-01  6.38170913e-02 -2.50696957e-01 -3.62431109e-01\n","     2.54662484e-01  5.72692640e-02 -2.30176263e-02 -4.51668352e-03\n","    -2.60506123e-01 -2.32347444e-01 -3.00771773e-01  1.73800528e-01\n","     4.26165164e-02 -2.59564161e-01 -6.72577620e-01  5.68462759e-02\n","    -1.36151016e-01 -3.71789575e-01 -2.07033753e-01 -5.67686334e-02\n","     3.73603925e-02 -3.02032173e-01  2.71094590e-01 -4.80862670e-02\n","     2.05768079e-01 -1.66335404e-01  1.00782745e-01  1.08109958e-01\n","     4.96198535e-01  1.38449162e-01  2.41575465e-01 -4.05595064e-01\n","    -9.54455882e-02  5.37792481e-02 -9.72433537e-02 -3.03994864e-04\n","     5.62717617e-01 -5.34145534e-01  1.05128318e-01  4.38278139e-01\n","    -3.02003950e-01 -4.26858887e-02  1.76312461e-01 -4.17484492e-01\n","     1.61198854e-01  1.53609872e-01 -5.03921732e-02 -2.13337615e-01\n","     1.26502901e-01  1.45939395e-01 -3.52373183e-01 -2.58180976e-01\n","     7.22595751e-02 -8.49078596e-02  6.73343360e-01  2.05063552e-01\n","     1.39143541e-02 -1.86033361e-02  1.24095529e-01 -4.52122122e-01\n","     9.60821062e-02 -3.56748283e-01  3.80424708e-02  3.33549023e-01\n","    -5.25688231e-02  5.40617108e-01  6.34321213e-01  2.53188163e-02\n","     1.42799318e-01 -1.11115471e-01 -7.28674978e-02 -2.71962374e-01\n","     1.33564666e-01  4.01362590e-02  9.72917080e-02  2.55355954e-01\n","     1.13244250e-01 -2.78525949e-02  1.08436316e-01  4.07911718e-01\n","     3.43391299e-01  2.17094868e-01  3.85801829e-02  2.63974704e-02\n","     9.54541266e-02 -3.78434584e-02 -8.07546005e-02  4.04461741e-01\n","     6.35512844e-02 -1.32816106e-01  1.82935625e-01 -3.23222190e-01\n","    -4.14811283e-01  3.37440521e-01  1.23094618e-02 -1.39810801e-01\n","     1.33478135e-01 -2.86957502e-01  4.29419652e-02  4.70805168e-02\n","     3.35021615e-01  8.62794518e-02  1.14288330e-01  9.93569642e-02\n","    -4.68185753e-01 -1.57474298e-02 -2.13604525e-01  6.04086578e-01\n","    -5.78494012e-01  1.10770479e-01 -9.66388360e-02  1.99088097e-01\n","     3.82330894e-01  4.64121938e-01 -1.98784620e-02  8.71031210e-02\n","     3.95506918e-01 -1.11545458e-01 -2.47765779e-01 -1.47156119e-01\n","    -2.03053355e-02 -1.84855133e-01 -3.31374168e-01 -3.31794351e-01\n","    -1.07329965e-01  4.73934650e-01 -1.19458221e-01  4.33120355e-02\n","    -2.68652141e-01  6.71273544e-02 -1.54387504e-01 -9.12876502e-02\n","     5.05887389e-01 -7.49223586e-03  1.98071003e-01  2.98811138e-01\n","    -2.73529142e-01  3.85891162e-02  3.29705000e-01 -1.39052048e-03\n","     1.89009905e-01  5.08693695e-01 -9.02734697e-02 -1.97205842e-02\n","    -1.14652231e-01  2.18123540e-01 -2.57933259e-01 -1.14831135e-01\n","    -1.64808661e-01 -8.27563256e-02  9.36153904e-02 -7.14728385e-02\n","    -5.29258013e-01 -3.98925781e-01  2.73810625e-01  1.24859802e-01\n","     1.50406450e-01 -1.85049504e-01  3.60028774e-01 -6.94456458e-01\n","     6.63601980e-02  8.91767442e-02 -2.66628414e-01  1.52441323e-01\n","     5.12640961e-02 -1.52783900e-01  1.47893876e-01 -3.33601296e-01\n","    -2.17383638e-01 -1.15214646e-01  1.00647099e-01 -2.12926716e-01\n","    -3.78033936e-01 -1.14732735e-01 -9.02993903e-02  3.81192207e-01\n","    -1.93802863e-01 -5.45391142e-02  1.68549478e-01 -2.66942412e-01\n","     1.35636643e-01  1.52409077e-01  1.28966838e-01 -1.97931677e-01\n","     5.03770709e-02 -6.81572378e-01  2.32391059e-01 -2.34852105e-01\n","     1.29519895e-01  3.09039772e-01 -1.94239855e-01  1.69992343e-01\n","    -9.82940793e-02  8.26662779e-03 -5.06454706e-01  5.33742130e-01\n","    -2.16715127e-01  4.80930626e-01  7.66251981e-02 -3.52757782e-01\n","    -3.20945919e-01 -9.40985233e-03  6.75702617e-02 -2.74036616e-01\n","    -6.12266362e-02 -4.05426919e-01 -4.14117992e-01 -2.45883942e-01\n","    -7.50863999e-02  8.27308297e-02 -1.80474073e-01 -1.20846651e-01\n","     1.91413626e-01  2.27349162e-01  3.60436559e-01 -1.89267695e-02\n","    -3.66154283e-01 -8.03499877e-01  6.81616813e-02 -2.85158485e-01\n","    -1.19671889e-01 -1.29306868e-01 -2.36667365e-01 -4.06102017e-02\n","    -4.34975624e-01  1.43651113e-01  5.53402752e-02  1.47455260e-01\n","    -4.17044014e-03  2.33266316e-03  4.05977428e-01  1.07920453e-01\n","     7.28444159e-02 -1.07511677e-01  9.21434239e-02  1.32787496e-01\n","     3.27418655e-01  1.28525600e-01 -9.24926847e-02  2.71833509e-01\n","     5.47199011e-01  2.81667054e-01  4.52309400e-01 -3.75312358e-01\n","    -6.36581421e-01  4.41271439e-02  5.13683200e-01  2.05080777e-01\n","     5.23166955e-01 -2.40502298e-01  2.17960924e-01 -5.25159359e-01\n","    -1.55334800e-01  3.53219867e-01  1.75237522e-01  1.28127798e-01\n","    -1.44112259e-01 -6.14072755e-03  1.41608179e-01  1.01979122e-01\n","     4.62231934e-02 -3.15860659e-01  6.60782874e-01  2.91916490e-01\n","    -4.66593951e-02 -3.03856045e-01 -2.06450179e-01 -2.43945003e-01\n","     3.86355147e-02  2.58403182e-01 -1.72157764e-01 -2.14447528e-01\n","     2.32071295e-01 -3.35042477e-01  2.03447849e-01  1.35686621e-01\n","    -8.69104788e-02 -8.05830508e-02 -1.16925731e-01 -3.23435307e-01\n","    -3.42588425e-01  1.86448455e-01 -2.31052458e-01  7.93279633e-02\n","     1.49303854e-01  7.85121247e-02 -2.02817559e-01  2.08290085e-01\n","     2.68203914e-01 -1.99254304e-01 -2.49554068e-01 -1.11116096e-01\n","     2.78567255e-01  5.23531139e-02 -4.44019735e-01  6.50156438e-01\n","     1.62831783e-01 -4.19153064e-01  3.00332457e-01  6.94076046e-02\n","     1.24011375e-01  2.84763992e-01 -2.58411050e-01 -1.94951266e-01\n","    -5.65545022e-01 -2.68613487e-01 -7.56000280e-02 -1.33585766e-01\n","     7.67073989e-01  9.70290601e-02 -1.37561888e-01  3.39848474e-02\n","     6.28272772e-01  2.60824680e-01 -2.53672659e-01  6.16177768e-02\n","    -4.83275950e-02  2.09421575e-01  4.35507804e-01 -2.04911157e-01\n","    -2.23223597e-01  1.17619902e-01  7.69189149e-02  1.65735334e-02\n","     5.44960164e-02 -1.61051765e-01 -1.13036051e-01 -7.93718100e-02\n","     2.07080022e-01 -4.39924687e-01  1.37215525e-01  4.56381381e-01\n","    -2.91138083e-01 -2.07296491e-01 -1.19903669e-01  1.67184442e-01\n","    -6.58879578e-02  1.89474851e-01 -1.11604989e-01 -5.95554709e-03\n","     9.42359865e-03 -8.88431147e-02 -3.94598782e-01 -4.81937043e-02\n","    -5.06987274e-02  4.07980531e-02 -2.84466237e-01  1.94956005e-01\n","     4.60185587e-01 -8.87307525e-02 -7.65896589e-02  1.95072532e-01\n","     4.04892445e-01 -1.67796686e-01 -1.02784790e-01  1.95677295e-01\n","    -1.92520544e-02 -4.18684185e-01 -1.50234237e-01 -7.18953609e-02\n","    -7.29144514e-02 -6.41866207e-01  7.53307343e-03  1.44625932e-01\n","     2.41807371e-01 -2.97755361e-01  3.80004048e-01  5.16923666e-01\n","    -2.20810398e-02  3.96872938e-01 -2.95182019e-01  1.56240165e-03\n","    -3.39981496e-01 -2.28182375e-01 -3.59180957e-01  3.57627384e-02]]]], shape=(1, 1, 1, 512), dtype=float32)\n","BRANCH AFTER RESHAPE\n","tf.Tensor(\n","[[[ 3.34978074e-01 -1.74074844e-02  4.84363317e-01 -4.47392240e-02\n","    1.99014276e-01  4.74684358e-01 -4.34720702e-02 -6.28485680e-02\n","    6.73566312e-02 -9.93627682e-03  3.35785836e-01 -6.61905715e-03\n","    2.49824002e-01  9.56793502e-02 -4.75332141e-02 -6.81814179e-02\n","   -6.04504645e-02 -6.14537438e-03 -1.08090136e-02  3.83937418e-01\n","   -4.27171402e-02  3.97230804e-01  4.47136790e-01  2.65472233e-01\n","   -4.38524857e-02 -5.98034635e-02  3.82028192e-01  2.52583921e-01\n","   -9.82932374e-03  2.08281115e-01 -7.69717321e-02  6.16698563e-01\n","   -8.63392875e-02 -1.03058480e-01  2.00812414e-01 -5.38116209e-02\n","    9.33620036e-02 -1.78371761e-02  1.86207548e-01 -7.15740472e-02\n","    2.79453844e-02  4.06312615e-01  3.34959030e-01  3.29565704e-01\n","   -7.03817010e-02 -1.10061495e-02  1.13866255e-01  9.93724987e-02\n","    9.78282541e-02  1.36746362e-01 -1.48990468e-04  9.12522078e-02\n","   -4.65340577e-02  5.87081760e-02 -2.18240148e-03  1.30675659e-02\n","   -8.19135550e-03  3.64533603e-01  4.33521807e-01  1.21904366e-01\n","    1.84751511e-01  1.40301362e-02 -6.84038848e-02  1.85932666e-02\n","   -2.10902598e-02  3.11126947e-01  3.22749585e-01  1.96697652e-01\n","    1.06339790e-02  2.22899854e-01 -2.91292053e-02  3.69698942e-01\n","    1.23715475e-02 -3.10106725e-02 -1.63074154e-02  4.26198930e-01\n","    4.15589511e-02  6.78792968e-02 -4.73043956e-02 -2.54121311e-02\n","   -3.83723043e-02 -5.62707186e-02  2.29494721e-01  1.41725183e-01\n","    4.05534595e-01  4.94804472e-01  1.31679401e-01  2.25525483e-01\n","   -5.90030923e-02 -1.94492638e-02 -4.79367981e-03 -1.93031263e-02\n","    2.46336743e-01  2.33794466e-01 -9.40343663e-02 -4.95192967e-02\n","    4.35011052e-02 -3.60927060e-02 -1.85097456e-02  1.39576152e-01\n","    7.90892541e-02  9.22825262e-02  1.62057996e-01 -1.23899177e-01\n","    2.63793409e-01  8.79021436e-02 -8.31380710e-02  4.90584910e-01\n","   -4.27871495e-02  6.23749614e-01 -1.92810446e-02  1.89357758e-01\n","   -4.95264195e-02  3.20503592e-01  1.28532544e-01  1.72024757e-01\n","    2.62952983e-01 -5.04091661e-03 -2.33465172e-02  1.39450818e-01\n","    3.43433022e-01  1.87746584e-02 -6.78055584e-02 -7.47119561e-02\n","    1.67003900e-01 -2.38885563e-02  5.26356339e-01  2.67910153e-01\n","   -7.55302981e-02 -6.93907216e-02  3.63543630e-01  1.46169573e-01\n","   -5.09534590e-02 -5.22884019e-02  5.76477885e-01  3.57677825e-02\n","    4.57403183e-01  6.38170913e-02 -5.01393937e-02 -7.24862218e-02\n","    2.54662484e-01  5.72692640e-02 -4.60352516e-03 -9.03336739e-04\n","   -5.21012247e-02 -4.64694910e-02 -6.01543561e-02  1.73800528e-01\n","    4.26165164e-02 -5.19128330e-02 -1.34515524e-01  5.68462759e-02\n","   -2.72302032e-02 -7.43579194e-02 -4.14067507e-02 -1.13537265e-02\n","    3.73603925e-02 -6.04064353e-02  2.71094590e-01 -9.61725321e-03\n","    2.05768079e-01 -3.32670808e-02  1.00782745e-01  1.08109958e-01\n","    4.96198535e-01  1.38449162e-01  2.41575465e-01 -8.11190158e-02\n","   -1.90891176e-02  5.37792481e-02 -1.94486715e-02 -6.07989750e-05\n","    5.62717617e-01 -1.06829107e-01  1.05128318e-01  4.38278139e-01\n","   -6.04007915e-02 -8.53717793e-03  1.76312461e-01 -8.34968984e-02\n","    1.61198854e-01  1.53609872e-01 -1.00784348e-02 -4.26675230e-02\n","    1.26502901e-01  1.45939395e-01 -7.04746395e-02 -5.16361967e-02\n","    7.22595751e-02 -1.69815719e-02  6.73343360e-01  2.05063552e-01\n","    1.39143541e-02 -3.72066721e-03  1.24095529e-01 -9.04244259e-02\n","    9.60821062e-02 -7.13496581e-02  3.80424708e-02  3.33549023e-01\n","   -1.05137648e-02  5.40617108e-01  6.34321213e-01  2.53188163e-02\n","    1.42799318e-01 -2.22230945e-02 -1.45734996e-02 -5.43924756e-02\n","    1.33564666e-01  4.01362590e-02  9.72917080e-02  2.55355954e-01\n","    1.13244250e-01 -5.57051925e-03  1.08436316e-01  4.07911718e-01\n","    3.43391299e-01  2.17094868e-01  3.85801829e-02  2.63974704e-02\n","    9.54541266e-02 -7.56869186e-03 -1.61509197e-02  4.04461741e-01\n","    6.35512844e-02 -2.65632216e-02  1.82935625e-01 -6.46444410e-02\n","   -8.29622597e-02  3.37440521e-01  1.23094618e-02 -2.79621612e-02\n","    1.33478135e-01 -5.73915020e-02  4.29419652e-02  4.70805168e-02\n","    3.35021615e-01  8.62794518e-02  1.14288330e-01  9.93569642e-02\n","   -9.36371535e-02 -3.14948591e-03 -4.27209064e-02  6.04086578e-01\n","   -1.15698807e-01  1.10770479e-01 -1.93277672e-02  1.99088097e-01\n","    3.82330894e-01  4.64121938e-01 -3.97569267e-03  8.71031210e-02\n","    3.95506918e-01 -2.23090928e-02 -4.95531559e-02 -2.94312239e-02]\n","  [-4.06106701e-03 -3.69710289e-02 -6.62748367e-02 -6.63588718e-02\n","   -2.14659926e-02  4.73934650e-01 -2.38916446e-02  4.33120355e-02\n","   -5.37304282e-02  6.71273544e-02 -3.08775008e-02 -1.82575304e-02\n","    5.05887389e-01 -1.49844715e-03  1.98071003e-01  2.98811138e-01\n","   -5.47058284e-02  3.85891162e-02  3.29705000e-01 -2.78104097e-04\n","    1.89009905e-01  5.08693695e-01 -1.80546939e-02 -3.94411711e-03\n","   -2.29304470e-02  2.18123540e-01 -5.15866540e-02 -2.29662266e-02\n","   -3.29617336e-02 -1.65512655e-02  9.36153904e-02 -1.42945675e-02\n","   -1.05851606e-01 -7.97851607e-02  2.73810625e-01  1.24859802e-01\n","    1.50406450e-01 -3.70099023e-02  3.60028774e-01 -1.38891295e-01\n","    6.63601980e-02  8.91767442e-02 -5.33256829e-02  1.52441323e-01\n","    5.12640961e-02 -3.05567812e-02  1.47893876e-01 -6.67202622e-02\n","   -4.34767269e-02 -2.30429303e-02  1.00647099e-01 -4.25853431e-02\n","   -7.56067857e-02 -2.29465477e-02 -1.80598777e-02  3.81192207e-01\n","   -3.87605727e-02 -1.09078232e-02  1.68549478e-01 -5.33884838e-02\n","    1.35636643e-01  1.52409077e-01  1.28966838e-01 -3.95863354e-02\n","    5.03770709e-02 -1.36314481e-01  2.32391059e-01 -4.69704233e-02\n","    1.29519895e-01  3.09039772e-01 -3.88479717e-02  1.69992343e-01\n","   -1.96588170e-02  8.26662779e-03 -1.01290941e-01  5.33742130e-01\n","   -4.33430262e-02  4.80930626e-01  7.66251981e-02 -7.05515593e-02\n","   -6.41891882e-02 -1.88197044e-03  6.75702617e-02 -5.48073240e-02\n","   -1.22453272e-02 -8.10853839e-02 -8.28235969e-02 -4.91767898e-02\n","   -1.50172804e-02  8.27308297e-02 -3.60948145e-02 -2.41693314e-02\n","    1.91413626e-01  2.27349162e-01  3.60436559e-01 -3.78535385e-03\n","   -7.32308552e-02 -1.60699978e-01  6.81616813e-02 -5.70316985e-02\n","   -2.39343774e-02 -2.58613732e-02 -4.73334752e-02 -8.12204089e-03\n","   -8.69951248e-02  1.43651113e-01  5.53402752e-02  1.47455260e-01\n","   -8.34088016e-04  2.33266316e-03  4.05977428e-01  1.07920453e-01\n","    7.28444159e-02 -2.15023365e-02  9.21434239e-02  1.32787496e-01\n","    3.27418655e-01  1.28525600e-01 -1.84985381e-02  2.71833509e-01\n","    5.47199011e-01  2.81667054e-01  4.52309400e-01 -7.50624761e-02\n","   -1.27316281e-01  4.41271439e-02  5.13683200e-01  2.05080777e-01\n","    5.23166955e-01 -4.81004603e-02  2.17960924e-01 -1.05031870e-01\n","   -3.10669597e-02  3.53219867e-01  1.75237522e-01  1.28127798e-01\n","   -2.88224518e-02 -1.22814556e-03  1.41608179e-01  1.01979122e-01\n","    4.62231934e-02 -6.31721318e-02  6.60782874e-01  2.91916490e-01\n","   -9.33187921e-03 -6.07712083e-02 -4.12900373e-02 -4.87890020e-02\n","    3.86355147e-02  2.58403182e-01 -3.44315544e-02 -4.28895056e-02\n","    2.32071295e-01 -6.70084953e-02  2.03447849e-01  1.35686621e-01\n","   -1.73820965e-02 -1.61166098e-02 -2.33851466e-02 -6.46870658e-02\n","   -6.85176849e-02  1.86448455e-01 -4.62104939e-02  7.93279633e-02\n","    1.49303854e-01  7.85121247e-02 -4.05635126e-02  2.08290085e-01\n","    2.68203914e-01 -3.98508608e-02 -4.99108136e-02 -2.22232193e-02\n","    2.78567255e-01  5.23531139e-02 -8.88039470e-02  6.50156438e-01\n","    1.62831783e-01 -8.38306174e-02  3.00332457e-01  6.94076046e-02\n","    1.24011375e-01  2.84763992e-01 -5.16822115e-02 -3.89902554e-02\n","   -1.13109007e-01 -5.37226982e-02 -1.51200062e-02 -2.67171543e-02\n","    7.67073989e-01  9.70290601e-02 -2.75123771e-02  3.39848474e-02\n","    6.28272772e-01  2.60824680e-01 -5.07345311e-02  6.16177768e-02\n","   -9.66551900e-03  2.09421575e-01  4.35507804e-01 -4.09822315e-02\n","   -4.46447209e-02  1.17619902e-01  7.69189149e-02  1.65735334e-02\n","    5.44960164e-02 -3.22103538e-02 -2.26072110e-02 -1.58743616e-02\n","    2.07080022e-01 -8.79849419e-02  1.37215525e-01  4.56381381e-01\n","   -5.82276173e-02 -4.14592996e-02 -2.39807349e-02  1.67184442e-01\n","   -1.31775914e-02  1.89474851e-01 -2.23209988e-02 -1.19110942e-03\n","    9.42359865e-03 -1.77686233e-02 -7.89197609e-02 -9.63874068e-03\n","   -1.01397457e-02  4.07980531e-02 -5.68932481e-02  1.94956005e-01\n","    4.60185587e-01 -1.77461505e-02 -1.53179318e-02  1.95072532e-01\n","    4.04892445e-01 -3.35593373e-02 -2.05569584e-02  1.95677295e-01\n","   -3.85041093e-03 -8.37368369e-02 -3.00468486e-02 -1.43790720e-02\n","   -1.45828901e-02 -1.28373250e-01  7.53307343e-03  1.44625932e-01\n","    2.41807371e-01 -5.95510714e-02  3.80004048e-01  5.16923666e-01\n","   -4.41620825e-03  3.96872938e-01 -5.90364039e-02  1.56240165e-03\n","   -6.79963008e-02 -4.56364751e-02 -7.18361959e-02  3.57627384e-02]]], shape=(1, 2, 256), dtype=float32)\n","Branch W_loop call\n","tf.Tensor(\n","[[[ 0.16074948  0.02726888 -0.1483281  -0.267167    0.03990196\n","    0.08452332  0.14645429 -0.00356812 -0.10468601  0.05803591\n","   -0.10396388  0.00307645 -0.0821885   0.11930558 -0.06114142\n","    0.0739757   0.16653067 -0.14567004 -0.06524757  0.23774514\n","   -0.21197534 -0.04361791  0.02712768 -0.0499827  -0.09425329\n","    0.05813421  0.1712763  -0.09171123  0.21146454  0.09214148\n","    0.06889249  0.01899497 -0.01753894 -0.05751219 -0.17041604\n","   -0.05311546 -0.06010672  0.08043291 -0.26893127  0.26422948\n","   -0.02669669 -0.07335306 -0.00670842  0.1758125   0.04051\n","   -0.13165647 -0.10632835 -0.06445012  0.05056855  0.05131036\n","    0.01985805 -0.03299287  0.00079969  0.10309062 -0.01499612\n","    0.2247858  -0.05651368 -0.08620442  0.03335249 -0.00156299\n","   -0.03221137  0.02656281 -0.01456533  0.11368202  0.0862291\n","    0.11850789 -0.08268655 -0.01728121 -0.12936658  0.04225958\n","   -0.0043244  -0.22280246  0.0531408   0.12354857 -0.05284657\n","   -0.27980733 -0.03345889 -0.08552787  0.24887145 -0.0715515\n","   -0.00382897  0.1590749  -0.04117434 -0.01570287  0.00084921\n","   -0.05047755 -0.14750984  0.05858883 -0.12180305 -0.02593904\n","    0.08740877 -0.08677705  0.12220299  0.14240755  0.15227541\n","   -0.15056443 -0.01735914 -0.06475174  0.04374303 -0.01475929\n","   -0.09665865 -0.04225376 -0.10757095  0.04016434  0.03781842\n","    0.03416488 -0.08288323  0.09459691  0.23653592 -0.29348114\n","   -0.07977653 -0.10122678  0.1232028   0.13514464  0.05272991\n","   -0.03134506 -0.32244426  0.1765544   0.13222633  0.09194539\n","   -0.20734307  0.1985744   0.05140049  0.15281382 -0.11262004\n","   -0.07085858 -0.07185218  0.01266574  0.06136954 -0.21903749\n","    0.18262674 -0.08638968  0.08531787  0.12090231  0.17026179\n","    0.01160554 -0.1808448   0.2810161   0.17602895 -0.23274575\n","    0.08761913  0.00486561  0.06303764  0.02690779  0.06987797\n","    0.12124018 -0.0668129   0.01672144 -0.09583361  0.00558215\n","   -0.04887192 -0.15390441  0.07534091  0.00192006 -0.20519021\n","   -0.00144393 -0.03281254  0.06122412  0.06790887 -0.09925167\n","   -0.3064173   0.12473246  0.19843921 -0.00666422 -0.0882775\n","   -0.19635715  0.04401489 -0.2890562  -0.1389639   0.00367336\n","    0.18854171  0.1081685   0.1599783   0.07547563  0.23892097\n","   -0.12416445 -0.15429212  0.03890444 -0.07352367  0.27211314\n","    0.00050581 -0.021532   -0.03327175  0.04543263 -0.29396614\n","    0.03276281 -0.03419798 -0.19412307 -0.02879955  0.00392969\n","    0.04395408 -0.01863541  0.09586294 -0.10265744 -0.04103258\n","   -0.10329395  0.04036458 -0.12530157  0.01006743  0.08466493\n","   -0.03669069  0.01904266 -0.07037892 -0.1154921   0.21641296\n","    0.06457568  0.10006975 -0.03458195 -0.00294731  0.0462677\n","    0.06478946 -0.13014261 -0.09071361 -0.1894634   0.17132398\n","    0.1276123  -0.03827671  0.12175569  0.21957383  0.03165514\n","   -0.18244347  0.26687852 -0.11556049  0.12284469 -0.05539681\n","    0.13815013  0.06103925 -0.13452373 -0.2615457   0.2387773\n","   -0.1852122   0.09198829  0.17801878 -0.02860207 -0.10346768\n","   -0.02084242  0.11763819 -0.25633517 -0.06889996 -0.07845236\n","    0.07391682 -0.03602176 -0.03374723 -0.27432477 -0.03138724\n","    0.14387512  0.08879986 -0.03371195  0.05439362  0.26902893\n","   -0.01121818  0.03943729 -0.02292426 -0.05779918 -0.05914938\n","    0.22619781]\n","  [-0.01425634 -0.03662914  0.03833952 -0.09963968 -0.03088565\n","   -0.07109192  0.19809943 -0.06457543  0.0251775  -0.01596653\n","   -0.09250514  0.00201368 -0.09142616  0.12216495  0.15627103\n","    0.13752963 -0.01279881 -0.20436838  0.12445036  0.0639714\n","    0.08422903  0.00241855  0.02686717 -0.1437985  -0.10350484\n","    0.17323075 -0.02549484 -0.0555728   0.05626568  0.13802797\n","   -0.0282817   0.04231317  0.00595787  0.17637143  0.05698347\n","    0.12146882 -0.17921098 -0.06118388 -0.04626917  0.20789298\n","   -0.0404161  -0.10845767 -0.02985429 -0.06016735 -0.12326469\n","   -0.09683482 -0.0574703   0.11214453  0.14516544 -0.04283319\n","    0.08021764 -0.10768892 -0.10782772  0.17886977 -0.08450971\n","    0.11438721  0.0641103  -0.19904682  0.07628594 -0.11651564\n","   -0.05125362 -0.10260174 -0.24767195 -0.0576984   0.06859164\n","   -0.08084103  0.02400726 -0.02037325 -0.2182062   0.14223874\n","   -0.05785464 -0.0815578   0.03198624  0.09553947  0.03469072\n","   -0.27230522  0.20286714  0.00911754  0.2144622  -0.15471601\n","   -0.0181185  -0.0088894  -0.10165767  0.08875224 -0.07564726\n","   -0.10078129 -0.03891566 -0.03211417 -0.08127805 -0.06217031\n","   -0.0193702  -0.09281202  0.02618396 -0.20915352  0.08349475\n","   -0.01667166 -0.05433206 -0.09178025  0.11594676 -0.2543074\n","    0.1760595  -0.10589138 -0.06377369  0.10963121  0.07627153\n","    0.21333653 -0.11486614  0.15275292 -0.12328048 -0.1391024\n","   -0.1291608  -0.15532775  0.13930035  0.10137748 -0.17556329\n","    0.08771285 -0.01745507  0.02151194 -0.00213874 -0.13725391\n","   -0.03756668  0.04571258 -0.12752804  0.00180555 -0.22273904\n","   -0.08649896  0.15354754  0.13414201  0.1112593  -0.23157838\n","    0.17118588 -0.05989585  0.13587904 -0.03107578  0.07905275\n","   -0.0537836  -0.11032557  0.05909959 -0.00102285  0.04236514\n","   -0.03589682 -0.15205355  0.1025994   0.02782393 -0.03878517\n","    0.02891292 -0.06118201 -0.15108801  0.00068246 -0.1102936\n","   -0.0318959  -0.03066588  0.13156448  0.01327852 -0.13186584\n","   -0.09228514 -0.14708611  0.15069434 -0.14072648 -0.15423551\n","   -0.18475604  0.09959497 -0.05079979  0.03113391 -0.06672648\n","   -0.07194476 -0.07825832  0.07773963 -0.07479079  0.01193397\n","   -0.10379459  0.05773868 -0.02728424  0.22903068  0.03935274\n","   -0.04130599 -0.06206866  0.03688546 -0.02754883  0.0447099\n","   -0.08129732 -0.02816521  0.16750903  0.03450377  0.01291153\n","   -0.09725697 -0.06206534  0.0016432  -0.12585685 -0.17352098\n","    0.17293058 -0.0031428  -0.08266135  0.1044226   0.06591092\n","    0.0574421   0.10515264 -0.24224576 -0.06327599  0.11009939\n","    0.16528888  0.04729218 -0.10151146  0.1429822  -0.07215926\n","    0.0208011  -0.07809237 -0.02551022  0.06086596 -0.1040473\n","   -0.01282828 -0.06412436 -0.03298854 -0.25187483  0.00818391\n","    0.16188706 -0.02749675 -0.25136843  0.03190576  0.07249652\n","   -0.07719547  0.16783063  0.06290688  0.12625128 -0.05381043\n","    0.04787702  0.01036133  0.00603143 -0.05800944  0.25659272\n","    0.0175705   0.08947144  0.05704606  0.11704442 -0.16404524\n","   -0.17457087  0.15119135 -0.12224986  0.02758343  0.01964212\n","   -0.0033455  -0.07691051  0.05675747 -0.13065238  0.022274\n","    0.11023051 -0.04975886 -0.18528885 -0.11182642 -0.04519416\n","    0.07627876  0.06922301 -0.03240526  0.1404152   0.00357265\n","    0.13449906]]], shape=(1, 2, 256), dtype=float32)\n","BRANCH AFTER RE TILE\n","tf.Tensor(\n","[[[-3.88771296e-05  7.89416850e-01 -1.05366731e+00 -3.73350978e-01\n","   -1.65082216e-01  1.46226740e+00  6.71455562e-01  4.13022608e-01\n","    3.14014673e-01  1.35762727e+00  3.69576365e-01  6.68668598e-02\n","   -9.56219137e-01 -2.63186246e-02 -5.34759104e-01  2.06206292e-02\n","   -4.01862800e-01  1.31315246e-01  7.46075511e-01  5.13874292e-01\n","    2.01678991e-01  2.02315480e-01 -1.05494249e+00  9.07956123e-01\n","   -1.02893484e+00  7.73661256e-01 -6.75921321e-01  5.95759809e-01\n","    1.03349006e+00 -1.43583000e-01  1.87329561e-01  1.03288817e+00\n","    2.39055067e-01 -4.76270527e-01  2.38149717e-01 -3.15522820e-01\n","   -7.57263005e-02 -6.33716702e-01  1.81611568e-01 -4.91549075e-02\n","    6.40514374e-01 -9.26582038e-01  2.22221583e-01 -1.55197665e-01\n","    2.58402467e-01 -4.60033834e-01 -5.08209288e-01 -1.45296037e-01\n","   -6.32720649e-01 -7.37550706e-02 -2.27156758e-01  1.48838162e-01\n","    4.46283758e-01  7.93269649e-02 -1.61894119e+00  2.66307235e-01\n","    2.97328651e-01 -6.35427058e-01 -1.05140245e+00  7.33439147e-01\n","    3.83916676e-01  8.89836773e-02  4.99536395e-01  6.43668532e-01\n","   -5.01968741e-01  3.67816627e-01  6.11755729e-01  2.42536098e-01\n","   -5.21498203e-01  1.17701709e-01 -4.25365627e-01 -7.57995903e-01\n","   -4.29586053e-01 -3.58756363e-01  1.08318758e+00  6.17459416e-01\n","    6.21146739e-01  4.68144745e-01  6.66654646e-01  4.23396170e-01\n","    4.16170388e-01 -2.43941337e-01 -2.85206437e-01 -8.08019578e-01\n","   -3.94127160e-01  1.69560984e-01 -4.09393042e-01 -3.07735026e-01\n","    1.09938003e-01 -2.61222482e-01 -1.40654817e-02 -1.34533346e+00\n","    4.74328846e-01 -9.33004916e-03  4.74130899e-01  8.19283545e-01\n","    5.98897636e-01  4.39723372e-01  2.51083493e-01  2.07025141e-01\n","   -6.77368045e-01 -2.79971898e-01 -8.66959035e-01  3.86057615e-01\n","    5.38044691e-01  3.37873757e-01 -2.00080693e-01  7.00131834e-01\n","   -4.67389941e-01 -2.17604190e-01  3.55929434e-01 -1.99370667e-01\n","   -5.73705792e-01  4.61803824e-02  1.57763511e-01 -9.47778821e-02\n","   -9.60075021e-01 -1.53374597e-01 -8.62111568e-01  8.00600290e-01\n","   -4.67622072e-01 -2.16297776e-01  5.14961220e-02  4.11427885e-01\n","   -3.06652188e-02 -7.32098520e-01  6.16076469e-01  1.11710958e-01\n","    1.05926502e+00 -7.34691739e-01  8.40644956e-01  7.30321527e-01\n","    4.83114958e-01  4.59475815e-01  1.13915598e+00 -1.32075429e+00\n","   -5.91086745e-01  1.15961313e-01 -2.12240830e-01 -5.59308529e-01\n","    1.14080000e+00 -1.44873190e+00  4.77483124e-01  7.40213871e-01\n","   -3.46724749e-01  2.29711205e-01  2.64892399e-01  4.42267656e-01\n","    5.50634921e-01 -4.15568233e-01  5.15102029e-01 -6.52180314e-01\n","   -2.03855887e-01  8.51464272e-01 -4.94505018e-01 -7.65228420e-02\n","   -1.23164082e+00 -8.87159407e-02 -2.33627573e-01 -9.88828838e-01\n","   -7.52005577e-02 -8.77261832e-02  1.97795987e-01  1.91985294e-01\n","    4.90389109e-01 -1.34351090e-01 -3.48457187e-01  6.45234823e-01\n","   -1.98298946e-01 -3.67205858e-01 -1.42673910e-01  9.80994105e-01\n","    1.12641543e-01  5.28570056e-01  5.50229132e-01  2.94225156e-01\n","   -3.39458048e-01 -3.46058667e-01  5.51697612e-01 -9.84082520e-02\n","    2.12108716e-01  2.85008729e-01  1.08711445e+00  4.15869981e-01\n","   -1.18004024e+00  8.88818130e-02 -2.48967633e-02  2.98894763e-01\n","    1.62217426e+00 -6.16036236e-01  1.64303899e+00 -5.45628309e-01\n","   -1.25527307e-01 -9.00000811e-01 -6.12862825e-01  8.65424156e-01\n","   -8.77523363e-01 -3.48252803e-01  8.47784996e-01 -1.62964121e-01\n","   -4.60999519e-01  6.68114483e-01 -1.14794362e+00  7.47861385e-01\n","    5.02736270e-01 -8.27404618e-01  3.24540198e-01 -1.69791436e+00\n","   -3.95137995e-01  1.91633373e-01  2.70862639e-01 -1.74231753e-01\n","    7.81994939e-01 -7.68011808e-03 -4.60449904e-01  5.76032162e-01\n","   -3.56004298e-01 -3.02713364e-02  8.72892618e-01  8.90181720e-01\n","   -4.66289520e-02 -1.92901820e-01 -6.87937677e-01 -4.01594639e-01\n","    2.93738782e-01  2.70904869e-01 -6.46246672e-01 -3.52077067e-01\n","   -7.76020169e-01  1.13116908e+00 -5.46334386e-01 -3.55811805e-01\n","    6.24650717e-01  4.08212990e-01  8.48179340e-01  6.99913979e-01\n","    1.74528837e-01 -1.29756629e+00 -3.38603288e-01 -1.50320202e-01\n","   -1.87482804e-01 -4.69830543e-01  1.18997917e-01 -5.67262352e-01\n","    1.03253722e-01  5.48545599e-01  2.21656471e-01  2.24102408e-01\n","   -8.80469561e-01  7.99130440e-01 -5.87793738e-02 -2.17512906e-01\n","    4.95290577e-01  3.00473683e-02  1.02458441e+00  6.44511402e-01]\n","  [-1.75044701e-01  7.25518823e-01 -8.66999745e-01 -2.05823660e-01\n","   -2.35869825e-01  1.30665219e+00  7.23100722e-01  3.52015287e-01\n","    4.43878204e-01  1.28362489e+00  3.81035089e-01  6.58040941e-02\n","   -9.65456843e-01 -2.34592557e-02 -3.17346692e-01  8.41745511e-02\n","   -5.81192255e-01  7.26169050e-02  9.35773432e-01  3.40100586e-01\n","    4.97883350e-01  2.48351932e-01 -1.05520296e+00  8.14140320e-01\n","   -1.03818643e+00  8.88757825e-01 -8.72692406e-01  6.31898224e-01\n","    8.78291190e-01 -9.76965129e-02  9.01553854e-02  1.05620646e+00\n","    2.62551874e-01 -2.42386907e-01  4.65549231e-01 -1.40938550e-01\n","   -1.94830552e-01 -7.75333464e-01  4.04273659e-01 -1.05491400e-01\n","    6.26794934e-01 -9.61686671e-01  1.99075714e-01 -3.91177505e-01\n","    9.46277976e-02 -4.25212175e-01 -4.59351212e-01  3.12986225e-02\n","   -5.38123727e-01 -1.67898625e-01 -1.66797191e-01  7.41421133e-02\n","    3.37656349e-01  1.55106112e-01 -1.68845475e+00  1.55908644e-01\n","    4.17952627e-01 -7.48269439e-01 -1.00846899e+00  6.18486524e-01\n","    3.64874423e-01 -4.01808694e-02  2.66429782e-01  4.72288102e-01\n","   -5.19606173e-01  1.68467730e-01  7.18449533e-01  2.39444047e-01\n","   -6.10337794e-01  2.17680871e-01 -4.78895873e-01 -6.16751254e-01\n","   -4.50740606e-01 -3.86765480e-01  1.17072487e+00  6.24961495e-01\n","    8.57472777e-01  5.62790155e-01  6.32245421e-01  3.40231657e-01\n","    4.01880860e-01 -4.11905646e-01 -3.45689774e-01 -7.03564525e-01\n","   -4.70623642e-01  1.19257241e-01 -3.00798863e-01 -3.98438036e-01\n","    1.50463015e-01 -2.97453731e-01 -1.20844454e-01 -1.35136843e+00\n","    3.78309816e-01 -3.60891104e-01  4.05350238e-01  9.53176320e-01\n","    5.61924696e-01  4.12694871e-01  3.23287249e-01 -3.25229615e-02\n","   -4.04649913e-01 -3.43609512e-01 -8.23161781e-01  4.55524504e-01\n","    5.76497793e-01  5.17045379e-01 -2.32063591e-01  7.58287847e-01\n","   -8.27206314e-01 -6.32254481e-02  3.06545138e-01 -2.53471643e-01\n","   -5.57608247e-01  1.24132261e-02 -7.05296844e-02  2.42800340e-02\n","   -6.55085862e-01 -3.08417052e-01 -9.96476650e-01  5.71401000e-01\n","   -2.97845662e-01 -3.69159579e-01 -1.27432406e-01  2.60419607e-01\n","   -1.40784219e-01 -7.47738898e-01  8.41476202e-01  2.33187228e-01\n","    1.10915482e+00 -7.47232676e-01  8.29204082e-01  7.56815314e-01\n","    5.33676147e-01  3.07497740e-01  1.04794705e+00 -1.38614345e+00\n","   -5.20567536e-01 -1.05955206e-01 -3.89292628e-01 -2.84197628e-01\n","    1.01728404e+00 -1.60565114e+00  5.17044902e-01  7.41129994e-01\n","   -4.55387890e-01  1.37383938e-01  2.70523310e-01  2.74458230e-01\n","    6.47150993e-01 -5.31444013e-01  5.32078087e-01 -5.28941751e-01\n","   -1.47632316e-01  8.62822771e-01 -4.21180665e-01 -1.67364061e-01\n","   -1.34591436e+00  7.54281878e-04 -4.42262918e-01 -1.04381263e+00\n","    4.64606881e-02 -1.12863675e-01 -5.14430106e-02  2.29783431e-01\n","    5.11940122e-01 -9.93870199e-03 -4.70730424e-01  1.01203072e+00\n","   -1.34125844e-01 -3.58945251e-01 -4.35010195e-01  9.30564284e-01\n","   -7.46209919e-02  6.82125092e-01  3.50660890e-01  3.77083629e-01\n","   -2.47234613e-01 -3.48077625e-01  5.97672403e-01 -3.25811505e-01\n","    1.30305588e-01  2.78375506e-01  1.28789532e+00  4.04941112e-01\n","   -8.73162508e-01 -4.11379710e-02 -5.27641252e-02  4.94661063e-01\n","    1.52511692e+00 -7.93486893e-01  1.77201545e+00 -5.30135691e-01\n","   -3.04051608e-01 -6.92920804e-01 -5.05919337e-01  1.02616024e+00\n","   -8.12735319e-01 -4.65196997e-01  7.74441540e-01 -1.37529656e-01\n","   -2.59019971e-01  6.96363986e-01 -1.17907619e+00  1.00633574e+00\n","    2.14164048e-01 -8.71179223e-01  1.46378070e-01 -1.68884265e+00\n","   -3.31324726e-01  4.13183719e-02  1.93244904e-01 -1.08213499e-01\n","    8.39720011e-01 -7.00915456e-02 -6.23589993e-01  6.10306919e-01\n","   -3.45224351e-01 -4.03395474e-01  6.85224593e-01  9.31023121e-01\n","    5.86190522e-02 -2.91949689e-01 -5.09470344e-01 -3.98188055e-01\n","    2.95325160e-01  1.80631757e-01 -6.96924627e-01 -2.11521924e-01\n","   -5.72483897e-01  1.14898455e+00 -3.43551725e-01 -3.58328640e-01\n","    5.03677964e-01  5.53859472e-01  7.87601829e-01  5.46185553e-01\n","    2.08082005e-01 -1.16348100e+00 -2.42119908e-01 -5.22257164e-02\n","   -2.64745116e-01 -5.10719299e-01  2.09502608e-01 -4.23589945e-01\n","    1.56914964e-01  5.14900923e-01  8.30977485e-02  7.25255013e-02\n","   -1.04668963e+00  4.84907329e-01  2.87175700e-02 -1.87727183e-01\n","    4.85809565e-01  2.28261754e-01  1.08730650e+00  5.52812636e-01]]], shape=(1, 2, 256), dtype=float32)\n","0\n","Tree INDEX:  0 2\n","tf.Tensor(\n","[[[0.01047182 0.59066546 0.39506686 0.6289226  0.61416733 0.11192453\n","   0.30162597 0.92322063 0.06005347 0.4205227  0.5107981  0.7969223\n","   0.9080839  0.57025886 0.2834581  0.90183246 0.9557593  0.9391173\n","   0.2427814  0.40333366 0.5925106  0.5375744  0.6049135  0.6379062\n","   0.83508635 0.6918887  0.01023054 0.8498752  0.24461305 0.33344865\n","   0.88443565 0.50010383 0.06586492 0.14401078 0.9661263  0.07820046\n","   0.8140285  0.32176793 0.48425317 0.39198327 0.75259864 0.44515467\n","   0.00307918 0.4255302  0.6385578  0.7718121  0.01598752 0.8888041\n","   0.7453935  0.9360999  0.469962   0.33280253 0.62882626 0.30295599\n","   0.8215525  0.13067889 0.2499367  0.43057394 0.4070083  0.10915458\n","   0.66520846 0.10049736 0.3901155  0.69108176 0.11987472 0.9388958\n","   0.39744174 0.48599482 0.8281683  0.17230654 0.7776722  0.5991373\n","   0.97225726 0.25942183 0.28829956 0.40875483 0.95815384 0.5111251\n","   0.09509945 0.65893793 0.51377916 0.574008   0.17741227 0.9151815\n","   0.48197544 0.5930363  0.9448329  0.66817796 0.83241916 0.9848572\n","   0.92965066 0.6101297  0.10795307 0.8371556  0.8690964  0.47578883]]], shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 2\n","Root Node\n","tf.Tensor(\n","[[[ 0.6632613   0.68516564  0.3042265  -0.2107657  -1.4531176\n","   -0.20845741 -0.01417748  0.14802778 -0.79086685 -0.15049106\n","   -0.14872026  0.77600014 -0.39948952  0.46300334  0.3617464\n","    0.39798474  0.06712358 -0.17936671 -0.0826888  -0.6960513\n","   -0.50789446 -0.1944342   0.16508183 -0.14948022  0.1300008\n","   -0.2373836  -0.34433728  0.1593484   0.320902   -0.39065146\n","   -0.5089533  -0.64818347 -0.34540945 -0.08503645  0.34379292\n","    0.80305076  0.4749193   0.34274185  0.7975503  -0.15406649\n","   -0.9346173  -0.3410474   0.2846639  -0.36210123  0.20321342\n","   -0.12854046  0.63309264  0.17024629  0.5595      0.01075546\n","   -0.54584515  0.47523075 -0.9439652   0.1755189   0.19673614\n","   -0.5018739  -0.08335758  0.54696995  0.64802855  0.6717834\n","    0.38025242 -0.35927272 -0.34342945 -0.6128185   0.5117775\n","    0.6006235   0.40368482 -0.41637504  0.00806776 -0.07722631\n","    0.31550783 -0.6080304  -0.18260752 -0.8508553  -0.02605394\n","   -0.49983886 -0.02911475 -0.41716626  0.3589707  -0.31082577\n","    0.8906671  -0.18614687  0.23710024  0.09858268 -0.26445153\n","   -0.20012128 -0.3475616  -0.26518625  0.30893806  0.11313678\n","   -0.3275937  -0.40451503 -0.6983604  -0.06895283 -0.04617908\n","   -0.61004865 -0.15393597 -0.09607557  0.26763877 -0.35492605\n","   -0.04385773 -0.6458854  -0.19070765  0.16422713  0.1301699\n","    0.53274506 -0.6140504  -0.767531    0.15913692 -0.38473153\n","   -0.37291563 -0.9063108   0.13194503 -0.01732063  0.12849447\n","    0.49464357  0.38875344 -0.41747904  0.5199798  -0.02926172\n","    0.3217219  -1.4142982   0.79720193 -0.1283504  -0.48398122\n","    0.27960864  0.7210635  -0.53832746  0.7664854   0.39928278\n","    0.42271802 -0.6459615   0.14368972  0.37559006 -0.6546595\n","   -0.20801216  0.35029328  0.0850905   0.21703134  0.5727135\n","   -0.4151516  -0.2980071   0.3160419  -0.07151449  0.08180514\n","    0.13059796  0.39283028 -0.60117155  0.98270583  0.9616673\n","   -0.6479023   0.08583649 -0.06407332  0.3270523  -0.71013796\n","   -0.25603718  0.39154184  0.307294   -0.12986428  0.3742876\n","    0.37414536 -0.2834705   0.7251962  -0.5145951   0.70029473\n","    0.14062855 -0.34867457 -0.1287576  -0.3969025  -0.09673394\n","    0.65680134 -0.52482826 -0.37531796 -0.60746765 -0.62569475\n","   -0.35817152  0.48944452  0.3764814   0.37760678  0.60828227\n","   -0.8230529  -0.17134795 -0.03615136  0.48474216  0.37672094\n","    0.58702683 -0.62301314 -0.0066128   0.04453525  0.48138118\n","    0.03378934 -0.04935614 -0.36998796 -0.28151712 -0.35662413\n","    0.5122338   0.98974645 -0.56819737  0.19747904 -0.12200113\n","    0.09453012  0.11628841 -0.6511903  -0.01695642  0.66803974\n","    0.57078016 -0.2342665   0.06346823 -0.5885804   0.04992911\n","    0.21792087  0.3136636   0.06481276 -0.82346433  0.1807735\n","   -0.23294857 -0.91709507 -0.55155593 -0.22695898 -0.34384775\n","    0.16462402 -0.24056047 -0.03301878  0.09458643 -0.41005972\n","    0.85906243  0.7430308  -0.4890173   0.15139744  0.07831056\n","    0.52241653 -0.6066263  -0.62899804 -0.11218226  0.5440091\n","   -0.02972428 -0.828465    0.5726259  -0.7418222   0.3575934\n","    0.29393625 -0.71848726 -0.53461426  0.01262228  0.10273795\n","   -0.12395599  0.9109055  -0.02589428 -0.68269324  0.29861984\n","   -0.40862036  0.4489106   0.02691494 -0.21568495 -0.20352142\n","    0.35007423]]], shape=(1, 1, 256), dtype=float32)\n","tf.Tensor([  1   1 256], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[ 0.6632613   0.68516564  0.3042265  -0.2107657  -1.4531176\n","   -0.20845741 -0.01417748  0.14802778 -0.79086685 -0.15049106\n","   -0.14872026  0.77600014 -0.39948952  0.46300334  0.3617464\n","    0.39798474  0.06712358 -0.17936671 -0.0826888  -0.6960513\n","   -0.50789446 -0.1944342   0.16508183 -0.14948022  0.1300008\n","   -0.2373836  -0.34433728  0.1593484   0.320902   -0.39065146\n","   -0.5089533  -0.64818347 -0.34540945 -0.08503645  0.34379292\n","    0.80305076  0.4749193   0.34274185  0.7975503  -0.15406649\n","   -0.9346173  -0.3410474   0.2846639  -0.36210123  0.20321342\n","   -0.12854046  0.63309264  0.17024629  0.5595      0.01075546\n","   -0.54584515  0.47523075 -0.9439652   0.1755189   0.19673614\n","   -0.5018739  -0.08335758  0.54696995  0.64802855  0.6717834\n","    0.38025242 -0.35927272 -0.34342945 -0.6128185   0.5117775\n","    0.6006235   0.40368482 -0.41637504  0.00806776 -0.07722631\n","    0.31550783 -0.6080304  -0.18260752 -0.8508553  -0.02605394\n","   -0.49983886 -0.02911475 -0.41716626  0.3589707  -0.31082577\n","    0.8906671  -0.18614687  0.23710024  0.09858268 -0.26445153\n","   -0.20012128 -0.3475616  -0.26518625  0.30893806  0.11313678\n","   -0.3275937  -0.40451503 -0.6983604  -0.06895283 -0.04617908\n","   -0.61004865 -0.15393597 -0.09607557  0.26763877 -0.35492605\n","   -0.04385773 -0.6458854  -0.19070765  0.16422713  0.1301699\n","    0.53274506 -0.6140504  -0.767531    0.15913692 -0.38473153\n","   -0.37291563 -0.9063108   0.13194503 -0.01732063  0.12849447\n","    0.49464357  0.38875344 -0.41747904  0.5199798  -0.02926172\n","    0.3217219  -1.4142982   0.79720193 -0.1283504  -0.48398122\n","    0.27960864  0.7210635  -0.53832746  0.7664854   0.39928278\n","    0.42271802 -0.6459615   0.14368972  0.37559006 -0.6546595\n","   -0.20801216  0.35029328  0.0850905   0.21703134  0.5727135\n","   -0.4151516  -0.2980071   0.3160419  -0.07151449  0.08180514\n","    0.13059796  0.39283028 -0.60117155  0.98270583  0.9616673\n","   -0.6479023   0.08583649 -0.06407332  0.3270523  -0.71013796\n","   -0.25603718  0.39154184  0.307294   -0.12986428  0.3742876\n","    0.37414536 -0.2834705   0.7251962  -0.5145951   0.70029473\n","    0.14062855 -0.34867457 -0.1287576  -0.3969025  -0.09673394\n","    0.65680134 -0.52482826 -0.37531796 -0.60746765 -0.62569475\n","   -0.35817152  0.48944452  0.3764814   0.37760678  0.60828227\n","   -0.8230529  -0.17134795 -0.03615136  0.48474216  0.37672094\n","    0.58702683 -0.62301314 -0.0066128   0.04453525  0.48138118\n","    0.03378934 -0.04935614 -0.36998796 -0.28151712 -0.35662413\n","    0.5122338   0.98974645 -0.56819737  0.19747904 -0.12200113\n","    0.09453012  0.11628841 -0.6511903  -0.01695642  0.66803974\n","    0.57078016 -0.2342665   0.06346823 -0.5885804   0.04992911\n","    0.21792087  0.3136636   0.06481276 -0.82346433  0.1807735\n","   -0.23294857 -0.91709507 -0.55155593 -0.22695898 -0.34384775\n","    0.16462402 -0.24056047 -0.03301878  0.09458643 -0.41005972\n","    0.85906243  0.7430308  -0.4890173   0.15139744  0.07831056\n","    0.52241653 -0.6066263  -0.62899804 -0.11218226  0.5440091\n","   -0.02972428 -0.828465    0.5726259  -0.7418222   0.3575934\n","    0.29393625 -0.71848726 -0.53461426  0.01262228  0.10273795\n","   -0.12395599  0.9109055  -0.02589428 -0.68269324  0.29861984\n","   -0.40862036  0.4489106   0.02691494 -0.21568495 -0.20352142\n","    0.35007423  0.6632613   0.68516564  0.3042265  -0.2107657\n","   -1.4531176  -0.20845741 -0.01417748  0.14802778 -0.79086685\n","   -0.15049106 -0.14872026  0.77600014 -0.39948952  0.46300334\n","    0.3617464   0.39798474  0.06712358 -0.17936671 -0.0826888\n","   -0.6960513  -0.50789446 -0.1944342   0.16508183 -0.14948022\n","    0.1300008  -0.2373836  -0.34433728  0.1593484   0.320902\n","   -0.39065146 -0.5089533  -0.64818347 -0.34540945 -0.08503645\n","    0.34379292  0.80305076  0.4749193   0.34274185  0.7975503\n","   -0.15406649 -0.9346173  -0.3410474   0.2846639  -0.36210123\n","    0.20321342 -0.12854046  0.63309264  0.17024629  0.5595\n","    0.01075546 -0.54584515  0.47523075 -0.9439652   0.1755189\n","    0.19673614 -0.5018739  -0.08335758  0.54696995  0.64802855\n","    0.6717834   0.38025242 -0.35927272 -0.34342945 -0.6128185\n","    0.5117775   0.6006235   0.40368482 -0.41637504  0.00806776\n","   -0.07722631  0.31550783 -0.6080304  -0.18260752 -0.8508553\n","   -0.02605394 -0.49983886 -0.02911475 -0.41716626  0.3589707\n","   -0.31082577  0.8906671  -0.18614687  0.23710024  0.09858268\n","   -0.26445153 -0.20012128 -0.3475616  -0.26518625  0.30893806\n","    0.11313678 -0.3275937  -0.40451503 -0.6983604  -0.06895283\n","   -0.04617908 -0.61004865 -0.15393597 -0.09607557  0.26763877\n","   -0.35492605 -0.04385773 -0.6458854  -0.19070765  0.16422713\n","    0.1301699   0.53274506 -0.6140504  -0.767531    0.15913692\n","   -0.38473153 -0.37291563 -0.9063108   0.13194503 -0.01732063\n","    0.12849447  0.49464357  0.38875344 -0.41747904  0.5199798\n","   -0.02926172  0.3217219  -1.4142982   0.79720193 -0.1283504\n","   -0.48398122  0.27960864  0.7210635  -0.53832746  0.7664854\n","    0.39928278  0.42271802 -0.6459615   0.14368972  0.37559006\n","   -0.6546595  -0.20801216  0.35029328  0.0850905   0.21703134\n","    0.5727135  -0.4151516  -0.2980071   0.3160419  -0.07151449\n","    0.08180514  0.13059796  0.39283028 -0.60117155  0.98270583\n","    0.9616673  -0.6479023   0.08583649 -0.06407332  0.3270523\n","   -0.71013796 -0.25603718  0.39154184  0.307294   -0.12986428\n","    0.3742876   0.37414536 -0.2834705   0.7251962  -0.5145951\n","    0.70029473  0.14062855 -0.34867457 -0.1287576  -0.3969025\n","   -0.09673394  0.65680134 -0.52482826 -0.37531796 -0.60746765\n","   -0.62569475 -0.35817152  0.48944452  0.3764814   0.37760678\n","    0.60828227 -0.8230529  -0.17134795 -0.03615136  0.48474216\n","    0.37672094  0.58702683 -0.62301314 -0.0066128   0.04453525\n","    0.48138118  0.03378934 -0.04935614 -0.36998796 -0.28151712\n","   -0.35662413  0.5122338   0.98974645 -0.56819737  0.19747904\n","   -0.12200113  0.09453012  0.11628841 -0.6511903  -0.01695642\n","    0.66803974  0.57078016 -0.2342665   0.06346823 -0.5885804\n","    0.04992911  0.21792087  0.3136636   0.06481276 -0.82346433\n","    0.1807735  -0.23294857 -0.91709507 -0.55155593 -0.22695898\n","   -0.34384775  0.16462402 -0.24056047 -0.03301878  0.09458643\n","   -0.41005972  0.85906243  0.7430308  -0.4890173   0.15139744\n","    0.07831056  0.52241653 -0.6066263  -0.62899804 -0.11218226\n","    0.5440091  -0.02972428 -0.828465    0.5726259  -0.7418222\n","    0.3575934   0.29393625 -0.71848726 -0.53461426  0.01262228\n","    0.10273795 -0.12395599  0.9109055  -0.02589428 -0.68269324\n","    0.29861984 -0.40862036  0.4489106   0.02691494 -0.21568495\n","   -0.20352142  0.35007423]]], shape=(1, 1, 512), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 0.6632613   0.68516564  0.3042265  -0.2107657  -1.4531176\n","   -0.20845741 -0.01417748  0.14802778 -0.79086685 -0.15049106\n","   -0.14872026  0.77600014 -0.39948952  0.46300334  0.3617464\n","    0.39798474  0.06712358 -0.17936671 -0.0826888  -0.6960513\n","   -0.50789446 -0.1944342   0.16508183 -0.14948022  0.1300008\n","   -0.2373836  -0.34433728  0.1593484   0.320902   -0.39065146\n","   -0.5089533  -0.64818347 -0.34540945 -0.08503645  0.34379292\n","    0.80305076  0.4749193   0.34274185  0.7975503  -0.15406649\n","   -0.9346173  -0.3410474   0.2846639  -0.36210123  0.20321342\n","   -0.12854046  0.63309264  0.17024629  0.5595      0.01075546\n","   -0.54584515  0.47523075 -0.9439652   0.1755189   0.19673614\n","   -0.5018739  -0.08335758  0.54696995  0.64802855  0.6717834\n","    0.38025242 -0.35927272 -0.34342945 -0.6128185   0.5117775\n","    0.6006235   0.40368482 -0.41637504  0.00806776 -0.07722631\n","    0.31550783 -0.6080304  -0.18260752 -0.8508553  -0.02605394\n","   -0.49983886 -0.02911475 -0.41716626  0.3589707  -0.31082577\n","    0.8906671  -0.18614687  0.23710024  0.09858268 -0.26445153\n","   -0.20012128 -0.3475616  -0.26518625  0.30893806  0.11313678\n","   -0.3275937  -0.40451503 -0.6983604  -0.06895283 -0.04617908\n","   -0.61004865 -0.15393597 -0.09607557  0.26763877 -0.35492605\n","   -0.04385773 -0.6458854  -0.19070765  0.16422713  0.1301699\n","    0.53274506 -0.6140504  -0.767531    0.15913692 -0.38473153\n","   -0.37291563 -0.9063108   0.13194503 -0.01732063  0.12849447\n","    0.49464357  0.38875344 -0.41747904  0.5199798  -0.02926172\n","    0.3217219  -1.4142982   0.79720193 -0.1283504  -0.48398122\n","    0.27960864  0.7210635  -0.53832746  0.7664854   0.39928278\n","    0.42271802 -0.6459615   0.14368972  0.37559006 -0.6546595\n","   -0.20801216  0.35029328  0.0850905   0.21703134  0.5727135\n","   -0.4151516  -0.2980071   0.3160419  -0.07151449  0.08180514\n","    0.13059796  0.39283028 -0.60117155  0.98270583  0.9616673\n","   -0.6479023   0.08583649 -0.06407332  0.3270523  -0.71013796\n","   -0.25603718  0.39154184  0.307294   -0.12986428  0.3742876\n","    0.37414536 -0.2834705   0.7251962  -0.5145951   0.70029473\n","    0.14062855 -0.34867457 -0.1287576  -0.3969025  -0.09673394\n","    0.65680134 -0.52482826 -0.37531796 -0.60746765 -0.62569475\n","   -0.35817152  0.48944452  0.3764814   0.37760678  0.60828227\n","   -0.8230529  -0.17134795 -0.03615136  0.48474216  0.37672094\n","    0.58702683 -0.62301314 -0.0066128   0.04453525  0.48138118\n","    0.03378934 -0.04935614 -0.36998796 -0.28151712 -0.35662413\n","    0.5122338   0.98974645 -0.56819737  0.19747904 -0.12200113\n","    0.09453012  0.11628841 -0.6511903  -0.01695642  0.66803974\n","    0.57078016 -0.2342665   0.06346823 -0.5885804   0.04992911\n","    0.21792087  0.3136636   0.06481276 -0.82346433  0.1807735\n","   -0.23294857 -0.91709507 -0.55155593 -0.22695898 -0.34384775\n","    0.16462402 -0.24056047 -0.03301878  0.09458643 -0.41005972\n","    0.85906243  0.7430308  -0.4890173   0.15139744  0.07831056\n","    0.52241653 -0.6066263  -0.62899804 -0.11218226  0.5440091\n","   -0.02972428 -0.828465    0.5726259  -0.7418222   0.3575934\n","    0.29393625 -0.71848726 -0.53461426  0.01262228  0.10273795\n","   -0.12395599  0.9109055  -0.02589428 -0.68269324  0.29861984\n","   -0.40862036  0.4489106   0.02691494 -0.21568495 -0.20352142\n","    0.35007423]\n","  [ 0.6632613   0.68516564  0.3042265  -0.2107657  -1.4531176\n","   -0.20845741 -0.01417748  0.14802778 -0.79086685 -0.15049106\n","   -0.14872026  0.77600014 -0.39948952  0.46300334  0.3617464\n","    0.39798474  0.06712358 -0.17936671 -0.0826888  -0.6960513\n","   -0.50789446 -0.1944342   0.16508183 -0.14948022  0.1300008\n","   -0.2373836  -0.34433728  0.1593484   0.320902   -0.39065146\n","   -0.5089533  -0.64818347 -0.34540945 -0.08503645  0.34379292\n","    0.80305076  0.4749193   0.34274185  0.7975503  -0.15406649\n","   -0.9346173  -0.3410474   0.2846639  -0.36210123  0.20321342\n","   -0.12854046  0.63309264  0.17024629  0.5595      0.01075546\n","   -0.54584515  0.47523075 -0.9439652   0.1755189   0.19673614\n","   -0.5018739  -0.08335758  0.54696995  0.64802855  0.6717834\n","    0.38025242 -0.35927272 -0.34342945 -0.6128185   0.5117775\n","    0.6006235   0.40368482 -0.41637504  0.00806776 -0.07722631\n","    0.31550783 -0.6080304  -0.18260752 -0.8508553  -0.02605394\n","   -0.49983886 -0.02911475 -0.41716626  0.3589707  -0.31082577\n","    0.8906671  -0.18614687  0.23710024  0.09858268 -0.26445153\n","   -0.20012128 -0.3475616  -0.26518625  0.30893806  0.11313678\n","   -0.3275937  -0.40451503 -0.6983604  -0.06895283 -0.04617908\n","   -0.61004865 -0.15393597 -0.09607557  0.26763877 -0.35492605\n","   -0.04385773 -0.6458854  -0.19070765  0.16422713  0.1301699\n","    0.53274506 -0.6140504  -0.767531    0.15913692 -0.38473153\n","   -0.37291563 -0.9063108   0.13194503 -0.01732063  0.12849447\n","    0.49464357  0.38875344 -0.41747904  0.5199798  -0.02926172\n","    0.3217219  -1.4142982   0.79720193 -0.1283504  -0.48398122\n","    0.27960864  0.7210635  -0.53832746  0.7664854   0.39928278\n","    0.42271802 -0.6459615   0.14368972  0.37559006 -0.6546595\n","   -0.20801216  0.35029328  0.0850905   0.21703134  0.5727135\n","   -0.4151516  -0.2980071   0.3160419  -0.07151449  0.08180514\n","    0.13059796  0.39283028 -0.60117155  0.98270583  0.9616673\n","   -0.6479023   0.08583649 -0.06407332  0.3270523  -0.71013796\n","   -0.25603718  0.39154184  0.307294   -0.12986428  0.3742876\n","    0.37414536 -0.2834705   0.7251962  -0.5145951   0.70029473\n","    0.14062855 -0.34867457 -0.1287576  -0.3969025  -0.09673394\n","    0.65680134 -0.52482826 -0.37531796 -0.60746765 -0.62569475\n","   -0.35817152  0.48944452  0.3764814   0.37760678  0.60828227\n","   -0.8230529  -0.17134795 -0.03615136  0.48474216  0.37672094\n","    0.58702683 -0.62301314 -0.0066128   0.04453525  0.48138118\n","    0.03378934 -0.04935614 -0.36998796 -0.28151712 -0.35662413\n","    0.5122338   0.98974645 -0.56819737  0.19747904 -0.12200113\n","    0.09453012  0.11628841 -0.6511903  -0.01695642  0.66803974\n","    0.57078016 -0.2342665   0.06346823 -0.5885804   0.04992911\n","    0.21792087  0.3136636   0.06481276 -0.82346433  0.1807735\n","   -0.23294857 -0.91709507 -0.55155593 -0.22695898 -0.34384775\n","    0.16462402 -0.24056047 -0.03301878  0.09458643 -0.41005972\n","    0.85906243  0.7430308  -0.4890173   0.15139744  0.07831056\n","    0.52241653 -0.6066263  -0.62899804 -0.11218226  0.5440091\n","   -0.02972428 -0.828465    0.5726259  -0.7418222   0.3575934\n","    0.29393625 -0.71848726 -0.53461426  0.01262228  0.10273795\n","   -0.12395599  0.9109055  -0.02589428 -0.68269324  0.29861984\n","   -0.40862036  0.4489106   0.02691494 -0.21568495 -0.20352142\n","    0.35007423]]], shape=(1, 2, 256), dtype=float32)\n","1\n","Tree INDEX:  1 2\n","tf.Tensor(\n","[[[-4.38085161e-02  5.14522731e-01  2.79901981e-01 -8.42245668e-02\n","    3.10131192e-01 -4.91717719e-02  2.82714933e-01  1.59668729e-01\n","    3.16451937e-01  1.06002778e-01 -1.75797984e-01  2.43300289e-01\n","   -1.64478689e-01 -1.36502862e-01 -6.29783124e-02  3.34693581e-01\n","    5.62972575e-02 -2.08755001e-01 -2.35163011e-02  4.75989431e-02\n","    6.91371381e-01  4.30168569e-01 -1.54355762e-03 -5.37517965e-02\n","   -5.20638600e-02  4.11936998e-01 -1.20539621e-01  1.11038074e-01\n","   -3.03011369e-02 -1.38722941e-01 -1.40641006e-02  6.65612340e-01\n","   -4.24496494e-02  3.96848619e-02  4.31291163e-02 -1.95318349e-02\n","    9.59906131e-02 -1.05199710e-01  1.95507586e-01 -1.26699820e-01\n","    1.28836364e-01 -6.88220784e-02 -3.85855585e-02 -5.60288690e-02\n","    5.18352509e-01 -6.01034872e-02  9.03500319e-01 -3.26057449e-02\n","   -9.54587013e-02  3.70612174e-01 -3.59645486e-02 -8.60777125e-02\n","   -6.46821409e-02  4.43804145e-01 -1.74348634e-02 -2.72681396e-02\n","   -1.01330522e-02  1.12554908e-01  6.42261267e-01  3.02520126e-01\n","   -6.61709928e-04 -1.60289556e-01 -7.79324695e-02 -1.38009591e-02\n","    9.41904336e-02  5.89249969e-01 -2.62701400e-02 -1.70951396e-01\n","   -3.97389568e-02 -1.82683662e-01 -1.02914207e-01  5.65070093e-01\n","   -1.69491798e-01  3.61192599e-02 -8.35777298e-02  3.07498991e-01\n","    1.70458123e-01  1.15783095e+00 -4.53899838e-02 -1.48425521e-02\n","   -2.28466671e-02 -9.98113677e-02  5.18225551e-01 -1.61068395e-01\n","   -1.15866914e-01  1.01097316e-01  3.80062699e-01  4.65870589e-01\n","    8.82818639e-01  1.05144113e-01 -4.04038420e-03  8.61021951e-02\n","   -7.97107145e-02  5.37506565e-02  1.61904633e-01 -1.22601725e-01\n","   -1.00071840e-01  8.22263807e-02 -2.52077286e-03  8.16332042e-01\n","   -1.21257246e-01  5.40857911e-01  3.20210099e-01  2.04921946e-01\n","   -1.39518946e-01 -1.00047044e-01  3.31661403e-01 -3.80643718e-02\n","    3.11563760e-02  7.30425954e-01 -1.22975193e-01  1.75942704e-01\n","   -8.55988488e-02  4.75723296e-02 -1.28500894e-01  5.40147871e-02\n","   -3.89585160e-02 -6.07193373e-02  3.22029412e-01 -1.83825597e-01\n","    3.60989213e-01 -3.17464583e-02 -9.42828655e-02 -1.57229009e-03\n","   -1.20822955e-02  5.33291325e-02  6.91701889e-01 -6.13104701e-02\n","    6.83839977e-01 -5.03671635e-03 -1.21477142e-01  6.75283194e-01\n","   -1.17253698e-01  2.13981539e-01 -1.75970748e-01 -1.57257378e-01\n","    3.83838773e-01  3.16658974e-01 -2.18769953e-01  3.01411927e-01\n","   -1.43378735e-01  5.75608850e-01  3.69392514e-01  4.21119153e-01\n","    1.99424356e-01  1.04867280e+00  5.83800554e-01 -2.83690728e-02\n","   -7.38091543e-02  4.98416334e-01 -1.14961743e-01 -1.04038253e-01\n","   -3.48988734e-02  8.40120792e-01  5.99176526e-01 -8.60372484e-02\n","    3.18731606e-01 -2.25727987e-02 -1.13547323e-02 -2.42312551e-01\n","   -1.66865084e-02 -2.36818776e-01 -3.06139886e-02  4.63447452e-01\n","   -2.03188490e-02  5.95955253e-01 -1.03045814e-01 -9.36243162e-02\n","   -1.38037264e-01 -8.49231109e-02  1.14787087e-01  2.94745386e-01\n","   -2.57693738e-01 -8.62302706e-02  2.48403400e-01 -8.06332752e-02\n","    8.42356443e-01  8.37407112e-01  7.04727113e-01 -1.05859868e-01\n","   -2.08054911e-02  5.99296167e-02 -5.57315908e-02 -1.19325612e-02\n","    3.27064395e-01 -9.52453166e-02  4.80743587e-01 -6.31099045e-02\n","   -7.79415295e-02 -1.89042166e-01  5.92057526e-01 -1.45959064e-01\n","    7.80217528e-01  5.93814313e-01  5.35137296e-01  2.92976677e-01\n","   -1.16906941e-01 -9.80610996e-02 -1.46089494e-01 -5.50946081e-03\n","   -5.49266301e-02 -1.54027566e-01  1.79697081e-01 -9.01245400e-02\n","   -2.96709426e-02 -1.16103508e-01  4.42664325e-03 -7.27676302e-02\n","    1.23814344e-01 -9.50086340e-02 -1.74927384e-01  3.07584763e-01\n","   -4.50636558e-02 -6.32648915e-02 -8.37559924e-02  8.36740255e-01\n","    7.35139966e-01 -4.36255559e-02  5.60533553e-02  9.75343883e-01\n","   -8.64997786e-03  9.29381847e-02  1.42363712e-01 -1.14082217e-01\n","   -8.13403651e-02  3.41797709e-01  7.97768474e-01 -1.34938331e-02\n","   -7.73214325e-02 -7.79429078e-02  5.68927169e-01 -3.44287418e-02\n","   -1.95526466e-01 -7.07361028e-02  2.91816294e-02 -4.70517054e-02\n","   -2.44555678e-02  3.53707671e-01 -5.52726388e-02 -1.31136447e-01\n","    5.78834474e-01  3.06794703e-01 -1.43088177e-01 -3.00416686e-02\n","   -7.45682567e-02  5.96050024e-01  1.32087752e-01 -9.65137500e-03\n","   -5.68172224e-02  4.14800346e-02  1.15839410e+00  3.20272565e-01\n","   -5.14090769e-02  2.63104320e-01 -7.59995803e-02 -1.75420044e-03]]], shape=(1, 1, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 2\n","Root Node\n","tf.Tensor(\n","[[[-0.03699152 -0.20767015 -0.1337964   0.1668877  -0.3399255\n","   -0.32769585  0.23808232 -0.16695033  0.02439449  0.00274041\n","    0.06088229 -0.2597509  -0.01767946  0.19207676  0.23022361\n","   -0.60714716  0.09048863 -0.2192395  -0.05936902  0.04191577\n","   -0.05270524  0.23663145 -0.06647035 -0.54862463  0.16574599\n","   -0.20493445 -0.16494587  0.26001602 -0.11982307  0.12590373\n","    0.13697457  0.14826775 -0.15493678  0.18912901 -0.1279011\n","   -0.07301702  0.05745639  0.24206267 -0.02269528 -0.07960842\n","    0.6378299   0.02634695  0.03155926  0.5116144   0.2427056\n","    0.3810838  -0.19384697 -0.14644541  0.287713   -0.48327503\n","   -0.2349413   0.1275169  -0.42661875  0.5994502  -0.10263976\n","   -0.11650018 -0.19316633 -0.24694708 -0.1447139   0.05126567\n","   -0.4715914   0.10365757  0.8339995   0.38659975 -0.25156486\n","   -0.1116536  -0.03726653 -0.17397496  0.08886705  0.08510463\n","   -0.00706091  0.4208346   0.40278375 -0.39136243  0.15153074\n","   -0.4667586  -0.46288723 -0.3722644  -0.02309956  0.07062495\n","    0.16996448  0.03153069 -0.00789718  0.20382309 -0.13460967\n","   -0.14165804 -0.23547551 -0.08047052  0.090488   -0.4384016\n","   -0.08614726 -0.04375869  0.26698977  0.4295684  -0.39686537\n","   -0.17702304  0.47151253  0.44915476  0.279186    0.59465057\n","   -0.7505502   0.12090574 -0.14538325 -0.06817994 -0.33098835\n","   -0.0608792   0.328292    0.45060647  0.05668586  0.5361295\n","    0.8194254  -0.23019755 -0.06987632  0.20807482  0.05329863\n","    0.1788369  -0.41585863  0.5538282  -0.71710116  0.06616964\n","    0.18955271 -0.38260132  0.01881558 -0.3303459   0.26025808\n","   -0.30446872  0.05062157  0.4780155   0.07619479 -0.17179933\n","    0.26400554  0.16338034 -0.06817717 -0.38345593  0.31583676\n","   -0.04153731  0.22735131 -0.04777666  0.12833025 -0.1599229\n","   -0.150472    0.78039926 -0.13005064  0.4458398   0.08069739\n","    0.6259585   0.14462194  0.44833484 -0.15025191 -0.27868068\n","   -0.54998535  0.01407127 -0.22403589 -0.1868908   0.16131379\n","   -0.18533367  0.34106225  0.25382408  0.47513118  0.00484329\n","    0.4046474   0.20917052 -0.05787653  0.02860564  0.09024564\n","   -0.37730074  0.04331394  0.2749188  -0.27024415 -0.10331126\n","   -0.62163925  0.7763341  -0.30267176 -0.2585101   0.390186\n","    0.3792786  -0.07594728  0.6475176  -0.25830585 -0.15307522\n","    0.15447363  0.11052534 -0.18355677 -0.23072208 -0.30175397\n","    0.13382037  0.46688986 -0.21265803  0.20327076  1.0517248\n","    0.00348808 -0.00151378  0.26972705  0.10598832 -0.32661507\n","    0.32142937 -0.3591305   0.2945135   0.0709611   0.23298934\n","    0.49614173  0.11726561  0.22872734  0.57879275 -0.08537485\n","    0.24196973  0.24599993  0.27652726 -0.36627078 -0.29571784\n","   -0.47953397  0.5380628   0.6377648  -0.11793889 -0.7081148\n","   -0.14172663  0.4966742   0.1157116  -0.09672577  0.20543545\n","   -0.23321733 -0.11515934  0.4234832  -0.08898574 -0.3681782\n","    0.29359117  0.2093176   0.67205423 -0.02213149 -0.28773314\n","    0.11225837 -0.7095693  -0.29595912  0.8231108  -0.16960219\n","   -0.4042877   0.11366334  0.01756098  0.14284015 -0.1696057\n","   -0.3693818   0.68302     0.14547247 -0.17018563 -0.19615938\n","   -0.36185277 -0.27712905  0.10943591  0.01087565 -0.40225816\n","   -0.46355543 -0.40717268  0.18082227 -0.09662735  0.19293416\n","    0.40781057]]], shape=(1, 1, 256), dtype=float32)\n","tf.Tensor([  1   1 256], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[-0.03699152 -0.20767015 -0.1337964   0.1668877  -0.3399255\n","   -0.32769585  0.23808232 -0.16695033  0.02439449  0.00274041\n","    0.06088229 -0.2597509  -0.01767946  0.19207676  0.23022361\n","   -0.60714716  0.09048863 -0.2192395  -0.05936902  0.04191577\n","   -0.05270524  0.23663145 -0.06647035 -0.54862463  0.16574599\n","   -0.20493445 -0.16494587  0.26001602 -0.11982307  0.12590373\n","    0.13697457  0.14826775 -0.15493678  0.18912901 -0.1279011\n","   -0.07301702  0.05745639  0.24206267 -0.02269528 -0.07960842\n","    0.6378299   0.02634695  0.03155926  0.5116144   0.2427056\n","    0.3810838  -0.19384697 -0.14644541  0.287713   -0.48327503\n","   -0.2349413   0.1275169  -0.42661875  0.5994502  -0.10263976\n","   -0.11650018 -0.19316633 -0.24694708 -0.1447139   0.05126567\n","   -0.4715914   0.10365757  0.8339995   0.38659975 -0.25156486\n","   -0.1116536  -0.03726653 -0.17397496  0.08886705  0.08510463\n","   -0.00706091  0.4208346   0.40278375 -0.39136243  0.15153074\n","   -0.4667586  -0.46288723 -0.3722644  -0.02309956  0.07062495\n","    0.16996448  0.03153069 -0.00789718  0.20382309 -0.13460967\n","   -0.14165804 -0.23547551 -0.08047052  0.090488   -0.4384016\n","   -0.08614726 -0.04375869  0.26698977  0.4295684  -0.39686537\n","   -0.17702304  0.47151253  0.44915476  0.279186    0.59465057\n","   -0.7505502   0.12090574 -0.14538325 -0.06817994 -0.33098835\n","   -0.0608792   0.328292    0.45060647  0.05668586  0.5361295\n","    0.8194254  -0.23019755 -0.06987632  0.20807482  0.05329863\n","    0.1788369  -0.41585863  0.5538282  -0.71710116  0.06616964\n","    0.18955271 -0.38260132  0.01881558 -0.3303459   0.26025808\n","   -0.30446872  0.05062157  0.4780155   0.07619479 -0.17179933\n","    0.26400554  0.16338034 -0.06817717 -0.38345593  0.31583676\n","   -0.04153731  0.22735131 -0.04777666  0.12833025 -0.1599229\n","   -0.150472    0.78039926 -0.13005064  0.4458398   0.08069739\n","    0.6259585   0.14462194  0.44833484 -0.15025191 -0.27868068\n","   -0.54998535  0.01407127 -0.22403589 -0.1868908   0.16131379\n","   -0.18533367  0.34106225  0.25382408  0.47513118  0.00484329\n","    0.4046474   0.20917052 -0.05787653  0.02860564  0.09024564\n","   -0.37730074  0.04331394  0.2749188  -0.27024415 -0.10331126\n","   -0.62163925  0.7763341  -0.30267176 -0.2585101   0.390186\n","    0.3792786  -0.07594728  0.6475176  -0.25830585 -0.15307522\n","    0.15447363  0.11052534 -0.18355677 -0.23072208 -0.30175397\n","    0.13382037  0.46688986 -0.21265803  0.20327076  1.0517248\n","    0.00348808 -0.00151378  0.26972705  0.10598832 -0.32661507\n","    0.32142937 -0.3591305   0.2945135   0.0709611   0.23298934\n","    0.49614173  0.11726561  0.22872734  0.57879275 -0.08537485\n","    0.24196973  0.24599993  0.27652726 -0.36627078 -0.29571784\n","   -0.47953397  0.5380628   0.6377648  -0.11793889 -0.7081148\n","   -0.14172663  0.4966742   0.1157116  -0.09672577  0.20543545\n","   -0.23321733 -0.11515934  0.4234832  -0.08898574 -0.3681782\n","    0.29359117  0.2093176   0.67205423 -0.02213149 -0.28773314\n","    0.11225837 -0.7095693  -0.29595912  0.8231108  -0.16960219\n","   -0.4042877   0.11366334  0.01756098  0.14284015 -0.1696057\n","   -0.3693818   0.68302     0.14547247 -0.17018563 -0.19615938\n","   -0.36185277 -0.27712905  0.10943591  0.01087565 -0.40225816\n","   -0.46355543 -0.40717268  0.18082227 -0.09662735  0.19293416\n","    0.40781057 -0.03699152 -0.20767015 -0.1337964   0.1668877\n","   -0.3399255  -0.32769585  0.23808232 -0.16695033  0.02439449\n","    0.00274041  0.06088229 -0.2597509  -0.01767946  0.19207676\n","    0.23022361 -0.60714716  0.09048863 -0.2192395  -0.05936902\n","    0.04191577 -0.05270524  0.23663145 -0.06647035 -0.54862463\n","    0.16574599 -0.20493445 -0.16494587  0.26001602 -0.11982307\n","    0.12590373  0.13697457  0.14826775 -0.15493678  0.18912901\n","   -0.1279011  -0.07301702  0.05745639  0.24206267 -0.02269528\n","   -0.07960842  0.6378299   0.02634695  0.03155926  0.5116144\n","    0.2427056   0.3810838  -0.19384697 -0.14644541  0.287713\n","   -0.48327503 -0.2349413   0.1275169  -0.42661875  0.5994502\n","   -0.10263976 -0.11650018 -0.19316633 -0.24694708 -0.1447139\n","    0.05126567 -0.4715914   0.10365757  0.8339995   0.38659975\n","   -0.25156486 -0.1116536  -0.03726653 -0.17397496  0.08886705\n","    0.08510463 -0.00706091  0.4208346   0.40278375 -0.39136243\n","    0.15153074 -0.4667586  -0.46288723 -0.3722644  -0.02309956\n","    0.07062495  0.16996448  0.03153069 -0.00789718  0.20382309\n","   -0.13460967 -0.14165804 -0.23547551 -0.08047052  0.090488\n","   -0.4384016  -0.08614726 -0.04375869  0.26698977  0.4295684\n","   -0.39686537 -0.17702304  0.47151253  0.44915476  0.279186\n","    0.59465057 -0.7505502   0.12090574 -0.14538325 -0.06817994\n","   -0.33098835 -0.0608792   0.328292    0.45060647  0.05668586\n","    0.5361295   0.8194254  -0.23019755 -0.06987632  0.20807482\n","    0.05329863  0.1788369  -0.41585863  0.5538282  -0.71710116\n","    0.06616964  0.18955271 -0.38260132  0.01881558 -0.3303459\n","    0.26025808 -0.30446872  0.05062157  0.4780155   0.07619479\n","   -0.17179933  0.26400554  0.16338034 -0.06817717 -0.38345593\n","    0.31583676 -0.04153731  0.22735131 -0.04777666  0.12833025\n","   -0.1599229  -0.150472    0.78039926 -0.13005064  0.4458398\n","    0.08069739  0.6259585   0.14462194  0.44833484 -0.15025191\n","   -0.27868068 -0.54998535  0.01407127 -0.22403589 -0.1868908\n","    0.16131379 -0.18533367  0.34106225  0.25382408  0.47513118\n","    0.00484329  0.4046474   0.20917052 -0.05787653  0.02860564\n","    0.09024564 -0.37730074  0.04331394  0.2749188  -0.27024415\n","   -0.10331126 -0.62163925  0.7763341  -0.30267176 -0.2585101\n","    0.390186    0.3792786  -0.07594728  0.6475176  -0.25830585\n","   -0.15307522  0.15447363  0.11052534 -0.18355677 -0.23072208\n","   -0.30175397  0.13382037  0.46688986 -0.21265803  0.20327076\n","    1.0517248   0.00348808 -0.00151378  0.26972705  0.10598832\n","   -0.32661507  0.32142937 -0.3591305   0.2945135   0.0709611\n","    0.23298934  0.49614173  0.11726561  0.22872734  0.57879275\n","   -0.08537485  0.24196973  0.24599993  0.27652726 -0.36627078\n","   -0.29571784 -0.47953397  0.5380628   0.6377648  -0.11793889\n","   -0.7081148  -0.14172663  0.4966742   0.1157116  -0.09672577\n","    0.20543545 -0.23321733 -0.11515934  0.4234832  -0.08898574\n","   -0.3681782   0.29359117  0.2093176   0.67205423 -0.02213149\n","   -0.28773314  0.11225837 -0.7095693  -0.29595912  0.8231108\n","   -0.16960219 -0.4042877   0.11366334  0.01756098  0.14284015\n","   -0.1696057  -0.3693818   0.68302     0.14547247 -0.17018563\n","   -0.19615938 -0.36185277 -0.27712905  0.10943591  0.01087565\n","   -0.40225816 -0.46355543 -0.40717268  0.18082227 -0.09662735\n","    0.19293416  0.40781057]]], shape=(1, 1, 512), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 0.62626976  0.4774955   0.1704301  -0.043878   -1.7930431\n","   -0.53615326  0.22390485 -0.01892255 -0.76647234 -0.14775065\n","   -0.08783797  0.51624924 -0.41716897  0.6550801   0.59197\n","   -0.20916241  0.1576122  -0.3986062  -0.14205782 -0.6541355\n","   -0.5605997   0.04219726  0.09861147 -0.69810486  0.2957468\n","   -0.44231805 -0.5092832   0.41936442  0.20107892 -0.26474774\n","   -0.3719787  -0.49991572 -0.50034624  0.10409256  0.21589181\n","    0.73003376  0.5323757   0.58480453  0.774855   -0.23367491\n","   -0.29678738 -0.31470045  0.31622314  0.14951316  0.44591904\n","    0.25254333  0.43924567  0.02380088  0.847213   -0.47251958\n","   -0.78078645  0.6027477  -1.370584    0.7749691   0.09409638\n","   -0.6183741  -0.27652392  0.30002287  0.5033147   0.72304904\n","   -0.09133899 -0.25561514  0.49057007 -0.22621873  0.26021266\n","    0.4889699   0.3664183  -0.59035003  0.09693481  0.00787832\n","    0.3084469  -0.18719578  0.22017623 -1.2422178   0.1254768\n","   -0.96659744 -0.49200198 -0.7894306   0.33587116 -0.24020082\n","    1.0606315  -0.15461618  0.22920308  0.30240577 -0.3990612\n","   -0.34177932 -0.58303714 -0.34565675  0.39942604 -0.3252648\n","   -0.413741   -0.44827372 -0.43137062  0.36061558 -0.44304445\n","   -0.7870717   0.31757656  0.3530792   0.5468248   0.23972452\n","   -0.79440796 -0.52497965 -0.33609092  0.09604719 -0.20081845\n","    0.47186586 -0.28575838 -0.3169245   0.21582279  0.15139794\n","    0.44650978 -1.1365083   0.06206871  0.1907542   0.1817931\n","    0.67348045 -0.02710518  0.13634914 -0.19712138  0.03690792\n","    0.51127464 -1.7968996   0.8160175  -0.4586963  -0.22372314\n","   -0.02486008  0.77168506 -0.06031194  0.84268016  0.22748345\n","    0.6867236  -0.4825812   0.07551255 -0.00786588 -0.33882275\n","   -0.24954948  0.5776446   0.03731384  0.3453616   0.4127906\n","   -0.5656236   0.48239216  0.18599124  0.3743253   0.16250253\n","    0.75655645  0.5374522  -0.15283671  0.8324539   0.6829866\n","   -1.1978877   0.09990776 -0.2881092   0.1401615  -0.5488242\n","   -0.44137084  0.7326041   0.5611181   0.3452669   0.3791309\n","    0.77879274 -0.07429999  0.66731966 -0.48598945  0.7905404\n","   -0.2366722  -0.30536062  0.1461612  -0.6671467  -0.2000452\n","    0.03516209  0.25150585 -0.6779897  -0.86597776 -0.23550874\n","    0.02110708  0.41349724  1.023999    0.11930093  0.45520705\n","   -0.6685792  -0.06082261 -0.21970813  0.2540201   0.07496697\n","    0.7208472  -0.15612328 -0.21927083  0.24780601  1.533106\n","    0.03727742 -0.05086992 -0.10026091 -0.1755288  -0.6832392\n","    0.83366317  0.63061595 -0.27368388  0.26844013  0.11098821\n","    0.59067184  0.23355402 -0.42246294  0.56183636  0.5826649\n","    0.81274986  0.01173343  0.3399955  -0.9548512  -0.24578872\n","   -0.2616131   0.8517264   0.7025776  -0.9414032  -0.5273413\n","   -0.3746752  -0.42042086 -0.43584433 -0.32368475 -0.1384123\n","   -0.06859331 -0.3557198   0.39046443  0.00560069 -0.77823794\n","    1.1526536   0.95234835  0.18303692  0.12926595 -0.20942257\n","    0.6346749  -1.3161955  -0.92495716  0.71092856  0.3744069\n","   -0.43401197 -0.71480167  0.59018683 -0.59898204  0.18798769\n","   -0.07544553 -0.03546727 -0.3891418  -0.15756334 -0.09342143\n","   -0.48580876  0.6337764   0.08354162 -0.6718176  -0.10363832\n","   -0.8721758   0.04173791  0.2077372  -0.3123123  -0.01058726\n","    0.7578848 ]\n","  [ 0.62626976  0.4774955   0.1704301  -0.043878   -1.7930431\n","   -0.53615326  0.22390485 -0.01892255 -0.76647234 -0.14775065\n","   -0.08783797  0.51624924 -0.41716897  0.6550801   0.59197\n","   -0.20916241  0.1576122  -0.3986062  -0.14205782 -0.6541355\n","   -0.5605997   0.04219726  0.09861147 -0.69810486  0.2957468\n","   -0.44231805 -0.5092832   0.41936442  0.20107892 -0.26474774\n","   -0.3719787  -0.49991572 -0.50034624  0.10409256  0.21589181\n","    0.73003376  0.5323757   0.58480453  0.774855   -0.23367491\n","   -0.29678738 -0.31470045  0.31622314  0.14951316  0.44591904\n","    0.25254333  0.43924567  0.02380088  0.847213   -0.47251958\n","   -0.78078645  0.6027477  -1.370584    0.7749691   0.09409638\n","   -0.6183741  -0.27652392  0.30002287  0.5033147   0.72304904\n","   -0.09133899 -0.25561514  0.49057007 -0.22621873  0.26021266\n","    0.4889699   0.3664183  -0.59035003  0.09693481  0.00787832\n","    0.3084469  -0.18719578  0.22017623 -1.2422178   0.1254768\n","   -0.96659744 -0.49200198 -0.7894306   0.33587116 -0.24020082\n","    1.0606315  -0.15461618  0.22920308  0.30240577 -0.3990612\n","   -0.34177932 -0.58303714 -0.34565675  0.39942604 -0.3252648\n","   -0.413741   -0.44827372 -0.43137062  0.36061558 -0.44304445\n","   -0.7870717   0.31757656  0.3530792   0.5468248   0.23972452\n","   -0.79440796 -0.52497965 -0.33609092  0.09604719 -0.20081845\n","    0.47186586 -0.28575838 -0.3169245   0.21582279  0.15139794\n","    0.44650978 -1.1365083   0.06206871  0.1907542   0.1817931\n","    0.67348045 -0.02710518  0.13634914 -0.19712138  0.03690792\n","    0.51127464 -1.7968996   0.8160175  -0.4586963  -0.22372314\n","   -0.02486008  0.77168506 -0.06031194  0.84268016  0.22748345\n","    0.6867236  -0.4825812   0.07551255 -0.00786588 -0.33882275\n","   -0.24954948  0.5776446   0.03731384  0.3453616   0.4127906\n","   -0.5656236   0.48239216  0.18599124  0.3743253   0.16250253\n","    0.75655645  0.5374522  -0.15283671  0.8324539   0.6829866\n","   -1.1978877   0.09990776 -0.2881092   0.1401615  -0.5488242\n","   -0.44137084  0.7326041   0.5611181   0.3452669   0.3791309\n","    0.77879274 -0.07429999  0.66731966 -0.48598945  0.7905404\n","   -0.2366722  -0.30536062  0.1461612  -0.6671467  -0.2000452\n","    0.03516209  0.25150585 -0.6779897  -0.86597776 -0.23550874\n","    0.02110708  0.41349724  1.023999    0.11930093  0.45520705\n","   -0.6685792  -0.06082261 -0.21970813  0.2540201   0.07496697\n","    0.7208472  -0.15612328 -0.21927083  0.24780601  1.533106\n","    0.03727742 -0.05086992 -0.10026091 -0.1755288  -0.6832392\n","    0.83366317  0.63061595 -0.27368388  0.26844013  0.11098821\n","    0.59067184  0.23355402 -0.42246294  0.56183636  0.5826649\n","    0.81274986  0.01173343  0.3399955  -0.9548512  -0.24578872\n","   -0.2616131   0.8517264   0.7025776  -0.9414032  -0.5273413\n","   -0.3746752  -0.42042086 -0.43584433 -0.32368475 -0.1384123\n","   -0.06859331 -0.3557198   0.39046443  0.00560069 -0.77823794\n","    1.1526536   0.95234835  0.18303692  0.12926595 -0.20942257\n","    0.6346749  -1.3161955  -0.92495716  0.71092856  0.3744069\n","   -0.43401197 -0.71480167  0.59018683 -0.59898204  0.18798769\n","   -0.07544553 -0.03546727 -0.3891418  -0.15756334 -0.09342143\n","   -0.48580876  0.6337764   0.08354162 -0.6718176  -0.10363832\n","   -0.8721758   0.04173791  0.2077372  -0.3123123  -0.01058726\n","    0.7578848 ]]], shape=(1, 2, 256), dtype=float32)\n","2\n","Tree INDEX:  2 2\n","tf.Tensor(\n","[[[ 2.28942782e-02  8.11658621e-01 -2.02293321e-01 -6.50015548e-02\n","   -4.09573875e-02  1.44525945e+00  7.32290745e-01  4.15430635e-01\n","    3.42702150e-01  1.36913133e+00  3.49966675e-01  8.11023414e-02\n","   -1.95633039e-01  2.37282068e-02 -1.07171588e-01  6.29860759e-02\n","   -7.47576505e-02  7.94603825e-02  6.88551307e-01  5.25790393e-01\n","    2.39426211e-01  2.39776865e-01 -2.21711352e-01  9.65806067e-01\n","   -2.13748023e-01  7.73119032e-01 -1.40551493e-01  5.98084927e-01\n","    1.08062303e+00 -2.14430336e-02  2.06584930e-01  1.07948041e+00\n","    2.93459922e-01 -9.41193700e-02  2.53894538e-01 -6.69687316e-02\n","   -1.73734780e-02 -1.34159222e-01  1.57943115e-01  1.04045868e-02\n","    6.95881367e-01 -1.77044779e-01  2.17973575e-01 -3.26493122e-02\n","    3.14492404e-01 -9.45108533e-02 -1.10995293e-01 -3.01248617e-02\n","   -1.23965375e-01 -2.46719699e-02 -4.45848778e-02  1.87752485e-01\n","    3.94855022e-01  2.68808678e-02 -3.14351588e-01  2.39115447e-01\n","    2.61684656e-01 -1.36640027e-01 -2.18017727e-01  6.94648981e-01\n","    3.93475711e-01  1.16962768e-01  5.18046260e-01  6.16195083e-01\n","   -9.77392197e-02  3.43647361e-01  6.12050533e-01  1.81732625e-01\n","   -9.57336426e-02  1.52521566e-01 -9.21245962e-02 -1.46728024e-01\n","   -7.71019310e-02 -8.13068971e-02  1.10716021e+00  6.60060644e-01\n","    6.32442415e-01  4.42325175e-01  6.90733850e-01  4.17922437e-01\n","    4.35869008e-01 -4.53414880e-02 -5.94712608e-02 -1.54656410e-01\n","   -7.68871456e-02  1.62567183e-01 -8.90828520e-02 -7.01754838e-02\n","    1.39210016e-01 -4.62824143e-02 -4.48014308e-03 -2.70100921e-01\n","    4.49816704e-01 -7.22234836e-03  5.26273608e-01  8.74142647e-01\n","    5.91114283e-01  4.15253401e-01  2.28505448e-01  2.30203807e-01\n","   -1.40195161e-01 -5.84980249e-02 -1.64658546e-01  3.94996166e-01\n","    4.92778391e-01  3.35376292e-01 -3.75669412e-02  6.44388080e-01\n","   -8.79342780e-02 -3.11986152e-02  3.70510995e-01 -4.58444878e-02\n","   -1.14205718e-01 -1.12867658e-03  1.90737024e-01 -1.17362617e-02\n","   -1.85712174e-01 -2.15930697e-02 -1.68206319e-01  8.28641534e-01\n","   -8.65851566e-02 -3.79724614e-02  4.42182161e-02  3.72782290e-01\n","    1.05473399e-02 -1.55067727e-01  6.18490815e-01  1.42095506e-01\n","    1.11332870e+00 -1.50907442e-01  8.38864267e-01  7.01104045e-01\n","    5.34901977e-01  4.86774564e-01  1.18238151e+00 -2.76024908e-01\n","   -1.29703507e-01  6.16024584e-02 -5.25553115e-02 -1.05581976e-01\n","    1.13459337e+00 -3.00172895e-01  5.21799684e-01  7.42535532e-01\n","   -5.97678684e-02  2.33031094e-01  2.47335747e-01  4.00373936e-01\n","    5.90226650e-01 -7.90362954e-02  5.24723470e-01 -1.33971810e-01\n","   -5.15720248e-02  9.03843164e-01 -1.05355971e-01 -1.99640635e-02\n","   -2.40213081e-01 -2.98465136e-02 -4.25048470e-02 -1.98760852e-01\n","   -1.86588410e-02 -2.66712066e-02  1.59496635e-01  2.24839449e-01\n","    4.41323876e-01 -1.58145931e-02 -6.98454157e-02  5.84723294e-01\n","   -3.27454172e-02 -6.29230887e-02 -3.36130299e-02  1.02122736e+00\n","    1.25457481e-01  5.59677243e-01  5.63320041e-01  2.55181432e-01\n","   -7.51130134e-02 -6.97627589e-02  5.60989439e-01 -1.01082474e-02\n","    2.53157467e-01  2.71697342e-01  1.02861214e+00  4.23002213e-01\n","   -2.35017970e-01  1.50183082e-01 -3.38705047e-03  2.80911624e-01\n","    1.66761863e+00 -1.19608045e-01  1.67584932e+00 -9.76188853e-02\n","   -1.84235312e-02 -1.89612687e-01 -1.31796420e-01  8.03854585e-01\n","   -1.64293215e-01 -6.26583397e-02  7.97578394e-01 -3.02760284e-02\n","   -9.29732472e-02  6.90427065e-01 -2.25347117e-01  7.62630224e-01\n","    5.21476507e-01 -1.56915784e-01  3.21315110e-01 -3.34483802e-01\n","   -6.81881979e-02  1.47488028e-01  2.52360702e-01 -4.00276594e-02\n","    7.47102201e-01 -1.09232366e-02 -8.41264948e-02  5.96413016e-01\n","   -7.83182755e-02 -2.28109374e-03  8.20720255e-01  9.01554167e-01\n","   -3.79990041e-03 -4.08827960e-02 -1.47858351e-01 -8.12575743e-02\n","    2.87548780e-01  2.89515674e-01 -1.18175425e-01 -6.25776127e-02\n","   -1.44843593e-01  1.09704030e+00 -1.11598395e-01 -6.10949881e-02\n","    6.12304568e-01  4.62835491e-01  8.01702142e-01  6.87359750e-01\n","    1.45541817e-01 -2.64827162e-01 -7.32801333e-02 -3.31942998e-02\n","   -3.83237302e-02 -9.47599262e-02  7.54449815e-02 -1.07691906e-01\n","    1.04889303e-01  5.68672717e-01  2.20583454e-01  1.93142906e-01\n","   -1.80695400e-01  7.73630559e-01 -9.63392842e-04 -5.13473116e-02\n","    4.79710639e-01  9.24431905e-03  1.05174375e+00  6.91279531e-01]\n","  [-2.68379897e-02  7.31460333e-01 -1.65465087e-01 -2.94551384e-02\n","   -5.72053194e-02  1.28204191e+00  6.88227057e-01  3.69218230e-01\n","    4.41759437e-01  1.31732619e+00  3.57997507e-01  8.68891329e-02\n","   -1.82479188e-01 -5.80520323e-03 -6.40475526e-02  1.16343044e-01\n","   -1.24063209e-01  1.32345200e-01  9.52868104e-01  3.75287354e-01\n","    4.63076115e-01  2.06540301e-01 -2.07384810e-01  8.22458982e-01\n","   -2.04749808e-01  9.00167823e-01 -1.78818941e-01  6.55819237e-01\n","    8.79181743e-01 -2.75140256e-02  1.39986455e-01  1.09588301e+00\n","    3.04239720e-01 -4.01352756e-02  4.34702128e-01 -2.30749287e-02\n","   -2.87729297e-02 -1.65147454e-01  3.98709357e-01 -3.22800949e-02\n","    6.42676413e-01 -2.03796849e-01  2.46769905e-01 -8.11627507e-02\n","    1.54924363e-01 -7.53252506e-02 -8.40917379e-02  1.84551775e-02\n","   -1.14419498e-01 -3.03296000e-02 -4.25932370e-02  1.05632991e-01\n","    3.41932088e-01  1.77137509e-01 -3.27192456e-01  1.05119810e-01\n","    4.02576357e-01 -1.45644471e-01 -1.93825766e-01  6.18649840e-01\n","    3.20195556e-01 -1.90866366e-02  3.12700599e-01  4.54531938e-01\n","   -1.03200190e-01  2.07420766e-01  6.67173564e-01  2.99582720e-01\n","   -1.11471988e-01  1.91416502e-01 -8.69917646e-02 -1.25543043e-01\n","   -8.96320865e-02 -7.91405663e-02  1.13221133e+00  6.05045080e-01\n","    8.39147508e-01  6.09907985e-01  6.65114880e-01  3.39969665e-01\n","    3.76990378e-01 -7.83638433e-02 -5.88245057e-02 -1.36469200e-01\n","   -9.43393782e-02  1.76484570e-01 -5.54788820e-02 -8.36137608e-02\n","    2.06215352e-01 -6.25617281e-02 -1.76393669e-02 -2.63798892e-01\n","    3.56787056e-01 -7.84940943e-02  4.02241647e-01  9.03124332e-01\n","    5.75087786e-01  3.65819305e-01  2.82073021e-01 -4.79414174e-03\n","   -9.00340900e-02 -5.79503477e-02 -1.55534819e-01  5.01899183e-01\n","    5.41385889e-01  4.96600747e-01 -5.69434129e-02  7.94632256e-01\n","   -1.59214124e-01 -2.41368096e-02  3.45294267e-01 -5.78652397e-02\n","   -1.21709958e-01  1.11863092e-02 -2.59800348e-02 -6.97514275e-03\n","   -1.42472029e-01 -6.66564479e-02 -2.04688415e-01  5.54423451e-01\n","   -5.23124114e-02 -7.18359351e-02 -3.25586312e-02  2.49376431e-01\n","   -3.39085013e-02 -1.60980135e-01  8.96071672e-01  2.49801323e-01\n","    1.06392920e+00 -1.47290781e-01  8.86778176e-01  7.02924013e-01\n","    5.77010512e-01  3.48505437e-01  1.00116658e+00 -2.75702715e-01\n","   -9.31251869e-02 -2.76391748e-02 -8.78166109e-02 -5.09071946e-02\n","    1.01391995e+00 -3.31253380e-01  5.51780343e-01  7.86866188e-01\n","   -8.96045193e-02  1.31866947e-01  2.84507662e-01  3.24626744e-01\n","    6.09078348e-01 -1.03543080e-01  5.43316007e-01 -1.13508321e-01\n","   -2.18384601e-02  8.54800642e-01 -7.71998912e-02 -3.91724035e-02\n","   -2.62365520e-01 -1.13659529e-02 -8.44310671e-02 -2.12400675e-01\n","    1.08765498e-01 -3.38210203e-02  5.60255349e-03  2.34590888e-01\n","    4.64735508e-01  3.50713730e-04 -1.00934997e-01  1.04461479e+00\n","   -3.60351391e-02 -7.38494545e-02 -8.12792554e-02  9.03383136e-01\n","   -8.52884352e-03  6.76909864e-01  3.30556780e-01  3.41281474e-01\n","   -3.85433920e-02 -7.62728453e-02  6.15106225e-01 -7.34978318e-02\n","    1.61477119e-01  2.78452128e-01  1.27066076e+00  4.04789984e-01\n","   -1.86032772e-01 -7.08469609e-03 -1.91583652e-02  5.15014529e-01\n","    1.51687431e+00 -1.68574363e-01  1.82523060e+00 -9.74152535e-02\n","   -6.18673675e-02 -1.27265319e-01 -1.11819446e-01  9.97415364e-01\n","   -1.71503454e-01 -9.05092657e-02  7.51964450e-01 -3.34959291e-02\n","   -5.85058592e-02  7.22450793e-01 -2.40729332e-01  1.01745999e+00\n","    2.49596909e-01 -1.63708016e-01  1.53035566e-01 -3.47643763e-01\n","   -7.30272159e-02  7.61751086e-02  2.55009025e-01 -1.23418421e-02\n","    8.87766004e-01 -2.62484755e-02 -1.28872931e-01  5.96677482e-01\n","   -7.94967636e-02 -7.51830265e-02  6.27049983e-01  9.07339573e-01\n","    4.09439206e-03 -5.87051995e-02 -1.00548945e-01 -8.03349540e-02\n","    2.49468356e-01  1.66675836e-01 -1.49613306e-01 -3.02671678e-02\n","   -1.07128143e-01  1.10219431e+00 -6.99632317e-02 -6.33282065e-02\n","    5.20832002e-01  5.10455847e-01  8.12533855e-01  5.31472087e-01\n","    2.30343997e-01 -2.40258768e-01 -5.81634417e-02 -8.87034868e-04\n","   -5.90272211e-02 -1.09656334e-01  2.46855140e-01 -8.63873661e-02\n","    1.04762733e-01  5.22276461e-01  9.72298905e-02  9.42916274e-02\n","   -2.13206723e-01  4.23992634e-01 -9.25098371e-04 -3.87604237e-02\n","    4.81675297e-01  2.80590445e-01  1.13410079e+00  5.36441147e-01]]], shape=(1, 2, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","2 1\n","Root Node\n","tf.Tensor(\n","[[[-3.41575444e-01  4.47795331e-01 -8.81828308e-01 -2.74222970e-01\n","   -2.02885881e-01  4.06915009e-01 -5.59846282e-01  1.98286682e-01\n","   -2.18409508e-01  1.87649071e-01  2.22648382e-01 -4.41050023e-01\n","    9.45154428e-01 -6.70521617e-01 -4.55473810e-02 -8.15826774e-01\n","   -7.03933358e-01  1.18376881e-01 -1.70319408e-01 -7.07028866e-01\n","   -2.33405873e-01  4.26360592e-02 -2.46486112e-01 -3.35784495e-01\n","    1.18086547e-01  3.42049092e-01  4.46287021e-02  5.43185890e-01\n","   -5.39435267e-01  5.90412915e-02 -3.38521540e-01  1.13701478e-01\n","    4.65545356e-01  3.18106711e-01  3.60465080e-01 -5.09213507e-01\n","   -5.45719266e-03  1.02202222e-01 -7.29030296e-02 -6.57049894e-01\n","   -8.11357796e-02  4.06799287e-01  4.96674836e-01  3.40347178e-02\n","   -1.86625019e-01  3.67518604e-01  7.93917030e-02 -1.07509881e-01\n","   -6.80730224e-01 -8.80909860e-02  7.73011148e-02  9.62241888e-02\n","    3.01903844e-01  1.62489772e-01  4.55967665e-01  2.29945660e-01\n","    2.58787751e-01 -1.08667874e+00 -1.93564758e-01 -3.16866100e-01\n","   -1.84027612e-01  7.53143251e-01 -2.86740780e-01  4.84646559e-01\n","    7.19333738e-02  3.01151365e-01  2.59037763e-01  9.44037735e-02\n","    3.09840024e-01 -3.68440062e-01 -7.72260278e-02 -5.84657609e-01\n","   -1.42075896e-01  2.00321928e-01 -1.62322491e-01  2.45987833e-01\n","    6.48179889e-01  7.42809027e-02  5.03252566e-01  1.06458642e-01\n","    4.61278200e-01  8.27432424e-02  6.54629409e-01  6.12606555e-02\n","   -4.83304471e-01 -3.10862273e-01 -4.96489406e-01 -7.80855358e-01\n","   -7.18084872e-02  3.28571767e-01 -7.29966760e-01  4.84119803e-02\n","   -2.24085316e-01  7.81001627e-01  6.84727907e-01  2.77593881e-01\n","   -2.99839258e-01  1.01424642e-01  6.54835254e-02 -2.54500031e-01\n","   -6.22079253e-01  7.45306164e-02 -5.05335629e-01 -4.12429869e-01\n","   -2.31015265e-01 -3.60344797e-01 -5.11953831e-01  2.28985846e-02\n","    6.08097017e-03  6.68464959e-01  5.46968341e-01 -6.47605538e-01\n","    2.57175326e-01 -1.65320650e-01 -1.49504110e-01 -3.85341644e-02\n","   -1.12558472e+00 -1.21722728e-01  3.43351424e-01 -3.71877193e-01\n","   -3.47662628e-01  6.13079071e-02  7.18105674e-01 -2.33225524e-03\n","   -1.86897427e-01 -1.46204054e-01  1.42881736e-01 -1.32559091e-01\n","   -1.36262625e-02  2.21713245e-01 -2.19951808e-01 -6.70891047e-01\n","    7.34437346e-01 -8.04145455e-01  6.38480902e-01 -6.57126427e-01\n","   -5.49288616e-02  8.66476074e-02 -2.77626723e-01  5.42478621e-01\n","   -2.62268543e-01 -3.50552917e-01  6.96324855e-02  5.60285687e-01\n","    4.29290459e-02 -3.63780886e-01 -7.32597947e-01  4.65484619e-01\n","    6.64484799e-02 -7.32875586e-01  3.03957611e-02  1.13374270e-01\n","    2.92039275e-01  6.04968131e-01  2.38610148e-01 -5.08626699e-02\n","   -8.60877812e-01 -1.10006191e-01  3.53284478e-02 -1.90409288e-01\n","    2.86839485e-01  8.26359868e-01 -6.01701438e-01  2.93487683e-02\n","   -8.30888748e-05 -4.03584152e-01  3.32347482e-01 -1.19594955e+00\n","    3.62419784e-01 -8.66369128e-01  2.14447349e-01 -4.33178604e-01\n","    1.16571017e-01 -3.34679484e-01 -1.28784597e+00  6.19629443e-01\n","    1.98851645e-01 -4.11067545e-01 -4.69526768e-01 -5.76372623e-01\n","   -8.39467108e-01  2.97926366e-01  8.17399561e-01 -5.01929760e-01\n","    3.16375792e-02  8.24770331e-01  1.71456993e-01  4.87486720e-01\n","   -3.33155245e-01  4.86901402e-03  4.10117865e-01  2.81127453e-01\n","   -6.02075815e-01 -4.80439961e-01  5.41141510e-01  4.85729367e-01\n","   -6.91986203e-01 -5.65216720e-01 -5.70316672e-01 -6.62604928e-01\n","   -3.01623404e-01  4.86200333e-01  4.02031898e-01 -3.27817678e-01\n","   -4.39343214e-01  8.55799675e-01 -5.90543032e-01 -2.93125749e-01\n","   -3.81201029e-01 -1.62822872e-01  7.73024857e-02  6.34296715e-01\n","   -5.29178262e-01 -3.87449950e-01  7.63798356e-02 -1.48063481e-01\n","   -3.39254707e-01  1.34811029e-02 -3.84028018e-01  3.31516325e-01\n","   -3.26806158e-02  5.96277714e-01  1.68754146e-01  6.98541045e-01\n","    2.58097708e-01 -2.75353730e-01  8.46623898e-01  1.05636191e+00\n","    5.38577288e-02 -2.74284571e-01  6.22903287e-01  8.94755125e-04\n","    3.27146053e-03 -2.55247116e-01 -7.33404607e-03  5.28226495e-01\n","    3.01855862e-01  1.28191125e+00  9.12382379e-02 -1.32366931e+00\n","    5.24222255e-01 -1.86897963e-01  4.08848703e-01 -1.46568745e-01\n","    6.44310474e-01  2.83505172e-01  4.69942331e-01 -6.27141893e-02\n","   -1.11746691e-01  3.33926082e-01  2.62787670e-01 -3.12031716e-01\n","   -5.17610788e-01  1.08784735e-01  4.11702335e-01  3.30192059e-01]\n","  [-3.20610851e-01  3.75077307e-01 -8.01792443e-01 -2.11911112e-01\n","    8.02534893e-02  3.50421041e-01 -4.88419980e-01  6.08291179e-02\n","   -2.40712136e-01  1.82494551e-01  2.56627381e-01 -4.24559057e-01\n","    9.70446467e-01 -6.49550915e-01  5.96369356e-02 -9.00142789e-01\n","   -7.69962668e-01  1.05360612e-01 -3.12438548e-01 -6.53366685e-01\n","   -2.79979110e-02  4.78884652e-02 -2.72321224e-01 -2.73549080e-01\n","    1.70192309e-02  1.82832539e-01  6.34202659e-02  8.43258619e-01\n","   -4.68189031e-01  7.71860778e-02 -2.72996813e-01  2.60039270e-01\n","    4.43157017e-01  1.91931158e-01  3.17318052e-01 -5.69992065e-01\n","   -1.37133360e-01  1.12936750e-01 -1.05689257e-01 -6.80503011e-01\n","   -1.28168583e-01  2.74955690e-01  4.82205272e-01 -4.66722324e-02\n","   -1.63938135e-01  3.21548939e-01  8.57854038e-02 -2.63696939e-01\n","   -7.14988887e-01 -1.23809099e-01  2.23945901e-02  1.06431819e-01\n","    2.56766587e-01  2.38442272e-01  4.48924869e-01  2.68583328e-01\n","    1.79281175e-01 -1.17557621e+00 -2.63119429e-01 -2.83145010e-01\n","   -2.71955788e-01  7.32673824e-01 -2.07793489e-01  4.76275772e-01\n","    1.91802979e-02  4.00217444e-01  1.77647263e-01  2.48829544e-01\n","    2.30327070e-01 -3.61569822e-01 -1.55775934e-01 -4.86008346e-01\n","   -4.51890081e-02  2.69549280e-01 -1.44100651e-01  1.10306233e-01\n","    5.48230231e-01  3.51921469e-01  6.91123188e-01  2.23788843e-01\n","    3.12145382e-01  1.22728921e-01  7.48450339e-01 -1.93075128e-02\n","   -4.73518908e-01 -2.50877440e-01 -5.89380622e-01 -7.97829688e-01\n","   -1.30029589e-01  1.17748894e-01 -6.43308997e-01  1.41978234e-01\n","   -1.83707595e-01  6.61172271e-01  6.75786138e-01  2.15591356e-01\n","   -4.35196489e-01 -4.38262969e-02 -3.92979756e-02 -1.37310445e-01\n","   -6.45360351e-01 -1.68920234e-02 -6.49700224e-01 -2.00181514e-01\n","   -1.61124051e-01 -3.77713621e-01 -5.34589708e-01  1.45261824e-01\n","   -6.81961030e-02  5.53320408e-01  3.86591136e-01 -5.07295907e-01\n","    4.30170119e-01 -8.07881355e-02 -1.79779023e-01 -1.69675350e-02\n","   -1.10002708e+00 -1.68974951e-01  2.66593754e-01 -4.70927835e-01\n","   -2.83668488e-01  8.61446559e-02  7.61348426e-01 -1.93904340e-02\n","   -9.35199261e-02 -2.55179375e-01  1.90298900e-01 -2.14235798e-01\n","    7.78674111e-02  2.13871434e-01 -1.79625496e-01 -4.66663957e-01\n","    7.22106159e-01 -6.64450288e-01  5.62245905e-01 -6.88216865e-01\n","   -1.09065697e-01  1.66367650e-01 -3.95398170e-01  4.32138205e-01\n","   -2.88537323e-01 -4.70378339e-01 -1.98672879e-02  4.97614563e-01\n","   -2.81647742e-02 -3.97529751e-01 -6.13384664e-01  5.75587988e-01\n","   -1.39963076e-01 -5.65166175e-01  1.72499731e-01  2.00316817e-01\n","    2.28631303e-01  6.21067107e-01  2.53253013e-01 -6.63158000e-02\n","   -9.73289728e-01 -8.45294893e-02 -8.00666511e-02 -2.51104712e-01\n","    2.95203507e-01  8.31181586e-01 -7.06895828e-01 -3.44231203e-02\n","   -7.16465563e-02 -5.90564728e-01  4.19428259e-01 -1.21092045e+00\n","    3.43884975e-01 -8.42980266e-01  2.38568664e-01 -4.27230597e-01\n","    1.98645428e-01 -2.56107032e-01 -1.32935798e+00  3.86626273e-01\n","    2.53625184e-01 -4.62020606e-01 -4.88956809e-01 -5.36752880e-01\n","   -9.48145986e-01  3.32367629e-01  7.89150238e-01 -4.60817456e-01\n","    9.15432498e-02  7.80063391e-01  1.09687269e-01  3.10879320e-01\n","   -1.78511500e-01  1.00687116e-01  3.90759170e-01  1.48760110e-01\n","   -6.03674531e-01 -2.75943041e-01  4.81284231e-01  3.77185166e-01\n","   -7.09374905e-01 -5.43725848e-01 -6.16553128e-01 -5.97760737e-01\n","   -2.60605574e-01  4.95350420e-01  2.95977652e-01 -3.34345400e-01\n","   -3.68971884e-01  5.81772685e-01 -4.31056857e-01 -1.16305418e-01\n","   -3.98865759e-01 -2.08031073e-01  4.78581637e-02  6.27244890e-01\n","   -2.35819459e-01 -3.85960460e-01 -3.91192436e-02 -3.38329732e-01\n","   -3.22523475e-01 -1.65440202e-01 -3.49030137e-01  4.56625521e-01\n","    8.56813788e-02  6.07041299e-01 -4.14815843e-02  5.78578115e-01\n","    1.48250639e-01 -4.16435570e-01  9.22507524e-01  1.03216267e+00\n","   -1.27161786e-01 -2.34323964e-01  5.28191209e-01 -7.68784881e-02\n","   -4.46533859e-02 -2.45017141e-01 -1.40178669e-02  4.64074641e-01\n","    2.37029940e-01  1.15372419e+00  2.93569863e-02 -1.16608739e+00\n","    6.57363236e-01 -1.23871595e-01  4.88650084e-01 -2.50022531e-01\n","    5.66099286e-01  2.06003845e-01  5.13832688e-01 -6.77115321e-02\n","   -1.76145792e-01  2.72531897e-01  1.75574064e-01 -4.14562106e-01\n","   -4.60465729e-01  1.47793517e-01  5.04401863e-01  3.59548360e-01]]], shape=(1, 2, 256), dtype=float32)\n","tf.Tensor([  1   2 256], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[-3.41575444e-01  4.47795331e-01 -8.81828308e-01 -2.74222970e-01\n","   -2.02885881e-01  4.06915009e-01 -5.59846282e-01  1.98286682e-01\n","   -2.18409508e-01  1.87649071e-01  2.22648382e-01 -4.41050023e-01\n","    9.45154428e-01 -6.70521617e-01 -4.55473810e-02 -8.15826774e-01\n","   -7.03933358e-01  1.18376881e-01 -1.70319408e-01 -7.07028866e-01\n","   -2.33405873e-01  4.26360592e-02 -2.46486112e-01 -3.35784495e-01\n","    1.18086547e-01  3.42049092e-01  4.46287021e-02  5.43185890e-01\n","   -5.39435267e-01  5.90412915e-02 -3.38521540e-01  1.13701478e-01\n","    4.65545356e-01  3.18106711e-01  3.60465080e-01 -5.09213507e-01\n","   -5.45719266e-03  1.02202222e-01 -7.29030296e-02 -6.57049894e-01\n","   -8.11357796e-02  4.06799287e-01  4.96674836e-01  3.40347178e-02\n","   -1.86625019e-01  3.67518604e-01  7.93917030e-02 -1.07509881e-01\n","   -6.80730224e-01 -8.80909860e-02  7.73011148e-02  9.62241888e-02\n","    3.01903844e-01  1.62489772e-01  4.55967665e-01  2.29945660e-01\n","    2.58787751e-01 -1.08667874e+00 -1.93564758e-01 -3.16866100e-01\n","   -1.84027612e-01  7.53143251e-01 -2.86740780e-01  4.84646559e-01\n","    7.19333738e-02  3.01151365e-01  2.59037763e-01  9.44037735e-02\n","    3.09840024e-01 -3.68440062e-01 -7.72260278e-02 -5.84657609e-01\n","   -1.42075896e-01  2.00321928e-01 -1.62322491e-01  2.45987833e-01\n","    6.48179889e-01  7.42809027e-02  5.03252566e-01  1.06458642e-01\n","    4.61278200e-01  8.27432424e-02  6.54629409e-01  6.12606555e-02\n","   -4.83304471e-01 -3.10862273e-01 -4.96489406e-01 -7.80855358e-01\n","   -7.18084872e-02  3.28571767e-01 -7.29966760e-01  4.84119803e-02\n","   -2.24085316e-01  7.81001627e-01  6.84727907e-01  2.77593881e-01\n","   -2.99839258e-01  1.01424642e-01  6.54835254e-02 -2.54500031e-01\n","   -6.22079253e-01  7.45306164e-02 -5.05335629e-01 -4.12429869e-01\n","   -2.31015265e-01 -3.60344797e-01 -5.11953831e-01  2.28985846e-02\n","    6.08097017e-03  6.68464959e-01  5.46968341e-01 -6.47605538e-01\n","    2.57175326e-01 -1.65320650e-01 -1.49504110e-01 -3.85341644e-02\n","   -1.12558472e+00 -1.21722728e-01  3.43351424e-01 -3.71877193e-01\n","   -3.47662628e-01  6.13079071e-02  7.18105674e-01 -2.33225524e-03\n","   -1.86897427e-01 -1.46204054e-01  1.42881736e-01 -1.32559091e-01\n","   -1.36262625e-02  2.21713245e-01 -2.19951808e-01 -6.70891047e-01\n","    7.34437346e-01 -8.04145455e-01  6.38480902e-01 -6.57126427e-01\n","   -5.49288616e-02  8.66476074e-02 -2.77626723e-01  5.42478621e-01\n","   -2.62268543e-01 -3.50552917e-01  6.96324855e-02  5.60285687e-01\n","    4.29290459e-02 -3.63780886e-01 -7.32597947e-01  4.65484619e-01\n","    6.64484799e-02 -7.32875586e-01  3.03957611e-02  1.13374270e-01\n","    2.92039275e-01  6.04968131e-01  2.38610148e-01 -5.08626699e-02\n","   -8.60877812e-01 -1.10006191e-01  3.53284478e-02 -1.90409288e-01\n","    2.86839485e-01  8.26359868e-01 -6.01701438e-01  2.93487683e-02\n","   -8.30888748e-05 -4.03584152e-01  3.32347482e-01 -1.19594955e+00\n","    3.62419784e-01 -8.66369128e-01  2.14447349e-01 -4.33178604e-01\n","    1.16571017e-01 -3.34679484e-01 -1.28784597e+00  6.19629443e-01\n","    1.98851645e-01 -4.11067545e-01 -4.69526768e-01 -5.76372623e-01\n","   -8.39467108e-01  2.97926366e-01  8.17399561e-01 -5.01929760e-01\n","    3.16375792e-02  8.24770331e-01  1.71456993e-01  4.87486720e-01\n","   -3.33155245e-01  4.86901402e-03  4.10117865e-01  2.81127453e-01\n","   -6.02075815e-01 -4.80439961e-01  5.41141510e-01  4.85729367e-01\n","   -6.91986203e-01 -5.65216720e-01 -5.70316672e-01 -6.62604928e-01\n","   -3.01623404e-01  4.86200333e-01  4.02031898e-01 -3.27817678e-01\n","   -4.39343214e-01  8.55799675e-01 -5.90543032e-01 -2.93125749e-01\n","   -3.81201029e-01 -1.62822872e-01  7.73024857e-02  6.34296715e-01\n","   -5.29178262e-01 -3.87449950e-01  7.63798356e-02 -1.48063481e-01\n","   -3.39254707e-01  1.34811029e-02 -3.84028018e-01  3.31516325e-01\n","   -3.26806158e-02  5.96277714e-01  1.68754146e-01  6.98541045e-01\n","    2.58097708e-01 -2.75353730e-01  8.46623898e-01  1.05636191e+00\n","    5.38577288e-02 -2.74284571e-01  6.22903287e-01  8.94755125e-04\n","    3.27146053e-03 -2.55247116e-01 -7.33404607e-03  5.28226495e-01\n","    3.01855862e-01  1.28191125e+00  9.12382379e-02 -1.32366931e+00\n","    5.24222255e-01 -1.86897963e-01  4.08848703e-01 -1.46568745e-01\n","    6.44310474e-01  2.83505172e-01  4.69942331e-01 -6.27141893e-02\n","   -1.11746691e-01  3.33926082e-01  2.62787670e-01 -3.12031716e-01\n","   -5.17610788e-01  1.08784735e-01  4.11702335e-01  3.30192059e-01]\n","  [-3.20610851e-01  3.75077307e-01 -8.01792443e-01 -2.11911112e-01\n","    8.02534893e-02  3.50421041e-01 -4.88419980e-01  6.08291179e-02\n","   -2.40712136e-01  1.82494551e-01  2.56627381e-01 -4.24559057e-01\n","    9.70446467e-01 -6.49550915e-01  5.96369356e-02 -9.00142789e-01\n","   -7.69962668e-01  1.05360612e-01 -3.12438548e-01 -6.53366685e-01\n","   -2.79979110e-02  4.78884652e-02 -2.72321224e-01 -2.73549080e-01\n","    1.70192309e-02  1.82832539e-01  6.34202659e-02  8.43258619e-01\n","   -4.68189031e-01  7.71860778e-02 -2.72996813e-01  2.60039270e-01\n","    4.43157017e-01  1.91931158e-01  3.17318052e-01 -5.69992065e-01\n","   -1.37133360e-01  1.12936750e-01 -1.05689257e-01 -6.80503011e-01\n","   -1.28168583e-01  2.74955690e-01  4.82205272e-01 -4.66722324e-02\n","   -1.63938135e-01  3.21548939e-01  8.57854038e-02 -2.63696939e-01\n","   -7.14988887e-01 -1.23809099e-01  2.23945901e-02  1.06431819e-01\n","    2.56766587e-01  2.38442272e-01  4.48924869e-01  2.68583328e-01\n","    1.79281175e-01 -1.17557621e+00 -2.63119429e-01 -2.83145010e-01\n","   -2.71955788e-01  7.32673824e-01 -2.07793489e-01  4.76275772e-01\n","    1.91802979e-02  4.00217444e-01  1.77647263e-01  2.48829544e-01\n","    2.30327070e-01 -3.61569822e-01 -1.55775934e-01 -4.86008346e-01\n","   -4.51890081e-02  2.69549280e-01 -1.44100651e-01  1.10306233e-01\n","    5.48230231e-01  3.51921469e-01  6.91123188e-01  2.23788843e-01\n","    3.12145382e-01  1.22728921e-01  7.48450339e-01 -1.93075128e-02\n","   -4.73518908e-01 -2.50877440e-01 -5.89380622e-01 -7.97829688e-01\n","   -1.30029589e-01  1.17748894e-01 -6.43308997e-01  1.41978234e-01\n","   -1.83707595e-01  6.61172271e-01  6.75786138e-01  2.15591356e-01\n","   -4.35196489e-01 -4.38262969e-02 -3.92979756e-02 -1.37310445e-01\n","   -6.45360351e-01 -1.68920234e-02 -6.49700224e-01 -2.00181514e-01\n","   -1.61124051e-01 -3.77713621e-01 -5.34589708e-01  1.45261824e-01\n","   -6.81961030e-02  5.53320408e-01  3.86591136e-01 -5.07295907e-01\n","    4.30170119e-01 -8.07881355e-02 -1.79779023e-01 -1.69675350e-02\n","   -1.10002708e+00 -1.68974951e-01  2.66593754e-01 -4.70927835e-01\n","   -2.83668488e-01  8.61446559e-02  7.61348426e-01 -1.93904340e-02\n","   -9.35199261e-02 -2.55179375e-01  1.90298900e-01 -2.14235798e-01\n","    7.78674111e-02  2.13871434e-01 -1.79625496e-01 -4.66663957e-01\n","    7.22106159e-01 -6.64450288e-01  5.62245905e-01 -6.88216865e-01\n","   -1.09065697e-01  1.66367650e-01 -3.95398170e-01  4.32138205e-01\n","   -2.88537323e-01 -4.70378339e-01 -1.98672879e-02  4.97614563e-01\n","   -2.81647742e-02 -3.97529751e-01 -6.13384664e-01  5.75587988e-01\n","   -1.39963076e-01 -5.65166175e-01  1.72499731e-01  2.00316817e-01\n","    2.28631303e-01  6.21067107e-01  2.53253013e-01 -6.63158000e-02\n","   -9.73289728e-01 -8.45294893e-02 -8.00666511e-02 -2.51104712e-01\n","    2.95203507e-01  8.31181586e-01 -7.06895828e-01 -3.44231203e-02\n","   -7.16465563e-02 -5.90564728e-01  4.19428259e-01 -1.21092045e+00\n","    3.43884975e-01 -8.42980266e-01  2.38568664e-01 -4.27230597e-01\n","    1.98645428e-01 -2.56107032e-01 -1.32935798e+00  3.86626273e-01\n","    2.53625184e-01 -4.62020606e-01 -4.88956809e-01 -5.36752880e-01\n","   -9.48145986e-01  3.32367629e-01  7.89150238e-01 -4.60817456e-01\n","    9.15432498e-02  7.80063391e-01  1.09687269e-01  3.10879320e-01\n","   -1.78511500e-01  1.00687116e-01  3.90759170e-01  1.48760110e-01\n","   -6.03674531e-01 -2.75943041e-01  4.81284231e-01  3.77185166e-01\n","   -7.09374905e-01 -5.43725848e-01 -6.16553128e-01 -5.97760737e-01\n","   -2.60605574e-01  4.95350420e-01  2.95977652e-01 -3.34345400e-01\n","   -3.68971884e-01  5.81772685e-01 -4.31056857e-01 -1.16305418e-01\n","   -3.98865759e-01 -2.08031073e-01  4.78581637e-02  6.27244890e-01\n","   -2.35819459e-01 -3.85960460e-01 -3.91192436e-02 -3.38329732e-01\n","   -3.22523475e-01 -1.65440202e-01 -3.49030137e-01  4.56625521e-01\n","    8.56813788e-02  6.07041299e-01 -4.14815843e-02  5.78578115e-01\n","    1.48250639e-01 -4.16435570e-01  9.22507524e-01  1.03216267e+00\n","   -1.27161786e-01 -2.34323964e-01  5.28191209e-01 -7.68784881e-02\n","   -4.46533859e-02 -2.45017141e-01 -1.40178669e-02  4.64074641e-01\n","    2.37029940e-01  1.15372419e+00  2.93569863e-02 -1.16608739e+00\n","    6.57363236e-01 -1.23871595e-01  4.88650084e-01 -2.50022531e-01\n","    5.66099286e-01  2.06003845e-01  5.13832688e-01 -6.77115321e-02\n","   -1.76145792e-01  2.72531897e-01  1.75574064e-01 -4.14562106e-01\n","   -4.60465729e-01  1.47793517e-01  5.04401863e-01  3.59548360e-01]]], shape=(1, 2, 256), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 0.2846943   0.9252908  -0.71139824 -0.318101   -1.995929\n","   -0.12923825 -0.33594143  0.17936413 -0.9848819   0.03989843\n","    0.13481042  0.07519922  0.52798545 -0.01544154  0.54642266\n","   -1.0249891  -0.54632115 -0.28022933 -0.3123772  -1.3611643\n","   -0.7940056   0.08483332 -0.14787464 -1.0338893   0.41383335\n","   -0.10026896 -0.46465448  0.9625503  -0.33835635 -0.20570645\n","   -0.71050024 -0.38621426 -0.03480089  0.42219928  0.5763569\n","    0.22082025  0.52691853  0.6870068   0.701952   -0.8907248\n","   -0.37792316  0.09209883  0.812898    0.18354787  0.25929403\n","    0.62006193  0.51863736 -0.083709    0.16648275 -0.56061053\n","   -0.70348537  0.69897187 -1.0686802   0.9374589   0.550064\n","   -0.38842845 -0.01773617 -0.7866559   0.3097499   0.40618294\n","   -0.2753666   0.4975281   0.20382929  0.25842783  0.33214605\n","    0.79012126  0.6254561  -0.49594626  0.40677482 -0.36056173\n","    0.23122089 -0.7718534   0.07810034 -1.0418959  -0.03684568\n","   -0.7206096   0.15617791 -0.7151497   0.8391237  -0.13374218\n","    1.5219097  -0.07187293  0.88383245  0.36366642 -0.8823657\n","   -0.6526416  -1.0795265  -1.126512    0.32761756  0.00330696\n","   -1.1437078  -0.39986175 -0.65545595  1.1416172   0.24168345\n","   -0.50947785  0.0177373   0.45450383  0.6123083  -0.01477551\n","   -1.4164872  -0.45044905 -0.84142655 -0.31638268 -0.4318337\n","    0.11152107 -0.7977122  -0.29402593  0.22190376  0.8198629\n","    0.9934781  -1.7841139   0.31924403  0.02543356  0.03228898\n","    0.6349463  -1.1526899   0.01462641  0.14623004 -0.33496928\n","    0.16361201 -1.7355917   1.5341232  -0.46102858 -0.41062057\n","   -0.17106414  0.9145668  -0.19287103  0.8290539   0.4491967\n","    0.46677178 -1.1534722   0.8099499  -0.81201136  0.29965815\n","   -0.90667593  0.52271575  0.12396145  0.06773487  0.9552692\n","   -0.8278921   0.13183925  0.25562373  0.93461096  0.20543158\n","    0.39277557 -0.19514573  0.3126479   0.8989024  -0.04988897\n","   -1.1674919   0.21328203  0.00393006  0.74512964 -0.31021404\n","   -0.4922335  -0.12827373  0.45111194  0.38059536  0.18872161\n","    1.0656322   0.7520599   0.06561822 -0.4566407   0.7904573\n","   -0.64025635  0.02698687 -1.0497884  -0.3047269  -1.0664144\n","    0.24960944 -0.18167275 -0.5614187  -1.2006572  -1.5233548\n","    0.6407365   0.6123489   0.61293143 -0.35022584 -0.12116557\n","   -1.5080464   0.23710376  0.5976914  -0.24790967  0.10660455\n","    1.5456176   0.01533371  0.2682159  -0.08534923  1.537975\n","    0.44739527  0.23025753 -0.7023367  -0.6559688  -0.14209771\n","    1.3193926  -0.06137025 -0.83890057 -0.30187654 -0.5516167\n","    0.28904843  0.71975434 -0.02043104  0.23401868  0.1433217\n","    1.6685495  -0.5788096   0.04686975 -1.3360522  -0.4086116\n","   -0.18431062  1.4860232   0.17339933 -1.3288531  -0.45096147\n","   -0.5227387  -0.75967556 -0.42236322 -0.70771277  0.19310403\n","   -0.10127392  0.24055791  0.5592186   0.70414174 -0.52014023\n","    0.87729985  1.7989722   1.2393988   0.18312368 -0.48370713\n","    1.2575781  -1.3153007  -0.9216857   0.45568144  0.36707285\n","    0.09421453 -0.4129458   1.8720981  -0.5077438  -1.1356816\n","    0.44877672 -0.22236523  0.0197069  -0.3041321   0.550889\n","   -0.20230359  1.1037188   0.02082743 -0.78356427  0.23028776\n","   -0.6093881  -0.2702938  -0.30987358 -0.20352757  0.40111506\n","    1.0880768 ]\n","  [ 0.3056589   0.8525728  -0.6313623  -0.2557891  -1.7127897\n","   -0.18573222 -0.26451513  0.04190657 -1.0071845   0.03474391\n","    0.16878942  0.09169018  0.5532775   0.00552917  0.651607\n","   -1.1093051  -0.61235046 -0.2932456  -0.45449638 -1.3075023\n","   -0.5885976   0.09008572 -0.17370975 -0.97165394  0.31276605\n","   -0.2594855  -0.44586292  1.2626231  -0.2671101  -0.18756166\n","   -0.64497554 -0.23987645 -0.05718923  0.29602373  0.53320986\n","    0.16004169  0.39524233  0.69774127  0.66916573 -0.9141779\n","   -0.42495596 -0.03974476  0.7984284   0.10284092  0.2819809\n","    0.57409227  0.5250311  -0.23989606  0.13222408 -0.5963287\n","   -0.75839186  0.7091795  -1.1138175   1.0134114   0.54302126\n","   -0.34979078 -0.09724274 -0.87555337  0.24019524  0.43990403\n","   -0.36329478  0.47705868  0.2827766   0.25005704  0.27939296\n","    0.88918734  0.5440656  -0.3415205   0.32726187 -0.35369152\n","    0.15267098 -0.6732041   0.17498723 -0.9726685  -0.01862384\n","   -0.8562912   0.05622825 -0.43750915  1.0269943  -0.01641198\n","    1.3727769  -0.03188726  0.9776534   0.28309825 -0.8725801\n","   -0.59265673 -1.1724178  -1.1434865   0.26939645 -0.20751593\n","   -1.05705    -0.30629548 -0.6150782   1.0217879   0.23274168\n","   -0.57148033 -0.11761993  0.30925292  0.5075268   0.10241407\n","   -1.4397683  -0.54187167 -0.98579115 -0.10413433 -0.3619425\n","    0.09415224 -0.8203481  -0.17166269  0.14762668  0.70471835\n","    0.8331009  -1.6438043   0.49223882  0.10996607  0.00201407\n","    0.6565129  -1.1271323  -0.03262581  0.06947237 -0.43401992\n","    0.22760615 -1.7107549   1.5773659  -0.47808674 -0.31724307\n","   -0.28003946  0.961984   -0.27454776  0.92054754  0.44135487\n","    0.5070981  -0.94924515  0.7976187  -0.6723162   0.22342315\n","   -0.9377663   0.46857888  0.2036815  -0.05003658  0.8449288\n","   -0.8541609   0.01201382  0.16612396  0.8719399   0.13433775\n","    0.3590267  -0.07593244  0.42275128  0.6924908   0.11782044\n","   -1.0253879   0.30022457 -0.05947791  0.7612286  -0.29557118\n","   -0.5076866  -0.24068564  0.47658864  0.26520026  0.12802619\n","    1.0739963   0.7568816  -0.03957617 -0.52041256  0.7188938\n","   -0.8272369   0.11406764 -1.0647593  -0.3232617  -1.0430255\n","    0.27373075 -0.17572474 -0.4793443  -1.1220849  -1.5648668\n","    0.40773335  0.6671224   0.56197834 -0.36965588 -0.08154583\n","   -1.6167252   0.27154502  0.5694421  -0.20679736  0.16651022\n","    1.5009105  -0.04643601  0.09160849  0.06929451  1.6337931\n","    0.42803657  0.09789018 -0.70393544 -0.45147184 -0.20195499\n","    1.2108483  -0.07875896 -0.81740975 -0.348113   -0.48677254\n","    0.33006626  0.7289044  -0.12648529  0.22749096  0.21369302\n","    1.3945225  -0.41932344  0.2236901  -1.353717   -0.4538198\n","   -0.21375494  1.4789712   0.46675813 -1.3273637  -0.56646055\n","   -0.71300495 -0.74294436 -0.6012845  -0.6727149   0.31821322\n","    0.01708807  0.2513215   0.34898284  0.5841788  -0.6299873\n","    0.736218    1.8748559   1.2151996   0.00210416 -0.44374654\n","    1.1628661  -1.393074   -0.9696106   0.46591142  0.36038902\n","    0.03006268 -0.47777173  1.743911   -0.569625   -0.9780997\n","    0.5819177  -0.15933886  0.09950829 -0.40758586  0.47267786\n","   -0.27980492  1.1476091   0.01583009 -0.8479634   0.16889358\n","   -0.69660175 -0.3728242  -0.25272852 -0.16451879  0.4938146\n","    1.1174332 ]]], shape=(1, 2, 256), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(2, 256, 512) dtype=float32, numpy=\n","array([[[-1.9868165e-03,  4.8832163e-02, -1.0633007e-02, ...,\n","         -1.6083717e-02,  1.7005473e-02,  5.8088034e-02],\n","        [ 2.9280782e-04, -1.6035661e-02,  3.2076791e-02, ...,\n","         -2.0043403e-03,  3.6689848e-02,  4.2286307e-02],\n","        [-7.6008588e-03,  2.3150459e-02, -1.8187404e-02, ...,\n","          6.8976134e-03, -2.4544224e-02, -4.0393382e-02],\n","        ...,\n","        [-3.8575396e-02,  3.9675713e-02, -2.2614285e-02, ...,\n","          6.6210777e-03,  3.8266107e-02, -4.0754646e-02],\n","        [ 1.9784644e-02, -1.0747954e-02, -3.7411466e-02, ...,\n","          6.1656743e-02,  1.0523781e-02,  1.4895052e-02],\n","        [ 1.4862433e-02, -8.7059140e-03, -2.0603165e-02, ...,\n","         -7.3561519e-03,  9.8729134e-03, -3.0127123e-02]],\n","\n","       [[ 6.1155125e-02,  4.5462504e-02,  1.3429388e-02, ...,\n","         -2.6458234e-02, -5.0062776e-02, -2.9009148e-02],\n","        [ 2.2957906e-02,  9.2141628e-03, -1.1840850e-02, ...,\n","         -4.6801075e-02, -5.1230475e-02, -2.2108704e-02],\n","        [-3.8398415e-02, -1.1142373e-02,  1.5042886e-02, ...,\n","         -3.4408927e-02,  9.9122524e-05, -1.8603057e-03],\n","        ...,\n","        [-3.1889871e-02, -2.4042249e-02,  6.0667038e-02, ...,\n","          3.4357056e-02, -1.6262174e-02,  3.3434659e-02],\n","        [ 4.2748392e-02,  3.0875757e-02,  2.0924106e-02, ...,\n","          1.0827482e-02,  5.6474149e-02, -4.1642845e-02],\n","        [-3.3523828e-02,  6.0721964e-02,  6.2817633e-03, ...,\n","          4.7092423e-02,  3.7557349e-02,  5.7960227e-02]]], dtype=float32)>\n","branch shape after EXPAND DIMS tf.Tensor(\n","[[[[ 0.22996582 -0.23217326 -0.19168073 ... -0.21591686  0.27155855\n","     0.1788115 ]]\n","\n","  [[ 0.25298718  0.01494963 -0.08455823 ... -0.35127303 -0.37185833\n","    -0.15424931]]]], shape=(1, 2, 1, 512), dtype=float32)\n","BRANCH AFTER RESHAPE\n","tf.Tensor(\n","[[[ 0.22996582 -0.04643465 -0.03833615 ... -0.06855598  0.64744425\n","    0.2698171 ]\n","  [-0.04116303  0.11841419 -0.01413295 ... -0.04318337  0.27155855\n","    0.1788115 ]\n","  [ 0.25298718  0.01494963 -0.01691165 ...  0.2640713  -0.01542187\n","    0.04824475]\n","  [-0.02445844  0.25563672 -0.0006562  ... -0.07025461 -0.07437167\n","   -0.03084986]]], shape=(1, 4, 256), dtype=float32)\n","Branch W_loop call\n","tf.Tensor(\n","[[[ 0.06619644 -0.05679064  0.09254476 ... -0.04085707  0.11309073\n","   -0.1254924 ]\n","  [-0.2512745   0.07318866 -0.02056946 ... -0.09664088 -0.00285757\n","    0.01664438]\n","  [-0.1550858   0.1827983  -0.05375993 ... -0.15365526 -0.0883507\n","    0.07269683]\n","  [ 0.11287831  0.10467756 -0.08067739 ...  0.26139975 -0.129885\n","   -0.1069901 ]]], shape=(1, 4, 256), dtype=float32)\n","BRANCH AFTER RE TILE\n","tf.Tensor(\n","[[[ 0.35089076  0.8685002  -0.61885345 ... -0.24438465  0.5142058\n","    0.96258444]\n","  [ 0.03341982  0.9984795  -0.7319677  ... -0.30016845  0.3982575\n","    1.1047212 ]\n","  [ 0.1505731   1.0353711  -0.68512225 ... -0.31817406  0.40546387\n","    1.19013   ]\n","  [ 0.4185372   0.95725036 -0.7120397  ...  0.09688096  0.36392957\n","    1.0104431 ]]], shape=(1, 4, 256), dtype=float32)\n","0\n","Tree INDEX:  0 3\n","tf.Tensor(\n","[[[0.01047182 0.59066546 0.39506686 0.6289226  0.61416733 0.11192453\n","   0.30162597 0.92322063 0.06005347 0.4205227  0.5107981  0.7969223\n","   0.9080839  0.57025886 0.2834581  0.90183246 0.9557593  0.9391173\n","   0.2427814  0.40333366 0.5925106  0.5375744  0.6049135  0.6379062\n","   0.83508635 0.6918887  0.01023054 0.8498752  0.24461305 0.33344865\n","   0.88443565 0.50010383 0.06586492 0.14401078 0.9661263  0.07820046\n","   0.8140285  0.32176793 0.48425317 0.39198327 0.75259864 0.44515467\n","   0.00307918 0.4255302  0.6385578  0.7718121  0.01598752 0.8888041\n","   0.7453935  0.9360999  0.469962   0.33280253 0.62882626 0.30295599\n","   0.8215525  0.13067889 0.2499367  0.43057394 0.4070083  0.10915458\n","   0.66520846 0.10049736 0.3901155  0.69108176 0.11987472 0.9388958\n","   0.39744174 0.48599482 0.8281683  0.17230654 0.7776722  0.5991373\n","   0.97225726 0.25942183 0.28829956 0.40875483 0.95815384 0.5111251\n","   0.09509945 0.65893793 0.51377916 0.574008   0.17741227 0.9151815\n","   0.48197544 0.5930363  0.9448329  0.66817796 0.83241916 0.9848572\n","   0.92965066 0.6101297  0.10795307 0.8371556  0.8690964  0.47578883]]], shape=(1, 1, 96), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 4\n","Root Node\n","tf.Tensor(\n","[[[ 1.0983922   0.6899245  -0.13008529  0.0642792   0.45594049\n","   -0.44937947  0.73308235  0.01282325 -0.07356071 -0.38853896\n","   -0.25537115  0.03714669  0.738181    0.64017487 -0.88583034\n","   -1.2504293  -0.65982944  0.42515704  1.0862116   0.87066066\n","    1.0270696   0.5275123   0.27382684 -0.57694936  0.44350713\n","    0.30802292  0.01922128 -0.6701652  -0.6169071   0.2609548\n","    0.5074135   0.6965234   0.43605363  0.20301327 -0.60771275\n","    0.34482145 -0.16585708 -0.5599365  -0.4903617   0.24190848\n","   -0.60219604 -0.03458136  0.01766305 -0.19599545 -0.31071463\n","   -0.66902006 -0.17676291  1.3055902   0.40082875 -0.7544803\n","    0.8133017   0.05474379  0.6945866  -1.2144136  -0.9175005\n","    0.5687816  -0.21933147 -0.5105225  -0.8634345  -0.01100412\n","    0.21047288  0.4508406  -0.13202477  0.7704735  -0.17602289\n","   -0.05158251  0.2683742  -0.94309485 -0.4373268  -0.63880426\n","   -0.15902689  0.42489517  0.36268517  0.02567907 -0.04377633\n","    0.02553736  0.14833866 -0.49860498  0.74800766  0.7132056\n","   -1.4623048  -1.2800046  -0.0617301  -0.20595464  0.4535599\n","   -0.5908381  -0.18770005  0.15187886 -0.5335014  -0.23328623\n","    0.46403736 -0.03054698 -0.0380311  -0.74564946 -0.7858455\n","    0.8684332   0.91371787  0.12256175 -0.4291812  -0.5887674\n","   -0.7496419   1.1237226  -0.81000304  0.6316091  -0.48793104\n","   -0.7382058   0.8037957   0.6677787  -0.37090218  0.62082404\n","   -0.07594129  0.35463533  0.17808697  0.566832    0.2861199\n","   -0.45456547  0.6142118   0.50899136 -0.33136046 -0.09710704\n","    0.5639059  -0.19302183 -0.6710843  -0.49916604 -0.18791166\n","    1.5070882  -0.32643858  0.74145174]]], shape=(1, 1, 128), dtype=float32)\n","tf.Tensor([  1   1 128], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[ 1.0983922   0.6899245  -0.13008529  0.0642792   0.45594049\n","   -0.44937947  0.73308235  0.01282325 -0.07356071 -0.38853896\n","   -0.25537115  0.03714669  0.738181    0.64017487 -0.88583034\n","   -1.2504293  -0.65982944  0.42515704  1.0862116   0.87066066\n","    1.0270696   0.5275123   0.27382684 -0.57694936  0.44350713\n","    0.30802292  0.01922128 -0.6701652  -0.6169071   0.2609548\n","    0.5074135   0.6965234   0.43605363  0.20301327 -0.60771275\n","    0.34482145 -0.16585708 -0.5599365  -0.4903617   0.24190848\n","   -0.60219604 -0.03458136  0.01766305 -0.19599545 -0.31071463\n","   -0.66902006 -0.17676291  1.3055902   0.40082875 -0.7544803\n","    0.8133017   0.05474379  0.6945866  -1.2144136  -0.9175005\n","    0.5687816  -0.21933147 -0.5105225  -0.8634345  -0.01100412\n","    0.21047288  0.4508406  -0.13202477  0.7704735  -0.17602289\n","   -0.05158251  0.2683742  -0.94309485 -0.4373268  -0.63880426\n","   -0.15902689  0.42489517  0.36268517  0.02567907 -0.04377633\n","    0.02553736  0.14833866 -0.49860498  0.74800766  0.7132056\n","   -1.4623048  -1.2800046  -0.0617301  -0.20595464  0.4535599\n","   -0.5908381  -0.18770005  0.15187886 -0.5335014  -0.23328623\n","    0.46403736 -0.03054698 -0.0380311  -0.74564946 -0.7858455\n","    0.8684332   0.91371787  0.12256175 -0.4291812  -0.5887674\n","   -0.7496419   1.1237226  -0.81000304  0.6316091  -0.48793104\n","   -0.7382058   0.8037957   0.6677787  -0.37090218  0.62082404\n","   -0.07594129  0.35463533  0.17808697  0.566832    0.2861199\n","   -0.45456547  0.6142118   0.50899136 -0.33136046 -0.09710704\n","    0.5639059  -0.19302183 -0.6710843  -0.49916604 -0.18791166\n","    1.5070882  -0.32643858  0.74145174  1.0983922   0.6899245\n","   -0.13008529  0.0642792   0.45594049 -0.44937947  0.73308235\n","    0.01282325 -0.07356071 -0.38853896 -0.25537115  0.03714669\n","    0.738181    0.64017487 -0.88583034 -1.2504293  -0.65982944\n","    0.42515704  1.0862116   0.87066066  1.0270696   0.5275123\n","    0.27382684 -0.57694936  0.44350713  0.30802292  0.01922128\n","   -0.6701652  -0.6169071   0.2609548   0.5074135   0.6965234\n","    0.43605363  0.20301327 -0.60771275  0.34482145 -0.16585708\n","   -0.5599365  -0.4903617   0.24190848 -0.60219604 -0.03458136\n","    0.01766305 -0.19599545 -0.31071463 -0.66902006 -0.17676291\n","    1.3055902   0.40082875 -0.7544803   0.8133017   0.05474379\n","    0.6945866  -1.2144136  -0.9175005   0.5687816  -0.21933147\n","   -0.5105225  -0.8634345  -0.01100412  0.21047288  0.4508406\n","   -0.13202477  0.7704735  -0.17602289 -0.05158251  0.2683742\n","   -0.94309485 -0.4373268  -0.63880426 -0.15902689  0.42489517\n","    0.36268517  0.02567907 -0.04377633  0.02553736  0.14833866\n","   -0.49860498  0.74800766  0.7132056  -1.4623048  -1.2800046\n","   -0.0617301  -0.20595464  0.4535599  -0.5908381  -0.18770005\n","    0.15187886 -0.5335014  -0.23328623  0.46403736 -0.03054698\n","   -0.0380311  -0.74564946 -0.7858455   0.8684332   0.91371787\n","    0.12256175 -0.4291812  -0.5887674  -0.7496419   1.1237226\n","   -0.81000304  0.6316091  -0.48793104 -0.7382058   0.8037957\n","    0.6677787  -0.37090218  0.62082404 -0.07594129  0.35463533\n","    0.17808697  0.566832    0.2861199  -0.45456547  0.6142118\n","    0.50899136 -0.33136046 -0.09710704  0.5639059  -0.19302183\n","   -0.6710843  -0.49916604 -0.18791166  1.5070882  -0.32643858\n","    0.74145174  1.0983922   0.6899245  -0.13008529  0.0642792\n","    0.45594049 -0.44937947  0.73308235  0.01282325 -0.07356071\n","   -0.38853896 -0.25537115  0.03714669  0.738181    0.64017487\n","   -0.88583034 -1.2504293  -0.65982944  0.42515704  1.0862116\n","    0.87066066  1.0270696   0.5275123   0.27382684 -0.57694936\n","    0.44350713  0.30802292  0.01922128 -0.6701652  -0.6169071\n","    0.2609548   0.5074135   0.6965234   0.43605363  0.20301327\n","   -0.60771275  0.34482145 -0.16585708 -0.5599365  -0.4903617\n","    0.24190848 -0.60219604 -0.03458136  0.01766305 -0.19599545\n","   -0.31071463 -0.66902006 -0.17676291  1.3055902   0.40082875\n","   -0.7544803   0.8133017   0.05474379  0.6945866  -1.2144136\n","   -0.9175005   0.5687816  -0.21933147 -0.5105225  -0.8634345\n","   -0.01100412  0.21047288  0.4508406  -0.13202477  0.7704735\n","   -0.17602289 -0.05158251  0.2683742  -0.94309485 -0.4373268\n","   -0.63880426 -0.15902689  0.42489517  0.36268517  0.02567907\n","   -0.04377633  0.02553736  0.14833866 -0.49860498  0.74800766\n","    0.7132056  -1.4623048  -1.2800046  -0.0617301  -0.20595464\n","    0.4535599  -0.5908381  -0.18770005  0.15187886 -0.5335014\n","   -0.23328623  0.46403736 -0.03054698 -0.0380311  -0.74564946\n","   -0.7858455   0.8684332   0.91371787  0.12256175 -0.4291812\n","   -0.5887674  -0.7496419   1.1237226  -0.81000304  0.6316091\n","   -0.48793104 -0.7382058   0.8037957   0.6677787  -0.37090218\n","    0.62082404 -0.07594129  0.35463533  0.17808697  0.566832\n","    0.2861199  -0.45456547  0.6142118   0.50899136 -0.33136046\n","   -0.09710704  0.5639059  -0.19302183 -0.6710843  -0.49916604\n","   -0.18791166  1.5070882  -0.32643858  0.74145174  1.0983922\n","    0.6899245  -0.13008529  0.0642792   0.45594049 -0.44937947\n","    0.73308235  0.01282325 -0.07356071 -0.38853896 -0.25537115\n","    0.03714669  0.738181    0.64017487 -0.88583034 -1.2504293\n","   -0.65982944  0.42515704  1.0862116   0.87066066  1.0270696\n","    0.5275123   0.27382684 -0.57694936  0.44350713  0.30802292\n","    0.01922128 -0.6701652  -0.6169071   0.2609548   0.5074135\n","    0.6965234   0.43605363  0.20301327 -0.60771275  0.34482145\n","   -0.16585708 -0.5599365  -0.4903617   0.24190848 -0.60219604\n","   -0.03458136  0.01766305 -0.19599545 -0.31071463 -0.66902006\n","   -0.17676291  1.3055902   0.40082875 -0.7544803   0.8133017\n","    0.05474379  0.6945866  -1.2144136  -0.9175005   0.5687816\n","   -0.21933147 -0.5105225  -0.8634345  -0.01100412  0.21047288\n","    0.4508406  -0.13202477  0.7704735  -0.17602289 -0.05158251\n","    0.2683742  -0.94309485 -0.4373268  -0.63880426 -0.15902689\n","    0.42489517  0.36268517  0.02567907 -0.04377633  0.02553736\n","    0.14833866 -0.49860498  0.74800766  0.7132056  -1.4623048\n","   -1.2800046  -0.0617301  -0.20595464  0.4535599  -0.5908381\n","   -0.18770005  0.15187886 -0.5335014  -0.23328623  0.46403736\n","   -0.03054698 -0.0380311  -0.74564946 -0.7858455   0.8684332\n","    0.91371787  0.12256175 -0.4291812  -0.5887674  -0.7496419\n","    1.1237226  -0.81000304  0.6316091  -0.48793104 -0.7382058\n","    0.8037957   0.6677787  -0.37090218  0.62082404 -0.07594129\n","    0.35463533  0.17808697  0.566832    0.2861199  -0.45456547\n","    0.6142118   0.50899136 -0.33136046 -0.09710704  0.5639059\n","   -0.19302183 -0.6710843  -0.49916604 -0.18791166  1.5070882\n","   -0.32643858  0.74145174]]], shape=(1, 1, 512), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 1.0983922   0.6899245  -0.13008529  0.0642792   0.45594049\n","   -0.44937947  0.73308235  0.01282325 -0.07356071 -0.38853896\n","   -0.25537115  0.03714669  0.738181    0.64017487 -0.88583034\n","   -1.2504293  -0.65982944  0.42515704  1.0862116   0.87066066\n","    1.0270696   0.5275123   0.27382684 -0.57694936  0.44350713\n","    0.30802292  0.01922128 -0.6701652  -0.6169071   0.2609548\n","    0.5074135   0.6965234   0.43605363  0.20301327 -0.60771275\n","    0.34482145 -0.16585708 -0.5599365  -0.4903617   0.24190848\n","   -0.60219604 -0.03458136  0.01766305 -0.19599545 -0.31071463\n","   -0.66902006 -0.17676291  1.3055902   0.40082875 -0.7544803\n","    0.8133017   0.05474379  0.6945866  -1.2144136  -0.9175005\n","    0.5687816  -0.21933147 -0.5105225  -0.8634345  -0.01100412\n","    0.21047288  0.4508406  -0.13202477  0.7704735  -0.17602289\n","   -0.05158251  0.2683742  -0.94309485 -0.4373268  -0.63880426\n","   -0.15902689  0.42489517  0.36268517  0.02567907 -0.04377633\n","    0.02553736  0.14833866 -0.49860498  0.74800766  0.7132056\n","   -1.4623048  -1.2800046  -0.0617301  -0.20595464  0.4535599\n","   -0.5908381  -0.18770005  0.15187886 -0.5335014  -0.23328623\n","    0.46403736 -0.03054698 -0.0380311  -0.74564946 -0.7858455\n","    0.8684332   0.91371787  0.12256175 -0.4291812  -0.5887674\n","   -0.7496419   1.1237226  -0.81000304  0.6316091  -0.48793104\n","   -0.7382058   0.8037957   0.6677787  -0.37090218  0.62082404\n","   -0.07594129  0.35463533  0.17808697  0.566832    0.2861199\n","   -0.45456547  0.6142118   0.50899136 -0.33136046 -0.09710704\n","    0.5639059  -0.19302183 -0.6710843  -0.49916604 -0.18791166\n","    1.5070882  -0.32643858  0.74145174]\n","  [ 1.0983922   0.6899245  -0.13008529  0.0642792   0.45594049\n","   -0.44937947  0.73308235  0.01282325 -0.07356071 -0.38853896\n","   -0.25537115  0.03714669  0.738181    0.64017487 -0.88583034\n","   -1.2504293  -0.65982944  0.42515704  1.0862116   0.87066066\n","    1.0270696   0.5275123   0.27382684 -0.57694936  0.44350713\n","    0.30802292  0.01922128 -0.6701652  -0.6169071   0.2609548\n","    0.5074135   0.6965234   0.43605363  0.20301327 -0.60771275\n","    0.34482145 -0.16585708 -0.5599365  -0.4903617   0.24190848\n","   -0.60219604 -0.03458136  0.01766305 -0.19599545 -0.31071463\n","   -0.66902006 -0.17676291  1.3055902   0.40082875 -0.7544803\n","    0.8133017   0.05474379  0.6945866  -1.2144136  -0.9175005\n","    0.5687816  -0.21933147 -0.5105225  -0.8634345  -0.01100412\n","    0.21047288  0.4508406  -0.13202477  0.7704735  -0.17602289\n","   -0.05158251  0.2683742  -0.94309485 -0.4373268  -0.63880426\n","   -0.15902689  0.42489517  0.36268517  0.02567907 -0.04377633\n","    0.02553736  0.14833866 -0.49860498  0.74800766  0.7132056\n","   -1.4623048  -1.2800046  -0.0617301  -0.20595464  0.4535599\n","   -0.5908381  -0.18770005  0.15187886 -0.5335014  -0.23328623\n","    0.46403736 -0.03054698 -0.0380311  -0.74564946 -0.7858455\n","    0.8684332   0.91371787  0.12256175 -0.4291812  -0.5887674\n","   -0.7496419   1.1237226  -0.81000304  0.6316091  -0.48793104\n","   -0.7382058   0.8037957   0.6677787  -0.37090218  0.62082404\n","   -0.07594129  0.35463533  0.17808697  0.566832    0.2861199\n","   -0.45456547  0.6142118   0.50899136 -0.33136046 -0.09710704\n","    0.5639059  -0.19302183 -0.6710843  -0.49916604 -0.18791166\n","    1.5070882  -0.32643858  0.74145174]\n","  [ 1.0983922   0.6899245  -0.13008529  0.0642792   0.45594049\n","   -0.44937947  0.73308235  0.01282325 -0.07356071 -0.38853896\n","   -0.25537115  0.03714669  0.738181    0.64017487 -0.88583034\n","   -1.2504293  -0.65982944  0.42515704  1.0862116   0.87066066\n","    1.0270696   0.5275123   0.27382684 -0.57694936  0.44350713\n","    0.30802292  0.01922128 -0.6701652  -0.6169071   0.2609548\n","    0.5074135   0.6965234   0.43605363  0.20301327 -0.60771275\n","    0.34482145 -0.16585708 -0.5599365  -0.4903617   0.24190848\n","   -0.60219604 -0.03458136  0.01766305 -0.19599545 -0.31071463\n","   -0.66902006 -0.17676291  1.3055902   0.40082875 -0.7544803\n","    0.8133017   0.05474379  0.6945866  -1.2144136  -0.9175005\n","    0.5687816  -0.21933147 -0.5105225  -0.8634345  -0.01100412\n","    0.21047288  0.4508406  -0.13202477  0.7704735  -0.17602289\n","   -0.05158251  0.2683742  -0.94309485 -0.4373268  -0.63880426\n","   -0.15902689  0.42489517  0.36268517  0.02567907 -0.04377633\n","    0.02553736  0.14833866 -0.49860498  0.74800766  0.7132056\n","   -1.4623048  -1.2800046  -0.0617301  -0.20595464  0.4535599\n","   -0.5908381  -0.18770005  0.15187886 -0.5335014  -0.23328623\n","    0.46403736 -0.03054698 -0.0380311  -0.74564946 -0.7858455\n","    0.8684332   0.91371787  0.12256175 -0.4291812  -0.5887674\n","   -0.7496419   1.1237226  -0.81000304  0.6316091  -0.48793104\n","   -0.7382058   0.8037957   0.6677787  -0.37090218  0.62082404\n","   -0.07594129  0.35463533  0.17808697  0.566832    0.2861199\n","   -0.45456547  0.6142118   0.50899136 -0.33136046 -0.09710704\n","    0.5639059  -0.19302183 -0.6710843  -0.49916604 -0.18791166\n","    1.5070882  -0.32643858  0.74145174]\n","  [ 1.0983922   0.6899245  -0.13008529  0.0642792   0.45594049\n","   -0.44937947  0.73308235  0.01282325 -0.07356071 -0.38853896\n","   -0.25537115  0.03714669  0.738181    0.64017487 -0.88583034\n","   -1.2504293  -0.65982944  0.42515704  1.0862116   0.87066066\n","    1.0270696   0.5275123   0.27382684 -0.57694936  0.44350713\n","    0.30802292  0.01922128 -0.6701652  -0.6169071   0.2609548\n","    0.5074135   0.6965234   0.43605363  0.20301327 -0.60771275\n","    0.34482145 -0.16585708 -0.5599365  -0.4903617   0.24190848\n","   -0.60219604 -0.03458136  0.01766305 -0.19599545 -0.31071463\n","   -0.66902006 -0.17676291  1.3055902   0.40082875 -0.7544803\n","    0.8133017   0.05474379  0.6945866  -1.2144136  -0.9175005\n","    0.5687816  -0.21933147 -0.5105225  -0.8634345  -0.01100412\n","    0.21047288  0.4508406  -0.13202477  0.7704735  -0.17602289\n","   -0.05158251  0.2683742  -0.94309485 -0.4373268  -0.63880426\n","   -0.15902689  0.42489517  0.36268517  0.02567907 -0.04377633\n","    0.02553736  0.14833866 -0.49860498  0.74800766  0.7132056\n","   -1.4623048  -1.2800046  -0.0617301  -0.20595464  0.4535599\n","   -0.5908381  -0.18770005  0.15187886 -0.5335014  -0.23328623\n","    0.46403736 -0.03054698 -0.0380311  -0.74564946 -0.7858455\n","    0.8684332   0.91371787  0.12256175 -0.4291812  -0.5887674\n","   -0.7496419   1.1237226  -0.81000304  0.6316091  -0.48793104\n","   -0.7382058   0.8037957   0.6677787  -0.37090218  0.62082404\n","   -0.07594129  0.35463533  0.17808697  0.566832    0.2861199\n","   -0.45456547  0.6142118   0.50899136 -0.33136046 -0.09710704\n","    0.5639059  -0.19302183 -0.6710843  -0.49916604 -0.18791166\n","    1.5070882  -0.32643858  0.74145174]]], shape=(1, 4, 128), dtype=float32)\n","1\n","Tree INDEX:  1 3\n","tf.Tensor(\n","[[[-4.38085161e-02  5.14522731e-01  2.79901981e-01 -8.42245668e-02\n","    3.10131192e-01 -4.91717719e-02  2.82714933e-01  1.59668729e-01\n","    3.16451937e-01  1.06002778e-01 -1.75797984e-01  2.43300289e-01\n","   -1.64478689e-01 -1.36502862e-01 -6.29783124e-02  3.34693581e-01\n","    5.62972575e-02 -2.08755001e-01 -2.35163011e-02  4.75989431e-02\n","    6.91371381e-01  4.30168569e-01 -1.54355762e-03 -5.37517965e-02\n","   -5.20638600e-02  4.11936998e-01 -1.20539621e-01  1.11038074e-01\n","   -3.03011369e-02 -1.38722941e-01 -1.40641006e-02  6.65612340e-01\n","   -4.24496494e-02  3.96848619e-02  4.31291163e-02 -1.95318349e-02\n","    9.59906131e-02 -1.05199710e-01  1.95507586e-01 -1.26699820e-01\n","    1.28836364e-01 -6.88220784e-02 -3.85855585e-02 -5.60288690e-02\n","    5.18352509e-01 -6.01034872e-02  9.03500319e-01 -3.26057449e-02\n","   -9.54587013e-02  3.70612174e-01 -3.59645486e-02 -8.60777125e-02\n","   -6.46821409e-02  4.43804145e-01 -1.74348634e-02 -2.72681396e-02\n","   -1.01330522e-02  1.12554908e-01  6.42261267e-01  3.02520126e-01\n","   -6.61709928e-04 -1.60289556e-01 -7.79324695e-02 -1.38009591e-02\n","    9.41904336e-02  5.89249969e-01 -2.62701400e-02 -1.70951396e-01\n","   -3.97389568e-02 -1.82683662e-01 -1.02914207e-01  5.65070093e-01\n","   -1.69491798e-01  3.61192599e-02 -8.35777298e-02  3.07498991e-01\n","    1.70458123e-01  1.15783095e+00 -4.53899838e-02 -1.48425521e-02\n","   -2.28466671e-02 -9.98113677e-02  5.18225551e-01 -1.61068395e-01\n","   -1.15866914e-01  1.01097316e-01  3.80062699e-01  4.65870589e-01\n","    8.82818639e-01  1.05144113e-01 -4.04038420e-03  8.61021951e-02\n","   -7.97107145e-02  5.37506565e-02  1.61904633e-01 -1.22601725e-01\n","   -1.00071840e-01  8.22263807e-02 -2.52077286e-03  8.16332042e-01\n","   -1.21257246e-01  5.40857911e-01  3.20210099e-01  2.04921946e-01\n","   -1.39518946e-01 -1.00047044e-01  3.31661403e-01 -3.80643718e-02\n","    3.11563760e-02  7.30425954e-01 -1.22975193e-01  1.75942704e-01\n","   -8.55988488e-02  4.75723296e-02 -1.28500894e-01  5.40147871e-02\n","   -3.89585160e-02 -6.07193373e-02  3.22029412e-01 -1.83825597e-01\n","    3.60989213e-01 -3.17464583e-02 -9.42828655e-02 -1.57229009e-03\n","   -1.20822955e-02  5.33291325e-02  6.91701889e-01 -6.13104701e-02\n","    6.83839977e-01 -5.03671635e-03 -1.21477142e-01  6.75283194e-01\n","   -1.17253698e-01  2.13981539e-01 -1.75970748e-01 -1.57257378e-01\n","    3.83838773e-01  3.16658974e-01 -2.18769953e-01  3.01411927e-01\n","   -1.43378735e-01  5.75608850e-01  3.69392514e-01  4.21119153e-01\n","    1.99424356e-01  1.04867280e+00  5.83800554e-01 -2.83690728e-02\n","   -7.38091543e-02  4.98416334e-01 -1.14961743e-01 -1.04038253e-01\n","   -3.48988734e-02  8.40120792e-01  5.99176526e-01 -8.60372484e-02\n","    3.18731606e-01 -2.25727987e-02 -1.13547323e-02 -2.42312551e-01\n","   -1.66865084e-02 -2.36818776e-01 -3.06139886e-02  4.63447452e-01\n","   -2.03188490e-02  5.95955253e-01 -1.03045814e-01 -9.36243162e-02\n","   -1.38037264e-01 -8.49231109e-02  1.14787087e-01  2.94745386e-01\n","   -2.57693738e-01 -8.62302706e-02  2.48403400e-01 -8.06332752e-02\n","    8.42356443e-01  8.37407112e-01  7.04727113e-01 -1.05859868e-01\n","   -2.08054911e-02  5.99296167e-02 -5.57315908e-02 -1.19325612e-02\n","    3.27064395e-01 -9.52453166e-02  4.80743587e-01 -6.31099045e-02\n","   -7.79415295e-02 -1.89042166e-01  5.92057526e-01 -1.45959064e-01\n","    7.80217528e-01  5.93814313e-01  5.35137296e-01  2.92976677e-01\n","   -1.16906941e-01 -9.80610996e-02 -1.46089494e-01 -5.50946081e-03\n","   -5.49266301e-02 -1.54027566e-01  1.79697081e-01 -9.01245400e-02\n","   -2.96709426e-02 -1.16103508e-01  4.42664325e-03 -7.27676302e-02\n","    1.23814344e-01 -9.50086340e-02 -1.74927384e-01  3.07584763e-01\n","   -4.50636558e-02 -6.32648915e-02 -8.37559924e-02  8.36740255e-01\n","    7.35139966e-01 -4.36255559e-02  5.60533553e-02  9.75343883e-01\n","   -8.64997786e-03  9.29381847e-02  1.42363712e-01 -1.14082217e-01\n","   -8.13403651e-02  3.41797709e-01  7.97768474e-01 -1.34938331e-02\n","   -7.73214325e-02 -7.79429078e-02  5.68927169e-01 -3.44287418e-02\n","   -1.95526466e-01 -7.07361028e-02  2.91816294e-02 -4.70517054e-02\n","   -2.44555678e-02  3.53707671e-01 -5.52726388e-02 -1.31136447e-01\n","    5.78834474e-01  3.06794703e-01 -1.43088177e-01 -3.00416686e-02\n","   -7.45682567e-02  5.96050024e-01  1.32087752e-01 -9.65137500e-03\n","   -5.68172224e-02  4.14800346e-02  1.15839410e+00  3.20272565e-01\n","   -5.14090769e-02  2.63104320e-01 -7.59995803e-02 -1.75420044e-03]]], shape=(1, 1, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","1 4\n","Root Node\n","tf.Tensor(\n","[[[-0.3328428  -0.15310417  0.14570665 -0.683204    0.6507988\n","   -0.3975009  -0.5368943  -0.31570217  0.75885916 -0.24650265\n","   -0.35908133 -0.20864362 -0.35965776 -0.40815318  0.2924817\n","    0.31201056  0.31388444 -0.3155065   0.18900451  0.900018\n","    0.28028393  0.39212552 -0.11371727  0.53058314  0.41766632\n","   -0.34871414  0.11946747  0.16296402 -0.6443969  -0.22147942\n","   -0.07787123 -0.1272329  -0.2533568  -0.55764645 -0.17936303\n","    0.27364296  0.3900627  -0.8493354   0.36568838 -0.35909656\n","   -0.5144919   0.21604964 -0.14676908  0.06813978 -0.31412527\n","    0.4059783  -0.11809671  0.32471076  0.13595393 -0.32438794\n","    0.30319244 -0.03118158  0.2720952  -0.5260025   0.2243012\n","    0.12872218  0.39189708  0.10343492  0.38298222  0.2998557\n","   -0.07102969  0.25416455  0.374968   -0.47233924 -0.18252769\n","    0.38339946 -0.16574654  0.15562496  0.03872239 -0.2490853\n","    0.13082416  0.24847774  0.39421618 -0.5055371   0.1035298\n","   -0.4481752  -0.2762258  -0.22294292 -0.33578587  0.05666116\n","    0.00752513 -0.03672354  0.11759033 -0.1345833  -0.35576645\n","   -0.41964996 -0.31882286 -0.2717303  -0.09150261 -0.24857655\n","   -0.52745557 -0.17235124 -0.03798041  0.41153097 -0.03346229\n","    0.31389531  0.26104614  0.1939565   0.15797813  0.79151136\n","    0.3354468  -0.18625319 -0.30435964 -0.39947972 -0.42205465\n","   -0.01521158 -0.5864355   0.06100601 -0.01222922  0.08919504\n","   -0.71342516 -0.06278159  0.26878688 -0.23994547  0.4098286\n","   -0.12681961  0.59259933  0.30835566 -0.07265969 -0.01775062\n","   -0.5338532   0.34189317  0.03726852 -0.774217    0.5328124\n","    0.6882061   0.48286617 -0.6246964 ]]], shape=(1, 1, 128), dtype=float32)\n","tf.Tensor([  1   1 128], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[-0.3328428  -0.15310417  0.14570665 -0.683204    0.6507988\n","   -0.3975009  -0.5368943  -0.31570217  0.75885916 -0.24650265\n","   -0.35908133 -0.20864362 -0.35965776 -0.40815318  0.2924817\n","    0.31201056  0.31388444 -0.3155065   0.18900451  0.900018\n","    0.28028393  0.39212552 -0.11371727  0.53058314  0.41766632\n","   -0.34871414  0.11946747  0.16296402 -0.6443969  -0.22147942\n","   -0.07787123 -0.1272329  -0.2533568  -0.55764645 -0.17936303\n","    0.27364296  0.3900627  -0.8493354   0.36568838 -0.35909656\n","   -0.5144919   0.21604964 -0.14676908  0.06813978 -0.31412527\n","    0.4059783  -0.11809671  0.32471076  0.13595393 -0.32438794\n","    0.30319244 -0.03118158  0.2720952  -0.5260025   0.2243012\n","    0.12872218  0.39189708  0.10343492  0.38298222  0.2998557\n","   -0.07102969  0.25416455  0.374968   -0.47233924 -0.18252769\n","    0.38339946 -0.16574654  0.15562496  0.03872239 -0.2490853\n","    0.13082416  0.24847774  0.39421618 -0.5055371   0.1035298\n","   -0.4481752  -0.2762258  -0.22294292 -0.33578587  0.05666116\n","    0.00752513 -0.03672354  0.11759033 -0.1345833  -0.35576645\n","   -0.41964996 -0.31882286 -0.2717303  -0.09150261 -0.24857655\n","   -0.52745557 -0.17235124 -0.03798041  0.41153097 -0.03346229\n","    0.31389531  0.26104614  0.1939565   0.15797813  0.79151136\n","    0.3354468  -0.18625319 -0.30435964 -0.39947972 -0.42205465\n","   -0.01521158 -0.5864355   0.06100601 -0.01222922  0.08919504\n","   -0.71342516 -0.06278159  0.26878688 -0.23994547  0.4098286\n","   -0.12681961  0.59259933  0.30835566 -0.07265969 -0.01775062\n","   -0.5338532   0.34189317  0.03726852 -0.774217    0.5328124\n","    0.6882061   0.48286617 -0.6246964  -0.3328428  -0.15310417\n","    0.14570665 -0.683204    0.6507988  -0.3975009  -0.5368943\n","   -0.31570217  0.75885916 -0.24650265 -0.35908133 -0.20864362\n","   -0.35965776 -0.40815318  0.2924817   0.31201056  0.31388444\n","   -0.3155065   0.18900451  0.900018    0.28028393  0.39212552\n","   -0.11371727  0.53058314  0.41766632 -0.34871414  0.11946747\n","    0.16296402 -0.6443969  -0.22147942 -0.07787123 -0.1272329\n","   -0.2533568  -0.55764645 -0.17936303  0.27364296  0.3900627\n","   -0.8493354   0.36568838 -0.35909656 -0.5144919   0.21604964\n","   -0.14676908  0.06813978 -0.31412527  0.4059783  -0.11809671\n","    0.32471076  0.13595393 -0.32438794  0.30319244 -0.03118158\n","    0.2720952  -0.5260025   0.2243012   0.12872218  0.39189708\n","    0.10343492  0.38298222  0.2998557  -0.07102969  0.25416455\n","    0.374968   -0.47233924 -0.18252769  0.38339946 -0.16574654\n","    0.15562496  0.03872239 -0.2490853   0.13082416  0.24847774\n","    0.39421618 -0.5055371   0.1035298  -0.4481752  -0.2762258\n","   -0.22294292 -0.33578587  0.05666116  0.00752513 -0.03672354\n","    0.11759033 -0.1345833  -0.35576645 -0.41964996 -0.31882286\n","   -0.2717303  -0.09150261 -0.24857655 -0.52745557 -0.17235124\n","   -0.03798041  0.41153097 -0.03346229  0.31389531  0.26104614\n","    0.1939565   0.15797813  0.79151136  0.3354468  -0.18625319\n","   -0.30435964 -0.39947972 -0.42205465 -0.01521158 -0.5864355\n","    0.06100601 -0.01222922  0.08919504 -0.71342516 -0.06278159\n","    0.26878688 -0.23994547  0.4098286  -0.12681961  0.59259933\n","    0.30835566 -0.07265969 -0.01775062 -0.5338532   0.34189317\n","    0.03726852 -0.774217    0.5328124   0.6882061   0.48286617\n","   -0.6246964  -0.3328428  -0.15310417  0.14570665 -0.683204\n","    0.6507988  -0.3975009  -0.5368943  -0.31570217  0.75885916\n","   -0.24650265 -0.35908133 -0.20864362 -0.35965776 -0.40815318\n","    0.2924817   0.31201056  0.31388444 -0.3155065   0.18900451\n","    0.900018    0.28028393  0.39212552 -0.11371727  0.53058314\n","    0.41766632 -0.34871414  0.11946747  0.16296402 -0.6443969\n","   -0.22147942 -0.07787123 -0.1272329  -0.2533568  -0.55764645\n","   -0.17936303  0.27364296  0.3900627  -0.8493354   0.36568838\n","   -0.35909656 -0.5144919   0.21604964 -0.14676908  0.06813978\n","   -0.31412527  0.4059783  -0.11809671  0.32471076  0.13595393\n","   -0.32438794  0.30319244 -0.03118158  0.2720952  -0.5260025\n","    0.2243012   0.12872218  0.39189708  0.10343492  0.38298222\n","    0.2998557  -0.07102969  0.25416455  0.374968   -0.47233924\n","   -0.18252769  0.38339946 -0.16574654  0.15562496  0.03872239\n","   -0.2490853   0.13082416  0.24847774  0.39421618 -0.5055371\n","    0.1035298  -0.4481752  -0.2762258  -0.22294292 -0.33578587\n","    0.05666116  0.00752513 -0.03672354  0.11759033 -0.1345833\n","   -0.35576645 -0.41964996 -0.31882286 -0.2717303  -0.09150261\n","   -0.24857655 -0.52745557 -0.17235124 -0.03798041  0.41153097\n","   -0.03346229  0.31389531  0.26104614  0.1939565   0.15797813\n","    0.79151136  0.3354468  -0.18625319 -0.30435964 -0.39947972\n","   -0.42205465 -0.01521158 -0.5864355   0.06100601 -0.01222922\n","    0.08919504 -0.71342516 -0.06278159  0.26878688 -0.23994547\n","    0.4098286  -0.12681961  0.59259933  0.30835566 -0.07265969\n","   -0.01775062 -0.5338532   0.34189317  0.03726852 -0.774217\n","    0.5328124   0.6882061   0.48286617 -0.6246964  -0.3328428\n","   -0.15310417  0.14570665 -0.683204    0.6507988  -0.3975009\n","   -0.5368943  -0.31570217  0.75885916 -0.24650265 -0.35908133\n","   -0.20864362 -0.35965776 -0.40815318  0.2924817   0.31201056\n","    0.31388444 -0.3155065   0.18900451  0.900018    0.28028393\n","    0.39212552 -0.11371727  0.53058314  0.41766632 -0.34871414\n","    0.11946747  0.16296402 -0.6443969  -0.22147942 -0.07787123\n","   -0.1272329  -0.2533568  -0.55764645 -0.17936303  0.27364296\n","    0.3900627  -0.8493354   0.36568838 -0.35909656 -0.5144919\n","    0.21604964 -0.14676908  0.06813978 -0.31412527  0.4059783\n","   -0.11809671  0.32471076  0.13595393 -0.32438794  0.30319244\n","   -0.03118158  0.2720952  -0.5260025   0.2243012   0.12872218\n","    0.39189708  0.10343492  0.38298222  0.2998557  -0.07102969\n","    0.25416455  0.374968   -0.47233924 -0.18252769  0.38339946\n","   -0.16574654  0.15562496  0.03872239 -0.2490853   0.13082416\n","    0.24847774  0.39421618 -0.5055371   0.1035298  -0.4481752\n","   -0.2762258  -0.22294292 -0.33578587  0.05666116  0.00752513\n","   -0.03672354  0.11759033 -0.1345833  -0.35576645 -0.41964996\n","   -0.31882286 -0.2717303  -0.09150261 -0.24857655 -0.52745557\n","   -0.17235124 -0.03798041  0.41153097 -0.03346229  0.31389531\n","    0.26104614  0.1939565   0.15797813  0.79151136  0.3354468\n","   -0.18625319 -0.30435964 -0.39947972 -0.42205465 -0.01521158\n","   -0.5864355   0.06100601 -0.01222922  0.08919504 -0.71342516\n","   -0.06278159  0.26878688 -0.23994547  0.4098286  -0.12681961\n","    0.59259933  0.30835566 -0.07265969 -0.01775062 -0.5338532\n","    0.34189317  0.03726852 -0.774217    0.5328124   0.6882061\n","    0.48286617 -0.6246964 ]]], shape=(1, 1, 512), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 0.7655494   0.5368203   0.01562136 -0.6189248   1.1067393\n","   -0.8468804   0.19618803 -0.30287892  0.68529844 -0.6350416\n","   -0.6144525  -0.17149693  0.37852323  0.23202169 -0.5933486\n","   -0.93841875 -0.345945    0.10965055  1.2752161   1.7706786\n","    1.3073535   0.9196378   0.16010956 -0.04636621  0.86117345\n","   -0.04069123  0.13868874 -0.5072012  -1.261304    0.03947538\n","    0.42954227  0.5692905   0.18269682 -0.35463318 -0.78707576\n","    0.6184644   0.22420561 -1.409272   -0.12467331 -0.11718808\n","   -1.116688    0.18146828 -0.12910603 -0.12785566 -0.6248399\n","   -0.26304176 -0.29485962  1.6303009   0.5367827  -1.0788683\n","    1.1164942   0.02356221  0.9666818  -1.7404162  -0.6931993\n","    0.6975038   0.17256561 -0.40708756 -0.48045227  0.2888516\n","    0.13944319  0.70500517  0.24294323  0.29813424 -0.35855058\n","    0.33181694  0.10262766 -0.78746986 -0.3986044  -0.88788956\n","   -0.02820273  0.6733729   0.7569014  -0.47985804  0.05975346\n","   -0.42263782 -0.12788714 -0.7215479   0.4122218   0.7698667\n","   -1.4547797  -1.3167281   0.05586023 -0.34053794  0.09779346\n","   -1.010488   -0.5065229  -0.11985144 -0.625004   -0.48186278\n","   -0.06341821 -0.20289822 -0.07601151 -0.3341185  -0.8193078\n","    1.1823285   1.174764    0.31651825 -0.27120304  0.20274395\n","   -0.4141951   0.93746936 -1.1143627   0.23212937 -0.90998566\n","   -0.7534174   0.2173602   0.7287847  -0.38313138  0.7100191\n","   -0.7893665   0.29185373  0.44687384  0.32688653  0.6959485\n","   -0.5813851   1.2068112   0.81734705 -0.40402013 -0.11485766\n","    0.03005272  0.14887133 -0.63381577 -1.273383    0.34490076\n","    2.1952944   0.15642759  0.11675537]\n","  [ 0.7655494   0.5368203   0.01562136 -0.6189248   1.1067393\n","   -0.8468804   0.19618803 -0.30287892  0.68529844 -0.6350416\n","   -0.6144525  -0.17149693  0.37852323  0.23202169 -0.5933486\n","   -0.93841875 -0.345945    0.10965055  1.2752161   1.7706786\n","    1.3073535   0.9196378   0.16010956 -0.04636621  0.86117345\n","   -0.04069123  0.13868874 -0.5072012  -1.261304    0.03947538\n","    0.42954227  0.5692905   0.18269682 -0.35463318 -0.78707576\n","    0.6184644   0.22420561 -1.409272   -0.12467331 -0.11718808\n","   -1.116688    0.18146828 -0.12910603 -0.12785566 -0.6248399\n","   -0.26304176 -0.29485962  1.6303009   0.5367827  -1.0788683\n","    1.1164942   0.02356221  0.9666818  -1.7404162  -0.6931993\n","    0.6975038   0.17256561 -0.40708756 -0.48045227  0.2888516\n","    0.13944319  0.70500517  0.24294323  0.29813424 -0.35855058\n","    0.33181694  0.10262766 -0.78746986 -0.3986044  -0.88788956\n","   -0.02820273  0.6733729   0.7569014  -0.47985804  0.05975346\n","   -0.42263782 -0.12788714 -0.7215479   0.4122218   0.7698667\n","   -1.4547797  -1.3167281   0.05586023 -0.34053794  0.09779346\n","   -1.010488   -0.5065229  -0.11985144 -0.625004   -0.48186278\n","   -0.06341821 -0.20289822 -0.07601151 -0.3341185  -0.8193078\n","    1.1823285   1.174764    0.31651825 -0.27120304  0.20274395\n","   -0.4141951   0.93746936 -1.1143627   0.23212937 -0.90998566\n","   -0.7534174   0.2173602   0.7287847  -0.38313138  0.7100191\n","   -0.7893665   0.29185373  0.44687384  0.32688653  0.6959485\n","   -0.5813851   1.2068112   0.81734705 -0.40402013 -0.11485766\n","    0.03005272  0.14887133 -0.63381577 -1.273383    0.34490076\n","    2.1952944   0.15642759  0.11675537]\n","  [ 0.7655494   0.5368203   0.01562136 -0.6189248   1.1067393\n","   -0.8468804   0.19618803 -0.30287892  0.68529844 -0.6350416\n","   -0.6144525  -0.17149693  0.37852323  0.23202169 -0.5933486\n","   -0.93841875 -0.345945    0.10965055  1.2752161   1.7706786\n","    1.3073535   0.9196378   0.16010956 -0.04636621  0.86117345\n","   -0.04069123  0.13868874 -0.5072012  -1.261304    0.03947538\n","    0.42954227  0.5692905   0.18269682 -0.35463318 -0.78707576\n","    0.6184644   0.22420561 -1.409272   -0.12467331 -0.11718808\n","   -1.116688    0.18146828 -0.12910603 -0.12785566 -0.6248399\n","   -0.26304176 -0.29485962  1.6303009   0.5367827  -1.0788683\n","    1.1164942   0.02356221  0.9666818  -1.7404162  -0.6931993\n","    0.6975038   0.17256561 -0.40708756 -0.48045227  0.2888516\n","    0.13944319  0.70500517  0.24294323  0.29813424 -0.35855058\n","    0.33181694  0.10262766 -0.78746986 -0.3986044  -0.88788956\n","   -0.02820273  0.6733729   0.7569014  -0.47985804  0.05975346\n","   -0.42263782 -0.12788714 -0.7215479   0.4122218   0.7698667\n","   -1.4547797  -1.3167281   0.05586023 -0.34053794  0.09779346\n","   -1.010488   -0.5065229  -0.11985144 -0.625004   -0.48186278\n","   -0.06341821 -0.20289822 -0.07601151 -0.3341185  -0.8193078\n","    1.1823285   1.174764    0.31651825 -0.27120304  0.20274395\n","   -0.4141951   0.93746936 -1.1143627   0.23212937 -0.90998566\n","   -0.7534174   0.2173602   0.7287847  -0.38313138  0.7100191\n","   -0.7893665   0.29185373  0.44687384  0.32688653  0.6959485\n","   -0.5813851   1.2068112   0.81734705 -0.40402013 -0.11485766\n","    0.03005272  0.14887133 -0.63381577 -1.273383    0.34490076\n","    2.1952944   0.15642759  0.11675537]\n","  [ 0.7655494   0.5368203   0.01562136 -0.6189248   1.1067393\n","   -0.8468804   0.19618803 -0.30287892  0.68529844 -0.6350416\n","   -0.6144525  -0.17149693  0.37852323  0.23202169 -0.5933486\n","   -0.93841875 -0.345945    0.10965055  1.2752161   1.7706786\n","    1.3073535   0.9196378   0.16010956 -0.04636621  0.86117345\n","   -0.04069123  0.13868874 -0.5072012  -1.261304    0.03947538\n","    0.42954227  0.5692905   0.18269682 -0.35463318 -0.78707576\n","    0.6184644   0.22420561 -1.409272   -0.12467331 -0.11718808\n","   -1.116688    0.18146828 -0.12910603 -0.12785566 -0.6248399\n","   -0.26304176 -0.29485962  1.6303009   0.5367827  -1.0788683\n","    1.1164942   0.02356221  0.9666818  -1.7404162  -0.6931993\n","    0.6975038   0.17256561 -0.40708756 -0.48045227  0.2888516\n","    0.13944319  0.70500517  0.24294323  0.29813424 -0.35855058\n","    0.33181694  0.10262766 -0.78746986 -0.3986044  -0.88788956\n","   -0.02820273  0.6733729   0.7569014  -0.47985804  0.05975346\n","   -0.42263782 -0.12788714 -0.7215479   0.4122218   0.7698667\n","   -1.4547797  -1.3167281   0.05586023 -0.34053794  0.09779346\n","   -1.010488   -0.5065229  -0.11985144 -0.625004   -0.48186278\n","   -0.06341821 -0.20289822 -0.07601151 -0.3341185  -0.8193078\n","    1.1823285   1.174764    0.31651825 -0.27120304  0.20274395\n","   -0.4141951   0.93746936 -1.1143627   0.23212937 -0.90998566\n","   -0.7534174   0.2173602   0.7287847  -0.38313138  0.7100191\n","   -0.7893665   0.29185373  0.44687384  0.32688653  0.6959485\n","   -0.5813851   1.2068112   0.81734705 -0.40402013 -0.11485766\n","    0.03005272  0.14887133 -0.63381577 -1.273383    0.34490076\n","    2.1952944   0.15642759  0.11675537]]], shape=(1, 4, 128), dtype=float32)\n","2\n","Tree INDEX:  2 3\n","tf.Tensor(\n","[[[ 2.28942782e-02  8.11658621e-01 -2.02293321e-01 -6.50015548e-02\n","   -4.09573875e-02  1.44525945e+00  7.32290745e-01  4.15430635e-01\n","    3.42702150e-01  1.36913133e+00  3.49966675e-01  8.11023414e-02\n","   -1.95633039e-01  2.37282068e-02 -1.07171588e-01  6.29860759e-02\n","   -7.47576505e-02  7.94603825e-02  6.88551307e-01  5.25790393e-01\n","    2.39426211e-01  2.39776865e-01 -2.21711352e-01  9.65806067e-01\n","   -2.13748023e-01  7.73119032e-01 -1.40551493e-01  5.98084927e-01\n","    1.08062303e+00 -2.14430336e-02  2.06584930e-01  1.07948041e+00\n","    2.93459922e-01 -9.41193700e-02  2.53894538e-01 -6.69687316e-02\n","   -1.73734780e-02 -1.34159222e-01  1.57943115e-01  1.04045868e-02\n","    6.95881367e-01 -1.77044779e-01  2.17973575e-01 -3.26493122e-02\n","    3.14492404e-01 -9.45108533e-02 -1.10995293e-01 -3.01248617e-02\n","   -1.23965375e-01 -2.46719699e-02 -4.45848778e-02  1.87752485e-01\n","    3.94855022e-01  2.68808678e-02 -3.14351588e-01  2.39115447e-01\n","    2.61684656e-01 -1.36640027e-01 -2.18017727e-01  6.94648981e-01\n","    3.93475711e-01  1.16962768e-01  5.18046260e-01  6.16195083e-01\n","   -9.77392197e-02  3.43647361e-01  6.12050533e-01  1.81732625e-01\n","   -9.57336426e-02  1.52521566e-01 -9.21245962e-02 -1.46728024e-01\n","   -7.71019310e-02 -8.13068971e-02  1.10716021e+00  6.60060644e-01\n","    6.32442415e-01  4.42325175e-01  6.90733850e-01  4.17922437e-01\n","    4.35869008e-01 -4.53414880e-02 -5.94712608e-02 -1.54656410e-01\n","   -7.68871456e-02  1.62567183e-01 -8.90828520e-02 -7.01754838e-02\n","    1.39210016e-01 -4.62824143e-02 -4.48014308e-03 -2.70100921e-01\n","    4.49816704e-01 -7.22234836e-03  5.26273608e-01  8.74142647e-01\n","    5.91114283e-01  4.15253401e-01  2.28505448e-01  2.30203807e-01\n","   -1.40195161e-01 -5.84980249e-02 -1.64658546e-01  3.94996166e-01\n","    4.92778391e-01  3.35376292e-01 -3.75669412e-02  6.44388080e-01\n","   -8.79342780e-02 -3.11986152e-02  3.70510995e-01 -4.58444878e-02\n","   -1.14205718e-01 -1.12867658e-03  1.90737024e-01 -1.17362617e-02\n","   -1.85712174e-01 -2.15930697e-02 -1.68206319e-01  8.28641534e-01\n","   -8.65851566e-02 -3.79724614e-02  4.42182161e-02  3.72782290e-01\n","    1.05473399e-02 -1.55067727e-01  6.18490815e-01  1.42095506e-01\n","    1.11332870e+00 -1.50907442e-01  8.38864267e-01  7.01104045e-01\n","    5.34901977e-01  4.86774564e-01  1.18238151e+00 -2.76024908e-01\n","   -1.29703507e-01  6.16024584e-02 -5.25553115e-02 -1.05581976e-01\n","    1.13459337e+00 -3.00172895e-01  5.21799684e-01  7.42535532e-01\n","   -5.97678684e-02  2.33031094e-01  2.47335747e-01  4.00373936e-01\n","    5.90226650e-01 -7.90362954e-02  5.24723470e-01 -1.33971810e-01\n","   -5.15720248e-02  9.03843164e-01 -1.05355971e-01 -1.99640635e-02\n","   -2.40213081e-01 -2.98465136e-02 -4.25048470e-02 -1.98760852e-01\n","   -1.86588410e-02 -2.66712066e-02  1.59496635e-01  2.24839449e-01\n","    4.41323876e-01 -1.58145931e-02 -6.98454157e-02  5.84723294e-01\n","   -3.27454172e-02 -6.29230887e-02 -3.36130299e-02  1.02122736e+00\n","    1.25457481e-01  5.59677243e-01  5.63320041e-01  2.55181432e-01\n","   -7.51130134e-02 -6.97627589e-02  5.60989439e-01 -1.01082474e-02\n","    2.53157467e-01  2.71697342e-01  1.02861214e+00  4.23002213e-01\n","   -2.35017970e-01  1.50183082e-01 -3.38705047e-03  2.80911624e-01\n","    1.66761863e+00 -1.19608045e-01  1.67584932e+00 -9.76188853e-02\n","   -1.84235312e-02 -1.89612687e-01 -1.31796420e-01  8.03854585e-01\n","   -1.64293215e-01 -6.26583397e-02  7.97578394e-01 -3.02760284e-02\n","   -9.29732472e-02  6.90427065e-01 -2.25347117e-01  7.62630224e-01\n","    5.21476507e-01 -1.56915784e-01  3.21315110e-01 -3.34483802e-01\n","   -6.81881979e-02  1.47488028e-01  2.52360702e-01 -4.00276594e-02\n","    7.47102201e-01 -1.09232366e-02 -8.41264948e-02  5.96413016e-01\n","   -7.83182755e-02 -2.28109374e-03  8.20720255e-01  9.01554167e-01\n","   -3.79990041e-03 -4.08827960e-02 -1.47858351e-01 -8.12575743e-02\n","    2.87548780e-01  2.89515674e-01 -1.18175425e-01 -6.25776127e-02\n","   -1.44843593e-01  1.09704030e+00 -1.11598395e-01 -6.10949881e-02\n","    6.12304568e-01  4.62835491e-01  8.01702142e-01  6.87359750e-01\n","    1.45541817e-01 -2.64827162e-01 -7.32801333e-02 -3.31942998e-02\n","   -3.83237302e-02 -9.47599262e-02  7.54449815e-02 -1.07691906e-01\n","    1.04889303e-01  5.68672717e-01  2.20583454e-01  1.93142906e-01\n","   -1.80695400e-01  7.73630559e-01 -9.63392842e-04 -5.13473116e-02\n","    4.79710639e-01  9.24431905e-03  1.05174375e+00  6.91279531e-01]\n","  [-2.68379897e-02  7.31460333e-01 -1.65465087e-01 -2.94551384e-02\n","   -5.72053194e-02  1.28204191e+00  6.88227057e-01  3.69218230e-01\n","    4.41759437e-01  1.31732619e+00  3.57997507e-01  8.68891329e-02\n","   -1.82479188e-01 -5.80520323e-03 -6.40475526e-02  1.16343044e-01\n","   -1.24063209e-01  1.32345200e-01  9.52868104e-01  3.75287354e-01\n","    4.63076115e-01  2.06540301e-01 -2.07384810e-01  8.22458982e-01\n","   -2.04749808e-01  9.00167823e-01 -1.78818941e-01  6.55819237e-01\n","    8.79181743e-01 -2.75140256e-02  1.39986455e-01  1.09588301e+00\n","    3.04239720e-01 -4.01352756e-02  4.34702128e-01 -2.30749287e-02\n","   -2.87729297e-02 -1.65147454e-01  3.98709357e-01 -3.22800949e-02\n","    6.42676413e-01 -2.03796849e-01  2.46769905e-01 -8.11627507e-02\n","    1.54924363e-01 -7.53252506e-02 -8.40917379e-02  1.84551775e-02\n","   -1.14419498e-01 -3.03296000e-02 -4.25932370e-02  1.05632991e-01\n","    3.41932088e-01  1.77137509e-01 -3.27192456e-01  1.05119810e-01\n","    4.02576357e-01 -1.45644471e-01 -1.93825766e-01  6.18649840e-01\n","    3.20195556e-01 -1.90866366e-02  3.12700599e-01  4.54531938e-01\n","   -1.03200190e-01  2.07420766e-01  6.67173564e-01  2.99582720e-01\n","   -1.11471988e-01  1.91416502e-01 -8.69917646e-02 -1.25543043e-01\n","   -8.96320865e-02 -7.91405663e-02  1.13221133e+00  6.05045080e-01\n","    8.39147508e-01  6.09907985e-01  6.65114880e-01  3.39969665e-01\n","    3.76990378e-01 -7.83638433e-02 -5.88245057e-02 -1.36469200e-01\n","   -9.43393782e-02  1.76484570e-01 -5.54788820e-02 -8.36137608e-02\n","    2.06215352e-01 -6.25617281e-02 -1.76393669e-02 -2.63798892e-01\n","    3.56787056e-01 -7.84940943e-02  4.02241647e-01  9.03124332e-01\n","    5.75087786e-01  3.65819305e-01  2.82073021e-01 -4.79414174e-03\n","   -9.00340900e-02 -5.79503477e-02 -1.55534819e-01  5.01899183e-01\n","    5.41385889e-01  4.96600747e-01 -5.69434129e-02  7.94632256e-01\n","   -1.59214124e-01 -2.41368096e-02  3.45294267e-01 -5.78652397e-02\n","   -1.21709958e-01  1.11863092e-02 -2.59800348e-02 -6.97514275e-03\n","   -1.42472029e-01 -6.66564479e-02 -2.04688415e-01  5.54423451e-01\n","   -5.23124114e-02 -7.18359351e-02 -3.25586312e-02  2.49376431e-01\n","   -3.39085013e-02 -1.60980135e-01  8.96071672e-01  2.49801323e-01\n","    1.06392920e+00 -1.47290781e-01  8.86778176e-01  7.02924013e-01\n","    5.77010512e-01  3.48505437e-01  1.00116658e+00 -2.75702715e-01\n","   -9.31251869e-02 -2.76391748e-02 -8.78166109e-02 -5.09071946e-02\n","    1.01391995e+00 -3.31253380e-01  5.51780343e-01  7.86866188e-01\n","   -8.96045193e-02  1.31866947e-01  2.84507662e-01  3.24626744e-01\n","    6.09078348e-01 -1.03543080e-01  5.43316007e-01 -1.13508321e-01\n","   -2.18384601e-02  8.54800642e-01 -7.71998912e-02 -3.91724035e-02\n","   -2.62365520e-01 -1.13659529e-02 -8.44310671e-02 -2.12400675e-01\n","    1.08765498e-01 -3.38210203e-02  5.60255349e-03  2.34590888e-01\n","    4.64735508e-01  3.50713730e-04 -1.00934997e-01  1.04461479e+00\n","   -3.60351391e-02 -7.38494545e-02 -8.12792554e-02  9.03383136e-01\n","   -8.52884352e-03  6.76909864e-01  3.30556780e-01  3.41281474e-01\n","   -3.85433920e-02 -7.62728453e-02  6.15106225e-01 -7.34978318e-02\n","    1.61477119e-01  2.78452128e-01  1.27066076e+00  4.04789984e-01\n","   -1.86032772e-01 -7.08469609e-03 -1.91583652e-02  5.15014529e-01\n","    1.51687431e+00 -1.68574363e-01  1.82523060e+00 -9.74152535e-02\n","   -6.18673675e-02 -1.27265319e-01 -1.11819446e-01  9.97415364e-01\n","   -1.71503454e-01 -9.05092657e-02  7.51964450e-01 -3.34959291e-02\n","   -5.85058592e-02  7.22450793e-01 -2.40729332e-01  1.01745999e+00\n","    2.49596909e-01 -1.63708016e-01  1.53035566e-01 -3.47643763e-01\n","   -7.30272159e-02  7.61751086e-02  2.55009025e-01 -1.23418421e-02\n","    8.87766004e-01 -2.62484755e-02 -1.28872931e-01  5.96677482e-01\n","   -7.94967636e-02 -7.51830265e-02  6.27049983e-01  9.07339573e-01\n","    4.09439206e-03 -5.87051995e-02 -1.00548945e-01 -8.03349540e-02\n","    2.49468356e-01  1.66675836e-01 -1.49613306e-01 -3.02671678e-02\n","   -1.07128143e-01  1.10219431e+00 -6.99632317e-02 -6.33282065e-02\n","    5.20832002e-01  5.10455847e-01  8.12533855e-01  5.31472087e-01\n","    2.30343997e-01 -2.40258768e-01 -5.81634417e-02 -8.87034868e-04\n","   -5.90272211e-02 -1.09656334e-01  2.46855140e-01 -8.63873661e-02\n","    1.04762733e-01  5.22276461e-01  9.72298905e-02  9.42916274e-02\n","   -2.13206723e-01  4.23992634e-01 -9.25098371e-04 -3.87604237e-02\n","    4.81675297e-01  2.80590445e-01  1.13410079e+00  5.36441147e-01]]], shape=(1, 2, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","2 2\n","Root Node\n","tf.Tensor(\n","[[[ 4.20203567e-01 -3.27098608e-01 -2.15829134e-01 -3.31001222e-01\n","   -6.43608212e-01 -5.67673206e-01 -4.74592745e-02 -2.50268102e-01\n","    1.16709575e-01 -4.62428816e-02 -6.65210605e-01  4.76286292e-01\n","   -6.43381327e-02  6.40829980e-01 -7.62392759e-01 -3.67752612e-01\n","    7.16334701e-01 -2.50008285e-01 -5.04752636e-01  2.22211838e-01\n","   -1.49952364e+00  1.47900498e+00  4.13018912e-01  5.76667964e-01\n","   -3.17432523e-01  1.39610082e-01 -8.47148001e-01 -4.99636739e-01\n","   -3.66623938e-01 -6.54928207e-01  9.19534445e-01 -3.94640684e-01\n","   -1.58225790e-01 -8.45081955e-02 -1.47809431e-01  1.30687237e-01\n","   -2.94258416e-01 -7.01018453e-01  1.35150716e-01 -6.76820755e-01\n","   -2.42486268e-01 -2.82539189e-01 -1.04611492e+00 -3.03604603e-02\n","    4.04693544e-01  4.80335057e-02 -1.58957615e-01  1.19828773e+00\n","   -7.12802708e-02  2.09576219e-01  1.22110581e+00  6.22033715e-01\n","   -3.05026770e-04  4.23938364e-01  6.46930218e-01 -3.46038878e-01\n","   -2.67561316e-01 -1.15670478e+00 -2.98350602e-02  1.53508306e-01\n","   -3.16405296e-01 -4.40856814e-01  3.20648178e-02  6.06848359e-01\n","   -5.07841587e-01 -3.48462552e-01  3.12016547e-01 -3.02597582e-01\n","    2.56527245e-01 -2.78818339e-01 -2.16476917e-01 -2.48826250e-01\n","    1.92156807e-01 -7.02079535e-01  5.44926941e-01  9.37170208e-01\n","   -2.34295771e-01  5.17018676e-01 -4.37326729e-01 -1.23115137e-01\n","    1.36322841e-01  5.69352329e-01  7.43151665e-01  5.59526801e-01\n","    4.04265076e-01  1.01417318e-01 -3.52668688e-02  1.90265998e-01\n","    1.64817661e-01  4.32210982e-01  4.25347149e-01 -8.07062089e-01\n","   -3.93016219e-01  3.79925907e-01 -2.05918193e-01 -1.78128809e-01\n","    3.95290583e-01 -3.65399897e-01 -2.81491846e-01  8.84173155e-01\n","   -4.09532934e-01 -5.14089942e-01 -1.91070393e-01 -2.54689604e-01\n","   -6.63358212e-01 -3.49213630e-02 -4.20944571e-01 -3.53494525e-01\n","    6.42274737e-01 -4.36029017e-01  6.35084093e-01  4.13873613e-01\n","   -4.14722532e-01 -3.58174384e-01  4.12274003e-01 -3.59850556e-01\n","    2.00939462e-01  1.41345218e-01 -7.58391619e-01  1.79558322e-01\n","   -1.45940828e+00  8.18842173e-01  6.69941157e-02 -7.06772208e-01\n","   -9.61707354e-01  8.05945933e-01 -5.57668447e-01 -9.00247097e-01]\n","  [ 4.62631166e-01 -4.72318023e-01 -1.23733625e-01 -1.84704661e-01\n","   -7.23692656e-01 -5.42105615e-01 -2.75523216e-02 -2.69143075e-01\n","   -1.96209103e-02 -3.73720601e-02 -5.81674695e-01  4.44820166e-01\n","   -8.13321471e-02  8.43429029e-01 -8.60530972e-01 -3.42480123e-01\n","    7.37435937e-01 -2.28276283e-01 -3.71664256e-01  4.11042929e-01\n","   -1.57238495e+00  1.53230035e+00  4.15851742e-01  7.12523758e-01\n","   -3.67886961e-01  1.30452633e-01 -6.69290364e-01 -6.18635297e-01\n","   -2.85587817e-01 -5.58383405e-01  7.82686949e-01 -3.19514573e-01\n","   -1.93377957e-01 -1.17509775e-01 -7.26764798e-02  8.27363729e-02\n","   -2.56560326e-01 -7.51101494e-01  1.74543381e-01 -5.58477879e-01\n","   -3.09387892e-01 -2.32073441e-01 -1.06974697e+00 -1.38625920e-01\n","    2.94653416e-01  4.09604162e-02 -3.85437906e-03  1.42711556e+00\n","   -7.75038302e-02  8.82779807e-02  1.01995301e+00  6.21514440e-01\n","   -1.03871763e-01  4.67396706e-01  8.06997836e-01 -4.72540021e-01\n","   -3.56997222e-01 -1.27785730e+00  1.00157276e-01  9.76974219e-02\n","   -2.72365153e-01 -5.59640169e-01 -1.64234340e-02  2.20463753e-01\n","   -7.19775319e-01 -2.62914270e-01  4.60611910e-01 -4.52650815e-01\n","    1.91183910e-01 -2.62425005e-01 -2.65450209e-01 -4.70780969e-01\n","    8.44557583e-02 -5.70664465e-01  4.56294596e-01  9.58427429e-01\n","   -2.59704888e-01  4.81361747e-01 -5.18736303e-01 -1.28860950e-01\n","    1.06423467e-01  3.81866872e-01  4.89113986e-01  4.37906504e-01\n","    5.10136425e-01  1.57227695e-01  1.81934647e-02 -6.09806180e-03\n","    1.21102788e-01  4.27911758e-01  3.45917970e-01 -8.07269990e-01\n","   -1.32599771e-01  3.03276628e-01 -2.99779594e-01 -1.49932534e-01\n","    3.40141952e-01 -5.85112929e-01 -3.52064610e-01  9.03443575e-01\n","   -4.89977717e-01 -4.57964361e-01 -1.08834475e-01 -4.86583412e-02\n","   -7.81626165e-01 -2.79167622e-01 -4.68513608e-01 -3.76642048e-01\n","    4.09426332e-01 -2.98973948e-01  9.18153584e-01  3.93631607e-01\n","   -7.00479627e-01 -2.54750401e-01  4.28961605e-01 -3.91157031e-01\n","   -1.46265589e-02  1.85021654e-01 -5.98320186e-01  6.65204227e-02\n","   -1.35446131e+00  7.20852971e-01  6.14893883e-02 -9.03621197e-01\n","   -1.11213601e+00  8.13755155e-01 -5.69692135e-01 -9.10734594e-01]]], shape=(1, 2, 128), dtype=float32)\n","tf.Tensor([  1   2 128], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[ 4.20203567e-01 -3.27098608e-01 -2.15829134e-01 -3.31001222e-01\n","   -6.43608212e-01 -5.67673206e-01 -4.74592745e-02 -2.50268102e-01\n","    1.16709575e-01 -4.62428816e-02 -6.65210605e-01  4.76286292e-01\n","   -6.43381327e-02  6.40829980e-01 -7.62392759e-01 -3.67752612e-01\n","    7.16334701e-01 -2.50008285e-01 -5.04752636e-01  2.22211838e-01\n","   -1.49952364e+00  1.47900498e+00  4.13018912e-01  5.76667964e-01\n","   -3.17432523e-01  1.39610082e-01 -8.47148001e-01 -4.99636739e-01\n","   -3.66623938e-01 -6.54928207e-01  9.19534445e-01 -3.94640684e-01\n","   -1.58225790e-01 -8.45081955e-02 -1.47809431e-01  1.30687237e-01\n","   -2.94258416e-01 -7.01018453e-01  1.35150716e-01 -6.76820755e-01\n","   -2.42486268e-01 -2.82539189e-01 -1.04611492e+00 -3.03604603e-02\n","    4.04693544e-01  4.80335057e-02 -1.58957615e-01  1.19828773e+00\n","   -7.12802708e-02  2.09576219e-01  1.22110581e+00  6.22033715e-01\n","   -3.05026770e-04  4.23938364e-01  6.46930218e-01 -3.46038878e-01\n","   -2.67561316e-01 -1.15670478e+00 -2.98350602e-02  1.53508306e-01\n","   -3.16405296e-01 -4.40856814e-01  3.20648178e-02  6.06848359e-01\n","   -5.07841587e-01 -3.48462552e-01  3.12016547e-01 -3.02597582e-01\n","    2.56527245e-01 -2.78818339e-01 -2.16476917e-01 -2.48826250e-01\n","    1.92156807e-01 -7.02079535e-01  5.44926941e-01  9.37170208e-01\n","   -2.34295771e-01  5.17018676e-01 -4.37326729e-01 -1.23115137e-01\n","    1.36322841e-01  5.69352329e-01  7.43151665e-01  5.59526801e-01\n","    4.04265076e-01  1.01417318e-01 -3.52668688e-02  1.90265998e-01\n","    1.64817661e-01  4.32210982e-01  4.25347149e-01 -8.07062089e-01\n","   -3.93016219e-01  3.79925907e-01 -2.05918193e-01 -1.78128809e-01\n","    3.95290583e-01 -3.65399897e-01 -2.81491846e-01  8.84173155e-01\n","   -4.09532934e-01 -5.14089942e-01 -1.91070393e-01 -2.54689604e-01\n","   -6.63358212e-01 -3.49213630e-02 -4.20944571e-01 -3.53494525e-01\n","    6.42274737e-01 -4.36029017e-01  6.35084093e-01  4.13873613e-01\n","   -4.14722532e-01 -3.58174384e-01  4.12274003e-01 -3.59850556e-01\n","    2.00939462e-01  1.41345218e-01 -7.58391619e-01  1.79558322e-01\n","   -1.45940828e+00  8.18842173e-01  6.69941157e-02 -7.06772208e-01\n","   -9.61707354e-01  8.05945933e-01 -5.57668447e-01 -9.00247097e-01\n","    4.20203567e-01 -3.27098608e-01 -2.15829134e-01 -3.31001222e-01\n","   -6.43608212e-01 -5.67673206e-01 -4.74592745e-02 -2.50268102e-01\n","    1.16709575e-01 -4.62428816e-02 -6.65210605e-01  4.76286292e-01\n","   -6.43381327e-02  6.40829980e-01 -7.62392759e-01 -3.67752612e-01\n","    7.16334701e-01 -2.50008285e-01 -5.04752636e-01  2.22211838e-01\n","   -1.49952364e+00  1.47900498e+00  4.13018912e-01  5.76667964e-01\n","   -3.17432523e-01  1.39610082e-01 -8.47148001e-01 -4.99636739e-01\n","   -3.66623938e-01 -6.54928207e-01  9.19534445e-01 -3.94640684e-01\n","   -1.58225790e-01 -8.45081955e-02 -1.47809431e-01  1.30687237e-01\n","   -2.94258416e-01 -7.01018453e-01  1.35150716e-01 -6.76820755e-01\n","   -2.42486268e-01 -2.82539189e-01 -1.04611492e+00 -3.03604603e-02\n","    4.04693544e-01  4.80335057e-02 -1.58957615e-01  1.19828773e+00\n","   -7.12802708e-02  2.09576219e-01  1.22110581e+00  6.22033715e-01\n","   -3.05026770e-04  4.23938364e-01  6.46930218e-01 -3.46038878e-01\n","   -2.67561316e-01 -1.15670478e+00 -2.98350602e-02  1.53508306e-01\n","   -3.16405296e-01 -4.40856814e-01  3.20648178e-02  6.06848359e-01\n","   -5.07841587e-01 -3.48462552e-01  3.12016547e-01 -3.02597582e-01\n","    2.56527245e-01 -2.78818339e-01 -2.16476917e-01 -2.48826250e-01\n","    1.92156807e-01 -7.02079535e-01  5.44926941e-01  9.37170208e-01\n","   -2.34295771e-01  5.17018676e-01 -4.37326729e-01 -1.23115137e-01\n","    1.36322841e-01  5.69352329e-01  7.43151665e-01  5.59526801e-01\n","    4.04265076e-01  1.01417318e-01 -3.52668688e-02  1.90265998e-01\n","    1.64817661e-01  4.32210982e-01  4.25347149e-01 -8.07062089e-01\n","   -3.93016219e-01  3.79925907e-01 -2.05918193e-01 -1.78128809e-01\n","    3.95290583e-01 -3.65399897e-01 -2.81491846e-01  8.84173155e-01\n","   -4.09532934e-01 -5.14089942e-01 -1.91070393e-01 -2.54689604e-01\n","   -6.63358212e-01 -3.49213630e-02 -4.20944571e-01 -3.53494525e-01\n","    6.42274737e-01 -4.36029017e-01  6.35084093e-01  4.13873613e-01\n","   -4.14722532e-01 -3.58174384e-01  4.12274003e-01 -3.59850556e-01\n","    2.00939462e-01  1.41345218e-01 -7.58391619e-01  1.79558322e-01\n","   -1.45940828e+00  8.18842173e-01  6.69941157e-02 -7.06772208e-01\n","   -9.61707354e-01  8.05945933e-01 -5.57668447e-01 -9.00247097e-01]\n","  [ 4.62631166e-01 -4.72318023e-01 -1.23733625e-01 -1.84704661e-01\n","   -7.23692656e-01 -5.42105615e-01 -2.75523216e-02 -2.69143075e-01\n","   -1.96209103e-02 -3.73720601e-02 -5.81674695e-01  4.44820166e-01\n","   -8.13321471e-02  8.43429029e-01 -8.60530972e-01 -3.42480123e-01\n","    7.37435937e-01 -2.28276283e-01 -3.71664256e-01  4.11042929e-01\n","   -1.57238495e+00  1.53230035e+00  4.15851742e-01  7.12523758e-01\n","   -3.67886961e-01  1.30452633e-01 -6.69290364e-01 -6.18635297e-01\n","   -2.85587817e-01 -5.58383405e-01  7.82686949e-01 -3.19514573e-01\n","   -1.93377957e-01 -1.17509775e-01 -7.26764798e-02  8.27363729e-02\n","   -2.56560326e-01 -7.51101494e-01  1.74543381e-01 -5.58477879e-01\n","   -3.09387892e-01 -2.32073441e-01 -1.06974697e+00 -1.38625920e-01\n","    2.94653416e-01  4.09604162e-02 -3.85437906e-03  1.42711556e+00\n","   -7.75038302e-02  8.82779807e-02  1.01995301e+00  6.21514440e-01\n","   -1.03871763e-01  4.67396706e-01  8.06997836e-01 -4.72540021e-01\n","   -3.56997222e-01 -1.27785730e+00  1.00157276e-01  9.76974219e-02\n","   -2.72365153e-01 -5.59640169e-01 -1.64234340e-02  2.20463753e-01\n","   -7.19775319e-01 -2.62914270e-01  4.60611910e-01 -4.52650815e-01\n","    1.91183910e-01 -2.62425005e-01 -2.65450209e-01 -4.70780969e-01\n","    8.44557583e-02 -5.70664465e-01  4.56294596e-01  9.58427429e-01\n","   -2.59704888e-01  4.81361747e-01 -5.18736303e-01 -1.28860950e-01\n","    1.06423467e-01  3.81866872e-01  4.89113986e-01  4.37906504e-01\n","    5.10136425e-01  1.57227695e-01  1.81934647e-02 -6.09806180e-03\n","    1.21102788e-01  4.27911758e-01  3.45917970e-01 -8.07269990e-01\n","   -1.32599771e-01  3.03276628e-01 -2.99779594e-01 -1.49932534e-01\n","    3.40141952e-01 -5.85112929e-01 -3.52064610e-01  9.03443575e-01\n","   -4.89977717e-01 -4.57964361e-01 -1.08834475e-01 -4.86583412e-02\n","   -7.81626165e-01 -2.79167622e-01 -4.68513608e-01 -3.76642048e-01\n","    4.09426332e-01 -2.98973948e-01  9.18153584e-01  3.93631607e-01\n","   -7.00479627e-01 -2.54750401e-01  4.28961605e-01 -3.91157031e-01\n","   -1.46265589e-02  1.85021654e-01 -5.98320186e-01  6.65204227e-02\n","   -1.35446131e+00  7.20852971e-01  6.14893883e-02 -9.03621197e-01\n","   -1.11213601e+00  8.13755155e-01 -5.69692135e-01 -9.10734594e-01\n","    4.62631166e-01 -4.72318023e-01 -1.23733625e-01 -1.84704661e-01\n","   -7.23692656e-01 -5.42105615e-01 -2.75523216e-02 -2.69143075e-01\n","   -1.96209103e-02 -3.73720601e-02 -5.81674695e-01  4.44820166e-01\n","   -8.13321471e-02  8.43429029e-01 -8.60530972e-01 -3.42480123e-01\n","    7.37435937e-01 -2.28276283e-01 -3.71664256e-01  4.11042929e-01\n","   -1.57238495e+00  1.53230035e+00  4.15851742e-01  7.12523758e-01\n","   -3.67886961e-01  1.30452633e-01 -6.69290364e-01 -6.18635297e-01\n","   -2.85587817e-01 -5.58383405e-01  7.82686949e-01 -3.19514573e-01\n","   -1.93377957e-01 -1.17509775e-01 -7.26764798e-02  8.27363729e-02\n","   -2.56560326e-01 -7.51101494e-01  1.74543381e-01 -5.58477879e-01\n","   -3.09387892e-01 -2.32073441e-01 -1.06974697e+00 -1.38625920e-01\n","    2.94653416e-01  4.09604162e-02 -3.85437906e-03  1.42711556e+00\n","   -7.75038302e-02  8.82779807e-02  1.01995301e+00  6.21514440e-01\n","   -1.03871763e-01  4.67396706e-01  8.06997836e-01 -4.72540021e-01\n","   -3.56997222e-01 -1.27785730e+00  1.00157276e-01  9.76974219e-02\n","   -2.72365153e-01 -5.59640169e-01 -1.64234340e-02  2.20463753e-01\n","   -7.19775319e-01 -2.62914270e-01  4.60611910e-01 -4.52650815e-01\n","    1.91183910e-01 -2.62425005e-01 -2.65450209e-01 -4.70780969e-01\n","    8.44557583e-02 -5.70664465e-01  4.56294596e-01  9.58427429e-01\n","   -2.59704888e-01  4.81361747e-01 -5.18736303e-01 -1.28860950e-01\n","    1.06423467e-01  3.81866872e-01  4.89113986e-01  4.37906504e-01\n","    5.10136425e-01  1.57227695e-01  1.81934647e-02 -6.09806180e-03\n","    1.21102788e-01  4.27911758e-01  3.45917970e-01 -8.07269990e-01\n","   -1.32599771e-01  3.03276628e-01 -2.99779594e-01 -1.49932534e-01\n","    3.40141952e-01 -5.85112929e-01 -3.52064610e-01  9.03443575e-01\n","   -4.89977717e-01 -4.57964361e-01 -1.08834475e-01 -4.86583412e-02\n","   -7.81626165e-01 -2.79167622e-01 -4.68513608e-01 -3.76642048e-01\n","    4.09426332e-01 -2.98973948e-01  9.18153584e-01  3.93631607e-01\n","   -7.00479627e-01 -2.54750401e-01  4.28961605e-01 -3.91157031e-01\n","   -1.46265589e-02  1.85021654e-01 -5.98320186e-01  6.65204227e-02\n","   -1.35446131e+00  7.20852971e-01  6.14893883e-02 -9.03621197e-01\n","   -1.11213601e+00  8.13755155e-01 -5.69692135e-01 -9.10734594e-01]]], shape=(1, 2, 256), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 1.185753    0.20972168 -0.20020777 -0.949926    0.46313107\n","   -1.4145536   0.14872876 -0.553147    0.80200803 -0.6812845\n","   -1.2796631   0.30478936  0.31418508  0.87285167 -1.3557414\n","   -1.3061714   0.3703897  -0.14035773  0.77046347  1.9928905\n","   -0.19217014  2.3986428   0.57312846  0.53030175  0.5437409\n","    0.09891886 -0.70845926 -1.006838   -1.627928   -0.6154528\n","    1.3490767   0.17464983  0.02447103 -0.4391414  -0.9348852\n","    0.74915165 -0.0700528  -2.1102905   0.01047741 -0.79400885\n","   -1.3591743  -0.10107091 -1.175221   -0.15821612 -0.22014636\n","   -0.21500826 -0.45381725  2.8285885   0.4655024  -0.869292\n","    2.3376      0.6455959   0.9663768  -1.3164778  -0.04626906\n","    0.35146493 -0.09499571 -1.5637923  -0.51028734  0.4423599\n","   -0.1769621   0.26414835  0.27500805  0.90498257 -0.86639214\n","   -0.01664561  0.4146442  -1.0900674  -0.14207715 -1.1667079\n","   -0.24467964  0.42454666  0.9490582  -1.1819376   0.6046804\n","    0.5145324  -0.36218292 -0.20452923 -0.02510494  0.6467516\n","   -1.3184569  -0.7473758   0.7990119   0.21898887  0.5020585\n","   -0.90907073 -0.54178977  0.07041456 -0.46018633 -0.0496518\n","    0.36192894 -1.0099603  -0.46902773  0.04580742 -1.025226\n","    1.0041996   1.5700547  -0.04888165 -0.5526949   1.0869172\n","   -0.823728    0.42337942 -1.3054332  -0.02256024 -1.5733439\n","   -0.7883387  -0.20358437  0.37529016  0.25914335  0.2739901\n","   -0.15428239  0.70572734  0.03215131 -0.03128785  1.1082225\n","   -0.94123566  1.4077506   0.95869225 -1.1624117   0.06470066\n","   -1.4293556   0.9677135  -0.56682163 -1.9801552  -0.6168066\n","    3.0012403  -0.40124086 -0.78349173]\n","  [ 1.185753    0.20972168 -0.20020777 -0.949926    0.46313107\n","   -1.4145536   0.14872876 -0.553147    0.80200803 -0.6812845\n","   -1.2796631   0.30478936  0.31418508  0.87285167 -1.3557414\n","   -1.3061714   0.3703897  -0.14035773  0.77046347  1.9928905\n","   -0.19217014  2.3986428   0.57312846  0.53030175  0.5437409\n","    0.09891886 -0.70845926 -1.006838   -1.627928   -0.6154528\n","    1.3490767   0.17464983  0.02447103 -0.4391414  -0.9348852\n","    0.74915165 -0.0700528  -2.1102905   0.01047741 -0.79400885\n","   -1.3591743  -0.10107091 -1.175221   -0.15821612 -0.22014636\n","   -0.21500826 -0.45381725  2.8285885   0.4655024  -0.869292\n","    2.3376      0.6455959   0.9663768  -1.3164778  -0.04626906\n","    0.35146493 -0.09499571 -1.5637923  -0.51028734  0.4423599\n","   -0.1769621   0.26414835  0.27500805  0.90498257 -0.86639214\n","   -0.01664561  0.4146442  -1.0900674  -0.14207715 -1.1667079\n","   -0.24467964  0.42454666  0.9490582  -1.1819376   0.6046804\n","    0.5145324  -0.36218292 -0.20452923 -0.02510494  0.6467516\n","   -1.3184569  -0.7473758   0.7990119   0.21898887  0.5020585\n","   -0.90907073 -0.54178977  0.07041456 -0.46018633 -0.0496518\n","    0.36192894 -1.0099603  -0.46902773  0.04580742 -1.025226\n","    1.0041996   1.5700547  -0.04888165 -0.5526949   1.0869172\n","   -0.823728    0.42337942 -1.3054332  -0.02256024 -1.5733439\n","   -0.7883387  -0.20358437  0.37529016  0.25914335  0.2739901\n","   -0.15428239  0.70572734  0.03215131 -0.03128785  1.1082225\n","   -0.94123566  1.4077506   0.95869225 -1.1624117   0.06470066\n","   -1.4293556   0.9677135  -0.56682163 -1.9801552  -0.6168066\n","    3.0012403  -0.40124086 -0.78349173]\n","  [ 1.2281806   0.06450227 -0.10811226 -0.80362946  0.38304663\n","   -1.388986    0.16863571 -0.57202196  0.66567755 -0.67241365\n","   -1.1961272   0.27332324  0.29719108  1.0754507  -1.4538796\n","   -1.2808988   0.39149094 -0.11862573  0.9035518   2.1817217\n","   -0.26503146  2.4519382   0.5759613   0.66615754  0.4932865\n","    0.08976141 -0.5306016  -1.1258365  -1.5468918  -0.518908\n","    1.2122293   0.24977595 -0.01068114 -0.47214296 -0.85975224\n","    0.7012008  -0.03235471 -2.1603734   0.04987007 -0.675666\n","   -1.4260759  -0.05060516 -1.198853   -0.26648158 -0.3301865\n","   -0.22208135 -0.29871398  3.0574164   0.45927885 -0.9905903\n","    2.1364472   0.64507663  0.86281    -1.2730194   0.11379856\n","    0.22496378 -0.18443161 -1.6849449  -0.38029498  0.386549\n","   -0.13292196  0.145365    0.2265198   0.51859796 -1.0783259\n","    0.06890267  0.5632396  -1.2401206  -0.20742048 -1.1503146\n","   -0.29365295  0.20259196  0.8413571  -1.0505226   0.5160481\n","    0.5357896  -0.38759202 -0.24018615 -0.10651451  0.64100575\n","   -1.3483562  -0.93486124  0.5449742   0.09736857  0.6079299\n","   -0.85326034 -0.48832944 -0.1259495  -0.5039012  -0.05395103\n","    0.28249976 -1.0101682  -0.20861128 -0.03084186 -1.1190875\n","    1.032396    1.5149059  -0.26859468 -0.62326765  1.1061876\n","   -0.9041728   0.479505   -1.2231972   0.18347102 -1.6916118\n","   -1.032585   -0.2511534   0.35214263  0.02629495  0.41104516\n","    0.1287871   0.68548536 -0.25360578  0.07213613  1.1249101\n","   -0.9725421   1.1921847   1.0023687  -1.0023403  -0.04833724\n","   -1.3244085   0.8697243  -0.57232636 -2.1770043  -0.7672353\n","    3.0090494  -0.41326454 -0.7939792 ]\n","  [ 1.2281806   0.06450227 -0.10811226 -0.80362946  0.38304663\n","   -1.388986    0.16863571 -0.57202196  0.66567755 -0.67241365\n","   -1.1961272   0.27332324  0.29719108  1.0754507  -1.4538796\n","   -1.2808988   0.39149094 -0.11862573  0.9035518   2.1817217\n","   -0.26503146  2.4519382   0.5759613   0.66615754  0.4932865\n","    0.08976141 -0.5306016  -1.1258365  -1.5468918  -0.518908\n","    1.2122293   0.24977595 -0.01068114 -0.47214296 -0.85975224\n","    0.7012008  -0.03235471 -2.1603734   0.04987007 -0.675666\n","   -1.4260759  -0.05060516 -1.198853   -0.26648158 -0.3301865\n","   -0.22208135 -0.29871398  3.0574164   0.45927885 -0.9905903\n","    2.1364472   0.64507663  0.86281    -1.2730194   0.11379856\n","    0.22496378 -0.18443161 -1.6849449  -0.38029498  0.386549\n","   -0.13292196  0.145365    0.2265198   0.51859796 -1.0783259\n","    0.06890267  0.5632396  -1.2401206  -0.20742048 -1.1503146\n","   -0.29365295  0.20259196  0.8413571  -1.0505226   0.5160481\n","    0.5357896  -0.38759202 -0.24018615 -0.10651451  0.64100575\n","   -1.3483562  -0.93486124  0.5449742   0.09736857  0.6079299\n","   -0.85326034 -0.48832944 -0.1259495  -0.5039012  -0.05395103\n","    0.28249976 -1.0101682  -0.20861128 -0.03084186 -1.1190875\n","    1.032396    1.5149059  -0.26859468 -0.62326765  1.1061876\n","   -0.9041728   0.479505   -1.2231972   0.18347102 -1.6916118\n","   -1.032585   -0.2511534   0.35214263  0.02629495  0.41104516\n","    0.1287871   0.68548536 -0.25360578  0.07213613  1.1249101\n","   -0.9725421   1.1921847   1.0023687  -1.0023403  -0.04833724\n","   -1.3244085   0.8697243  -0.57232636 -2.1770043  -0.7672353\n","    3.0090494  -0.41326454 -0.7939792 ]]], shape=(1, 4, 128), dtype=float32)\n","3\n","Tree INDEX:  3 3\n","tf.Tensor(\n","[[[ 0.33615896  0.8991513  -0.13135123 ... -0.0512444   0.5014652\n","    0.93582827]\n","  [ 0.02782361  0.9903315  -0.15102752 ... -0.05758461  0.4356063\n","    1.044573  ]\n","  [ 0.13584131  1.0660222  -0.144605   ... -0.06600229  0.39272326\n","    1.1633738 ]\n","  [ 0.41294098  0.94910234 -0.14704192 ...  0.10912634  0.40127838\n","    0.9502948 ]]], shape=(1, 4, 256), dtype=float32)\n","PRINTING ROOT_NUM, REPEAT_NUM\n","4 1\n","Root Node\n","tf.Tensor(\n","[[[ 1.17816031e-02 -7.79897392e-01  5.96917979e-02  3.93613905e-01\n","   -1.83555260e-01 -3.04668427e-01 -3.56282115e-01 -6.01522624e-01\n","    8.60495567e-02  5.95250279e-02 -3.46176624e-02 -6.32611871e-01\n","    1.17644720e-01  7.10190833e-01  5.39888322e-01 -7.63161957e-01\n","    2.88406342e-01 -8.92855167e-01  8.08749378e-01  6.74844146e-01\n","    6.24214113e-01 -1.36715400e+00  1.01653266e+00  6.89466447e-02\n","   -7.26643205e-02 -3.64010036e-02 -3.02888095e-01  5.56215525e-01\n","   -9.28365052e-01 -1.89401776e-01  9.36919093e-01 -4.85432863e-01\n","   -2.14981735e-01  2.41634846e-02  2.02152103e-01 -6.12584174e-01\n","   -6.69778109e-01 -8.66268158e-01 -1.28439263e-01 -4.38241661e-02\n","    5.38326323e-01  3.63360435e-01  6.98803008e-01  1.85332358e-01\n","   -4.02028501e-01  1.57244354e-01  4.33138072e-01  8.45125079e-01\n","    7.51577854e-01  3.90111208e-01  5.55614591e-01  3.30964565e-01\n","    1.34215736e+00  4.27132457e-01 -7.58566856e-01 -2.49722660e-01\n","   -1.39991850e-01 -3.13035101e-02  1.12462491e-01  4.13716406e-01\n","    6.05398893e-01 -8.31397474e-02 -2.48553008e-02  5.11024654e-01\n","    1.29661715e+00  1.11728489e+00 -4.33036864e-01  8.88753414e-01\n","   -4.97295856e-02 -1.43992603e-01 -6.86927319e-01 -4.07865584e-01\n","    9.37564969e-01  2.14593828e-01  1.53276592e-01 -1.35102585e-01\n","   -1.37393486e+00  2.68534124e-01 -1.95035487e-01  5.96224964e-01\n","    3.49517643e-01 -1.07112899e-01 -3.48432064e-01 -1.07012659e-01\n","    8.47013220e-02 -6.33694530e-01  6.39146149e-01 -3.04830134e-01\n","   -4.31665987e-01 -2.46459335e-01 -1.21170275e-01 -4.73311424e-01\n","    2.50235081e-01 -4.64875996e-01 -1.29754019e+00  1.07757592e+00\n","    9.89012867e-02 -6.85574174e-01 -9.07645971e-02 -3.87175381e-02\n","    7.16257095e-01 -8.88337433e-01 -9.66061711e-01 -7.11837888e-01\n","    1.01575613e-01 -2.78444827e-01  7.17753410e-01  2.38248050e-01\n","   -1.94900602e-01 -1.03095770e-01  6.39721036e-01 -3.45759541e-02\n","    2.13965312e-01 -2.79286623e-01 -1.05687869e+00 -1.96306482e-01\n","   -4.62162018e-01 -1.11845899e+00  4.66042191e-01  8.70777071e-02\n","   -4.92378592e-01  9.40339565e-02 -4.29061025e-01 -5.77020347e-02\n","   -5.66805601e-02  5.56844473e-01  6.37717962e-01  9.53799069e-01]\n","  [ 1.50980413e-01 -7.82433331e-01  1.47333533e-01  4.57121432e-01\n","   -1.46336153e-01 -2.39377558e-01 -3.34803462e-01 -7.63889670e-01\n","   -2.21599638e-03  6.60550594e-03  1.94404304e-01 -6.59838080e-01\n","    1.42362952e-01  6.59814298e-01  2.08955079e-01 -8.02223325e-01\n","    4.65390235e-01 -7.49683976e-01  7.65330255e-01  8.58141541e-01\n","    6.02647245e-01 -1.20686054e+00  1.07284999e+00  8.63736570e-02\n","   -5.48685491e-02 -2.53076777e-02 -2.04088181e-01  6.43821955e-01\n","   -1.04306400e+00 -2.70931482e-01  8.50932717e-01 -7.88352251e-01\n","   -3.01504731e-01  9.62540209e-02  2.00189412e-01 -5.25082946e-01\n","   -7.60564983e-01 -7.01166868e-01  9.56398845e-02 -3.69734377e-01\n","    5.82103908e-01  3.19729507e-01  5.77648997e-01 -2.65651830e-02\n","   -3.30545455e-01  2.42261440e-01  3.31554234e-01  6.76010251e-01\n","    7.70711124e-01  2.94789732e-01  3.96333873e-01  4.57950413e-01\n","    1.27956557e+00  2.85897255e-01 -7.50788093e-01 -4.12461907e-01\n","   -1.98167861e-01 -4.54149395e-02 -1.49462163e-01  5.10483086e-01\n","    4.82872725e-01 -1.12109900e-01  1.11762054e-01  2.15848178e-01\n","    1.29538333e+00  1.18274510e+00 -5.00017107e-01  7.78097451e-01\n","    8.31038281e-02  9.30615962e-02 -8.49191427e-01 -3.76085520e-01\n","    7.57235706e-01  2.86512226e-01  1.45575047e-01 -3.37692082e-01\n","   -1.41263068e+00  2.59688616e-01 -2.56015241e-01  3.48673612e-01\n","    6.47101879e-01 -8.05801898e-03 -4.16975498e-01 -1.89070821e-01\n","    7.69312978e-02 -7.85137713e-01  4.52620834e-01 -5.00365615e-01\n","   -3.52813482e-01 -2.09701940e-01 -3.80849600e-01 -4.90961015e-01\n","    2.73974091e-01 -3.50444406e-01 -1.34906363e+00  9.82455909e-01\n","    6.12564459e-02 -6.84298873e-01 -3.62658650e-02  4.74598706e-02\n","    7.59407043e-01 -9.37278867e-01 -8.95768344e-01 -4.95004773e-01\n","    9.47986841e-02 -3.12080026e-01  6.04412854e-01  1.97577477e-01\n","   -2.95090586e-01  2.58221030e-02  7.67051578e-01 -1.78590000e-01\n","    1.38406783e-01 -4.05023217e-01 -9.95161057e-01 -3.84670079e-01\n","   -3.47168446e-01 -1.07858562e+00  4.19506818e-01  5.20727038e-03\n","   -7.17683375e-01  3.01752567e-01 -4.94333148e-01 -7.71580637e-02\n","   -1.49626181e-01  5.65104961e-01  7.48878717e-01  9.05041635e-01]\n","  [-2.65755832e-01 -8.01541507e-01  1.80797696e-01  6.00896120e-01\n","    2.78191920e-02 -2.21526608e-01 -3.13584238e-01 -6.78549469e-01\n","   -1.48092359e-01  9.38168168e-03 -1.05860680e-01 -6.16981745e-01\n","    8.54103193e-02  7.69143939e-01  3.45168531e-01 -8.72365296e-01\n","    2.24897385e-01 -5.34291565e-01  8.69038820e-01  8.14586639e-01\n","    3.14266533e-01 -1.28113008e+00  7.30834723e-01 -1.55314356e-02\n","   -9.00646448e-02 -1.74909830e-04 -2.25629881e-01  7.39883244e-01\n","   -1.14104247e+00 -2.45643258e-01  8.41107011e-01 -5.44580340e-01\n","   -4.00597483e-01  2.13409066e-01  2.14980692e-01 -6.61909640e-01\n","   -8.48584890e-01 -7.62969255e-01 -1.74408257e-02 -2.97096550e-01\n","    5.38666844e-01  4.57093239e-01  4.86798465e-01 -2.13396102e-01\n","   -4.55643594e-01  4.48780149e-01  2.00668678e-01  8.99201035e-01\n","    1.00779891e+00  9.81306434e-02  3.96546960e-01  4.25761431e-01\n","    1.37113953e+00  3.13597918e-01 -5.11297703e-01 -3.85477990e-01\n","   -4.08577263e-01 -1.89460680e-01  5.11072874e-02  3.43610764e-01\n","    5.70178390e-01 -7.26139545e-02  1.76242977e-01  4.57679302e-01\n","    1.03090858e+00  1.06291580e+00 -4.68747199e-01  7.53218174e-01\n","    3.70877683e-01  3.17762941e-02 -9.12923992e-01 -5.12044191e-01\n","    9.29951251e-01  9.13939551e-02  1.42516375e-01 -3.48494947e-01\n","   -1.42097318e+00  1.89290017e-01 -1.38455302e-01  4.28246230e-01\n","    5.70306182e-01  1.71102345e-01 -3.16778988e-01 -3.36258650e-01\n","    1.77490711e-01 -9.24983740e-01  6.30970120e-01 -3.64075691e-01\n","   -1.05424687e-01 -1.74421489e-01 -1.80468813e-01 -2.18323857e-01\n","    2.32625976e-01 -2.24580497e-01 -1.07175922e+00  7.38794386e-01\n","    8.16094801e-02 -3.27542543e-01 -1.65132463e-01  8.29099566e-02\n","    8.30293417e-01 -1.06998563e+00 -8.67299080e-01 -7.03198373e-01\n","    4.94127870e-02 -6.59180954e-02  5.05117655e-01  1.03687070e-01\n","   -1.65656075e-01  4.18128669e-02  6.57224774e-01 -3.46055925e-02\n","    1.98301777e-01 -4.50411588e-01 -9.18063700e-01 -1.40334994e-01\n","   -4.45295751e-01 -1.01936364e+00  2.95528173e-01 -1.19309843e-01\n","   -6.82999551e-01  3.96178037e-01 -4.91650522e-01  1.72230750e-01\n","   -3.56327266e-01  6.33878589e-01  6.99638367e-01  8.88886392e-01]\n","  [-1.19583160e-01 -7.61659622e-01  1.96260631e-01  3.94879580e-01\n","   -7.74784312e-02 -2.31976837e-01 -4.15163159e-01 -7.05329061e-01\n","   -1.75994977e-01 -9.28193033e-02  1.79456919e-02 -4.72893506e-01\n","   -1.51517307e-02  4.90706205e-01  1.82074040e-01 -6.38396502e-01\n","    5.01186848e-01 -6.95010662e-01  8.84567440e-01  8.50973248e-01\n","    3.77206326e-01 -1.37819457e+00  6.52864575e-01  1.39238954e-01\n","   -3.66590023e-02 -3.02727968e-02 -2.46116653e-01  7.50263274e-01\n","   -1.14863932e+00 -3.27766895e-01  9.12920952e-01 -5.44625163e-01\n","   -4.18414026e-01  2.42073834e-02  1.77393749e-01 -6.73653245e-01\n","   -9.08806205e-01 -7.53063440e-01 -1.09686837e-01 -3.86061668e-01\n","    5.19797802e-01  3.48143458e-01  4.50648874e-01 -2.63501890e-02\n","   -4.11276758e-01  4.25142676e-01  2.51456141e-01  9.11336124e-01\n","    9.21721756e-01  1.44614473e-01  4.16009605e-01  3.98287147e-01\n","    1.42796326e+00  3.11665356e-01 -5.93053818e-01 -2.63509065e-01\n","   -3.86111379e-01 -1.82726875e-01  4.05290276e-02  4.18793619e-01\n","    4.59703535e-01 -2.00518087e-01  2.22887218e-01  4.48455602e-01\n","    1.15332699e+00  1.06190515e+00 -4.52016383e-01  8.83231819e-01\n","    3.21373165e-01  8.38241726e-02 -1.00137424e+00 -3.52008700e-01\n","    9.37048554e-01  9.28878635e-02  2.97960728e-01 -2.80545115e-01\n","   -1.42113423e+00  4.25418079e-01 -2.84623891e-01  3.26284200e-01\n","    6.21988416e-01  1.65298328e-01 -4.75185037e-01 -3.36927980e-01\n","    1.76076859e-01 -8.95561576e-01  5.26412129e-01 -2.27091119e-01\n","   -2.91494668e-01 -1.46318808e-01 -8.97075832e-02 -3.27232838e-01\n","    1.81362972e-01 -3.47222239e-01 -1.13638282e+00  9.43845034e-01\n","    1.60344422e-01 -4.48300898e-01 -1.60732284e-01  9.09867883e-03\n","    7.22285509e-01 -1.00339580e+00 -8.51310253e-01 -3.94064218e-01\n","    2.62576282e-01 -2.06133455e-01  4.10367817e-01  2.10663646e-01\n","   -5.91351390e-02 -2.57822275e-02  5.13076186e-01 -2.22609043e-02\n","   -2.21303403e-02 -4.33169067e-01 -1.09764647e+00 -3.08488727e-01\n","   -4.57579762e-01 -1.14804757e+00  2.56992042e-01 -1.15499839e-01\n","   -6.92223251e-01  2.49040961e-01 -3.93428326e-01  1.10748410e-03\n","   -2.68635780e-01  6.36834264e-01  7.22174346e-01  8.49560142e-01]]], shape=(1, 4, 128), dtype=float32)\n","tf.Tensor([  1   4 128], shape=(3,), dtype=int32)\n","TEMP AFTER TILE\n","tf.Tensor(\n","[[[ 1.17816031e-02 -7.79897392e-01  5.96917979e-02  3.93613905e-01\n","   -1.83555260e-01 -3.04668427e-01 -3.56282115e-01 -6.01522624e-01\n","    8.60495567e-02  5.95250279e-02 -3.46176624e-02 -6.32611871e-01\n","    1.17644720e-01  7.10190833e-01  5.39888322e-01 -7.63161957e-01\n","    2.88406342e-01 -8.92855167e-01  8.08749378e-01  6.74844146e-01\n","    6.24214113e-01 -1.36715400e+00  1.01653266e+00  6.89466447e-02\n","   -7.26643205e-02 -3.64010036e-02 -3.02888095e-01  5.56215525e-01\n","   -9.28365052e-01 -1.89401776e-01  9.36919093e-01 -4.85432863e-01\n","   -2.14981735e-01  2.41634846e-02  2.02152103e-01 -6.12584174e-01\n","   -6.69778109e-01 -8.66268158e-01 -1.28439263e-01 -4.38241661e-02\n","    5.38326323e-01  3.63360435e-01  6.98803008e-01  1.85332358e-01\n","   -4.02028501e-01  1.57244354e-01  4.33138072e-01  8.45125079e-01\n","    7.51577854e-01  3.90111208e-01  5.55614591e-01  3.30964565e-01\n","    1.34215736e+00  4.27132457e-01 -7.58566856e-01 -2.49722660e-01\n","   -1.39991850e-01 -3.13035101e-02  1.12462491e-01  4.13716406e-01\n","    6.05398893e-01 -8.31397474e-02 -2.48553008e-02  5.11024654e-01\n","    1.29661715e+00  1.11728489e+00 -4.33036864e-01  8.88753414e-01\n","   -4.97295856e-02 -1.43992603e-01 -6.86927319e-01 -4.07865584e-01\n","    9.37564969e-01  2.14593828e-01  1.53276592e-01 -1.35102585e-01\n","   -1.37393486e+00  2.68534124e-01 -1.95035487e-01  5.96224964e-01\n","    3.49517643e-01 -1.07112899e-01 -3.48432064e-01 -1.07012659e-01\n","    8.47013220e-02 -6.33694530e-01  6.39146149e-01 -3.04830134e-01\n","   -4.31665987e-01 -2.46459335e-01 -1.21170275e-01 -4.73311424e-01\n","    2.50235081e-01 -4.64875996e-01 -1.29754019e+00  1.07757592e+00\n","    9.89012867e-02 -6.85574174e-01 -9.07645971e-02 -3.87175381e-02\n","    7.16257095e-01 -8.88337433e-01 -9.66061711e-01 -7.11837888e-01\n","    1.01575613e-01 -2.78444827e-01  7.17753410e-01  2.38248050e-01\n","   -1.94900602e-01 -1.03095770e-01  6.39721036e-01 -3.45759541e-02\n","    2.13965312e-01 -2.79286623e-01 -1.05687869e+00 -1.96306482e-01\n","   -4.62162018e-01 -1.11845899e+00  4.66042191e-01  8.70777071e-02\n","   -4.92378592e-01  9.40339565e-02 -4.29061025e-01 -5.77020347e-02\n","   -5.66805601e-02  5.56844473e-01  6.37717962e-01  9.53799069e-01]\n","  [ 1.50980413e-01 -7.82433331e-01  1.47333533e-01  4.57121432e-01\n","   -1.46336153e-01 -2.39377558e-01 -3.34803462e-01 -7.63889670e-01\n","   -2.21599638e-03  6.60550594e-03  1.94404304e-01 -6.59838080e-01\n","    1.42362952e-01  6.59814298e-01  2.08955079e-01 -8.02223325e-01\n","    4.65390235e-01 -7.49683976e-01  7.65330255e-01  8.58141541e-01\n","    6.02647245e-01 -1.20686054e+00  1.07284999e+00  8.63736570e-02\n","   -5.48685491e-02 -2.53076777e-02 -2.04088181e-01  6.43821955e-01\n","   -1.04306400e+00 -2.70931482e-01  8.50932717e-01 -7.88352251e-01\n","   -3.01504731e-01  9.62540209e-02  2.00189412e-01 -5.25082946e-01\n","   -7.60564983e-01 -7.01166868e-01  9.56398845e-02 -3.69734377e-01\n","    5.82103908e-01  3.19729507e-01  5.77648997e-01 -2.65651830e-02\n","   -3.30545455e-01  2.42261440e-01  3.31554234e-01  6.76010251e-01\n","    7.70711124e-01  2.94789732e-01  3.96333873e-01  4.57950413e-01\n","    1.27956557e+00  2.85897255e-01 -7.50788093e-01 -4.12461907e-01\n","   -1.98167861e-01 -4.54149395e-02 -1.49462163e-01  5.10483086e-01\n","    4.82872725e-01 -1.12109900e-01  1.11762054e-01  2.15848178e-01\n","    1.29538333e+00  1.18274510e+00 -5.00017107e-01  7.78097451e-01\n","    8.31038281e-02  9.30615962e-02 -8.49191427e-01 -3.76085520e-01\n","    7.57235706e-01  2.86512226e-01  1.45575047e-01 -3.37692082e-01\n","   -1.41263068e+00  2.59688616e-01 -2.56015241e-01  3.48673612e-01\n","    6.47101879e-01 -8.05801898e-03 -4.16975498e-01 -1.89070821e-01\n","    7.69312978e-02 -7.85137713e-01  4.52620834e-01 -5.00365615e-01\n","   -3.52813482e-01 -2.09701940e-01 -3.80849600e-01 -4.90961015e-01\n","    2.73974091e-01 -3.50444406e-01 -1.34906363e+00  9.82455909e-01\n","    6.12564459e-02 -6.84298873e-01 -3.62658650e-02  4.74598706e-02\n","    7.59407043e-01 -9.37278867e-01 -8.95768344e-01 -4.95004773e-01\n","    9.47986841e-02 -3.12080026e-01  6.04412854e-01  1.97577477e-01\n","   -2.95090586e-01  2.58221030e-02  7.67051578e-01 -1.78590000e-01\n","    1.38406783e-01 -4.05023217e-01 -9.95161057e-01 -3.84670079e-01\n","   -3.47168446e-01 -1.07858562e+00  4.19506818e-01  5.20727038e-03\n","   -7.17683375e-01  3.01752567e-01 -4.94333148e-01 -7.71580637e-02\n","   -1.49626181e-01  5.65104961e-01  7.48878717e-01  9.05041635e-01]\n","  [-2.65755832e-01 -8.01541507e-01  1.80797696e-01  6.00896120e-01\n","    2.78191920e-02 -2.21526608e-01 -3.13584238e-01 -6.78549469e-01\n","   -1.48092359e-01  9.38168168e-03 -1.05860680e-01 -6.16981745e-01\n","    8.54103193e-02  7.69143939e-01  3.45168531e-01 -8.72365296e-01\n","    2.24897385e-01 -5.34291565e-01  8.69038820e-01  8.14586639e-01\n","    3.14266533e-01 -1.28113008e+00  7.30834723e-01 -1.55314356e-02\n","   -9.00646448e-02 -1.74909830e-04 -2.25629881e-01  7.39883244e-01\n","   -1.14104247e+00 -2.45643258e-01  8.41107011e-01 -5.44580340e-01\n","   -4.00597483e-01  2.13409066e-01  2.14980692e-01 -6.61909640e-01\n","   -8.48584890e-01 -7.62969255e-01 -1.74408257e-02 -2.97096550e-01\n","    5.38666844e-01  4.57093239e-01  4.86798465e-01 -2.13396102e-01\n","   -4.55643594e-01  4.48780149e-01  2.00668678e-01  8.99201035e-01\n","    1.00779891e+00  9.81306434e-02  3.96546960e-01  4.25761431e-01\n","    1.37113953e+00  3.13597918e-01 -5.11297703e-01 -3.85477990e-01\n","   -4.08577263e-01 -1.89460680e-01  5.11072874e-02  3.43610764e-01\n","    5.70178390e-01 -7.26139545e-02  1.76242977e-01  4.57679302e-01\n","    1.03090858e+00  1.06291580e+00 -4.68747199e-01  7.53218174e-01\n","    3.70877683e-01  3.17762941e-02 -9.12923992e-01 -5.12044191e-01\n","    9.29951251e-01  9.13939551e-02  1.42516375e-01 -3.48494947e-01\n","   -1.42097318e+00  1.89290017e-01 -1.38455302e-01  4.28246230e-01\n","    5.70306182e-01  1.71102345e-01 -3.16778988e-01 -3.36258650e-01\n","    1.77490711e-01 -9.24983740e-01  6.30970120e-01 -3.64075691e-01\n","   -1.05424687e-01 -1.74421489e-01 -1.80468813e-01 -2.18323857e-01\n","    2.32625976e-01 -2.24580497e-01 -1.07175922e+00  7.38794386e-01\n","    8.16094801e-02 -3.27542543e-01 -1.65132463e-01  8.29099566e-02\n","    8.30293417e-01 -1.06998563e+00 -8.67299080e-01 -7.03198373e-01\n","    4.94127870e-02 -6.59180954e-02  5.05117655e-01  1.03687070e-01\n","   -1.65656075e-01  4.18128669e-02  6.57224774e-01 -3.46055925e-02\n","    1.98301777e-01 -4.50411588e-01 -9.18063700e-01 -1.40334994e-01\n","   -4.45295751e-01 -1.01936364e+00  2.95528173e-01 -1.19309843e-01\n","   -6.82999551e-01  3.96178037e-01 -4.91650522e-01  1.72230750e-01\n","   -3.56327266e-01  6.33878589e-01  6.99638367e-01  8.88886392e-01]\n","  [-1.19583160e-01 -7.61659622e-01  1.96260631e-01  3.94879580e-01\n","   -7.74784312e-02 -2.31976837e-01 -4.15163159e-01 -7.05329061e-01\n","   -1.75994977e-01 -9.28193033e-02  1.79456919e-02 -4.72893506e-01\n","   -1.51517307e-02  4.90706205e-01  1.82074040e-01 -6.38396502e-01\n","    5.01186848e-01 -6.95010662e-01  8.84567440e-01  8.50973248e-01\n","    3.77206326e-01 -1.37819457e+00  6.52864575e-01  1.39238954e-01\n","   -3.66590023e-02 -3.02727968e-02 -2.46116653e-01  7.50263274e-01\n","   -1.14863932e+00 -3.27766895e-01  9.12920952e-01 -5.44625163e-01\n","   -4.18414026e-01  2.42073834e-02  1.77393749e-01 -6.73653245e-01\n","   -9.08806205e-01 -7.53063440e-01 -1.09686837e-01 -3.86061668e-01\n","    5.19797802e-01  3.48143458e-01  4.50648874e-01 -2.63501890e-02\n","   -4.11276758e-01  4.25142676e-01  2.51456141e-01  9.11336124e-01\n","    9.21721756e-01  1.44614473e-01  4.16009605e-01  3.98287147e-01\n","    1.42796326e+00  3.11665356e-01 -5.93053818e-01 -2.63509065e-01\n","   -3.86111379e-01 -1.82726875e-01  4.05290276e-02  4.18793619e-01\n","    4.59703535e-01 -2.00518087e-01  2.22887218e-01  4.48455602e-01\n","    1.15332699e+00  1.06190515e+00 -4.52016383e-01  8.83231819e-01\n","    3.21373165e-01  8.38241726e-02 -1.00137424e+00 -3.52008700e-01\n","    9.37048554e-01  9.28878635e-02  2.97960728e-01 -2.80545115e-01\n","   -1.42113423e+00  4.25418079e-01 -2.84623891e-01  3.26284200e-01\n","    6.21988416e-01  1.65298328e-01 -4.75185037e-01 -3.36927980e-01\n","    1.76076859e-01 -8.95561576e-01  5.26412129e-01 -2.27091119e-01\n","   -2.91494668e-01 -1.46318808e-01 -8.97075832e-02 -3.27232838e-01\n","    1.81362972e-01 -3.47222239e-01 -1.13638282e+00  9.43845034e-01\n","    1.60344422e-01 -4.48300898e-01 -1.60732284e-01  9.09867883e-03\n","    7.22285509e-01 -1.00339580e+00 -8.51310253e-01 -3.94064218e-01\n","    2.62576282e-01 -2.06133455e-01  4.10367817e-01  2.10663646e-01\n","   -5.91351390e-02 -2.57822275e-02  5.13076186e-01 -2.22609043e-02\n","   -2.21303403e-02 -4.33169067e-01 -1.09764647e+00 -3.08488727e-01\n","   -4.57579762e-01 -1.14804757e+00  2.56992042e-01 -1.15499839e-01\n","   -6.92223251e-01  2.49040961e-01 -3.93428326e-01  1.10748410e-03\n","   -2.68635780e-01  6.36834264e-01  7.22174346e-01  8.49560142e-01]]], shape=(1, 4, 128), dtype=float32)\n","ROOT\n","tf.Tensor(\n","[[[ 1.1975346  -0.5701757  -0.14051597 -0.5563121   0.27957582\n","   -1.7192221  -0.20755336 -1.1546696   0.8880576  -0.6217595\n","   -1.3142807  -0.3278225   0.4318298   1.5830425  -0.81585306\n","   -2.0693333   0.6587961  -1.0332129   1.5792129   2.6677346\n","    0.43204397  1.0314888   1.5896611   0.5992484   0.4710766\n","    0.06251785 -1.0113473  -0.45062244 -2.556293   -0.80485463\n","    2.285996   -0.31078303 -0.1905107  -0.4149779  -0.73273313\n","    0.13656747 -0.7398309  -2.9765587  -0.11796185 -0.83783305\n","   -0.8208479   0.26228952 -0.47641796  0.02711624 -0.62217486\n","   -0.0577639  -0.02067918  3.6737137   1.2170802  -0.4791808\n","    2.8932147   0.9765605   2.3085341  -0.8893453  -0.8048359\n","    0.10174227 -0.23498756 -1.5950959  -0.39782485  0.8560763\n","    0.4284368   0.1810086   0.25015277  1.4160073   0.430225\n","    1.1006393  -0.01839265 -0.20131397 -0.19180673 -1.3107004\n","   -0.93160695  0.01668108  1.8866231  -0.96734375  0.757957\n","    0.37942982 -1.7361178   0.0640049  -0.22014043  1.2429765\n","   -0.96893924 -0.8544887   0.45057982  0.11197621  0.5867598\n","   -1.5427653   0.09735638 -0.23441558 -0.8918523  -0.29611114\n","    0.24075866 -1.4832717  -0.21879265 -0.41906857 -2.3227663\n","    2.0817757   1.6689559  -0.7344558  -0.6434595   1.0481997\n","   -0.10747093 -0.464958   -2.2714949  -0.7343981  -1.4717683\n","   -1.0667835   0.51416904  0.6135382   0.06424275  0.17089432\n","    0.48543864  0.6711514   0.24611662 -0.31057447  0.0513438\n","   -1.1375421   0.9455886  -0.15976673 -0.6963695   0.15177837\n","   -1.9217342   1.0617474  -0.99588263 -2.0378573  -0.6734872\n","    3.5580847   0.2364771   0.17030734]\n","  [ 1.3367333  -0.57271165 -0.05287424 -0.4928046   0.31679493\n","   -1.6539311  -0.1860747  -1.3170366   0.79979205 -0.674679\n","   -1.0852587  -0.35504872  0.45654804  1.532666   -1.1467863\n","   -2.1083946   0.8357799  -0.8900417   1.5357938   2.851032\n","    0.4104771   1.1917822   1.6459785   0.6166754   0.48887238\n","    0.07361118 -0.91254747 -0.363016   -2.670992   -0.8863843\n","    2.2000093  -0.6137024  -0.2770337  -0.34288737 -0.7346958\n","    0.2240687  -0.8306178  -2.8114574   0.10611729 -1.1637433\n","   -0.77707034  0.2186586  -0.59757197 -0.1847813  -0.55069184\n","    0.02725318 -0.12226301  3.5045986   1.2362136  -0.5745023\n","    2.733934    1.1035464   2.2459424  -1.0305805  -0.79705715\n","   -0.06099698 -0.29316357 -1.6092073  -0.6597495   0.95284295\n","    0.30591062  0.15203846  0.3867701   1.1208308   0.4289912\n","    1.1660995  -0.0853729  -0.31196994 -0.05897332 -1.0736463\n","   -1.0938711   0.04846114  1.7062938  -0.8954253   0.75025547\n","    0.1768403  -1.7748137   0.05515939 -0.28112018  0.9954252\n","   -0.671355   -0.7554338   0.3820364   0.02991804  0.5789898\n","   -1.6942084  -0.08916894 -0.42995107 -0.81299984 -0.25935376\n","   -0.01892066 -1.5009212  -0.19505364 -0.30463699 -2.3742895\n","    1.9866555   1.631311   -0.7331805  -0.58896077  1.134377\n","   -0.06432098 -0.51389945 -2.2012014  -0.517565   -1.4785452\n","   -1.1004188   0.40082848  0.57286763 -0.03594723  0.2998122\n","    0.6127692   0.52713734  0.1705581  -0.43631107  0.11306143\n","   -1.3259058   1.0605822  -0.11989337 -0.7429049   0.06990793\n","   -2.147039    1.269466   -1.0611548  -2.0573132  -0.7664328\n","    3.5663452   0.34763786  0.1215499 ]\n","  [ 0.9624248  -0.7370392   0.07268544 -0.20273334  0.4108658\n","   -1.6105126  -0.14494853 -1.2505715   0.51758516 -0.66303194\n","   -1.3019879  -0.3436585   0.3826014   1.8445946  -1.108711\n","   -2.153264    0.6163883  -0.65291727  1.7725906   2.9963083\n","    0.04923508  1.1708081   1.3067961   0.6506261   0.40322185\n","    0.0895865  -0.7562315  -0.38595325 -2.6879344  -0.7645513\n","    2.0533361  -0.2948044  -0.4112786  -0.2587339  -0.6447716\n","    0.03929114 -0.8809396  -2.9233427   0.03242925 -0.9727625\n","   -0.8874091   0.40648806 -0.71205455 -0.47987768 -0.7858301\n","    0.2266988  -0.0980453   3.9566174   1.4670777  -0.89245963\n","    2.5329943   1.0708381   2.2339497  -0.9594215  -0.39749914\n","   -0.1605142  -0.5930089  -1.8744055  -0.3291877   0.73015976\n","    0.43725643  0.07275105  0.40276277  0.97627723 -0.04741728\n","    1.1318185   0.09449238 -0.48690248  0.1634572  -1.1185383\n","   -1.206577   -0.30945224  1.7713084  -0.9591286   0.65856445\n","    0.18729466 -1.8085651  -0.05089614 -0.24496982  1.069252\n","   -0.77805007 -0.7637589   0.22819522 -0.23889008  0.7854206\n","   -1.778244    0.14264068 -0.4900252  -0.6093259  -0.22837251\n","    0.10203095 -1.228492    0.0240147  -0.25542235 -2.1908467\n","    1.7711904   1.5965154  -0.5961372  -0.7884001   1.1890975\n","   -0.07387936 -0.5904806  -2.0904963  -0.51972735 -1.642199\n","   -1.0985031   0.25396425  0.4558297  -0.13936113  0.45285803\n","    0.7860119   0.65087974 -0.05530401 -0.37827545  0.20684642\n","   -1.1128771   0.74688894 -0.01699495 -0.70681214 -0.16764708\n","   -2.0074081   1.2659023  -1.0639769  -2.0047736  -1.1235626\n","    3.6429281   0.28637382  0.09490716]\n","  [ 1.1085975  -0.6971574   0.08814837 -0.40874988  0.3055682\n","   -1.6209629  -0.24652745 -1.277351    0.48968256 -0.7652329\n","   -1.1781815  -0.19957027  0.28203934  1.5661569  -1.2718055\n","   -1.9192953   0.8926778  -0.8136364   1.7881193   3.0326948\n","    0.11217487  1.0737436   1.2288258   0.8053965   0.4566275\n","    0.05948861 -0.77671826 -0.37557322 -2.6955311  -0.8466749\n","    2.1251502  -0.29484922 -0.42909515 -0.44793558 -0.6823585\n","    0.02754754 -0.9411609  -2.913437   -0.05981676 -1.0617276\n","   -0.90627813  0.29753828 -0.7482041  -0.29283178 -0.74146324\n","    0.20306133 -0.04725784  3.9687526   1.3810006  -0.8459758\n","    2.5524569   1.0433638   2.2907734  -0.9613541  -0.47925526\n","   -0.03854528 -0.570543   -1.8676717  -0.33976597  0.8053426\n","    0.32678157 -0.05515309  0.449407    0.96705353  0.07500112\n","    1.1308079   0.11122319 -0.35688883  0.11395268 -1.0664904\n","   -1.2950273  -0.14941674  1.7784057  -0.9576347   0.81400883\n","    0.2552445  -1.8087263   0.18523192 -0.3911384   0.9672899\n","   -0.72636783 -0.7695629   0.06978917 -0.23955941  0.7840067\n","   -1.748822    0.03808269 -0.35304064 -0.79539585 -0.20026983\n","    0.19279218 -1.337401   -0.02724831 -0.3780641  -2.2554703\n","    1.976241    1.6752503  -0.7168956  -0.7839999   1.1152862\n","   -0.18188727 -0.5238908  -2.0745075  -0.2105932  -1.4290354\n","   -1.2387185   0.1592144   0.56280625 -0.03284019  0.38526294\n","    0.6418633   0.66322446 -0.27573612 -0.36103293  0.02726364\n","   -1.2810309   0.73460495 -0.14567888 -0.7453483  -0.16383708\n","   -2.0166318   1.1187652  -0.9657547  -2.175897   -1.035871\n","    3.6458836   0.3089098   0.05558091]]], shape=(1, 4, 128), dtype=float32)\n","W_BRANCH\n","<tf.Variable 'branch:0' shape=(4, 256, 512) dtype=float32, numpy=\n","array([[[-0.03009224, -0.00677618, -0.00361813, ..., -0.01032512,\n","         -0.00554201, -0.01178243],\n","        [ 0.00312731, -0.02768424,  0.01637152, ...,  0.03930544,\n","          0.03160414, -0.02430691],\n","        [-0.00150134, -0.03897779,  0.02742402, ...,  0.01140099,\n","          0.03181763,  0.03925965],\n","        ...,\n","        [ 0.04408756, -0.02569934,  0.04227072, ...,  0.01308854,\n","          0.01962818, -0.00525773],\n","        [-0.00600958,  0.02501137, -0.01751335, ..., -0.01247739,\n","         -0.01204221, -0.03826368],\n","        [ 0.0092322 , -0.00274382,  0.00843845, ...,  0.0286173 ,\n","          0.02375009,  0.02126947]],\n","\n","       [[-0.01667403,  0.02640149,  0.00835985, ...,  0.01644699,\n","          0.00356097,  0.00574647],\n","        [-0.02885515,  0.040049  ,  0.01393329, ...,  0.00694275,\n","         -0.00485325,  0.03785332],\n","        [-0.00932257, -0.04334537, -0.00767964, ...,  0.04305198,\n","         -0.01549064, -0.02634417],\n","        ...,\n","        [-0.03923723, -0.00451674, -0.03398534, ..., -0.03576432,\n","         -0.01944701,  0.0055682 ],\n","        [ 0.01917038,  0.04296838, -0.00617167, ...,  0.03831573,\n","          0.01361654,  0.02035287],\n","        [-0.04347001,  0.02697948,  0.00847249, ..., -0.0083055 ,\n","          0.00455561, -0.00244437]],\n","\n","       [[-0.02403852, -0.00511273,  0.01790581, ..., -0.02993347,\n","         -0.00796901, -0.02799411],\n","        [ 0.00967953,  0.00328637, -0.02925835, ..., -0.01027175,\n","          0.00948068,  0.01088836],\n","        [-0.02686564,  0.01272351, -0.02632605, ..., -0.03310195,\n","         -0.02148637, -0.03323333],\n","        ...,\n","        [ 0.03829757, -0.03088775, -0.00772725, ...,  0.03422616,\n","         -0.01571058,  0.00738567],\n","        [ 0.02064679,  0.02923403,  0.01795475, ...,  0.0316521 ,\n","         -0.03205798,  0.0247387 ],\n","        [ 0.03790383, -0.01137993, -0.02008103, ...,  0.00537942,\n","         -0.026375  , -0.01753796]],\n","\n","       [[-0.01068196,  0.01196547, -0.00370338, ..., -0.03389202,\n","          0.03475738, -0.01159745],\n","        [-0.006156  , -0.00529592,  0.03766511, ...,  0.03627594,\n","         -0.01263181, -0.03186371],\n","        [ 0.002687  ,  0.01237009, -0.04296147, ...,  0.04247766,\n","         -0.03908657,  0.02488768],\n","        ...,\n","        [-0.02530662,  0.01025791, -0.02769265, ..., -0.02599269,\n","         -0.00142657, -0.00157027],\n","        [ 0.02538982,  0.01974029,  0.03265217, ..., -0.01507034,\n","          0.04363482, -0.0237385 ],\n","        [-0.00222729, -0.04385767,  0.01163597, ..., -0.02902848,\n","          0.00967833,  0.03021375]]], dtype=float32)>\n","branch shape after EXPAND DIMS tf.Tensor(\n","[[[[ 0.20061816 -0.00369401  0.25268102 ...  0.07817443 -0.10540203\n","    -0.017308  ]]\n","\n","  [[-0.18945967  0.31177637 -0.21872877 ...  0.10851723  0.03455729\n","     0.56925887]]\n","\n","  [[ 0.11414672  0.10455538 -0.15761483 ...  0.20170912  0.09258241\n","    -0.2625281 ]]\n","\n","  [[-0.2608871  -0.09741855  0.08034496 ...  0.14241745 -0.00153932\n","     0.13146594]]]], shape=(1, 4, 1, 512), dtype=float32)\n","BRANCH AFTER RESHAPE\n","tf.Tensor(\n","[[[ 2.0061816e-01 -7.3880254e-04  2.5268102e-01 ... -6.4894103e-02\n","    5.2211247e-03 -6.3311301e-02]\n","  [ 5.8686659e-02  1.2979479e-01 -8.1203980e-03 ...  7.8174427e-02\n","   -2.1080406e-02 -3.4615993e-03]\n","  [-3.7891936e-02  3.1177637e-01 -4.3745752e-02 ... -4.4202060e-04\n","   -6.0214397e-02  3.7605521e-01]\n","  ...\n","  [ 1.2462946e-02  1.4610390e-01  1.3455211e-01 ...  2.0170912e-01\n","    9.2582412e-02 -5.2505620e-02]\n","  [-5.2177418e-02 -1.9483710e-02  8.0344960e-02 ... -3.9036050e-03\n","    2.9150523e-02 -4.7646321e-02]\n","  [-3.7830155e-02  3.2636523e-04  2.2492048e-01 ...  1.4241745e-01\n","   -3.0786425e-04  1.3146594e-01]]], shape=(1, 8, 256), dtype=float32)\n","Branch W_loop call\n","tf.Tensor(\n","[[[ 0.05762696  0.06116816 -0.08245084 ... -0.06073053  0.06519675\n","   -0.03710044]\n","  [ 0.03735537 -0.07263018 -0.19541459 ...  0.06953764  0.1451926\n","    0.0076574 ]\n","  [ 0.07973991  0.16645497  0.04215004 ...  0.04806349  0.05035848\n","    0.0100895 ]\n","  ...\n","  [ 0.05885735 -0.05131136 -0.011904   ...  0.04551613 -0.00235643\n","   -0.09836151]\n","  [ 0.02650038  0.07966717 -0.18245281 ... -0.07541965  0.06245149\n","   -0.04364493]\n","  [-0.13048065  0.07789506 -0.22303149 ... -0.04586698 -0.09300179\n","   -0.04477819]]], shape=(1, 8, 128), dtype=float32)\n","BRANCH AFTER RE TILE\n","tf.Tensor(\n","[[[ 1.25516152e+00 -5.09007573e-01 -2.22966805e-01 ...  3.49735427e+00\n","    3.01673859e-01  1.33206904e-01]\n","  [ 1.23488998e+00 -6.42805874e-01 -3.35930556e-01 ...  3.62762237e+00\n","    3.81669700e-01  1.77964747e-01]\n","  [ 1.41647327e+00 -4.06256676e-01 -1.07241943e-02 ...  3.61440873e+00\n","    3.97996336e-01  1.31639406e-01]\n","  ...\n","  [ 1.02128220e+00 -7.88350582e-01  6.07814416e-02 ...  3.68844414e+00\n","    2.84017384e-01 -3.45434248e-03]\n","  [ 1.13509786e+00 -6.17490232e-01 -9.43044424e-02 ...  3.57046390e+00\n","    3.71361285e-01  1.19359866e-02]\n","  [ 9.78116870e-01 -6.19262338e-01 -1.34883121e-01 ...  3.60001659e+00\n","    2.15908021e-01  1.08027235e-02]]], shape=(1, 8, 128), dtype=float32)\n","[TensorShape([1, 1, 96]), TensorShape([1, 1, 256]), TensorShape([1, 2, 256]), TensorShape([1, 4, 256]), TensorShape([1, 8, 128])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cygca-n2zl-y","colab":{"base_uri":"https://localhost:8080/","height":77},"executionInfo":{"status":"ok","timestamp":1614718167818,"user_tz":300,"elapsed":257,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"f48c222f-a1d6-41c9-e31c-a28dc413b7d4"},"source":["\r\n","keras.utils.plot_model(D, show_shapes=True)\r\n","# keras.utils.plot_model(G, show_shapes=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAKMAAAA8CAYAAAAKXAoWAAAABmJLR0QA/wD/AP+gvaeTAAAI4ElEQVR4nO3ce0hT7x8H8Pc03dyWTs00myZadFNCu5lpFBEVQRctEvJPo+yPjKSCghK72sUENegiERZaWhBWUFRgRWJFeatMCyx1iHaZLrdS2/v7xw/3+9rmwnTufOt5gf885zzP53O2945nujMZSUIQnK/YxdkdCEIfEUZBMkQYBckQYRQkY9TPA+Xl5cjKynJGL8JfpLi42GrM6szY1NSEkpKSEWlI+Ps0NzcPmC+rM2MfW8kVhKG6cuUK1q9fb3ObuGYUJEOEUZAMEUZBMkQYBckQYRQkQ4RRkAwRRkEyRBgFyRBhFCRDhFGQDBFGQTJEGAXJEGEUJEOEUZAMh4QxOTkZo0ePhkwmQ2VlpWX81q1b8PLyQmlpqSPKOqzOSPXtLGazGSdPnkRMTIzN7QcOHIBMJrP6CQ8PH9Y+HBLGc+fO4ezZs1bjI3VX7HDX+ZPv5m1oaMCCBQuwfft2GI1Gp/Yy4IdrHWHFihXo6Oj4z9VxZN8mkwmLFy/G48ePHbK+PVVVVcjIyEBKSgq6urrsvugKCgqQlJTk0H4cds0ok8kctfQfJT8/H21tbU6pPWPGDFy9ehUbNmyAXC53Sg//NixhJIljx45h8uTJkMvl8PLywo4dO/rt8+jRIwQHB0MmkyE3N9cyXlZWhjlz5kCpVMLT0xMRERHo7Oy0bC8oKMCsWbOgUCigUqkQEhKC/fv34+jRo1AqlRg9ejTa2tqQlpaG8ePHIz8/36pOdnY2VCoVXFxcMHPmTPj7+8PNzQ0qlQpRUVGIi4tDUFAQFAoFNBoNdu7cabfvU6dOQaVSQalU4vr161i+fDk8PT2h1WpRWFjY77gfPnyIadOmwcvLCwqFAhEREbh9+zYAYNu2bUhLS8O7d+8gk8kwceJEy+OZlZWFqVOnQi6Xw9vbG6tXr0ZdXZ1l3YGO/82bN8PxlDoHf3L58mXaGLZrz549lMlkPHHiBL98+UKj0ci8vDwC4IsXLyz7NTU1EQBzcnJIkl+/fqWnpyczMzNpMpnY2trK+Ph4tre3kyRPnjxJADx8+DA/ffrEz58/8/Tp09ywYYOlLgCmpqYyJyeH8fHxfP36tVUdkty3bx8BsKKigl1dXfz48SOXLVtGALx58ybb29vZ1dXFrVu3EgArKysH7Pvfte/du8eOjg62tbUxLi6OKpWK3d3dlv2Ki4uZnp7Oz58/89OnT4yOjqavr69le0JCAsPCwvo9nnv37qW7uzsLCgqo1+tZXV3NqKgojhkzhq2trVY9/Hz8v2Pu3LmcMWOGzW379++nVqulRqOhm5sbQ0JCuGrVKj558mTQdezk68qQw2g0GqlUKrlkyZJ+44WFhb8MY21tLQHwxo0bVut2d3dTo9Fw0aJF/cZ7e3uZnZ1N8v9Phslk6rePvTAaDAbL2IULFwiANTU1lrEnT54QAIuKiuyuZ6t23wvw7du3Az5ehw4dIgC2tbWRtA6j0WikWq1mYmJiv3l9fWVkZNjt4XfZC+OHDx/4/PlzGgwGfv/+neXl5YyMjKSHhwdra2sHVcdeGIf8a/rt27cwGo1YvHjxoOeGhoZi7NixSEpKQnp6OhobGy3bqqurodfrsXTp0n5zXF1dkZqaOtS2AQDu7u4AgN7eXsuYm5sbAKCnp+e317M3t2/9Hz9+2Nz+8uVLfP36FbNmzeo3Pnv2bLi7u6OiomLQfQ1VUFAQIiMjoVar4e7ujujoaJw/fx4mkwl5eXnDVmfIYWxubgYA+Pn5DXquh4cH7t+/j9jYWBw8eBChoaFITEyEyWSyXDdqNJqhtuhUN2/exMKFC+Hn5we5XN7vetQWvV4PAFCr1VbbNBoNDAaDQ/ocrIiICLi6uqK+vn7Y1hxyGBUKBQDg+/fvvzV/+vTpKC0thU6nw65du3D58mUcP34cgYGBAICPHz8OtUWn+fDhA9asWYOAgABUVFSgo6MDmZmZduf0vfhshU6v10Or1Tqk18Eym80wm83D+i58yGEMDw+Hi4sLysrKBj1Xp9Ph1atXAP53Zj18+DCioqLw6tUrhISEwMfHB3fu3Blqi05TU1ODnp4ebNmyBaGhoVAoFL/8k1d4eDjUajWePXvWb7yiogLd3d2YOXOmI1u26edLJQB4+vQpSGLevHnDVmfIYfTz80NCQgJKSkqQn5+Pzs5OVFdX48yZM7+cq9PpsHnzZtTV1aG7uxsvXrzA+/fvER0dDblcjt27d+PBgwfYunUrWlpaYDabYTAYLAGWuuDgYADA3bt38e3bNzQ0NFhd8/n4+ECn06GxsREGgwGurq5IS0vDtWvXcPHiRXR2dqKmpgYpKSkYN24cNm3aNOLH0dLSgqKiIuj1evT09KC8vBzJyckIDg5GSkrK8BUaxLudARkMBiYnJ9PX15dqtZqxsbHcu3cvAVCr1bKqqoo5OTkMCAggACqVSq5cuZKNjY2MiYmht7c3XV1dGRgYyD179rC3t9eydm5uLiMiIqhQKKhQKBgZGcm8vDxmZmbSw8ODABgUFMSCggKStFknOzubSqWSABgSEsKHDx/yyJEj9PLyIgD6+/vz0qVLLCoqor+/PwHQ29ubhYWFNtfLy8uzrDdp0iS+e/eOZ86coaenJwFwwoQJrK+vJ0nu2rWLPj4+1Gg0XLduHXNzcwmAYWFhlnepEyZMoIeHB2NjY9na2kqz2cxjx45x0qRJdHNzo7e3N9esWcM3b95YHpeBjn8wysvLOX/+fI4bN44ACIABAQGMiYlhWVmZZb+0tDSGhYVRpVJx1KhR1Gq13LhxI3U63aBr2ns3LSP7/w+o77tQ+Af/P1ZwHjv5El+jLEiHCOMfpK6uzuZHvX7+SUxMdHarNo3op3YEx5oyZcp/+vJKnBkFyRBhFCRDhFGQDBFGQTJEGAXJEGEUJEOEUZAMEUZBMkQYBckQYRQkQ4RRkAwRRkEyRBgFyRBhFCRjwI+QrVu3biT7EP4Sfbc222J1ZgwKCsLatWsd2pDw99JqtQPmy+oeGEFwEnEPjCAdIoyCZIgwCpIhwihIxj+MoZR4lQWJcAAAAABJRU5ErkJggg==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"eowfefeOzmGv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"w_Fflm-Z24Sx","executionInfo":{"status":"error","timestamp":1614204113516,"user_tz":300,"elapsed":689,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"7bf10cdb-52e5-46bb-950d-d04ea7625ae5"},"source":["# Declarations\r\n","epochs = 10\r\n","latent_dim = 96\r\n","batch_size = 1\r\n","G_FEAT = [96, 256, 256, 256, 128, 128, 128, 3]\r\n","D_FEAT = [3, 64, 128, 256, 512, 1024]\r\n","# DEGREES = [1, 2, 2, 2, 2, 2, 64]\r\n","DEGREES = [1, 2, 2, 2, 2, 3, 64] # (2^4)(3)(64) = 3072\r\n","support = 10\r\n","lambdaGP = 10\r\n","D_iter = 2\r\n","\r\n","\r\n","\r\n","G = Generator(batch_size=batch_size, features=G_FEAT, degrees=DEGREES, support=support)\r\n","D = Discriminator(batch_size=batch_size, features=D_FEAT)\r\n","\r\n","GP = GradientPenalty(lambdaGP, gamma=1)\r\n","\r\n","print(\"Network Prepared\")\r\n","\r\n","def run(G, D, GP): # Add arguments for whether to save/load data\r\n","  # Add option to load trained model parameters\r\n","\r\n","\r\n","  #training loop (for one epoch)\r\n","  for epoch in range(epochs):\r\n","    for _iter, data in enumerate(male_30):\r\n","      # Start Time\r\n","      start_time = time.time()\r\n","      point = data\r\n","      # point = point.to(self.args.device)\r\n","    # for batch in range(batch_size):\r\n","    #   start_time = time.time()\r\n","      # half_batch = int (batch_size / 2)\r\n","      half_batch = 1\r\n","\r\n","      # -------Discriminator------- #\r\n","      d_loss_sum = 0\r\n","      for iter in range(D_iter):\r\n","        latent = np.random.randn(latent_dim * half_batch)\r\n","        latent = latent.reshape(half_batch, 1, latent_dim)\r\n","        # fake_point = G.predict(latent) # will generator run through multiple point array?\r\n","        fake_point = G([latent]) # will generator run through multiple point array?\r\n","\r\n","        print(f\"shape fake point: {str(fake_point.shape)}\")\r\n","        fake_labels = np.zeros((half_batch, 1))\r\n","\r\n","        # Need to generate real samples and labels of 1\r\n","        real_labels = np.ones(1) # come back to this\r\n","\r\n","        D_real = D(point)\r\n","        D_realm = D_real.mean()\r\n","\r\n","        D_fake = D(fake_point)\r\n","        D_fakem = D_fake.mean()\r\n","\r\n","        gp_loss = GP(D, point, fake_point)\r\n","                    \r\n","        d_loss = -D_realm + D_fakem\r\n","        d_loss_gp = d_loss + gp_loss\r\n","        d_loss_gp.backward()\r\n","          \r\n","          \r\n","          \r\n","        d_loss_sum += d_loss\r\n","      epoch_d_loss = d_loss_sum / D_iter\r\n","      print(epoch_d_loss)\r\n","\r\n","run(G, D, GP)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["layer num : 0\n","printing root network\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_7 (Dense)              (None, 256)               24576     \n","=================================================================\n","Total params: 24,576\n","Trainable params: 24,576\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","printing loop network\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_8 (Dense)              (None, 960)               92160     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 256)               245760    \n","=================================================================\n","Total params: 337,920\n","Trainable params: 337,920\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","layer num : 1\n","printing root network\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_10 (Dense)             (None, 256)               24576     \n","=================================================================\n","Total params: 24,576\n","Trainable params: 24,576\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_11 (Dense)             (None, 256)               65536     \n","=================================================================\n","Total params: 65,536\n","Trainable params: 65,536\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","printing loop network\n","Model: \"sequential_11\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_12 (Dense)             (None, 2560)              655360    \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","layer num : 2\n","printing root network\n","Model: \"sequential_12\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_14 (Dense)             (None, 256)               24576     \n","=================================================================\n","Total params: 24,576\n","Trainable params: 24,576\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_13\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_15 (Dense)             (None, 256)               65536     \n","=================================================================\n","Total params: 65,536\n","Trainable params: 65,536\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_14\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_16 (Dense)             (None, 256)               65536     \n","=================================================================\n","Total params: 65,536\n","Trainable params: 65,536\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","printing loop network\n","Model: \"sequential_15\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_17 (Dense)             (None, 2560)              655360    \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 256)               655360    \n","=================================================================\n","Total params: 1,310,720\n","Trainable params: 1,310,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","layer num : 3\n","printing root network\n","Model: \"sequential_16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_19 (Dense)             (None, 128)               12288     \n","=================================================================\n","Total params: 12,288\n","Trainable params: 12,288\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_17\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_20 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_18\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_21 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_22 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","printing loop network\n","Model: \"sequential_20\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_23 (Dense)             (None, 2560)              655360    \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 128)               327680    \n","=================================================================\n","Total params: 983,040\n","Trainable params: 983,040\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","layer num : 4\n","printing root network\n","Model: \"sequential_21\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_25 (Dense)             (None, 128)               12288     \n","=================================================================\n","Total params: 12,288\n","Trainable params: 12,288\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_22\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_26 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_23\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_27 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_24\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_28 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_25\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_29 (Dense)             (None, 128)               16384     \n","=================================================================\n","Total params: 16,384\n","Trainable params: 16,384\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","printing loop network\n","Model: \"sequential_26\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_30 (Dense)             (None, 1280)              163840    \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","layer num : 5\n","printing root network\n","Model: \"sequential_27\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_32 (Dense)             (None, 128)               12288     \n","=================================================================\n","Total params: 12,288\n","Trainable params: 12,288\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_28\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_33 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_29\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_34 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_30\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_35 (Dense)             (None, 128)               32768     \n","=================================================================\n","Total params: 32,768\n","Trainable params: 32,768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_31\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_36 (Dense)             (None, 128)               16384     \n","=================================================================\n","Total params: 16,384\n","Trainable params: 16,384\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_32\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_37 (Dense)             (None, 128)               16384     \n","=================================================================\n","Total params: 16,384\n","Trainable params: 16,384\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","printing loop network\n","Model: \"sequential_33\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_38 (Dense)             (None, 1280)              163840    \n","_________________________________________________________________\n","dense_39 (Dense)             (None, 128)               163840    \n","=================================================================\n","Total params: 327,680\n","Trainable params: 327,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","layer num : 6\n","printing root network\n","Model: \"sequential_34\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_40 (Dense)             (None, 3)                 288       \n","=================================================================\n","Total params: 288\n","Trainable params: 288\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_35\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_41 (Dense)             (None, 3)                 768       \n","=================================================================\n","Total params: 768\n","Trainable params: 768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_36\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_42 (Dense)             (None, 3)                 768       \n","=================================================================\n","Total params: 768\n","Trainable params: 768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_37\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_43 (Dense)             (None, 3)                 768       \n","=================================================================\n","Total params: 768\n","Trainable params: 768\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_38\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_44 (Dense)             (None, 3)                 384       \n","=================================================================\n","Total params: 384\n","Trainable params: 384\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_39\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_45 (Dense)             (None, 3)                 384       \n","=================================================================\n","Total params: 384\n","Trainable params: 384\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Model: \"sequential_40\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_46 (Dense)             (None, 3)                 384       \n","=================================================================\n","Total params: 384\n","Trainable params: 384\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","printing loop network\n","Model: \"sequential_41\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_47 (Dense)             (None, 1280)              163840    \n","_________________________________________________________________\n","dense_48 (Dense)             (None, 3)                 3840      \n","=================================================================\n","Total params: 167,680\n","Trainable params: 167,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Network Prepared\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-a7972e2f65a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_d_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-21-a7972e2f65a3>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(G, D, GP)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m#training loop (for one epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmale_30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0;31m# Start Time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'male_30' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"_pCgqwv183Sx","executionInfo":{"status":"error","timestamp":1614203928052,"user_tz":300,"elapsed":4110,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"dcc1d1ee-2526-4820-b680-864ba3e45a77"},"source":["t1 = tf.ragged.constant([1, 2, 3, 4])\n","t15 = tf.ragged.constant([5, 6, 7, 8])\n","t2 = tf.ragged.constant([5, 6, 7])\n","rslt = tf.ragged.stack([t1, t2], axis=0)\n","rslt2 = tf.concat([t1, t2], axis=0)\n","print(\"Append\")\n","print(tf.append(t1, t2))\n","print(\"Stack:\")\n","print(rslt)\n","print(rslt.shape)\n","print(\"\\n\\nConcat:\")\n","print(rslt2)\n","print(rslt2.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Append\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-5be5f78c1edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrslt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Append\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stack:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrslt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'append'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPIyG_6L5Xcw","executionInfo":{"status":"ok","timestamp":1614202661447,"user_tz":300,"elapsed":369,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"aa3279dc-64eb-4b58-bd76-43def1d09cd9"},"source":["root_node = np.random.rand(1,96)\r\n","np.tile(root_node,(1,1, 0,))\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([], shape=(1, 1, 0), dtype=float64)"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wfa8z0H85ZHN","executionInfo":{"status":"ok","timestamp":1614202662400,"user_tz":300,"elapsed":275,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"ff47eab8-cd60-4140-f481-fb563c409c17"},"source":["batch_size = 1\r\n","z = torch.randn(batch_size, 1, 96)\r\n","z"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.8733, -0.0546,  2.2709,  0.0183,  0.9948, -0.2578, -0.0441,\n","           0.4027, -0.7995, -0.7677, -1.3520,  1.0531,  0.8074,  0.0935,\n","           0.8771, -0.3280, -0.3718,  0.8556,  0.9983,  1.4913, -0.2695,\n","          -0.6800, -1.0328,  0.9548,  0.3431,  2.1092, -0.7956,  1.8980,\n","           0.6018,  1.4046, -1.6744, -0.8126, -0.5736, -1.2721, -0.9579,\n","           0.8323, -0.4504, -0.7566,  0.4937, -0.9049, -0.8361,  2.0934,\n","          -1.0041,  0.9372, -0.0170,  1.0036, -0.9464,  1.1170, -0.6734,\n","           1.7174, -1.0596, -0.5771, -1.7171,  0.5099,  0.9728,  1.9991,\n","           1.1616, -2.5841, -1.2355, -0.0977,  0.9207,  1.5323, -3.2910,\n","          -0.4647,  0.9143, -0.2745, -0.2522,  0.5150,  1.1296, -0.6209,\n","          -0.3460, -0.5545, -0.1199,  1.2911,  1.0014,  1.5679, -1.0336,\n","           0.1151,  0.4952,  0.6442, -1.0836,  0.0331, -0.4824,  0.3427,\n","          -0.5273, -0.0797, -0.2759, -1.0274, -0.5612, -1.2850,  0.5042,\n","           0.3359, -0.1767, -0.5021,  0.8841, -0.3958]]])"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"E4IcClF_SrDS"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import math\n","from torchsummary import summary\n","\n","class TreeGCN2(nn.Module):\n","    def __init__(self, batch, depth, features, degrees, support=10, node=1, upsample=False, activation=True):\n","        self.batch = batch\n","        self.depth = depth\n","        self.in_feature = features[depth]\n","        self.out_feature = features[depth+1]\n","        self.node = node\n","        self.degree = degrees[depth]\n","        self.upsample = upsample\n","        self.activation = activation\n","        super(TreeGCN2, self).__init__()\n","\n","        self.W_root = nn.ModuleList([nn.Linear(features[inx], self.out_feature, bias=False) for inx in range(self.depth+1)])\n","\n","      \n","        if self.upsample:\n","            self.W_branch = nn.Parameter(torch.FloatTensor(self.node, self.in_feature, self.degree*self.in_feature))\n","        \n","        self.W_loop = nn.Sequential(nn.Linear(self.in_feature, self.in_feature*support, bias=False),\n","                                    nn.Linear(self.in_feature*support, self.out_feature, bias=False))\n","\n","        self.bias = nn.Parameter(torch.FloatTensor(1, self.degree, self.out_feature))\n","\n","        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n","\n","        self.init_param()\n","\n","    def init_param(self):\n","        if self.upsample:\n","            init.xavier_uniform_(self.W_branch.data, gain=init.calculate_gain('relu'))\n","\n","        stdv = 1. / math.sqrt(self.out_feature)\n","        self.bias.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, tree):\n","        root = 0\n","        for inx in range(self.depth+1):\n","            print(\"Tree Index: \", inx)\n","            root_num = tree[inx].size(1)\n","            repeat_num = int(self.node / root_num)\n","            root_node = self.W_root[inx](tree[inx])\n","            \n","            print(\"W_Root \" * 5)\n","            print(root_node)\n","            print(root_node.size())\n","            root = root + root_node.repeat(1,1,repeat_num).view(self.batch,-1,self.out_feature)\n","\n","        branch = 0\n","        if self.upsample:\n","            # print(\"BRANCH BEFORE: \", self.W_branch, self.W_branch.size())\n","            print(self.W_branch)\n","            branch = tree[-1].unsqueeze(2) @ self.W_branch\n","            print(\"BRANCH AFTER EXPAND DIMS: \", branch)\n","            branch = self.leaky_relu(branch)\n","            branch = branch.view(self.batch,self.node*self.degree,self.in_feature)\n","            print(\"BRANCH AFTER RESHAPE\")\n","            print(branch)\n","            branch = self.W_loop(branch)\n","            print(\"BRANCH AFTER W_LOOP\")\n","            print(branch)\n","\n","            branch = root.repeat(1,1,self.degree).view(self.batch,-1,self.out_feature) + branch\n","            print(\"BRANCH AFTER RE-TILE\")\n","            print(branch)\n","        else:\n","            branch = self.W_loop(tree[-1])\n","\n","            branch = root + branch\n","\n","        if self.activation:\n","            branch = self.leaky_relu(branch + self.bias.repeat(1,self.node,1))\n","        # print(\"BRANCH: \", branch)\n","        # print(branch.size())\n","        tree.append(branch)\n","        print(\"TREE: \", tree)\n","        # print(tree[self.degree].size(2))\n","\n","        return tree"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDfoJqx_qUph","executionInfo":{"status":"ok","timestamp":1614202664185,"user_tz":300,"elapsed":1169,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"3fc10773-8280-494e-8a87-ce2ac6a908b5"},"source":["import torch\r\n","e = torch.Tensor(np.random.rand(96,1)).size(1)\r\n","print(e)\r\n","torch.Tensor(np.random.rand(1,256)).repeat(1,1,e)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([[[8.8406e-01, 1.9698e-01, 6.4448e-01, 7.6747e-02, 1.1835e-01,\n","          7.1322e-01, 5.2173e-01, 2.2455e-01, 1.1613e-01, 6.1025e-01,\n","          9.0531e-01, 6.1741e-01, 4.4902e-01, 1.0194e-01, 8.4654e-01,\n","          3.7144e-02, 3.9426e-01, 2.9562e-01, 4.8583e-01, 2.6039e-01,\n","          2.5511e-01, 7.2638e-02, 1.0020e-01, 1.1377e-01, 2.4851e-01,\n","          6.3778e-01, 9.8248e-01, 4.2398e-01, 3.4107e-01, 9.0604e-01,\n","          6.1468e-01, 9.3168e-01, 5.7363e-01, 1.0410e-01, 5.7699e-01,\n","          2.5268e-01, 7.8311e-01, 3.1477e-02, 1.2948e-01, 2.8539e-01,\n","          7.5978e-01, 2.0567e-01, 4.0710e-01, 1.7996e-01, 3.5197e-01,\n","          4.3026e-01, 6.1660e-01, 3.4781e-01, 6.6200e-02, 3.1306e-01,\n","          6.0058e-01, 5.4066e-01, 9.5578e-01, 4.3579e-01, 7.3190e-01,\n","          5.9338e-01, 4.2013e-01, 5.9922e-01, 6.8946e-01, 4.6765e-01,\n","          1.0542e-01, 6.7928e-01, 2.9240e-01, 1.2834e-01, 8.7227e-01,\n","          1.6970e-01, 2.2152e-01, 1.1495e-02, 8.5221e-01, 1.6846e-01,\n","          7.8849e-01, 7.0620e-01, 5.5853e-01, 3.3302e-01, 3.8092e-01,\n","          7.4322e-01, 2.1888e-01, 6.4042e-01, 7.4875e-01, 7.1902e-01,\n","          8.1751e-01, 7.4254e-01, 9.5376e-01, 5.5526e-01, 3.6782e-01,\n","          2.0120e-01, 3.7632e-01, 5.2886e-02, 1.3724e-01, 5.6007e-01,\n","          7.3359e-01, 2.2056e-01, 4.4142e-01, 3.3114e-01, 5.3386e-01,\n","          6.3814e-01, 7.5952e-01, 4.2758e-01, 6.3987e-01, 5.9811e-01,\n","          9.0174e-01, 6.4115e-01, 3.2372e-01, 4.8541e-01, 7.2025e-01,\n","          4.0031e-01, 8.0158e-01, 1.3242e-01, 4.4194e-01, 2.8698e-01,\n","          8.1691e-01, 2.1891e-01, 1.0323e-01, 7.2995e-01, 8.3369e-01,\n","          2.8656e-01, 1.5994e-01, 5.2855e-01, 7.0896e-01, 9.7405e-01,\n","          2.8575e-01, 1.9367e-01, 8.6195e-01, 8.4270e-01, 4.0017e-01,\n","          9.6907e-01, 5.0765e-01, 6.2540e-02, 2.5256e-01, 7.3798e-01,\n","          3.0154e-01, 6.5964e-01, 3.3773e-01, 1.3107e-01, 9.9752e-01,\n","          6.7382e-01, 2.8578e-01, 7.3911e-02, 6.3192e-01, 9.8902e-01,\n","          9.5345e-01, 7.3954e-01, 8.2628e-01, 5.1289e-01, 2.2884e-01,\n","          8.4225e-01, 4.5911e-01, 3.9740e-01, 1.6627e-01, 4.6144e-01,\n","          2.1752e-01, 4.4113e-01, 5.5605e-01, 7.3393e-01, 2.5208e-01,\n","          5.1320e-01, 6.6893e-01, 6.9970e-01, 6.8059e-01, 3.3336e-01,\n","          1.9722e-01, 6.4070e-01, 8.6423e-01, 7.9444e-02, 7.3833e-01,\n","          7.3947e-01, 4.3606e-01, 9.6083e-01, 9.3593e-01, 9.8750e-01,\n","          7.2673e-01, 4.8329e-02, 7.6830e-01, 9.0689e-01, 5.5767e-01,\n","          6.3283e-01, 7.3342e-01, 7.8576e-01, 6.6195e-02, 4.6928e-01,\n","          2.1048e-01, 4.8001e-01, 5.0739e-01, 5.8472e-02, 9.8018e-02,\n","          4.7511e-01, 9.4072e-01, 1.3461e-01, 7.4212e-01, 2.6035e-01,\n","          3.8840e-01, 9.0441e-01, 8.5186e-01, 6.5166e-01, 5.7998e-01,\n","          4.3702e-01, 7.8550e-01, 3.3006e-02, 9.2545e-01, 7.3448e-01,\n","          8.4142e-02, 3.9975e-01, 4.8384e-01, 2.5515e-01, 6.1807e-01,\n","          2.2535e-01, 6.9036e-01, 7.0667e-01, 8.8130e-01, 8.4401e-01,\n","          7.9483e-01, 7.4742e-01, 7.3224e-02, 2.0990e-02, 4.2454e-01,\n","          9.6045e-01, 4.5735e-03, 8.1674e-01, 5.9992e-01, 6.2254e-01,\n","          8.9432e-01, 5.9984e-01, 2.8935e-01, 8.4643e-01, 2.0276e-01,\n","          5.1703e-01, 2.6577e-02, 2.8752e-02, 5.4179e-02, 5.3033e-01,\n","          1.9217e-01, 8.7399e-01, 5.2069e-01, 7.4916e-01, 7.3333e-02,\n","          1.2515e-01, 8.4781e-01, 1.6007e-02, 2.0769e-01, 2.1426e-02,\n","          2.8118e-01, 9.5898e-01, 4.0538e-02, 5.1811e-01, 3.4048e-01,\n","          6.3072e-01, 3.7267e-02, 8.2496e-01, 4.8666e-01, 1.2799e-01,\n","          1.5878e-01, 7.7951e-01, 3.2695e-04, 6.2564e-01, 3.4212e-01,\n","          7.9297e-01]]])"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPFvZM8OsoQG","executionInfo":{"status":"ok","timestamp":1614205801531,"user_tz":300,"elapsed":481,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"48324328-0386-4b60-a6e4-f6e6a6e676b8"},"source":["b_size = 1\r\n","depth = 0\r\n","features = [96, 256, 256, 256, 128, 128, 128, 3]\r\n","degrees = [1, 2, 2, 2, 2, 3, 64]\r\n","support = 10\r\n","node = 1\r\n","\r\n","model = nn.Sequential()\r\n","model.add_module('TreeGCN_1', TreeGCN2(b_size, depth, features, degrees, \r\n","                                          support=support, node=node, upsample=True, activation=True))\r\n","model.add_module('TreeGCN_2', TreeGCN2(b_size, 1, features, degrees, \r\n","                                        support=support, node=96, upsample=True, activation=False))\r\n","\r\n","z = torch.randn(1, 1, 96).to('cpu')\r\n","\r\n","tree = [z]\r\n","print(tree)\r\n","\r\n","rslt = model(tree)\r\n","# print(rslt[2].size())\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[tensor([[[-0.5592,  0.7195,  0.0902, -0.7645,  0.5009,  0.9356,  1.1576,\n","           0.0895,  0.0499,  1.3580,  0.9120,  0.1221, -1.2000,  0.2125,\n","          -0.6897,  1.3398, -0.2230, -0.1560,  1.1665, -2.5133,  0.3422,\n","           2.0728,  0.0940, -0.5081,  0.7896,  0.7702, -2.9093, -0.8321,\n","          -0.0458, -0.3320,  1.3263,  0.1174, -2.0827,  1.2304, -1.6795,\n","          -0.2438,  1.4297, -1.4262, -1.2684, -1.4513,  0.9206,  0.2446,\n","           1.7557, -0.3561, -1.1258, -0.6415, -1.8889,  1.5338,  2.2119,\n","          -0.0136,  1.5002, -0.8671, -0.1292, -0.3307,  1.2108, -0.7479,\n","          -1.8422, -1.0137,  2.4267,  0.7600,  2.0832, -1.7096,  1.8181,\n","          -1.8974,  2.6776, -1.3456, -0.9727, -1.4971,  0.1858,  0.1951,\n","          -1.1137, -0.8314,  1.2338,  0.0291,  1.0746, -0.3362, -1.2208,\n","           1.2026, -1.2525,  1.8656,  1.0375,  0.1856,  1.9435,  0.8650,\n","           0.3755,  1.3335, -0.6190, -0.6345,  0.0618, -0.0166,  0.4907,\n","          -1.2111, -0.1377,  1.4718,  0.3810, -0.2304]]])]\n","Tree Index:  tensor([[[-0.5592,  0.7195,  0.0902, -0.7645,  0.5009,  0.9356,  1.1576,\n","           0.0895,  0.0499,  1.3580,  0.9120,  0.1221, -1.2000,  0.2125,\n","          -0.6897,  1.3398, -0.2230, -0.1560,  1.1665, -2.5133,  0.3422,\n","           2.0728,  0.0940, -0.5081,  0.7896,  0.7702, -2.9093, -0.8321,\n","          -0.0458, -0.3320,  1.3263,  0.1174, -2.0827,  1.2304, -1.6795,\n","          -0.2438,  1.4297, -1.4262, -1.2684, -1.4513,  0.9206,  0.2446,\n","           1.7557, -0.3561, -1.1258, -0.6415, -1.8889,  1.5338,  2.2119,\n","          -0.0136,  1.5002, -0.8671, -0.1292, -0.3307,  1.2108, -0.7479,\n","          -1.8422, -1.0137,  2.4267,  0.7600,  2.0832, -1.7096,  1.8181,\n","          -1.8974,  2.6776, -1.3456, -0.9727, -1.4971,  0.1858,  0.1951,\n","          -1.1137, -0.8314,  1.2338,  0.0291,  1.0746, -0.3362, -1.2208,\n","           1.2026, -1.2525,  1.8656,  1.0375,  0.1856,  1.9435,  0.8650,\n","           0.3755,  1.3335, -0.6190, -0.6345,  0.0618, -0.0166,  0.4907,\n","          -1.2111, -0.1377,  1.4718,  0.3810, -0.2304]]])\n","W_Root W_Root W_Root W_Root W_Root \n","tensor([[[ 8.3562e-01,  1.9869e-01,  3.9870e-01,  8.1843e-01, -1.5585e+00,\n","           1.0127e+00, -1.1335e+00, -9.2384e-01, -8.3172e-01, -1.5718e-01,\n","          -4.8662e-01, -3.6405e-01, -6.4894e-02,  5.6619e-01,  1.3410e-01,\n","          -7.9907e-01,  1.6092e-01, -6.8953e-01, -7.3494e-01, -2.1285e-02,\n","          -5.8759e-01,  5.7415e-02, -7.1600e-02,  7.8471e-01, -3.7380e-01,\n","          -5.4131e-01,  3.0269e-02, -3.5236e-01, -7.0772e-01,  3.1647e-01,\n","           7.0987e-01,  3.8555e-01, -3.2212e-01, -7.9960e-02, -4.3333e-01,\n","           2.9259e-01, -1.6460e-01, -5.3712e-01, -1.9449e+00, -3.0151e-02,\n","           1.4277e+00, -4.5824e-01,  5.0351e-02,  1.5465e-01, -5.2242e-01,\n","          -1.6185e-01, -3.0622e-01, -1.1010e+00,  8.0394e-01, -7.3121e-02,\n","          -1.7137e-01, -2.0421e-01,  4.1514e-01,  1.7229e-01,  2.3542e-01,\n","           7.0957e-01, -5.9354e-01, -4.8630e-01, -6.6921e-02,  4.1319e-01,\n","          -1.7753e+00,  4.0206e-01,  1.2464e-01,  7.5623e-01, -2.8473e-01,\n","           9.2237e-01,  2.0305e-01,  5.1613e-01,  4.3203e-01, -4.5132e-01,\n","          -5.9265e-01,  1.4119e+00,  2.1639e-01, -3.8986e-01, -7.5980e-01,\n","          -3.1975e-02,  9.3111e-01,  3.4701e-01,  1.0647e+00,  1.5111e-02,\n","           4.4354e-01, -1.0424e+00, -8.3812e-02,  1.7336e-01, -4.6614e-01,\n","           2.1216e-01,  2.2777e-01, -1.0137e-01,  1.7596e-01,  9.1158e-01,\n","           9.2447e-01, -9.9413e-01, -5.9796e-01, -2.1892e-01, -8.9624e-01,\n","          -1.4176e+00, -2.5196e-01,  4.8970e-01, -1.0148e+00, -3.7422e-01,\n","          -1.4933e-01,  1.9247e+00, -3.1681e-01, -1.2090e-01, -3.9777e-01,\n","           1.1370e+00,  1.8880e-02,  1.1204e+00,  1.0493e+00, -3.5860e-02,\n","           4.3025e-01,  8.4700e-02, -2.0739e-01, -5.2657e-01, -3.5613e-02,\n","          -4.6451e-01, -2.2147e-01,  5.2646e-01, -5.7434e-03,  3.9012e-01,\n","          -4.9380e-01, -4.3631e-01,  4.3130e-01, -9.0256e-01, -1.9992e-02,\n","           1.6688e+00, -7.4412e-01, -5.9519e-01, -3.7151e-01,  9.0394e-02,\n","           5.0265e-01, -5.0659e-01, -8.8655e-02,  1.2395e-01, -1.8868e+00,\n","           4.1060e-02, -1.0974e+00, -8.3820e-01, -1.4841e+00,  5.6109e-01,\n","          -1.4296e+00,  2.4729e-01,  1.8158e+00,  5.6922e-01,  2.0911e-01,\n","          -5.4179e-01,  9.1288e-01,  2.4321e-01, -1.0213e+00, -3.8915e-02,\n","           4.7277e-01,  9.1443e-01,  8.6340e-01, -3.8543e-01,  2.6349e-01,\n","          -1.5365e-02,  6.2782e-01, -6.2307e-01, -4.5657e-01,  5.2373e-01,\n","          -1.0135e-01,  1.4490e+00,  9.0904e-02,  5.5717e-01, -6.3384e-02,\n","           1.6826e-02, -7.8436e-01,  5.6069e-01,  1.2325e+00, -4.0958e-01,\n","          -9.0217e-01, -4.7990e-01,  1.0041e+00, -4.5844e-01, -6.1507e-01,\n","          -7.3363e-01,  6.7342e-01, -1.1775e+00, -1.0319e-01, -5.6197e-01,\n","           3.9024e-02,  6.5308e-01,  1.2353e+00,  5.3374e-01, -3.0585e-01,\n","           5.3483e-01, -3.8243e-01, -3.7046e-01, -2.1990e-01,  6.2824e-01,\n","          -1.8289e-03, -9.1339e-01, -7.8721e-01, -3.3664e-02, -5.9925e-01,\n","          -5.4716e-02,  1.4787e+00, -3.4679e-01,  2.5834e-01, -1.0596e+00,\n","           1.0267e+00, -6.9575e-01,  1.5756e+00, -4.0355e-01, -4.4600e-01,\n","          -3.8896e-01,  2.0116e+00,  4.3818e-01, -1.3672e-01,  9.8707e-01,\n","           6.7349e-02,  9.6246e-02,  2.5925e-01,  1.4411e-01, -4.2480e-01,\n","           2.6576e-01, -9.5225e-01, -4.3775e-01, -6.8355e-01,  1.1648e+00,\n","          -1.2744e+00,  5.4099e-01,  1.2666e+00,  2.9273e-01, -6.6129e-01,\n","           5.8387e-01, -5.4672e-01, -2.1382e-01, -6.6843e-01, -3.3133e-01,\n","          -3.7760e-02, -1.3176e+00,  1.5558e-01,  3.6012e-01, -2.2250e-01,\n","          -6.2221e-01,  5.0540e-01, -6.9961e-01,  6.8401e-01, -3.6396e-01,\n","          -6.3539e-01,  3.0320e-01,  1.6058e+00,  7.9362e-01, -4.5705e-01,\n","           9.9667e-01,  4.0589e-01, -1.0236e+00, -6.5998e-01, -7.2058e-01,\n","           8.0484e-01,  6.4665e-03, -1.7013e-01,  1.7147e+00,  3.3207e-02,\n","           1.2361e+00]]], grad_fn=<UnsafeViewBackward>)\n","torch.Size([1, 1, 256])\n","BRANCH BEFORE:  Parameter containing:\n","tensor([[[ 0.0101,  0.0173,  0.0292,  ...,  0.0081,  0.0068, -0.0116],\n","         [ 0.0290, -0.0047,  0.0073,  ..., -0.0300,  0.0007, -0.0238],\n","         [ 0.0046,  0.0118, -0.0228,  ..., -0.0311,  0.0044, -0.0285],\n","         ...,\n","         [ 0.0019,  0.0169, -0.0126,  ..., -0.0125, -0.0189,  0.0202],\n","         [ 0.0050, -0.0012,  0.0301,  ..., -0.0313,  0.0344,  0.0313],\n","         [-0.0317, -0.0022,  0.0098,  ..., -0.0235,  0.0073,  0.0169]]],\n","       requires_grad=True) torch.Size([1, 96, 96])\n","BRANCH AFTER:  Parameter containing:\n","tensor([[[ 0.0101,  0.0173,  0.0292,  ...,  0.0081,  0.0068, -0.0116],\n","         [ 0.0290, -0.0047,  0.0073,  ..., -0.0300,  0.0007, -0.0238],\n","         [ 0.0046,  0.0118, -0.0228,  ..., -0.0311,  0.0044, -0.0285],\n","         ...,\n","         [ 0.0019,  0.0169, -0.0126,  ..., -0.0125, -0.0189,  0.0202],\n","         [ 0.0050, -0.0012,  0.0301,  ..., -0.0313,  0.0344,  0.0313],\n","         [-0.0317, -0.0022,  0.0098,  ..., -0.0235,  0.0073,  0.0169]]],\n","       requires_grad=True) torch.Size([1, 96, 96])\n","BRANCH:  tensor([[[ 0.7358,  0.1693,  0.4479,  0.7351, -0.3110,  0.9803, -0.2274,\n","          -0.1966, -0.1583, -0.0321, -0.1076, -0.0604, -0.0144,  0.5510,\n","           0.1015, -0.1812,  0.2557, -0.1325, -0.1648,  0.0095, -0.1101,\n","          -0.0124, -0.0048,  0.8342, -0.0684, -0.1245,  0.0749, -0.0597,\n","          -0.1251,  0.3170,  0.7090,  0.4599, -0.0623, -0.0302, -0.0786,\n","           0.2874, -0.0174, -0.1008, -0.3807, -0.0070,  1.4262, -0.1077,\n","           0.0309,  0.0958, -0.1032, -0.0231, -0.0771, -0.2092,  0.8505,\n","          -0.0328, -0.0196, -0.0375,  0.3615,  0.1830,  0.3542,  0.6663,\n","          -0.1111, -0.0985, -0.0265,  0.2768, -0.3380,  0.4356,  0.0755,\n","           0.7967, -0.0367,  1.0447,  0.2533,  0.5097,  0.4157, -0.0946,\n","          -0.1063,  1.4655,  0.2084, -0.0864, -0.1352, -0.0208,  0.8515,\n","           0.3666,  0.9740,  0.0206,  0.3751, -0.1906, -0.0149,  0.2276,\n","          -0.1120,  0.2272,  0.2680,  0.0632,  0.2179,  0.9969,  0.9550,\n","          -0.1952, -0.1177, -0.0458, -0.1727, -0.2851, -0.0605,  0.4244,\n","          -0.1858, -0.0790, -0.0148,  1.9164, -0.0610, -0.0523, -0.0450,\n","           1.1191,  0.1232,  1.2442,  0.9286, -0.0510,  0.4186,  0.0692,\n","          -0.0286, -0.1100,  0.0120, -0.0623, -0.0383,  0.4155,  0.0359,\n","           0.4415, -0.0888, -0.0813,  0.5011, -0.1869,  0.0357,  1.5522,\n","          -0.1511, -0.1071, -0.0404, -0.0021,  0.4934, -0.1180, -0.0260,\n","           0.1476, -0.4001,  0.0631, -0.2233, -0.1715, -0.2968,  0.5482,\n","          -0.2770,  0.2900,  1.7649,  0.5198,  0.2039, -0.0979,  0.8643,\n","           0.3092, -0.2138, -0.0123,  0.3981,  0.8008,  0.8972, -0.0632,\n","           0.3875,  0.0528,  0.6652, -0.1248, -0.0768,  0.4964, -0.0301,\n","           1.4712,  0.1098,  0.6611, -0.0260, -0.0185, -0.1572,  0.5201,\n","           1.2694, -0.0862, -0.1765, -0.0975,  1.0323, -0.0987, -0.1003,\n","          -0.1628,  0.6909, -0.2399, -0.0345, -0.1182,  0.0609,  0.6563,\n","           1.3359,  0.5535, -0.0535,  0.6260, -0.0732, -0.0902, -0.0624,\n","           0.6456,  0.0528, -0.1955, -0.1698, -0.0247, -0.1138, -0.0052,\n","           1.5242, -0.0878,  0.2992, -0.2155,  1.0760, -0.1222,  1.6512,\n","          -0.0907, -0.0956, -0.0698,  1.9884,  0.3114, -0.0512,  0.9575,\n","           0.0495,  0.0540,  0.2020,  0.1658, -0.0627,  0.2027, -0.1944,\n","          -0.0871, -0.1546,  1.2768, -0.2475,  0.5590,  1.3347,  0.3842,\n","          -0.1542,  0.5490, -0.1324, -0.0266, -0.1164, -0.0479, -0.0062,\n","          -0.2520,  0.1501,  0.3951, -0.0373, -0.1160,  0.4953, -0.1435,\n","           0.7051, -0.0651, -0.1415,  0.2818,  1.6788,  0.8235, -0.1163,\n","           0.9233,  0.5002, -0.2065, -0.1344, -0.1568,  0.9962, -0.0039,\n","          -0.0212,  1.6511,  0.0722,  1.1950]]], grad_fn=<LeakyReluBackward0>)\n","torch.Size([1, 1, 256])\n","TREE:  [tensor([[[-0.5592,  0.7195,  0.0902, -0.7645,  0.5009,  0.9356,  1.1576,\n","           0.0895,  0.0499,  1.3580,  0.9120,  0.1221, -1.2000,  0.2125,\n","          -0.6897,  1.3398, -0.2230, -0.1560,  1.1665, -2.5133,  0.3422,\n","           2.0728,  0.0940, -0.5081,  0.7896,  0.7702, -2.9093, -0.8321,\n","          -0.0458, -0.3320,  1.3263,  0.1174, -2.0827,  1.2304, -1.6795,\n","          -0.2438,  1.4297, -1.4262, -1.2684, -1.4513,  0.9206,  0.2446,\n","           1.7557, -0.3561, -1.1258, -0.6415, -1.8889,  1.5338,  2.2119,\n","          -0.0136,  1.5002, -0.8671, -0.1292, -0.3307,  1.2108, -0.7479,\n","          -1.8422, -1.0137,  2.4267,  0.7600,  2.0832, -1.7096,  1.8181,\n","          -1.8974,  2.6776, -1.3456, -0.9727, -1.4971,  0.1858,  0.1951,\n","          -1.1137, -0.8314,  1.2338,  0.0291,  1.0746, -0.3362, -1.2208,\n","           1.2026, -1.2525,  1.8656,  1.0375,  0.1856,  1.9435,  0.8650,\n","           0.3755,  1.3335, -0.6190, -0.6345,  0.0618, -0.0166,  0.4907,\n","          -1.2111, -0.1377,  1.4718,  0.3810, -0.2304]]]), tensor([[[ 0.7358,  0.1693,  0.4479,  0.7351, -0.3110,  0.9803, -0.2274,\n","          -0.1966, -0.1583, -0.0321, -0.1076, -0.0604, -0.0144,  0.5510,\n","           0.1015, -0.1812,  0.2557, -0.1325, -0.1648,  0.0095, -0.1101,\n","          -0.0124, -0.0048,  0.8342, -0.0684, -0.1245,  0.0749, -0.0597,\n","          -0.1251,  0.3170,  0.7090,  0.4599, -0.0623, -0.0302, -0.0786,\n","           0.2874, -0.0174, -0.1008, -0.3807, -0.0070,  1.4262, -0.1077,\n","           0.0309,  0.0958, -0.1032, -0.0231, -0.0771, -0.2092,  0.8505,\n","          -0.0328, -0.0196, -0.0375,  0.3615,  0.1830,  0.3542,  0.6663,\n","          -0.1111, -0.0985, -0.0265,  0.2768, -0.3380,  0.4356,  0.0755,\n","           0.7967, -0.0367,  1.0447,  0.2533,  0.5097,  0.4157, -0.0946,\n","          -0.1063,  1.4655,  0.2084, -0.0864, -0.1352, -0.0208,  0.8515,\n","           0.3666,  0.9740,  0.0206,  0.3751, -0.1906, -0.0149,  0.2276,\n","          -0.1120,  0.2272,  0.2680,  0.0632,  0.2179,  0.9969,  0.9550,\n","          -0.1952, -0.1177, -0.0458, -0.1727, -0.2851, -0.0605,  0.4244,\n","          -0.1858, -0.0790, -0.0148,  1.9164, -0.0610, -0.0523, -0.0450,\n","           1.1191,  0.1232,  1.2442,  0.9286, -0.0510,  0.4186,  0.0692,\n","          -0.0286, -0.1100,  0.0120, -0.0623, -0.0383,  0.4155,  0.0359,\n","           0.4415, -0.0888, -0.0813,  0.5011, -0.1869,  0.0357,  1.5522,\n","          -0.1511, -0.1071, -0.0404, -0.0021,  0.4934, -0.1180, -0.0260,\n","           0.1476, -0.4001,  0.0631, -0.2233, -0.1715, -0.2968,  0.5482,\n","          -0.2770,  0.2900,  1.7649,  0.5198,  0.2039, -0.0979,  0.8643,\n","           0.3092, -0.2138, -0.0123,  0.3981,  0.8008,  0.8972, -0.0632,\n","           0.3875,  0.0528,  0.6652, -0.1248, -0.0768,  0.4964, -0.0301,\n","           1.4712,  0.1098,  0.6611, -0.0260, -0.0185, -0.1572,  0.5201,\n","           1.2694, -0.0862, -0.1765, -0.0975,  1.0323, -0.0987, -0.1003,\n","          -0.1628,  0.6909, -0.2399, -0.0345, -0.1182,  0.0609,  0.6563,\n","           1.3359,  0.5535, -0.0535,  0.6260, -0.0732, -0.0902, -0.0624,\n","           0.6456,  0.0528, -0.1955, -0.1698, -0.0247, -0.1138, -0.0052,\n","           1.5242, -0.0878,  0.2992, -0.2155,  1.0760, -0.1222,  1.6512,\n","          -0.0907, -0.0956, -0.0698,  1.9884,  0.3114, -0.0512,  0.9575,\n","           0.0495,  0.0540,  0.2020,  0.1658, -0.0627,  0.2027, -0.1944,\n","          -0.0871, -0.1546,  1.2768, -0.2475,  0.5590,  1.3347,  0.3842,\n","          -0.1542,  0.5490, -0.1324, -0.0266, -0.1164, -0.0479, -0.0062,\n","          -0.2520,  0.1501,  0.3951, -0.0373, -0.1160,  0.4953, -0.1435,\n","           0.7051, -0.0651, -0.1415,  0.2818,  1.6788,  0.8235, -0.1163,\n","           0.9233,  0.5002, -0.2065, -0.1344, -0.1568,  0.9962, -0.0039,\n","          -0.0212,  1.6511,  0.0722,  1.1950]]], grad_fn=<LeakyReluBackward0>)]\n","256\n","Tree Index:  tensor([[[-0.5592,  0.7195,  0.0902, -0.7645,  0.5009,  0.9356,  1.1576,\n","           0.0895,  0.0499,  1.3580,  0.9120,  0.1221, -1.2000,  0.2125,\n","          -0.6897,  1.3398, -0.2230, -0.1560,  1.1665, -2.5133,  0.3422,\n","           2.0728,  0.0940, -0.5081,  0.7896,  0.7702, -2.9093, -0.8321,\n","          -0.0458, -0.3320,  1.3263,  0.1174, -2.0827,  1.2304, -1.6795,\n","          -0.2438,  1.4297, -1.4262, -1.2684, -1.4513,  0.9206,  0.2446,\n","           1.7557, -0.3561, -1.1258, -0.6415, -1.8889,  1.5338,  2.2119,\n","          -0.0136,  1.5002, -0.8671, -0.1292, -0.3307,  1.2108, -0.7479,\n","          -1.8422, -1.0137,  2.4267,  0.7600,  2.0832, -1.7096,  1.8181,\n","          -1.8974,  2.6776, -1.3456, -0.9727, -1.4971,  0.1858,  0.1951,\n","          -1.1137, -0.8314,  1.2338,  0.0291,  1.0746, -0.3362, -1.2208,\n","           1.2026, -1.2525,  1.8656,  1.0375,  0.1856,  1.9435,  0.8650,\n","           0.3755,  1.3335, -0.6190, -0.6345,  0.0618, -0.0166,  0.4907,\n","          -1.2111, -0.1377,  1.4718,  0.3810, -0.2304]]])\n","W_Root W_Root W_Root W_Root W_Root \n","tensor([[[ 8.5895e-02, -1.5657e-02, -1.4502e-01, -1.0601e+00, -1.0472e+00,\n","          -2.0818e-01, -7.7935e-01, -1.1191e+00,  8.9103e-01, -1.4189e-01,\n","           1.4084e-01,  5.4037e-02,  1.0067e-01,  5.4170e-01,  1.3794e-01,\n","           9.6891e-01,  1.8892e-01, -9.1065e-01, -9.1044e-01,  2.4100e-01,\n","          -2.2347e-01, -2.8585e-01,  6.6929e-01, -1.3011e+00,  1.1844e-01,\n","           2.3479e-01, -8.7020e-01, -4.2015e-01, -4.8413e-01, -5.1018e-01,\n","          -2.2082e-01,  4.5502e-01, -4.3065e-01, -6.1389e-01,  3.7023e-01,\n","          -3.0614e-01,  1.8342e-01,  4.6578e-01, -2.0348e-01,  3.2187e-01,\n","          -3.6717e-01, -1.9093e+00,  5.3640e-01,  7.6829e-01, -6.1267e-01,\n","          -1.0292e+00, -1.2999e+00,  1.6844e-01, -1.5149e-02, -1.0149e+00,\n","           5.9340e-01, -3.6307e-02,  1.2928e+00, -5.7326e-01,  1.7270e-01,\n","           3.1023e-02,  2.6167e-01,  2.6904e-02,  3.4870e-01, -4.2686e-02,\n","           2.8671e-01, -1.2781e-01,  6.2187e-01, -7.1862e-01,  5.2075e-02,\n","           1.5261e-01, -6.4188e-01,  7.2079e-01,  2.8039e-01, -6.0153e-02,\n","          -1.3101e-01, -3.9757e-01,  6.3616e-01,  2.9241e-01,  7.6954e-01,\n","          -2.4122e-01, -6.4971e-01, -4.6636e-01,  6.7951e-01, -2.9277e-01,\n","           1.1348e-01,  2.7955e-01, -2.5272e-01, -3.3925e-01, -5.5802e-01,\n","          -7.4301e-02, -2.0840e-01, -3.3080e-01, -9.8008e-01,  5.7527e-01,\n","          -7.1723e-01, -1.3523e-01,  1.1316e+00,  4.3396e-01,  6.9942e-01,\n","          -2.3976e-01, -1.2525e+00, -1.2025e-01, -1.2285e-01, -2.0449e+00,\n","           1.2749e-01,  3.1427e-01,  1.2803e-02,  1.0473e+00,  1.2445e+00,\n","          -5.4093e-01,  2.3669e-01, -9.1277e-01, -7.8967e-01, -3.6277e-01,\n","           7.5381e-01, -5.4082e-01, -2.7382e-02,  4.1351e-01,  6.2755e-01,\n","           1.3990e-01,  1.8755e-01, -1.6992e-01, -9.2479e-01, -7.3789e-01,\n","          -1.2009e-02,  5.8485e-01,  4.2565e-01, -9.6737e-01,  1.1094e+00,\n","           1.0993e+00,  5.1602e-01, -7.7671e-01,  3.0005e-01,  8.2672e-01,\n","          -4.6916e-03, -5.4212e-01,  3.3470e-01,  6.8221e-01, -5.0245e-01,\n","          -1.5011e-01, -8.6996e-01,  3.1726e-01, -4.1423e-01,  4.4045e-01,\n","          -1.6502e-01, -3.4555e-01, -6.6074e-01,  5.7192e-01,  3.2457e-01,\n","           2.9618e-01, -5.1934e-01, -1.0227e-01, -3.3785e-01, -4.0607e-02,\n","          -3.2934e-01, -1.8523e-01, -4.5495e-01, -3.7570e-01,  2.2552e-01,\n","           1.6244e+00, -4.2897e-01,  9.8753e-01, -1.5731e+00,  3.8917e-01,\n","          -2.6064e-01, -3.5958e-01, -1.9880e-01, -7.4235e-03, -6.2910e-01,\n","          -1.2383e-01,  5.2019e-02, -1.1907e+00,  7.3507e-01, -3.3673e-01,\n","           3.5741e-02, -1.3696e-01, -5.6041e-02, -2.0774e-01, -1.3149e+00,\n","          -8.6845e-02, -6.4210e-01, -4.8157e-01, -3.6688e-02,  4.7459e-01,\n","          -4.3279e-01, -3.3234e-01, -8.0738e-01, -7.0541e-01,  9.9211e-01,\n","          -8.4913e-03,  3.8487e-01,  1.0933e+00,  3.0571e-01,  8.9228e-01,\n","          -5.6501e-01, -7.0814e-01,  1.2282e-01,  9.0230e-01,  5.0917e-01,\n","          -7.2095e-01,  6.2231e-02, -1.1940e+00, -1.5896e+00,  5.5854e-01,\n","           7.3437e-01,  1.5803e+00,  3.9454e-01, -1.2426e+00,  1.4072e+00,\n","           9.6111e-01, -7.7039e-01, -7.2836e-01,  1.0116e-01, -4.1100e-01,\n","          -7.7751e-01,  5.5220e-01,  7.8852e-02,  6.3170e-01,  4.4384e-01,\n","           1.5518e-01, -4.2336e-01, -9.1338e-01,  6.4291e-01,  4.3865e-01,\n","           1.0260e+00,  8.2971e-01,  1.0108e+00,  1.3953e-01,  5.5817e-01,\n","          -1.8932e-01, -4.4294e-01,  5.0869e-01,  8.4417e-01,  5.5836e-01,\n","          -2.3792e-01,  4.7869e-01, -4.2150e-01, -4.2971e-01, -2.5827e-01,\n","           1.9045e-02, -6.8510e-01, -9.5817e-01, -4.7656e-01,  1.4147e-01,\n","           2.5436e-01, -9.0583e-01,  9.7423e-01, -6.6736e-01,  5.9546e-02,\n","           6.6616e-01, -5.5760e-04,  3.0261e-01, -7.2143e-01,  7.6947e-01,\n","           7.3774e-01,  4.6427e-01, -2.3682e-01,  6.2044e-01,  7.1902e-01,\n","          -4.7867e-02]]], grad_fn=<UnsafeViewBackward>)\n","torch.Size([1, 1, 256])\n","Tree Index:  tensor([[[ 0.7358,  0.1693,  0.4479,  0.7351, -0.3110,  0.9803, -0.2274,\n","          -0.1966, -0.1583, -0.0321, -0.1076, -0.0604, -0.0144,  0.5510,\n","           0.1015, -0.1812,  0.2557, -0.1325, -0.1648,  0.0095, -0.1101,\n","          -0.0124, -0.0048,  0.8342, -0.0684, -0.1245,  0.0749, -0.0597,\n","          -0.1251,  0.3170,  0.7090,  0.4599, -0.0623, -0.0302, -0.0786,\n","           0.2874, -0.0174, -0.1008, -0.3807, -0.0070,  1.4262, -0.1077,\n","           0.0309,  0.0958, -0.1032, -0.0231, -0.0771, -0.2092,  0.8505,\n","          -0.0328, -0.0196, -0.0375,  0.3615,  0.1830,  0.3542,  0.6663,\n","          -0.1111, -0.0985, -0.0265,  0.2768, -0.3380,  0.4356,  0.0755,\n","           0.7967, -0.0367,  1.0447,  0.2533,  0.5097,  0.4157, -0.0946,\n","          -0.1063,  1.4655,  0.2084, -0.0864, -0.1352, -0.0208,  0.8515,\n","           0.3666,  0.9740,  0.0206,  0.3751, -0.1906, -0.0149,  0.2276,\n","          -0.1120,  0.2272,  0.2680,  0.0632,  0.2179,  0.9969,  0.9550,\n","          -0.1952, -0.1177, -0.0458, -0.1727, -0.2851, -0.0605,  0.4244,\n","          -0.1858, -0.0790, -0.0148,  1.9164, -0.0610, -0.0523, -0.0450,\n","           1.1191,  0.1232,  1.2442,  0.9286, -0.0510,  0.4186,  0.0692,\n","          -0.0286, -0.1100,  0.0120, -0.0623, -0.0383,  0.4155,  0.0359,\n","           0.4415, -0.0888, -0.0813,  0.5011, -0.1869,  0.0357,  1.5522,\n","          -0.1511, -0.1071, -0.0404, -0.0021,  0.4934, -0.1180, -0.0260,\n","           0.1476, -0.4001,  0.0631, -0.2233, -0.1715, -0.2968,  0.5482,\n","          -0.2770,  0.2900,  1.7649,  0.5198,  0.2039, -0.0979,  0.8643,\n","           0.3092, -0.2138, -0.0123,  0.3981,  0.8008,  0.8972, -0.0632,\n","           0.3875,  0.0528,  0.6652, -0.1248, -0.0768,  0.4964, -0.0301,\n","           1.4712,  0.1098,  0.6611, -0.0260, -0.0185, -0.1572,  0.5201,\n","           1.2694, -0.0862, -0.1765, -0.0975,  1.0323, -0.0987, -0.1003,\n","          -0.1628,  0.6909, -0.2399, -0.0345, -0.1182,  0.0609,  0.6563,\n","           1.3359,  0.5535, -0.0535,  0.6260, -0.0732, -0.0902, -0.0624,\n","           0.6456,  0.0528, -0.1955, -0.1698, -0.0247, -0.1138, -0.0052,\n","           1.5242, -0.0878,  0.2992, -0.2155,  1.0760, -0.1222,  1.6512,\n","          -0.0907, -0.0956, -0.0698,  1.9884,  0.3114, -0.0512,  0.9575,\n","           0.0495,  0.0540,  0.2020,  0.1658, -0.0627,  0.2027, -0.1944,\n","          -0.0871, -0.1546,  1.2768, -0.2475,  0.5590,  1.3347,  0.3842,\n","          -0.1542,  0.5490, -0.1324, -0.0266, -0.1164, -0.0479, -0.0062,\n","          -0.2520,  0.1501,  0.3951, -0.0373, -0.1160,  0.4953, -0.1435,\n","           0.7051, -0.0651, -0.1415,  0.2818,  1.6788,  0.8235, -0.1163,\n","           0.9233,  0.5002, -0.2065, -0.1344, -0.1568,  0.9962, -0.0039,\n","          -0.0212,  1.6511,  0.0722,  1.1950]]], grad_fn=<LeakyReluBackward0>)\n","W_Root W_Root W_Root W_Root W_Root \n","tensor([[[-0.2195, -0.0061,  0.0969, -0.0172, -0.1774,  0.1236,  0.7865,\n","           0.4428, -0.0019, -0.2733,  0.0505, -0.2505, -0.2647, -0.1628,\n","           0.4325,  0.0485,  0.1240,  0.1822, -0.1014, -0.4997,  0.4194,\n","          -0.1301,  0.0402,  0.1120, -0.2908, -0.1936, -0.2299,  0.2359,\n","           0.3248, -0.3201, -0.0627, -0.6148,  0.1362, -0.1920,  0.1214,\n","           0.3096,  0.4713, -0.1560, -0.4365, -0.0218,  0.1684, -0.8805,\n","           0.4391, -0.2973, -0.0238, -0.5776,  0.3871, -0.1376,  0.2925,\n","           0.0466, -0.2604, -0.2370, -0.3570, -0.2699,  0.0215, -0.3758,\n","           0.5582, -0.2734,  0.5947, -0.2008,  0.3776, -0.1651, -0.4957,\n","           0.5506,  0.1842,  0.1176, -0.1226, -0.1332,  0.0941, -0.1134,\n","          -0.3495,  0.1590, -0.6254,  0.2714,  0.0135,  0.0988, -0.0566,\n","          -0.1208, -0.2040, -0.1041, -0.0756, -0.1071, -0.1976, -0.0915,\n","           0.0729, -0.0405,  0.6323,  0.0084,  0.0643, -0.3706,  0.0831,\n","           0.1974,  0.6434, -0.0571, -0.2060,  0.0479, -0.3943, -0.2416,\n","          -0.2447,  0.0093,  0.0598,  0.1917, -0.0827,  0.1104,  0.3423,\n","          -0.4290,  0.1849, -0.3623,  0.2386, -0.0523,  0.3732, -0.1336,\n","           0.1235, -0.0810,  0.2163,  0.2913,  0.5911, -0.0701, -0.0464,\n","           0.1258, -0.0396, -0.4937,  0.6606,  0.3560,  0.2323, -0.0061,\n","          -0.0400,  0.1977, -0.1322,  0.7618, -0.4591,  0.0413, -0.1113,\n","          -0.7436, -0.3190,  0.2586,  0.1601, -0.5003,  0.7022,  0.7503,\n","           0.3822, -0.2817,  0.1133,  0.6671,  0.0131,  0.4957, -0.3232,\n","          -0.2277, -0.3768,  0.1207,  0.0076, -0.1634,  0.0559,  0.2184,\n","           0.7211,  0.0226, -0.0516, -0.0422,  0.0412, -0.2187, -0.0496,\n","          -0.2927, -0.3757, -0.1240,  0.1065, -0.1271, -0.3688, -0.1643,\n","          -0.0442,  0.4094, -0.6851, -0.2885, -0.1360,  0.0108, -0.1190,\n","          -0.0250,  0.2842,  0.0593,  0.0060, -0.0679,  0.4823,  0.1966,\n","           0.1207,  0.4893,  0.0053, -0.1340, -0.1090, -0.0857,  0.0826,\n","          -0.0960, -0.0271,  0.0420,  0.2161, -0.6203,  0.3163, -0.2139,\n","          -0.1438,  0.1778, -0.4530, -0.1484,  0.1807, -0.0032,  0.0274,\n","           0.3634,  0.0654,  0.4908,  0.1913,  0.0092, -0.3307, -0.4439,\n","           0.1412, -0.4124, -0.0424,  0.0406, -0.0349, -0.1577, -0.3039,\n","           0.2581, -0.0167, -0.2750, -0.4898, -0.2731,  0.1564, -0.3068,\n","          -0.3006,  0.3615, -0.3417,  0.2023, -0.1668, -0.3861,  0.2125,\n","           0.3584,  0.2551,  0.2482,  0.0045,  0.0437,  0.3436, -0.4432,\n","           0.0773, -0.1205,  0.3267, -0.0201,  0.1317,  0.4647,  0.2477,\n","           0.4494, -0.0410,  0.9509, -0.2554, -0.0091,  0.3874, -0.0996,\n","          -0.3959,  0.0966,  0.1368,  0.2212]]], grad_fn=<UnsafeViewBackward>)\n","torch.Size([1, 1, 256])\n","BRANCH BEFORE:  Parameter containing:\n","tensor([[[ 1.2852e-03, -1.5951e-03, -6.4173e-03,  ..., -5.0258e-03,\n","          -4.1718e-03,  2.9739e-03],\n","         [-5.8645e-03, -7.0546e-03, -2.7142e-03,  ..., -7.2061e-03,\n","           7.6615e-04, -5.8792e-03],\n","         [-1.1879e-05,  2.2752e-03,  1.1748e-03,  ...,  1.6394e-03,\n","          -1.3241e-03, -5.0064e-03],\n","         ...,\n","         [ 4.8801e-03, -6.9423e-03, -6.7744e-04,  ...,  3.5294e-03,\n","          -3.0165e-03, -3.2380e-03],\n","         [-6.1905e-04,  5.5283e-03,  1.3020e-03,  ..., -6.9714e-03,\n","           2.4444e-04, -1.6572e-03],\n","         [ 6.4606e-03, -5.9233e-03, -5.8016e-03,  ...,  1.9038e-03,\n","           3.9027e-03,  1.8205e-03]],\n","\n","        [[ 4.0169e-03, -8.0076e-03,  2.6991e-03,  ..., -3.7771e-03,\n","          -3.5036e-03, -2.1902e-03],\n","         [ 3.5199e-03, -4.6862e-03, -3.5464e-03,  ...,  2.0913e-03,\n","          -5.9452e-03,  5.9137e-03],\n","         [ 8.0451e-03,  6.8849e-03, -3.4756e-03,  ..., -6.0620e-03,\n","           4.6678e-03, -2.9761e-04],\n","         ...,\n","         [-1.7786e-03,  5.0447e-03, -7.8808e-03,  ..., -3.2263e-03,\n","           2.7528e-04,  1.2409e-03],\n","         [ 4.1325e-04, -1.1934e-03, -3.8841e-03,  ...,  1.0160e-03,\n","          -7.5488e-03,  5.4043e-03],\n","         [ 1.6837e-03,  6.3346e-03, -1.3269e-04,  ...,  5.8951e-03,\n","           3.6627e-03, -2.7404e-03]],\n","\n","        [[ 2.5319e-03,  2.8138e-03, -2.8059e-03,  ..., -6.8582e-04,\n","          -3.1352e-03, -7.6065e-03],\n","         [-3.3075e-05,  7.3808e-03, -1.5620e-03,  ...,  1.0983e-03,\n","          -4.9285e-03,  7.8801e-03],\n","         [ 4.8830e-03,  4.9176e-03, -2.4950e-03,  ..., -3.4431e-03,\n","          -7.7536e-03,  7.7116e-03],\n","         ...,\n","         [ 8.0323e-03, -4.8781e-03,  6.5505e-03,  ..., -7.9485e-03,\n","          -2.0797e-03,  6.0188e-03],\n","         [ 7.3967e-03, -4.7575e-03,  6.0650e-03,  ..., -8.3276e-04,\n","          -6.6591e-03, -6.0164e-03],\n","         [ 6.8381e-04,  4.9775e-03,  1.6232e-03,  ...,  4.8438e-03,\n","          -6.2987e-03,  3.2884e-03]],\n","\n","        ...,\n","\n","        [[ 3.1932e-03, -7.4681e-03, -6.1858e-04,  ..., -2.8758e-03,\n","           2.6285e-03,  7.3666e-03],\n","         [ 5.0239e-03, -6.5743e-03,  2.4796e-03,  ...,  3.7150e-03,\n","           6.8991e-04,  6.2734e-04],\n","         [ 8.1459e-03,  7.6440e-03, -2.4494e-04,  ...,  7.0166e-03,\n","           3.4987e-03, -5.3361e-03],\n","         ...,\n","         [-1.5973e-03,  2.7792e-03,  1.4110e-04,  ...,  8.1312e-04,\n","           3.0488e-03, -4.7955e-04],\n","         [-6.3627e-04, -5.6547e-03, -4.8981e-03,  ..., -6.5939e-03,\n","           2.3363e-04, -6.0020e-03],\n","         [-9.3765e-04,  6.5136e-03,  1.4198e-03,  ...,  1.7124e-03,\n","          -7.0472e-03, -1.5018e-03]],\n","\n","        [[ 6.4184e-03,  7.0658e-03,  7.3231e-04,  ...,  3.0979e-03,\n","          -2.2176e-03, -2.0056e-03],\n","         [-7.2944e-03, -6.4539e-03,  6.6004e-03,  ...,  1.6907e-03,\n","          -4.6634e-03, -5.6688e-03],\n","         [ 7.5333e-03,  7.4420e-03, -8.9683e-04,  ...,  7.7321e-03,\n","          -5.3744e-03, -6.8258e-03],\n","         ...,\n","         [ 5.8733e-03, -6.7130e-04,  7.1452e-03,  ..., -5.7123e-03,\n","          -8.0777e-03, -6.6401e-03],\n","         [ 3.7439e-03, -8.0016e-03, -8.0162e-04,  ..., -1.1465e-04,\n","           2.5994e-04, -6.6251e-03],\n","         [-5.5819e-03, -6.4214e-03, -6.6032e-03,  ..., -1.0820e-03,\n","          -6.8989e-03,  5.2123e-03]],\n","\n","        [[ 5.6921e-03,  4.6653e-03, -3.0449e-03,  ...,  8.1476e-03,\n","          -3.0293e-03, -8.9539e-04],\n","         [-4.9951e-03, -7.3817e-03, -4.0663e-03,  ...,  2.5544e-03,\n","           2.4626e-03,  2.4156e-03],\n","         [-5.0487e-03,  7.6467e-03,  6.7690e-03,  ..., -5.3323e-03,\n","           2.1704e-03,  5.5592e-03],\n","         ...,\n","         [-6.9513e-03,  5.4949e-03,  2.9309e-03,  ..., -3.2000e-03,\n","          -7.5751e-03,  1.5326e-03],\n","         [-4.4325e-03,  5.3693e-03, -5.8519e-03,  ..., -4.9482e-03,\n","           3.0744e-03,  4.8630e-04],\n","         [-4.3530e-03, -3.3101e-03, -6.0813e-03,  ..., -5.7220e-03,\n","           6.6196e-03,  7.7229e-03]]], requires_grad=True) torch.Size([96, 256, 512])\n","BRANCH AFTER:  Parameter containing:\n","tensor([[[ 1.2852e-03, -1.5951e-03, -6.4173e-03,  ..., -5.0258e-03,\n","          -4.1718e-03,  2.9739e-03],\n","         [-5.8645e-03, -7.0546e-03, -2.7142e-03,  ..., -7.2061e-03,\n","           7.6615e-04, -5.8792e-03],\n","         [-1.1879e-05,  2.2752e-03,  1.1748e-03,  ...,  1.6394e-03,\n","          -1.3241e-03, -5.0064e-03],\n","         ...,\n","         [ 4.8801e-03, -6.9423e-03, -6.7744e-04,  ...,  3.5294e-03,\n","          -3.0165e-03, -3.2380e-03],\n","         [-6.1905e-04,  5.5283e-03,  1.3020e-03,  ..., -6.9714e-03,\n","           2.4444e-04, -1.6572e-03],\n","         [ 6.4606e-03, -5.9233e-03, -5.8016e-03,  ...,  1.9038e-03,\n","           3.9027e-03,  1.8205e-03]],\n","\n","        [[ 4.0169e-03, -8.0076e-03,  2.6991e-03,  ..., -3.7771e-03,\n","          -3.5036e-03, -2.1902e-03],\n","         [ 3.5199e-03, -4.6862e-03, -3.5464e-03,  ...,  2.0913e-03,\n","          -5.9452e-03,  5.9137e-03],\n","         [ 8.0451e-03,  6.8849e-03, -3.4756e-03,  ..., -6.0620e-03,\n","           4.6678e-03, -2.9761e-04],\n","         ...,\n","         [-1.7786e-03,  5.0447e-03, -7.8808e-03,  ..., -3.2263e-03,\n","           2.7528e-04,  1.2409e-03],\n","         [ 4.1325e-04, -1.1934e-03, -3.8841e-03,  ...,  1.0160e-03,\n","          -7.5488e-03,  5.4043e-03],\n","         [ 1.6837e-03,  6.3346e-03, -1.3269e-04,  ...,  5.8951e-03,\n","           3.6627e-03, -2.7404e-03]],\n","\n","        [[ 2.5319e-03,  2.8138e-03, -2.8059e-03,  ..., -6.8582e-04,\n","          -3.1352e-03, -7.6065e-03],\n","         [-3.3075e-05,  7.3808e-03, -1.5620e-03,  ...,  1.0983e-03,\n","          -4.9285e-03,  7.8801e-03],\n","         [ 4.8830e-03,  4.9176e-03, -2.4950e-03,  ..., -3.4431e-03,\n","          -7.7536e-03,  7.7116e-03],\n","         ...,\n","         [ 8.0323e-03, -4.8781e-03,  6.5505e-03,  ..., -7.9485e-03,\n","          -2.0797e-03,  6.0188e-03],\n","         [ 7.3967e-03, -4.7575e-03,  6.0650e-03,  ..., -8.3276e-04,\n","          -6.6591e-03, -6.0164e-03],\n","         [ 6.8381e-04,  4.9775e-03,  1.6232e-03,  ...,  4.8438e-03,\n","          -6.2987e-03,  3.2884e-03]],\n","\n","        ...,\n","\n","        [[ 3.1932e-03, -7.4681e-03, -6.1858e-04,  ..., -2.8758e-03,\n","           2.6285e-03,  7.3666e-03],\n","         [ 5.0239e-03, -6.5743e-03,  2.4796e-03,  ...,  3.7150e-03,\n","           6.8991e-04,  6.2734e-04],\n","         [ 8.1459e-03,  7.6440e-03, -2.4494e-04,  ...,  7.0166e-03,\n","           3.4987e-03, -5.3361e-03],\n","         ...,\n","         [-1.5973e-03,  2.7792e-03,  1.4110e-04,  ...,  8.1312e-04,\n","           3.0488e-03, -4.7955e-04],\n","         [-6.3627e-04, -5.6547e-03, -4.8981e-03,  ..., -6.5939e-03,\n","           2.3363e-04, -6.0020e-03],\n","         [-9.3765e-04,  6.5136e-03,  1.4198e-03,  ...,  1.7124e-03,\n","          -7.0472e-03, -1.5018e-03]],\n","\n","        [[ 6.4184e-03,  7.0658e-03,  7.3231e-04,  ...,  3.0979e-03,\n","          -2.2176e-03, -2.0056e-03],\n","         [-7.2944e-03, -6.4539e-03,  6.6004e-03,  ...,  1.6907e-03,\n","          -4.6634e-03, -5.6688e-03],\n","         [ 7.5333e-03,  7.4420e-03, -8.9683e-04,  ...,  7.7321e-03,\n","          -5.3744e-03, -6.8258e-03],\n","         ...,\n","         [ 5.8733e-03, -6.7130e-04,  7.1452e-03,  ..., -5.7123e-03,\n","          -8.0777e-03, -6.6401e-03],\n","         [ 3.7439e-03, -8.0016e-03, -8.0162e-04,  ..., -1.1465e-04,\n","           2.5994e-04, -6.6251e-03],\n","         [-5.5819e-03, -6.4214e-03, -6.6032e-03,  ..., -1.0820e-03,\n","          -6.8989e-03,  5.2123e-03]],\n","\n","        [[ 5.6921e-03,  4.6653e-03, -3.0449e-03,  ...,  8.1476e-03,\n","          -3.0293e-03, -8.9539e-04],\n","         [-4.9951e-03, -7.3817e-03, -4.0663e-03,  ...,  2.5544e-03,\n","           2.4626e-03,  2.4156e-03],\n","         [-5.0487e-03,  7.6467e-03,  6.7690e-03,  ..., -5.3323e-03,\n","           2.1704e-03,  5.5592e-03],\n","         ...,\n","         [-6.9513e-03,  5.4949e-03,  2.9309e-03,  ..., -3.2000e-03,\n","          -7.5751e-03,  1.5326e-03],\n","         [-4.4325e-03,  5.3693e-03, -5.8519e-03,  ..., -4.9482e-03,\n","           3.0744e-03,  4.8630e-04],\n","         [-4.3530e-03, -3.3101e-03, -6.0813e-03,  ..., -5.7220e-03,\n","           6.6196e-03,  7.7229e-03]]], requires_grad=True) torch.Size([96, 256, 512])\n","BRANCH:  tensor([[[-0.1176, -0.0222, -0.0435,  ...,  0.7105,  0.8569,  0.1630],\n","         [-0.1341, -0.0322, -0.0432,  ...,  0.7220,  0.8573,  0.1534],\n","         [-0.1329, -0.0290, -0.0491,  ...,  0.7105,  0.8584,  0.1678],\n","         ...,\n","         [-0.1386, -0.0162, -0.0509,  ...,  0.7137,  0.8603,  0.1753],\n","         [-0.1468, -0.0162, -0.0419,  ...,  0.7082,  0.8580,  0.1803],\n","         [-0.1481, -0.0209, -0.0425,  ...,  0.7303,  0.8472,  0.1798]]],\n","       grad_fn=<AddBackward0>)\n","torch.Size([1, 192, 256])\n","TREE:  [tensor([[[-0.5592,  0.7195,  0.0902, -0.7645,  0.5009,  0.9356,  1.1576,\n","           0.0895,  0.0499,  1.3580,  0.9120,  0.1221, -1.2000,  0.2125,\n","          -0.6897,  1.3398, -0.2230, -0.1560,  1.1665, -2.5133,  0.3422,\n","           2.0728,  0.0940, -0.5081,  0.7896,  0.7702, -2.9093, -0.8321,\n","          -0.0458, -0.3320,  1.3263,  0.1174, -2.0827,  1.2304, -1.6795,\n","          -0.2438,  1.4297, -1.4262, -1.2684, -1.4513,  0.9206,  0.2446,\n","           1.7557, -0.3561, -1.1258, -0.6415, -1.8889,  1.5338,  2.2119,\n","          -0.0136,  1.5002, -0.8671, -0.1292, -0.3307,  1.2108, -0.7479,\n","          -1.8422, -1.0137,  2.4267,  0.7600,  2.0832, -1.7096,  1.8181,\n","          -1.8974,  2.6776, -1.3456, -0.9727, -1.4971,  0.1858,  0.1951,\n","          -1.1137, -0.8314,  1.2338,  0.0291,  1.0746, -0.3362, -1.2208,\n","           1.2026, -1.2525,  1.8656,  1.0375,  0.1856,  1.9435,  0.8650,\n","           0.3755,  1.3335, -0.6190, -0.6345,  0.0618, -0.0166,  0.4907,\n","          -1.2111, -0.1377,  1.4718,  0.3810, -0.2304]]]), tensor([[[ 0.7358,  0.1693,  0.4479,  0.7351, -0.3110,  0.9803, -0.2274,\n","          -0.1966, -0.1583, -0.0321, -0.1076, -0.0604, -0.0144,  0.5510,\n","           0.1015, -0.1812,  0.2557, -0.1325, -0.1648,  0.0095, -0.1101,\n","          -0.0124, -0.0048,  0.8342, -0.0684, -0.1245,  0.0749, -0.0597,\n","          -0.1251,  0.3170,  0.7090,  0.4599, -0.0623, -0.0302, -0.0786,\n","           0.2874, -0.0174, -0.1008, -0.3807, -0.0070,  1.4262, -0.1077,\n","           0.0309,  0.0958, -0.1032, -0.0231, -0.0771, -0.2092,  0.8505,\n","          -0.0328, -0.0196, -0.0375,  0.3615,  0.1830,  0.3542,  0.6663,\n","          -0.1111, -0.0985, -0.0265,  0.2768, -0.3380,  0.4356,  0.0755,\n","           0.7967, -0.0367,  1.0447,  0.2533,  0.5097,  0.4157, -0.0946,\n","          -0.1063,  1.4655,  0.2084, -0.0864, -0.1352, -0.0208,  0.8515,\n","           0.3666,  0.9740,  0.0206,  0.3751, -0.1906, -0.0149,  0.2276,\n","          -0.1120,  0.2272,  0.2680,  0.0632,  0.2179,  0.9969,  0.9550,\n","          -0.1952, -0.1177, -0.0458, -0.1727, -0.2851, -0.0605,  0.4244,\n","          -0.1858, -0.0790, -0.0148,  1.9164, -0.0610, -0.0523, -0.0450,\n","           1.1191,  0.1232,  1.2442,  0.9286, -0.0510,  0.4186,  0.0692,\n","          -0.0286, -0.1100,  0.0120, -0.0623, -0.0383,  0.4155,  0.0359,\n","           0.4415, -0.0888, -0.0813,  0.5011, -0.1869,  0.0357,  1.5522,\n","          -0.1511, -0.1071, -0.0404, -0.0021,  0.4934, -0.1180, -0.0260,\n","           0.1476, -0.4001,  0.0631, -0.2233, -0.1715, -0.2968,  0.5482,\n","          -0.2770,  0.2900,  1.7649,  0.5198,  0.2039, -0.0979,  0.8643,\n","           0.3092, -0.2138, -0.0123,  0.3981,  0.8008,  0.8972, -0.0632,\n","           0.3875,  0.0528,  0.6652, -0.1248, -0.0768,  0.4964, -0.0301,\n","           1.4712,  0.1098,  0.6611, -0.0260, -0.0185, -0.1572,  0.5201,\n","           1.2694, -0.0862, -0.1765, -0.0975,  1.0323, -0.0987, -0.1003,\n","          -0.1628,  0.6909, -0.2399, -0.0345, -0.1182,  0.0609,  0.6563,\n","           1.3359,  0.5535, -0.0535,  0.6260, -0.0732, -0.0902, -0.0624,\n","           0.6456,  0.0528, -0.1955, -0.1698, -0.0247, -0.1138, -0.0052,\n","           1.5242, -0.0878,  0.2992, -0.2155,  1.0760, -0.1222,  1.6512,\n","          -0.0907, -0.0956, -0.0698,  1.9884,  0.3114, -0.0512,  0.9575,\n","           0.0495,  0.0540,  0.2020,  0.1658, -0.0627,  0.2027, -0.1944,\n","          -0.0871, -0.1546,  1.2768, -0.2475,  0.5590,  1.3347,  0.3842,\n","          -0.1542,  0.5490, -0.1324, -0.0266, -0.1164, -0.0479, -0.0062,\n","          -0.2520,  0.1501,  0.3951, -0.0373, -0.1160,  0.4953, -0.1435,\n","           0.7051, -0.0651, -0.1415,  0.2818,  1.6788,  0.8235, -0.1163,\n","           0.9233,  0.5002, -0.2065, -0.1344, -0.1568,  0.9962, -0.0039,\n","          -0.0212,  1.6511,  0.0722,  1.1950]]], grad_fn=<LeakyReluBackward0>), tensor([[[-0.1176, -0.0222, -0.0435,  ...,  0.7105,  0.8569,  0.1630],\n","         [-0.1341, -0.0322, -0.0432,  ...,  0.7220,  0.8573,  0.1534],\n","         [-0.1329, -0.0290, -0.0491,  ...,  0.7105,  0.8584,  0.1678],\n","         ...,\n","         [-0.1386, -0.0162, -0.0509,  ...,  0.7137,  0.8603,  0.1753],\n","         [-0.1468, -0.0162, -0.0419,  ...,  0.7082,  0.8580,  0.1803],\n","         [-0.1481, -0.0209, -0.0425,  ...,  0.7303,  0.8472,  0.1798]]],\n","       grad_fn=<AddBackward0>)]\n","256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WgNwLchds0wE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614203125982,"user_tz":300,"elapsed":1169,"user":{"displayName":"Ethan Bonnardeaux","photoUrl":"","userId":"12692726343044625248"}},"outputId":"f670f82a-78ea-477a-da57-5a7b7d2b688c"},"source":["from keras.layers import *\r\n","from keras.models import *\r\n","import numpy as np\r\n","\r\n","class Lay(Layer):\r\n","    def init(self):\r\n","        super(Lay,self).__init__()\r\n","\r\n","    def build(self, inputShape):\r\n","        super(Lay,self).build(inputShape)\r\n","\r\n","    def call(self,x):\r\n","        return [x[0],x[-1]]\r\n","\r\n","    def compute_output_shape(self,inputShape):\r\n","        return [(None,1),(None,1)]\r\n","\r\n","\r\n","inp = Input((2,))\r\n","out = Lay()(inp)\r\n","print(type(out))\r\n","# out = Concatenate()(out)\r\n","out = Lay()(out)\r\n","\r\n","new = Lay(out)\r\n","# final = Concatenate()(new)\r\n","\r\n","model = Model(inp,out)\r\n","model.summary()\r\n","\r\n","data = [[1,2],[3,4],[5,6]]\r\n","print(model.predict(data))\r\n","\r\n","import keras\r\n","print(keras.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","Model: \"model_10\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_34 (InputLayer)           [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","lay_30 (Lay)                    [(2,), (2,)]         0           input_34[0][0]                   \n","__________________________________________________________________________________________________\n","lay_31 (Lay)                    [(2,), (2,)]         0           lay_30[0][0]                     \n","                                                                 lay_30[0][1]                     \n","==================================================================================================\n","Total params: 0\n","Trainable params: 0\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7704d5ed40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","[array([1., 2.], dtype=float32), array([5., 6.], dtype=float32)]\n","2.4.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kmRt8GXVyRea"},"source":[""],"execution_count":null,"outputs":[]}]}